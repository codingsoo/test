[
  {
    "id": "https://github.com/dzhng/deep-research/issues/26",
    "source": {
      "issue_number": 26
    },
    "initial_question": {
      "title": "[Locally Hosted] Timeout Issue with Local LLMs",
      "body": "### **Issue:** \n\nRunning deep-research using firecrawl API and LM studio endpoint using the deepseek-r1-distill-llama-8b model. Timeout happens at about 30 seconds. \n\n```Ran What is the current state of lunar regolith composition and its implications for future space exploration, found 5 contents\nError running query: What is the current state of lunar regolith composition and its implications for future space exploration:  \n\nDOMException [TimeoutError]: The operation was aborted due to timeout  \n    at node:internal/deps/undici/undici:12625:11  \n    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)  \n    at postToApi (/app/node_modules/@ai-sdk/provider-utils/src/post-to-api.ts:65:22)  \n    at OpenAIChatLanguageModel.doGenerate (/app/node_modules/@ai-sdk/openai/src/openai-chat-language-model.ts:367:50)  \n    at fn (/app/node_modules/ai/core/generate-object/generate-object.ts:489:32)  \n    at <anonymous> (/app/node_modules/ai/core/telemetry/record-span.ts:18:22)  \n    at _retryWithExponentialBackoff (/app/node_modules/ai/util/retry-with-exponential-backoff.ts:36:12)  \n    at fn (/app/node_modules/ai/core/generate-object/generate-object.ts:457:34)  \n    at <anonymous> (/app/node_modules/ai/core/telemetry/record-span.ts:18:22)  \n    at processSerpResult (/app/src/deep-research.ts:86:15)\n```\nLM Studio log\n```\n2025-02-08 13:55:46 [DEBUG] PromptProcessing: 22.7597\n2025-02-08 13:55:50 [DEBUG] PromptProcessing: 23.7942\n2025-02-08 13:55:52  [INFO] [LM STUDIO SERVER] Client disconnected. Stopping generation... (If the model is busy processing the prompt, it will finish first.)\n```\n### **Steps Taken to Fix:**\nI'm not a TS dev so I did what I could. I removed the timeouts and abort signal code in deep-research.ts, but that did nothing. Extended timeouts and abort signals, also nothing.  \n\n### **Potential Reason:**\n\nIt obviously is expecting an openai response which is much faster than a local LLM can provide. I assume the fetch in postToApi has a default timeout also, which is why removing timeouts in deep-research.ts didn't work. \n\nUnfortunately, I don't have the skills/expertise in this area to troubleshoot further. I already spent 125 credits trying. "
    },
    "satisfaction_conditions": [
      "Local LLM requests must complete without timing out",
      "Client connection must remain active until LLM response is complete",
      "Changes must persist after application restart",
      "System must handle slower response times from local LLMs compared to cloud APIs"
    ],
    "created_at": "2025-02-08T05:02:32Z"
  },
  {
    "id": "https://github.com/dzhng/deep-research/issues/6",
    "source": {
      "issue_number": 6
    },
    "initial_question": {
      "title": "Not starting",
      "body": "Hi, I get \n`> open-deep-research@0.0.1 start\n> tsx --env-file=.env.local src/run.ts` on start and it exits (on Windows)"
    },
    "satisfaction_conditions": [
      "Application successfully starts and runs without premature exit",
      "Environment variables are properly loaded",
      "Runtime environment compatibility is achieved"
    ],
    "created_at": "2025-02-06T12:41:06Z"
  }
]