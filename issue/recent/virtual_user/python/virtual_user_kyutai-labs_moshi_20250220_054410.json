[
  {
    "id": "https://github.com/kyutai-labs/moshi/issues/175",
    "source": {
      "issue_number": 175
    },
    "initial_question": {
      "title": "Semantic token inference for user stream",
      "body": "### Due diligence\n\n- [X] I have done my due diligence in trying to find the answer myself.\n\n### Topic\n\nThe PyTorch implementation\n\n### Question\n\n(My question is about the behavior of depformer in the training phase) I found that the semantic token inference for **moshi** stream is based on depformer's text emb and transformer_out \r\n\r\n```python\r\n        depformer_input = transformer_out\r\n        if self.depformer_multi_linear:\r\n            depformer_input = self.depformer_in[depformer_cb_index](depformer_input)  # depformer_in: cb_index \ubcc4\ub85c trasnforme_out encoding\r\n        else:\r\n            depformer_input = self.depformer_in[0](depformer_input)\r\n        if depformer_cb_index == 0:\r\n            last_token_input = self.depformer_text_emb(sequence[:, 0])\r\n        else:\r\n            last_token_input = self.depformer_emb[depformer_cb_index - 1](\r\n                sequence[:, 0]\r\n            )\r\n        depformer_input = depformer_input + last_token_input\r\n        assert depformer_input.shape[1] == 1\r\n        # depformer_input is [B, 1, depformer_dim].\r\n        # The streaming state of the depformer ensures that the proper layer is run.\r\n        dep_output = self.depformer(depformer_input)\r\n``` \r\n\r\nHowever, for the user stream, there is **no text_emb** so how can do the inference for semantic token? At the first time I see the paper, the author wrote that they simply concat the text, moshi and user stream along the codebook dimension so I guess the semantice token inference for user stream can be done with last acoustic token for moshi stream; however, in the code, there is no depformer_in for the last acoustic token with the comment \"# Only using up to dep_q - 1 because the last codebook is never an input to Depformer.\" ; so my guess is incorrect.\r\n\r\nCould you let me know how the user stream's semantic token inference can be done? did you insert some zero values between user and moshi stream? or use user's text stream only for the training phase?"
    },
    "satisfaction_conditions": [
      "The semantic token inference system must handle both moshi and user streams during training",
      "The system must maintain proper sequential dependencies between text, moshi, and user tokens",
      "Training and inference architectures must be able to differ while maintaining functional equivalence",
      "The system must maintain causal attention mechanisms across all processing stages"
    ],
    "created_at": "2024-12-26T01:50:39Z"
  },
  {
    "id": "https://github.com/kyutai-labs/moshi/issues/123",
    "source": {
      "issue_number": 123
    },
    "initial_question": {
      "title": "Which token ID is used to represent the empty token in the delay pattern?",
      "body": "### Due diligence\n\n- [X] I have done my due diligence in trying to find the answer myself.\n\n### Topic\n\nThe paper\n\n### Question\n\nHi, I want to ask which token ID is used to represent the empty token in the delay pattern? In your Figure 4, I see you use token 0 denotes the empty token. I want to confirm that whether 0 is used as the empty token during training? This token will be considered when calculating the loss?"
    },
    "satisfaction_conditions": [
      "The empty token ID must be consistently defined for delay pattern implementation",
      "The empty token must be distinct from padding tokens used for text sequences",
      "The empty token implementation must maintain compatibility with pre-trained checkpoints"
    ],
    "created_at": "2024-09-29T08:44:19Z"
  }
]