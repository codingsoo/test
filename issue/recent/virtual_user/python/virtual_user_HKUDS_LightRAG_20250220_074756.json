[
  {
    "id": "https://github.com/HKUDS/LightRAG/issues/855",
    "source": {
      "issue_number": 855
    },
    "initial_question": {
      "title": "Run examples/lightrag_zhipu_postgres_demo.py failed:  RuntimeWarning: coroutine 'LightRAG.initialize_storages' was never awaited",
      "body": "```\n  File \"/Users/sunny/.local/share/uv/python/cpython-3.13.1-macos-x86_64-none/lib/python3.13/asyncio/runners.py\", line 194, in run\n    return runner.run(main)\n           ~~~~~~~~~~^^^^^^\n  File \"/Users/sunny/.local/share/uv/python/cpython-3.13.1-macos-x86_64-none/lib/python3.13/asyncio/runners.py\", line 118, in run\n    return self._loop.run_until_complete(task)\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n  File \"/Users/sunny/.local/share/uv/python/cpython-3.13.1-macos-x86_64-none/lib/python3.13/asyncio/base_events.py\", line 720, in run_until_complete\n    return future.result()\n           ~~~~~~~~~~~~~^^\n  File \"/private/var/www/LightRAG/hello2.py\", line 32, in main\n    rag = LightRAG(\n        working_dir=WORKING_DIR,\n    ...<15 lines>...\n        vector_storage=\"PGVectorStorage\",\n    )\n  File \"<string>\", line 34, in __init__\n  File \"/private/var/www/LightRAG/lightrag/lightrag.py\", line 563, in __post_init__\n    loop.run_until_complete(self.initialize_storages())\n    ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/sunny/.local/share/uv/python/cpython-3.13.1-macos-x86_64-none/lib/python3.13/asyncio/base_events.py\", line 696, in run_until_complete\n    self._check_running()\n    ~~~~~~~~~~~~~~~~~~~^^\n  File \"/Users/sunny/.local/share/uv/python/cpython-3.13.1-macos-x86_64-none/lib/python3.13/asyncio/base_events.py\", line 632, in _check_running\n    raise RuntimeError('This event loop is already running')\nRuntimeError: This event loop is already running\nINFO:Creating a new event loop in main thread.\n<sys>:0: RuntimeWarning: coroutine 'LightRAG.initialize_storages' was never awaited\n```"
    },
    "satisfaction_conditions": [
      "Asynchronous event loop conflicts must be resolved",
      "The application must be able to run in environments with existing event loops"
    ],
    "created_at": "2025-02-19T08:49:00Z"
  },
  {
    "id": "https://github.com/HKUDS/LightRAG/pull/715",
    "source": {
      "issue_number": 715
    },
    "initial_question": {
      "title": "Fix: AttributeError in NanoVectorDB Initialization",
      "body": "Issue\r\nThe following error occurred during the initialization of NanoVectorDB in nano_vector_db_impl.py:\r\n\r\nFile \".../LightRAG/LightRAG/lightrag/kg/nano_vector_db_impl.py\", line 92, in __post_init__\r\n    self.embedding_func.embedding_dim, storage_file=self._client_file_name\r\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nAttributeError: 'function' object has no attribute 'embedding_dim'\r\n\r\nRoot Cause\r\nThe embedding_func variable was declared locally instead of being assigned to self.embedding_func.\r\nAs a result, self.embedding_func was referring to a function instead of an instance of EmbeddingFunc, causing the AttributeError.\r\n\r\nChanges Made\r\n1. Explicitly Initialized self.embedding_func in __post_init__ and query using:\r\n\r\nself.embedding_func = EmbeddingFunc(\r\n    embedding_dim=4096, max_token_size=8192, func=gpt_4o_mini_complete\r\n)\r\n\r\n2. Imported EmbeddingFunc and gpt_4o_mini_complete to avoid reference errors.\r\n\r\n\r\n\r\n"
    },
    "satisfaction_conditions": [
      "The embedding function must be passed through LightRAG's initialization rather than created within NanoVectorDB",
      "The embedding function instance must expose an embedding_dim attribute",
      "The embedding function configuration must respect the parent application's user preferences"
    ],
    "created_at": "2025-02-05T08:12:34Z"
  },
  {
    "id": "https://github.com/HKUDS/LightRAG/issues/662",
    "source": {
      "issue_number": 662
    },
    "initial_question": {
      "title": "AttributeError: 'function' object has no attribute 'embedding_dim' in \"lightrag_openai_demo.py\" (PLEASE EXPLAIN THE FIX)",
      "body": "Hi\n\nI am getting the following error in the lightrag_openai_demo.py. Can someone please help me fix it?\n\nTraceback (most recent call last):\n  File \"C:\\Users\\arpit\\LLM Projects\\RAG\\Tutorial - GraphRAG\\LightRAG\\examples\\lightrag_openai_demo.py\", line 11, in <module>\n    rag = LightRAG(\n          ^^^^^^^^^\n  File \"<string>\", line 32, in __init__\n  File \"C:\\Users\\arpit\\LLM Projects\\RAG\\Tutorial - GraphRAG\\LightRAG\\lightrag\\lightrag.py\", line 254, in __post_init__\n    self.entities_vdb = self.vector_db_storage_cls(\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\arpit\\LLM Projects\\RAG\\Tutorial - GraphRAG\\LightRAG\\lightrag\\lightrag.py\", line 80, in import_class\n    return cls(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"<string>\", line 8, in __init__\n  File \"C:\\Users\\arpit\\LLM Projects\\RAG\\Tutorial - GraphRAG\\LightRAG\\lightrag\\kg\\nano_vector_db_impl.py\", line 84, in __post_init__\n    self.embedding_func.embedding_dim, storage_file=self._client_file_name\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAttributeError: 'function' object has no attribute 'embedding_dim'"
    },
    "satisfaction_conditions": [
      "Embedding function must have a defined embedding dimension",
      "Embedding function configuration must be properly structured",
      "Working directory must be accessible for storage operations"
    ],
    "created_at": "2025-01-27T22:04:01Z"
  },
  {
    "id": "https://github.com/HKUDS/LightRAG/issues/562",
    "source": {
      "issue_number": 562
    },
    "initial_question": {
      "title": "Error running Postgres Demo - SyntaxError",
      "body": "Error running DEMO . I'm using Python 3.11. \r\n\r\n/home/asksuite/asksuite-dev/test-lightrag/venv311/bin/python /home/asksuite/asksuite-dev/test-lightrag/lightrag_openai_demo_costao_postgres.py \r\nTraceback (most recent call last):\r\n  File \"/home/asksuite/asksuite-dev/test-lightrag/lightrag_openai_demo_costao_postgres.py\", line 5, in <module>\r\n    from lightrag.kg.postgres_impl import PostgreSQLDB\r\n  File \"/home/asksuite/asksuite-dev/test-lightrag/venv311/lib/python3.11/site-packages/lightrag/kg/postgres_impl.py\", line 406\r\n    sql = f\"SELECT id FROM LIGHTRAG_DOC_STATUS WHERE workspace=$1 AND id IN ({\",\".join([f\"'{_id}'\" for _id in data])})\"\r\n                                                                               ^\r\nSyntaxError: f-string: expecting '}'"
    },
    "satisfaction_conditions": [
      "The f-string syntax must be valid Python code",
      "The SQL query string must be properly constructed",
      "The query must preserve the original functionality",
      "The solution must handle string concatenation within the query"
    ],
    "created_at": "2025-01-09T17:05:10Z"
  },
  {
    "id": "https://github.com/HKUDS/LightRAG/issues/249",
    "source": {
      "issue_number": 249
    },
    "initial_question": {
      "title": "RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper_CUDA__index_select)",
      "body": "I am using a huggingface demo, but with a local model.How to deal with it?please help me , thank you very much!!\r\n**code**:\r\nimport os\r\n\r\nfrom lightrag import LightRAG, QueryParam\r\nfrom lightrag.llm import hf_model_complete, hf_embedding\r\nfrom lightrag.utils import EmbeddingFunc\r\nfrom transformers import AutoModel, AutoTokenizer\r\n\r\nWORKING_DIR = \"./dickens\"\r\n\r\nif not os.path.exists(WORKING_DIR):\r\n    os.mkdir(WORKING_DIR)\r\n\r\nrag = LightRAG(\r\n    working_dir=WORKING_DIR,\r\n    llm_model_func=hf_model_complete,\r\n    llm_model_name=\"/data/Qwen2.5-14B-Instruct\",\r\n    embedding_func=EmbeddingFunc(\r\n        embedding_dim=1024,\r\n        max_token_size=5000,\r\n        func=lambda texts: hf_embedding(\r\n            texts,\r\n            tokenizer=AutoTokenizer.from_pretrained(\r\n                r\"/data/project/raag/bge-large-zh-v1.5/\", model_max_length=512\r\n            ),\r\n            embed_model=AutoModel.from_pretrained(\r\n                r\"/data/project/raag/bge-large-zh-v1.5/\"\r\n            ),\r\n        ),\r\n    ),\r\n)\r\n\r\nwith open(r\"/data/project/raag/caiwu.txt\", \"r\", encoding=\"utf-8\") as f:\r\n    rag.insert(f.read())\r\n\r\n# Perform naive search\r\nprint(\r\n    rag.query(\"What are the top themes in this story?\", param=QueryParam(mode=\"naive\"))\r\n)\r\n\r\n# Perform local search\r\nprint(\r\n    rag.query(\"What are the top themes in this story?\", param=QueryParam(mode=\"local\"))\r\n)\r\n\r\n# Perform global search\r\nprint(\r\n    rag.query(\"What are the top themes in this story?\", param=QueryParam(mode=\"global\"))\r\n)\r\n\r\n# Perform hybrid search\r\nprint(\r\n    rag.query(\"What are the top themes in this story?\", param=QueryParam(mode=\"hybrid\"))\r\n)\r\nerror:\r\nroot@c15e0721d1a6:~# CUDA_VISIBLE_DEVICES=0  python /data/project/raag/light_rag.py\r\nINFO:lightrag:Logger initialized for working directory: /data/project/raag/dickens\r\nDEBUG:lightrag:LightRAG init with param:\r\n  working_dir = /data/project/raag/dickens,\r\n  chunk_token_size = 1200,\r\n  chunk_overlap_token_size = 100,\r\n  tiktoken_model_name = gpt-4o-mini,\r\n  entity_extract_max_gleaning = 1,\r\n  entity_summary_to_max_tokens = 500,\r\n  node_embedding_algorithm = node2vec,\r\n  node2vec_params = {'dimensions': 1536, 'num_walks': 10, 'walk_length': 40, 'window_size': 2, 'iterations': 3, 'random_seed': 3},\r\n  embedding_func = {'embedding_dim': 1024, 'max_token_size': 5000, 'func': <function <lambda> at 0x7f5eaa0bfd90>},\r\n  embedding_batch_num = 32,\r\n  embedding_func_max_async = 16,\r\n  llm_model_func = <function hf_model_complete at 0x7f5dc1cd6b00>,\r\n  llm_model_name = /data/Qwen2.5-14B-Instruct,\r\n  llm_model_max_token_size = 32768,\r\n  llm_model_max_async = 16,\r\n  key_string_value_json_storage_cls = <class 'lightrag.storage.JsonKVStorage'>,\r\n  vector_db_storage_cls = <class 'lightrag.storage.NanoVectorDBStorage'>,\r\n  vector_db_storage_cls_kwargs = {},\r\n  graph_storage_cls = <class 'lightrag.storage.NetworkXStorage'>,\r\n  enable_llm_cache = True,\r\n  addon_params = {},\r\n  convert_response_to_json_func = <function convert_response_to_json at 0x7f5dc1cbfeb0>\r\n\r\nINFO:lightrag:Load KV full_docs with 0 data\r\nINFO:lightrag:Load KV text_chunks with 0 data\r\nINFO:lightrag:Load KV llm_response_cache with 0 data\r\nINFO:lightrag:Loaded graph from /data/project/raag/dickens/graph_chunk_entity_relation.graphml with 0 nodes, 0 edges\r\nINFO:nano-vectordb:Load (0, 1024) data\r\nINFO:nano-vectordb:Init {'embedding_dim': 1024, 'metric': 'cosine', 'storage_file': '/data/project/raag/dickens/vdb_entities.json'} 0 data\r\nINFO:nano-vectordb:Load (0, 1024) data\r\nINFO:nano-vectordb:Init {'embedding_dim': 1024, 'metric': 'cosine', 'storage_file': '/data/project/raag/dickens/vdb_relationships.json'} 0 data\r\nINFO:nano-vectordb:Load (2, 1024) data\r\nINFO:nano-vectordb:Init {'embedding_dim': 1024, 'metric': 'cosine', 'storage_file': '/data/project/raag/dickens/vdb_chunks.json'} 2 data\r\nINFO:lightrag:Creating a new event loop in a sub-thread.\r\nINFO:lightrag:[New Docs] inserting 1 docs\r\nINFO:lightrag:[New Chunks] inserting 2 chunks\r\nINFO:lightrag:Inserting 2 vectors to chunks\r\nINFO:lightrag:[Entity Extraction]...\r\nINFO:accelerate.utils.modeling:We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\r\n/usr/local/lib/python3.10/site-packages/accelerate/utils/modeling.py:1390: UserWarning: Current model requires 12544 bytes of buffer for offloaded layers, which seems does not fit any GPU's remaining memory. If you are experiencing a OOM later, please consider using offload_buffers=True.\r\n  warnings.warn(\r\nLoading checkpoint shards: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 8/8 [00:07<00:00,  1.00it/s]\r\n/usr/local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:638: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\r\n  warnings.warn(\r\n/usr/local/lib/python3.10/site-packages/transformers/generation/utils.py:2097: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cuda, whereas the model is on cpu. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cpu') before running `.generate()`.\r\n  warnings.warn(\r\n/usr/local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:638: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\r\n  warnings.warn(\r\nINFO:lightrag:Writing graph with 0 nodes, 0 edges\r\nTraceback (most recent call last):\r\n  File \"/data/project/raag/light_rag.py\", line 33, in <module>\r\n    rag.insert(f.read())\r\n  File \"/usr/local/lib/python3.10/site-packages/lightrag/lightrag.py\", line 164, in insert\r\n    return loop.run_until_complete(self.ainsert(string_or_strings))\r\n  File \"/usr/local/lib/python3.10/asyncio/base_events.py\", line 649, in run_until_complete\r\n    return future.result()\r\n  File \"/usr/local/lib/python3.10/site-packages/lightrag/lightrag.py\", line 211, in ainsert\r\n    maybe_new_kg = await extract_entities(\r\n  File \"/usr/local/lib/python3.10/site-packages/lightrag/operate.py\", line 331, in extract_entities\r\n    results = await asyncio.gather(\r\n  File \"/usr/local/lib/python3.10/site-packages/lightrag/operate.py\", line 270, in _process_single_content\r\n    final_result = await use_llm_func(hint_prompt)\r\n  File \"/usr/local/lib/python3.10/site-packages/lightrag/utils.py\", line 87, in wait_func\r\n    result = await func(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.10/site-packages/lightrag/llm.py\", line 377, in hf_model_complete\r\n    return await hf_model_if_cache(\r\n  File \"/usr/local/lib/python3.10/site-packages/lightrag/llm.py\", line 286, in hf_model_if_cache\r\n    output = hf_model.generate(\r\n  File \"/usr/local/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.10/site-packages/transformers/generation/utils.py\", line 2215, in generate\r\n    result = self._sample(\r\n  File \"/usr/local/lib/python3.10/site-packages/transformers/generation/utils.py\", line 3206, in _sample\r\n    outputs = self(**model_inputs, return_dict=True)\r\n  File \"/usr/local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\r\n    return self._call_impl(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py\", line 1164, in forward\r\n    outputs = self.model(\r\n  File \"/usr/local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\r\n    return self._call_impl(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py\", line 854, in forward\r\n    inputs_embeds = self.embed_tokens(input_ids)\r\n  File \"/usr/local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\r\n    return self._call_impl(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.10/site-packages/torch/nn/modules/sparse.py\", line 190, in forward\r\n    return F.embedding(\r\n  File \"/usr/local/lib/python3.10/site-packages/torch/nn/functional.py\", line 2551, in embedding\r\n    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)\r\nRuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper_CUDA__index_select)\r\n"
    },
    "satisfaction_conditions": [
      "All model tensors must operate on the same device",
      "Model and input data device allocation must be explicitly managed"
    ],
    "created_at": "2024-11-11T08:49:13Z"
  },
  {
    "id": "https://github.com/HKUDS/LightRAG/issues/105",
    "source": {
      "issue_number": 105
    },
    "initial_question": {
      "title": "AttributeError: module 'ollama' has no attribute 'embeddings'",
      "body": "I'm running the following adaptation to the ollama example:\r\n\r\n```\r\nimport os\r\n\r\nfrom lightrag import LightRAG, QueryParam\r\nfrom lightrag.llm import ollama_model_complete, ollama_embedding\r\nfrom lightrag.utils import EmbeddingFunc\r\n\r\nWORKING_DIR = \"light_rag/dickens\"\r\nMODEL_NAME = \"llama3.2:3b\"\r\n\r\nif not os.path.exists(WORKING_DIR):\r\n    os.mkdir(WORKING_DIR)\r\n\r\nrag = LightRAG(\r\n    working_dir=WORKING_DIR,\r\n    llm_model_func=ollama_model_complete,\r\n    llm_model_name=MODEL_NAME,\r\n    embedding_func=EmbeddingFunc(\r\n        embedding_dim=768,\r\n        max_token_size=8192,\r\n        func=lambda texts: ollama_embedding(texts, embed_model=\"nomic-embed-text\"),\r\n    ),\r\n)\r\n\r\n\r\nwith open(\"light_rag/dickens/book.txt\") as f:\r\n    rag.insert(f.read())\r\n\r\n# Perform naive search\r\nprint(\r\n    rag.query(\"What are the top themes in this story?\", param=QueryParam(mode=\"naive\"))\r\n)\r\n\r\n# Perform local search\r\nprint(\r\n    rag.query(\"What are the top themes in this story?\", param=QueryParam(mode=\"local\"))\r\n)\r\n\r\n# Perform global search\r\nprint(\r\n    rag.query(\"What are the top themes in this story?\", param=QueryParam(mode=\"global\"))\r\n)\r\n\r\n# Perform hybrid search\r\nprint(\r\n    rag.query(\"What are the top themes in this story?\", param=QueryParam(mode=\"hybrid\"))\r\n)\r\n```\r\n\r\nUnfortunately, I'm getting the following error:\r\n\r\n```\r\nINFO:lightrag:Logger initialized for working directory: light_rag/dickens\r\nDEBUG:lightrag:LightRAG init with param:\r\n  working_dir = light_rag/dickens,\r\n  chunk_token_size = 1200,\r\n  chunk_overlap_token_size = 100,\r\n  tiktoken_model_name = gpt-4o-mini,\r\n  entity_extract_max_gleaning = 1,\r\n  entity_summary_to_max_tokens = 500,\r\n  node_embedding_algorithm = node2vec,\r\n  node2vec_params = {'dimensions': 1536, 'num_walks': 10, 'walk_length': 40, 'window_size': 2, 'iterations': 3, 'random_seed': 3},\r\n  embedding_func = {'embedding_dim': 768, 'max_token_size': 8192, 'func': <function <lambda> at 0x1268d1440>},\r\n  embedding_batch_num = 32,\r\n  embedding_func_max_async = 16,\r\n  llm_model_func = <function ollama_model_complete at 0x142289800>,\r\n  llm_model_name = llama3.2:3b,\r\n  llm_model_max_token_size = 32768,\r\n  llm_model_max_async = 16,\r\n  key_string_value_json_storage_cls = <class 'lightrag.storage.JsonKVStorage'>,\r\n  vector_db_storage_cls = <class 'lightrag.storage.NanoVectorDBStorage'>,\r\n  vector_db_storage_cls_kwargs = {},\r\n  graph_storage_cls = <class 'lightrag.storage.NetworkXStorage'>,\r\n  enable_llm_cache = True,\r\n  addon_params = {},\r\n  convert_response_to_json_func = <function convert_response_to_json at 0x141af6980>\r\nINFO:lightrag:Load KV full_docs with 0 data\r\nINFO:lightrag:Load KV text_chunks with 0 data\r\nINFO:lightrag:Load KV llm_response_cache with 0 data\r\nINFO:nano-vectordb:Init {'embedding_dim': 768, 'metric': 'cosine', 'storage_file': 'light_rag/dickens/vdb_entities.json'} 0 data\r\nINFO:nano-vectordb:Init {'embedding_dim': 768, 'metric': 'cosine', 'storage_file': 'light_rag/dickens/vdb_relationships.json'} 0 data\r\nINFO:nano-vectordb:Init {'embedding_dim': 768, 'metric': 'cosine', 'storage_file': 'light_rag/dickens/vdb_chunks.json'} 0 data\r\nINFO:lightrag:Creating a new event loop in a sub-thread.\r\nINFO:lightrag:[New Docs] inserting 1 docs\r\nINFO:lightrag:[New Chunks] inserting 42 chunks\r\nINFO:lightrag:Inserting 42 vectors to chunks\r\nINFO:lightrag:Writing graph with 0 nodes, 0 edges\r\nTraceback (most recent call last):\r\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\r\n  File \"<frozen runpy>\", line 88, in _run_code\r\n  File \"light_rag/src/example.py\", line 26, in <module>\r\n    rag.insert(f.read())\r\n  File \"site-packages/lightrag/lightrag.py\", line 162, in insert\r\n    return loop.run_until_complete(self.ainsert(string_or_strings))\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py\", line 653, in run_until_complete\r\n    return future.result()\r\n           ^^^^^^^^^^^^^^^\r\n  File \"site-packages/lightrag/lightrag.py\", line 206, in ainsert\r\n    await self.chunks_vdb.upsert(inserting_chunks)\r\n  File \"site-packages/lightrag/storage.py\", line 92, in upsert\r\n    embeddings_list = await asyncio.gather(\r\n                      ^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/site-packages/lightrag/utils.py\", line 87, in wait_func\r\n    result = await func(*args, **kwargs)\r\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"site-packages/lightrag/utils.py\", line 43, in __call__\r\n    return await self.func(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"site-packages/lightrag/llm.py\", line 421, in ollama_embedding\r\n    data = ollama.embeddings(model=embed_model, prompt=text)\r\n           ^^^^^^^^^^^^^^^^^\r\nAttributeError: module 'ollama' has no attribute 'embeddings'\r\n```"
    },
    "satisfaction_conditions": [
      "The Python environment must properly resolve the 'embeddings' attribute for the ollama module",
      "The environment's package dependencies must be in a consistent state"
    ],
    "created_at": "2024-10-22T23:18:40Z"
  },
  {
    "id": "https://github.com/HKUDS/LightRAG/issues/60",
    "source": {
      "issue_number": 60
    },
    "initial_question": {
      "title": "Embeddings with ndim != 4096",
      "body": "I'm having trouble running this with embedding funcs with `ndim != 4096`.\r\n\r\nSo tying this with \r\n\r\n```python3\r\nrag = LightRAG(\r\n    working_dir=WORKING_DIR,\r\n    llm_model_func=llm_model_func,\r\n    embedding_func=EmbeddingFunc(\r\n        embedding_dim=768, max_token_size=8192, func=embedding_func\r\n    ),\r\n)\r\n```\r\n\r\nI keep getting\r\n\r\n```\r\nvenv/lib/python3.12/site-packages/nano_vectordb/dbs.py\", line 71, in __post_init__\r\n    storage[\"embedding_dim\"] == self.embedding_dim\r\nAssertionError: Embedding dim mismatch, expected: 768, but loaded: 4096\r\n```\r\n\r\nIs this `4096` somehow a magic number?"
    },
    "satisfaction_conditions": [
      "The EmbeddingFunc configuration must reflect the actual dimensions of the embedding model being used"
    ],
    "created_at": "2024-10-19T16:28:08Z"
  },
  {
    "id": "https://github.com/HKUDS/LightRAG/issues/51",
    "source": {
      "issue_number": 51
    },
    "initial_question": {
      "title": "Can't run any example",
      "body": "I'm not able to run the example.\r\n\r\nI've tried this with python 3.9, 3.10, and 3.11. The initial bit of the examples work up until I run\r\n```python\r\nwith open(\"./book.txt\") as f:\r\n    rag.insert(f.read())\r\n\r\n```\r\n\r\nWhen `rag.insert(f.read())`, is run the following error appears every time:\r\n\r\n```logs\r\nRuntimeError                              Traceback (most recent call last)\r\nCell In[9], line 1\r\n----> 1 rag.insert(our_docs)\r\n\r\nFile /home/jupyter/projects/LightRAG/lightrag/lightrag.py:166, in LightRAG.insert(self, string_or_strings)\r\n    164 def insert(self, string_or_strings):\r\n    165     loop = always_get_an_event_loop()\r\n--> 166     return loop.run_until_complete(self.ainsert(string_or_strings))\r\n\r\nFile /opt/conda/envs/lightrag/lib/python3.11/asyncio/base_events.py:626, in BaseEventLoop.run_until_complete(self, future)\r\n    615 \"\"\"Run until the Future is done.\r\n    616 \r\n    617 If the argument is a coroutine, it is wrapped in a Task.\r\n   (...)\r\n    623 Return the Future's result, or raise its exception.\r\n    624 \"\"\"\r\n    625 self._check_closed()\r\n--> 626 self._check_running()\r\n    628 new_task = not futures.isfuture(future)\r\n    629 future = tasks.ensure_future(future, loop=self)\r\n\r\nFile /opt/conda/envs/lightrag/lib/python3.11/asyncio/base_events.py:586, in BaseEventLoop._check_running(self)\r\n    584 def _check_running(self):\r\n    585     if self.is_running():\r\n--> 586         raise RuntimeError('This event loop is already running')\r\n    587     if events._get_running_loop() is not None:\r\n    588         raise RuntimeError(\r\n    589             'Cannot run the event loop while another loop is running')\r\n\r\nRuntimeError: This event loop is already running\r\n```\r\n"
    },
    "satisfaction_conditions": [
      "Event loop conflicts must be resolved",
      "File content must be successfully inserted into the RAG system",
      "Solution must be compatible with Jupyter notebook environment",
      "Async operations must complete successfully"
    ],
    "created_at": "2024-10-18T19:25:37Z"
  }
]