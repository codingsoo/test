[
  {
    "number": 799,
    "title": "[Bug][Neo4j] get_edge() returns incorrect edge properties due to schema mismatch",
    "created_at": "2025-02-16T19:21:04Z",
    "closed_at": "2025-02-17T17:36:17Z",
    "labels": [],
    "url": "https://github.com/HKUDS/LightRAG/issues/799",
    "body": "## Description\nWhen using Neo4j as `LIGHTRAG_GRAPH_STORAGE` ~with a non-empty `NAMESPACE_PREFIX`~, the web UI query fails because the edge data is missing the required 'description' field. This issue doesn't occur when:\n- ~`NAMESPACE_PREFIX` is empty, or~ (I can't reproduce this today; maybe I made a mistake yesterday.) \n- Using MongoDB as `LIGHTRAG_GRAPH_STORAGE`\n\n## Error Message\n```\n[ERROR][2025-02-16 19:07:40] Traceback (most recent call last):\n  File \"/app/lightrag/api/lightrag_server.py\", line 1299, in query_text\n    response = await rag.aquery(\n  File \"/app/lightrag/lightrag.py\", line 1022, in aquery\n    response = await kg_query(\n  File \"/app/lightrag/operate.py\", line 659, in kg_query\n    context = await _build_query_context(\n  File \"/app/lightrag/operate.py\", line 1038, in _build_query_context\n    ll_data, hl_data = await asyncio.gather(\n  File \"/app/lightrag/operate.py\", line 1355, in _get_edge_data\n    edge_datas = truncate_list_by_token_size(\n  File \"/app/lightrag/utils.py\", line 228, in truncate_list_by_token_size\n    tokens += len(encode_string_by_tiktoken(key(data)))\n  File \"/app/lightrag/operate.py\", line 1357, in <lambda>\n    key=lambda x: x[\"description\"],\nKeyError: 'description'\n```\n\n## Debug Information\nThe edge data object `x` contains the following in this case:\n```python\n{\n    'src_id': '\"XXXXXX\"', 'tgt_id': '\"XXXXXXX\"', 'rank': 11, 'created_at': None, 'weight': 0.0, 'source_id': None, 'target_id': None\n}\n```\n\n## Environment\n- Storage: Neo4j\n\n## Expected Behavior\nData should include a 'description' field when retrieved from Neo4j.  I also believe that these keys\n```\n'created_at': None, 'weight': 0.0, 'source_id': None, 'target_id': None\n```\nshould contain non-trivial data.\n\n## Current Behavior\nData is missing the 'description' field, causing the query to fail.\n\nPS: Additionally, I'd like to understand if there are any differences in retrieval results when using MongoDB versus Neo4j as the graph storage backend, thanks.",
    "comments_url": "https://api.github.com/repos/HKUDS/LightRAG/issues/799/comments",
    "author": "atYuguo",
    "comments": [
      {
        "user": "atYuguo",
        "created_at": "2025-02-17T14:05:45Z",
        "body": "After investigating the code, I found the issue is related to a mismatch between the `edge_property` formats in different parts of the codebase.\n\n1. In the following part of `neo4j_impl.py`\n```python\n@@ -278,14 +278,16 @@ class Neo4JStorage(BaseGraphStorage):\n\n                result = await session.run(query)\n                record = await result.single()\n                if record and \"edge_properties\" in record:\n                    try:\n                        result = dict(record[\"edge_properties\"])\n\n                        # Ensure required keys exist with defaults\n                        required_keys = {\n                            \"weight\": 0.0,\n                            \"source_id\": None,\n                            \"target_id\": None,\n\n                        }\n                        for key, default_value in required_keys.items():\n                            if key not in result:\n@@ -305,20 +307,20 @@ class Neo4JStorage(BaseGraphStorage):\n                            f\"and {entity_name_label_target}: {str(e)}\"\n                        )\n                        # Return default edge properties on error\n                        return {\"weight\": 0.0, \"source_id\": None, \"target_id\": None}\n\n                logger.debug(\n                    f\"{inspect.currentframe().f_code.co_name}: No edge found between {entity_name_label_source} and {entity_name_label_target}\"\n                )\n                # Return default edge properties when no edge found\n                return {\"weight\": 0.0, \"source_id\": None, \"target_id\": None}\n\n        except Exception as e:\n            logger.error(\n                f\"Error in get_edge between {source_node_id} and {target_node_id}: {str(e)}\"\n            )\n            # Return default edge properties on error\n            return {\"weight\": 0.0, \"source_id\": None, \"target_id\": None}\n\n    async def get_node_edges(self, source_node_id: str) -> list[tuple[str, str]] | None:\n        node_label = source_node_id.strip('\"')\n```\n, there are two issues:\n   - The condition `if record and \"edge_properties\" in record` never evaluates to true\n   - The default edge properties do not match the expected format\n\n2. Current Edge Property Format:\n   ```python\n   # In neo4j_impl.py\n   # Default edge properties\n   {\n       \"weight\": 0.0,\n       \"source_id\": None,\n       \"target_id\": None  # Note this field\n   }\n   ```\nalso\n   ```python\n   return {\"weight\": 0.0, \"source_id\": None, \"target_id\": None}\n   ```\n\n3. Expected Edge Property Format (from `operate.py`):\n   ```python\n   # In operate.py\n   edge_data = {\n       \"weight\": weight,\n       \"description\": description,  # Required field that's missing\n       \"keywords\": keywords,\n       \"source_id\": source_id\n       # No 'target_id' field\n   }\n   ```\n\n## Suggested Fix\n```python\n@@ -278,14 +278,16 @@ class Neo4JStorage(BaseGraphStorage):\n\n                result = await session.run(query)\n                record = await result.single()\n                if record:\n                    try:\n                        result = dict(record[\"edge_properties\"])\n                        logger.info(f\"Result: {result}\")\n                        # Ensure required keys exist with defaults\n                        required_keys = {\n                            \"weight\": 0.0,\n                            \"source_id\": None,\n                            \"description\": None,\n                            \"keywords\": None,\n                        }\n                        for key, default_value in required_keys.items():\n                            if key not in result:\n@@ -305,20 +307,20 @@ class Neo4JStorage(BaseGraphStorage):\n                            f\"and {entity_name_label_target}: {str(e)}\"\n                        )\n                        # Return default edge properties on error\n                        return {\"weight\": 0.0, \"description\": None, \"keywords\": None, \"source_id\": None}\n\n                logger.debug(\n                    f\"{inspect.currentframe().f_code.co_name}: No edge found between {entity_name_label_source} and {entity_name_label_target}\"\n                )\n                # Return default edge properties when no edge found\n                return {\"weight\": 0.0, \"description\": None, \"keywords\": None, \"source_id\": None}\n\n        except Exception as e:\n            logger.error(\n                f\"Error in get_edge between {source_node_id} and {target_node_id}: {str(e)}\"\n            )\n            # Return default edge properties on error\n            return {\"weight\": 0.0, \"description\": None, \"keywords\": None, \"source_id\": None}\n\n    async def get_node_edges(self, source_node_id: str) -> list[tuple[str, str]] | None:\n        node_label = source_node_id.strip('\"')\n```"
      },
      {
        "user": "spo0nman",
        "created_at": "2025-02-17T17:33:31Z",
        "body": "With your changes i get a TypeError because `source_id` is None when trying to split it. We have to modify the `get_edge` method to ensure `source_id` is always a string, even when empty.\n\n\n\n`    async def get_edge(\n        self, source_node_id: str, target_node_id: str\n    ) -> dict[str, str] | None:\n        try:\n            entity_name_label_source = source_node_id.strip('\"')\n            entity_name_label_target = target_node_id.strip('\"')\n\n            async with self._driver.session(database=self._DATABASE) as session:\n                query = f\"\"\"\n                MATCH (start:`{entity_name_label_source}`)-[r]->(end:`{entity_name_label_target}`)\n                RETURN properties(r) as edge_properties\n                LIMIT 1\n                \"\"\".format(\n                    entity_name_label_source=entity_name_label_source,\n                    entity_name_label_target=entity_name_label_target,\n                )\n\n                result = await session.run(query)\n                record = await result.single()\n                if record and \"edge_properties\" in record:\n                    try:\n                        result = dict(record[\"edge_properties\"])\n                        logger.info(f\"Result: {result}\")\n                        # Ensure required keys exist with defaults\n                        required_keys = {\n                            \"weight\": 0.0,\n                            \"source_id\": \"\",  # Changed from None to empty string\n                            \"target_id\": \"\",  # Changed from None to empty string\n                            \"description\": \"\",\n                            \"keywords\": \"\",\n                        }\n                        for key, default_value in required_keys.items():\n                            if key not in result or result[key] is None:  # Also check for None values\n                                result[key] = default_value\n                                logger.warning(\n                                    f\"Edge between {entity_name_label_source} and {entity_name_label_target} \"\n                                    f\"missing {key}, using default: {default_value}\"\n                                )\n\n                        logger.debug(\n                            f\"{inspect.currentframe().f_code.co_name}:query:{query}:result:{result}\"\n                        )\n                        return result\n                    except (KeyError, TypeError, ValueError) as e:\n                        logger.error(\n                            f\"Error processing edge properties between {entity_name_label_source} \"\n                            f\"and {entity_name_label_target}: {str(e)}\"\n                        )\n                        # Return default edge properties on error\n                        return {\n                            \"weight\": 0.0,\n                            \"source_id\": \"\",\n                            \"target_id\": \"\",\n                            \"description\": \"\",\n                            \"keywords\": \"\"\n                        }\n\n                logger.debug(\n                    f\"{inspect.currentframe().f_code.co_name}: No edge found between {entity_name_label_source} and {entity_name_label_target}\"\n                )\n                # Return default edge properties when no edge found\n                return {\n                    \"weight\": 0.0,\n                    \"source_id\": \"\",\n                    \"target_id\": \"\",\n                    \"description\": \"\",\n                    \"keywords\": \"\"\n                }\n\n        except Exception as e:\n            logger.error(\n                f\"Error in get_edge between {source_node_id} and {target_node_id}: {str(e)}\"\n            )\n            # Return default edge properties on error\n            return {\n                \"weight\": 0.0,\n                \"source_id\": \"\",\n                \"target_id\": \"\",\n                \"description\": \"\",\n                \"keywords\": \"\"\n            }`"
      }
    ]
  },
  {
    "number": 445,
    "title": "\u5173\u4e8e\u5355\u7eaf\u4f7f\u7528LightRAG",
    "created_at": "2024-12-10T11:23:06Z",
    "closed_at": "2024-12-11T10:13:49Z",
    "labels": [],
    "url": "https://github.com/HKUDS/LightRAG/issues/445",
    "body": "\u8bf7\u95ee\u5982\u679c\u4e0d\u7528\u5927\u6a21\u578b\uff0c\u5355\u7eaf\u4f7f\u7528LightRAG\u5206\u6790\u4e00\u4e2a\u6587\u6863\u5b9e\u4f53\u4e0e\u5b9e\u4f53\u95f4\u3001\u5b9e\u4f53\u4e0e\u4e8b\u4ef6\u3001\u4e8b\u4ef6\u4e0e\u4e8b\u4ef6\u7684\u5173\u7cfb\uff0c\u8fd9\u4e2a\u53ef\u4ee5\u8f93\u51fa\u51fa\u6765\u5417\uff1f",
    "comments_url": "https://api.github.com/repos/HKUDS/LightRAG/issues/445/comments",
    "author": "joseph16388",
    "comments": [
      {
        "user": "magicyuan876",
        "created_at": "2024-12-11T01:59:26Z",
        "body": "\u63d0\u53d6\u5b9e\u4f53\u548c\u5173\u7cfb\u672c\u8eab\u5c31\u662f\u7528LLM\u6765\u62bd\u53d6\u7684\u5440\uff0c\u4e0d\u7528LLM\u80af\u5b9a\u4e0d\u884c\u5440"
      }
    ]
  },
  {
    "number": 109,
    "title": "Local, Global, and Hybrid Modes Not Working in HF Example",
    "created_at": "2024-10-23T04:32:56Z",
    "closed_at": "2024-10-25T01:04:27Z",
    "labels": [],
    "url": "https://github.com/HKUDS/LightRAG/issues/109",
    "body": "I'm using the Hugging Face example from the LightRAG repository, and only the naive mode functions correctly. The local, global, and hybrid modes fail to work.\r\n\r\nLLM Model: llam3.1 8b instruct\r\nEmbed Model: all-MiniLM-L12-V2\r\n\r\nAny advice? ",
    "comments_url": "https://api.github.com/repos/HKUDS/LightRAG/issues/109/comments",
    "author": "shmily1012",
    "comments": [
      {
        "user": "TianyuFan0504",
        "created_at": "2024-10-23T06:42:32Z",
        "body": "Hi @shmily1012.\r\nWe have understood your question. Due to the diverse response formats of the HF model, we have not yet added optimizations to all models.\r\nYour problem may arise from the following reasons:\r\n1.The reply format of llama8B is not stable and may generate unreadable JSON, resulting in the query process being unable to proceed\r\n2.Llama8B is not strong enough to find enough entity/relation to handle this type of query.\r\n\r\nAfter our testing, models above 14B can generally perform well"
      },
      {
        "user": "DayanaYuan",
        "created_at": "2024-10-23T07:09:17Z",
        "body": "> Hi @shmily1012. We have understood your question. Due to the diverse response formats of the HF model, we have not yet added optimizations to all models. Your problem may arise from the following reasons: 1.The reply format of llama8B is not stable and may generate unreadable JSON, resulting in the query process being unable to proceed 2.Llama8B is not strong enough to find enough entity/relation to handle this type of query.\r\n> \r\n> After our testing, models above 14B can generally perform well\r\n\r\nmy code is follow:WORKING_DIR = \"./dickens\"\r\n\r\nif not os.path.exists(WORKING_DIR):\r\n    os.mkdir(WORKING_DIR)\r\n\r\nrag = LightRAG(\r\n    working_dir=WORKING_DIR,\r\n    llm_model_func=hf_model_complete,\r\n    llm_model_name=\"/LightRAG/examples/meta-llama/Llama3-8B-instruct\",\r\n    # llm_model_name=\"meta-llama/Llama-3.1-8B-Instruct\",\r\n    embedding_func=EmbeddingFunc(\r\n        embedding_dim=384,\r\n        max_token_size=5000,\r\n        func=lambda texts: hf_embedding(\r\n            texts,\r\n            tokenizer=AutoTokenizer.from_pretrained(\r\n                \"LightRAG/examples/sentence-transformers/all-MiniLM-L6-v2\"\r\n            ),\r\n            embed_model=AutoModel.from_pretrained(\r\n                \"LightRAG/examples/sentence-transformers/all-MiniLM-L6-v2\"\r\n            ),\r\n        ),\r\n    ),\r\n)\r\n\r\n\r\nwith open(\"./book.txt\") as f:\r\n    rag.insert(f.read())\r\n\r\n# Perform naive search\r\nprint(\r\n    rag.query(\"What are the top themes in this story?\", param=QueryParam(mode=\"naive\"))\r\n)\r\n\r\n# Perform local search\r\nprint(\r\n    rag.query(\"What are the top themes in this story?\", param=QueryParam(mode=\"local\"))\r\n)\r\n\r\n# Perform global search\r\nprint(\r\n    rag.query(\"What are the top themes in this story?\", param=QueryParam(mode=\"global\"))\r\n)\r\n\r\n# Perform hybrid search\r\nprint(\r\n    rag.query(\"What are the top themes in this story?\", param=QueryParam(mode=\"hybrid\"))\r\n)\r\n\r\nbut the answer is follow:agraphs\r\n\r\nassistant\r\n\r\nBased on the provided text, some of the top themes in this story are:\r\n\r\n1. **Redemption and Change**: The story explores the theme of redemption as Ebenezer Scrooge, a miserly and bitter character, undergoes a transformation after being visited by the Ghost of Christmas Past, Present, and Yet to Come. Scrooge's experiences lead him to reevaluate his values and behavior, ultimately changing his ways and becoming a kinder and more generous person.\r\n2. **Kindness and Generosity**: The story highlights the importance of kindness and generosity, particularly around Christmas. The character of Bob Cratchit, a poor but kind and hardworking man, is a prime example of this theme. The story also shows how small acts of kindness, such as the Cratchits' humble celebrations and Scrooge's eventual generosity, can bring joy and warmth to those around them.\r\n3. **Social Class and Poverty**: The story touches on the theme of social class and poverty\r\nINFO:lightrag:Creating a new event loop in a sub-thread.\r\nLoading checkpoint shards: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4/4 [00:03<00:00,  1.03it/s]\r\nWARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu.\r\nSorry, I'm not able to provide an answer to that question.\r\nINFO:lightrag:Creating a new event loop in a sub-thread.\r\nLoading checkpoint shards: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4/4 [00:06<00:00,  1.58s/it]\r\nINFO:lightrag:Creating a new event loop in a sub-thread.\r\nSorry, I'm not able to provide an answer to that question.\r\nLoading checkpoint shards: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4/4 [00:03<00:00,  1.03it/s]\r\nWARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu.\r\n/LightRAG/lightrag/operate.py:990: UserWarning: High Level context is None. Return empty High entity/relationship/source\r\n  warnings.warn(\r\nLightRAG/lightrag/operate.py:998: UserWarning: Low Level context is None. Return empty Low entity/relationship/source\r\n  warnings.warn(\r\nLoading checkpoint shards: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4/4 [00:06<00:00,  1.58s/it]\r\nsystem\r\n\r\n---Role---\r\n\r\nYou are a helpful assistant responding to questions about data in the tables provided.\r\n\r\n\r\n---Goal---\r\n\r\nGenerate a response of the target length and format that responds to the 's question, summarizing all information in the input data tables appropriate for the response length and format, and incorporating any relevant general knowledge.\r\nIf you don't know the answer, just say so. Do not make anything up.\r\nDo not include information where the supporting evidence for it is not provided.\r\n\r\n---Target response length and format---\r\n\r\nMultiple Paragraphs\r\n\r\n---Data tables---\r\n\r\n\r\n-----Entities-----\r\n```csv\r\n\r\n-----Relationships-----\r\n\r\n-----Sources-----\r\n\r\n\r\n\r\nAdd sections and commentary to the response as appropriate for the length and format. Style the response in markdown.\r\n\r\nassistant\r\n\r\nI'm happy to help! However, I don't see any data tables provided. Could you please provide the tables for \"Entities\", \"Relationships\", and \"Sources\" so I can assist you in identifying the top themes in the story?\r\n\r\n\u8fdb\u7a0b\u5df2\u7ed3\u675f,\u9000\u51fa\u4ee3\u78010 \r\n\r\nIs this because of a problem with the 3B model?"
      },
      {
        "user": "shmily1012",
        "created_at": "2024-10-23T14:31:11Z",
        "body": "> Hi @shmily1012. We have understood your question. Due to the diverse response formats of the HF model, we have not yet added optimizations to all models. Your problem may arise from the following reasons: 1.The reply format of llama8B is not stable and may generate unreadable JSON, resulting in the query process being unable to proceed 2.Llama8B is not strong enough to find enough entity/relation to handle this type of query.\r\n> \r\n> After our testing, models above 14B can generally perform well\r\n\r\nHi @TianyuFan0504, thanks for your quick response. I am wondering if you can you provide the full name of your 14B model. I really would like to give it a try.\r\nBR,\r\nAlex"
      },
      {
        "user": "TianyuFan0504",
        "created_at": "2024-10-24T10:41:40Z",
        "body": "> > Hi @shmily1012. We have understood your question. Due to the diverse response formats of the HF model, we have not yet added optimizations to all models. Your problem may arise from the following reasons: 1.The reply format of llama8B is not stable and may generate unreadable JSON, resulting in the query process being unable to proceed 2.Llama8B is not strong enough to find enough entity/relation to handle this type of query.\r\n> > After our testing, models above 14B can generally perform well\r\n> \r\n> Hi @TianyuFan0504, thanks for your quick response. I am wondering if you can you provide the full name of your 14B model. I really would like to give it a try. BR, Alex\r\n\r\nThere are some models we have tested:llama1b/3b/7b/11b, qwen 14b, minicpm4b, gemma2b, baichuan2b. \r\nOnly qwen  work. : ("
      },
      {
        "user": "amenhere",
        "created_at": "2025-01-17T03:04:47Z",
        "body": "\u6211\u6d4b\u8bd5\u4e86qwen-vl-plus\uff0cglm-4-flash\uff0cgpt-4-turbo\u548cgpt-4o-mini-2024-07-18\u90fd\u6709\u53ef\u80fd\u51fa\u73b0\u8fd9\u4e2a\u95ee\u9898\uff0c\u800c\u4e14\u9891\u7387\u5f88\u9ad8\u3002\n\u6211\u63d0\u51fa\u7684\u7684\u95ee\u9898\u5982\u4e0b\uff1a\n\nprompt\uff1a\n\u8bf7\u6839\u636e\u4ee5\u4e0b\u6bcf\u4e2a\u6807\u7b7e\u540e\u7684\u63cf\u8ff0\uff0c\u51c6\u786e\u63d0\u53d6\u5408\u540c\u4e2d\u6bcf\u4e2a\u5b9e\u4f53\u7684\u5bf9\u5e94\u4fe1\u606f\uff1a\n\u89c4\u5219\uff1a\n1\u3001\u5f53\u524d\u5408\u540c\u4e2d\u6ca1\u6709\u8fd9\u4e2a\u6807\u7b7e\u5b9e\u4f53\u65f6\u53ef\u4ee5\u7528\"None\"\u586b\u5199\uff1b\n2\u3001\u7528\u4e2d\u6587\u8f93\u51fa\uff1b\n3\u3001\u5b9e\u4f53\u4fe1\u606f\u5fc5\u987b\u662f\u5408\u540c\u4e2d\u7684\u539f\u6587\uff0c\u4e0d\u53ef\u4ee5\u8fdb\u884c\u7f16\u9020\uff01\uff01\uff01\n4\u3001\u4e0d\u8981\u51fa\u73b0\u65e0\u5173\u7684\u63d0\u793a\u8bcd\uff0c\u5982\uff1a\u6211\u8ba4\u4e3a\uff0c\u603b\u7ed3\uff0c\u53ef\u80fd\uff0c\u7b49\u7b49\uff1b\n5\u3001\u7528json\u7684\u683c\u5f0f\u8fd4\u56de\u5b9e\u4f53\u5b57\u5178\u8868\u548c\u4ed6\u5bf9\u5e94\u7684\u5b9e\u4f53\u4fe1\u606f\uff0c\u4f8b\u5982\uff1a{\"\u5b9e\u4f53\u6807\u7b7e\":\"\u5b9e\u4f53\u5185\u5bb9\"}\uff1b\n\n####\u6807\u7b7e\u89e3\u91ca\n\u5408\u540c\u7f16\u53f7: \u5408\u540c\u7684\u552f\u4e00\u6807\u8bc6\u7b26\uff0c\u901a\u5e38\u4e3a\u4e00\u4e32\u6570\u5b57\u6216\u5b57\u6bcd\u7ec4\u5408\u3002\u7528\u4e8e\u533a\u5206\u4e0d\u540c\u5408\u540c\u3002\n\u5408\u540c\u540d\u79f0: \u5408\u540c\u7684\u6b63\u5f0f\u540d\u79f0\u6216\u6807\u9898\uff0c\u901a\u5e38\u5305\u62ec\u5408\u540c\u7c7b\u578b\u3001\u7b7e\u7ea6\u65b9\u6216\u9879\u76ee\u540d\u79f0\u7b49\u4fe1\u606f\u3002\n\u7b7e\u8ba2\u65e5\u671f: \u5408\u540c\u8fbe\u6210\u7684\u65e5\u671f\uff0c\u901a\u5e38\u662f\u7532\u65b9\u548c\u4e59\u65b9\u53cc\u65b9\u7b7e\u7f72\u5408\u540c\u7684\u5177\u4f53\u65e5\u671f\u3002\n\u5408\u540c\u6709\u6548\u671f: \u5408\u540c\u5728\u6cd5\u5f8b\u4e0a\u751f\u6548\u5e76\u6301\u7eed\u6709\u6548\u7684\u65f6\u95f4\u6bb5\uff0c\u901a\u5e38\u5305\u62ec\u5f00\u59cb\u65e5\u671f\u548c\u7ed3\u675f\u65e5\u671f\u3002\n\u5408\u540c\u4e3b\u8981\u5185\u5bb9: \u5408\u540c\u7684\u6838\u5fc3\u6761\u6b3e\u6216\u6d89\u53ca\u7684\u4e3b\u8981\u4e8b\u9879\uff0c\u7b80\u8981\u6982\u8ff0\u5408\u540c\u7684\u57fa\u672c\u7ea6\u5b9a\u3002\n\u670d\u52a1\u5185\u5bb9: \u4e59\u65b9\u63d0\u4f9b\u7684\u670d\u52a1\u6216\u7532\u65b9\u8981\u6c42\u4e59\u65b9\u5b8c\u6210\u7684\u4efb\u52a1\u548c\u5de5\u4f5c\u5185\u5bb9\u3002\n\u7532\u65b9\u540d\u79f0: \u5408\u540c\u4e2d\u7684\u4e00\u65b9\uff0c\u901a\u5e38\u4e3a\u53d1\u8d77\u65b9\u6216\u59d4\u6258\u65b9\uff0c\u5e38\u89c1\u4e8e\u8d2d\u4e70\u3001\u5408\u4f5c\u6216\u59d4\u6258\u7b49\u5408\u540c\u3002\n\u4e59\u65b9\u540d\u79f0: \u5408\u540c\u4e2d\u7684\u53e6\u4e00\u65b9\uff0c\u901a\u5e38\u4e3a\u63a5\u53d7\u65b9\u6216\u670d\u52a1\u63d0\u4f9b\u65b9\u3002\n\u7532\u65b9\u7eb3\u7a0e\u4eba\u8bc6\u522b\u53f7: \u7532\u65b9\u5728\u7a0e\u52a1\u7cfb\u7edf\u4e2d\u7684\u552f\u4e00\u8bc6\u522b\u53f7\u7801\uff0c\u7528\u4e8e\u7a0e\u52a1\u8bc6\u522b\u3002\n\u4e59\u65b9\u7eb3\u7a0e\u4eba\u8bc6\u522b\u53f7: \u4e59\u65b9\u5728\u7a0e\u52a1\u7cfb\u7edf\u4e2d\u7684\u552f\u4e00\u8bc6\u522b\u53f7\u7801\uff0c\u7528\u4e8e\u7a0e\u52a1\u8bc6\u522b\u3002\n\u7532\u65b9\u5730\u5740: \u7532\u65b9\u7684\u6ce8\u518c\u5730\u5740\u6216\u4e3b\u8981\u529e\u516c\u5730\u70b9\uff0c\u901a\u5e38\u4e3a\u6cd5\u4eba\u6ce8\u518c\u5730\u6216\u8054\u7cfb\u5730\u5740\u3002\n\u4e59\u65b9\u5730\u5740: \u4e59\u65b9\u7684\u6ce8\u518c\u5730\u5740\u6216\u4e3b\u8981\u529e\u516c\u5730\u70b9\uff0c\u901a\u5e38\u4e3a\u6cd5\u4eba\u6ce8\u518c\u5730\u6216\u8054\u7cfb\u5730\u5740\u3002\n\u7532\u65b9\u7535\u8bdd: \u7532\u65b9\u7684\u8054\u7cfb\u65b9\u5f0f\uff0c\u901a\u5e38\u662f\u7535\u8bdd\u53f7\u7801\uff0c\u7528\u4e8e\u65e5\u5e38\u6c9f\u901a\u3002\n\u4e59\u65b9\u7535\u8bdd: \u4e59\u65b9\u7684\u8054\u7cfb\u65b9\u5f0f\uff0c\u901a\u5e38\u662f\u7535\u8bdd\u53f7\u7801\uff0c\u7528\u4e8e\u65e5\u5e38\u6c9f\u901a\u3002\n\u8fdd\u7ea6\u8d23\u4efb: \u5408\u540c\u4e2d\u89c4\u5b9a\u7684\u8fdd\u7ea6\u6761\u6b3e\uff0c\u63cf\u8ff0\u5f53\u4e8b\u4e00\u65b9\u672a\u5c65\u884c\u5408\u540c\u4e49\u52a1\u65f6\u5e94\u627f\u62c5\u7684\u8d23\u4efb\u3002\n\u4e89\u8bae\u89e3\u51b3\u65b9\u5f0f: \u5f53\u5408\u540c\u53cc\u65b9\u53d1\u751f\u4e89\u8bae\u65f6\uff0c\u7ea6\u5b9a\u7684\u89e3\u51b3\u65b9\u5f0f\uff0c\u5982\u4ef2\u88c1\u3001\u8bc9\u8bbc\u6216\u8c03\u89e3\u7b49\u3002\n\n####\u5b9e\u4f53\u5b57\u5178\n{\n    \u5408\u540c\u7f16\u53f7:\n    \u5408\u540c\u540d\u79f0:\n    \u7b7e\u8ba2\u65e5\u671f:\n    \u5408\u540c\u6709\u6548\u671f:\n    \u5408\u540c\u4e3b\u8981\u5185\u5bb9:\n    \u670d\u52a1\u5185\u5bb9:\n    \u7532\u65b9\u540d\u79f0:\n    \u4e59\u65b9\u540d\u79f0:\n    \u7532\u65b9\u7eb3\u7a0e\u4eba\u8bc6\u522b\u53f7:\n    \u4e59\u65b9\u7eb3\u7a0e\u4eba\u8bc6\u522b\u53f7:\n    \u7532\u65b9\u5730\u5740:\n    \u4e59\u65b9\u5730\u5740:\n    \u7532\u65b9\u7535\u8bdd:\n    \u4e59\u65b9\u7535\u8bdd:\n    \u8fdd\u7ea6\u8d23\u4efb:\n    \u4e89\u8bae\u89e3\u51b3\u65b9\u5f0f:\n}"
      }
    ]
  }
]