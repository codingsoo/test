[
  {
    "number": 8,
    "title": "A lot of reprocessing promt.",
    "created_at": "2025-01-04T01:17:16Z",
    "closed_at": "2025-01-05T09:30:08Z",
    "labels": [],
    "url": "https://github.com/cierru/st-stepped-thinking/issues/8",
    "body": "hi\r\n\r\nFirst of all, I love your extension. I use local models (koboltcpp) and I noticed that after some time (5k tokens sometimes less) there is a lot of reprocessing (not so much when generating thoughts or plans, but afterwards).\r\n\r\nThere is a setting in your extension \"Number of included thoughts for a character:\" significantly increasing this number eliminates the processing problem. I don't quite understand how it works, why is the default value only \"2\"? When generating text (after generating thoughts and plans) is only the part of the previous conversation taken into account? (this would explain the reprocessing)",
    "comments_url": "https://api.github.com/repos/cierru/st-stepped-thinking/issues/8/comments",
    "author": "Danik-droid",
    "comments": [
      {
        "user": "cierru",
        "created_at": "2025-01-04T07:24:49Z",
        "body": "Hi,\r\n\r\nFirst of all, thank you! I'm glad to hear that you like the extension.\r\n\r\nAs for the so-called reprocessing, it happens because, after thoughts are generated, the API reloads the entire context. Why does this happen? Because some thoughts are evicted from the context after a new message is generated. In other words, the context changes somewhere in the middle, making it impossible to execute a Context Shift. There is no way to avoid this unless you disable eviction by setting a large value for \"Number of included thoughts for a character.\"\r\n\r\nWhy is it set to 2 by default? Well, some models tend to confuse thoughts with regular messages if there are too many thoughts in the context. Additionally, they can become rigid, sticking to the initial thoughts and not altering them enough as the chat continues. Old thoughts may also become less useful, so keeping them could be considered a waste of context.\r\n\r\nHowever, in your case, if your model handles thoughts well and speed is a top priority for you, using a large number for \"Number of included thoughts for a character\" is perfectly fine. That's why the setting is configurable after all \ud83d\ude42"
      },
      {
        "user": "Danik-droid",
        "created_at": "2025-01-04T13:16:32Z",
        "body": "I see... That makes sense, llama 8b actually started to get a bit lost after a while... Mistral small copes well with a lot of \"Number of included thoughts for a character.\", but you're right that characters are more stubborn when you increase this value - which can be annoying. (they can bring up things that happened much much earlier, which is interesting but often tiring)...\r\n\r\nIt doesn't occur to me how this could be easily solved... I wondered earlier what it would be like to assign another model to do the thinking and planning, but now I know that it would not contribute anything to the topic of reprocessing.\r\n\r\nThank you very much for your answer. Oh well... I guess I need to work on my patience, because without your expansion, roleplay is losing a lot.\r\n"
      }
    ]
  }
]