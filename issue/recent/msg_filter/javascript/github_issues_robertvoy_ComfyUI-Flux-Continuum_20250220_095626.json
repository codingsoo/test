[
  {
    "number": 8,
    "title": "Need more info!",
    "created_at": "2024-12-01T21:37:11Z",
    "closed_at": "2024-12-08T17:22:11Z",
    "labels": [],
    "url": "https://github.com/robertvoy/ComfyUI-Flux-Continuum/issues/8",
    "body": "Hi!\r\n\r\nI really love your approach with this workflow, but I really can't grasp the procedure for, say, using canny or other controls for img2img. More specifically, I don't understand how to define the starting image: is it the latest image I generated, or the image I have in the Img Load tab?\r\n\r\nAt the end of the tutorial video you ask for feedback on the need for more videos\u2026 Well, here's feedback: yes, please! \ud83d\ude43",
    "comments_url": "https://api.github.com/repos/robertvoy/ComfyUI-Flux-Continuum/issues/8/comments",
    "author": "mbac",
    "comments": [
      {
        "user": "robertvoy",
        "created_at": "2024-12-01T21:58:21Z",
        "body": "Thanks! Yes, the tutorial is coming soon.\r\n\r\nQuick info for now:\r\n- Any img2img operation (detailer, img2img, inpainting, outpainting etc.), but also upscaler, canny, depth, they all use the Img Load tab as an input\r\n- For operations requiring a mask, use the Img Mask tab\r\n- The other image load tabs: IP1, IP2, IP3/Face are used for Redux (the new IP Adapter), with IP3/Face also used in Face Swap\r\n\r\nUsing Canny:\r\n> The new Black Forest Labs canny and depth ControlNets work differently from what we're used to. Instead of being applied as part of the conditioning, the ControlNet is a model in itself.\r\n1. Load image you want to use as an input for canny into the Img Load tab.\r\n2. Set the output to Output - canny preprocessor\r\n3. Run the workflow to preview your canny preprocessor output\r\n4. Adjust the canny parameters in the Canny tab (below the image load nodes)\r\n5. Change output to Output - canny\r\n6. Run the workflow\r\n\r\nUsing Depth: same as above but you can tweak the depth map using the CC tab.\r\n\r\nA common workflow:\r\n1. Generate images with txt2img, until you find something you like\r\n3. Right-click the output in the main window named Img Preview and Copy (Clipspace)\r\n4. Right-click the Img Load tab and Paste (Clipspace)\r\n> Now the generation from txt2img is your starting image for img2img operations\r\n5. Create a mask in the Img Mask tab to change something\r\n6. Set the output to Output - inpanting, adjust the prompt if needed, increase the guidance and run\r\n7. Right-click the output in Img Preview and Copy (Clipspace) and Paste (Clipspace) into Img Load tab\r\n8. Repeat the process with any other operations you need\r\n9. Set the output to Output - upscaler\r\n10. Set the upscale model and resolution multiply in the bottom right corner\r\n11. Run workflow\r\n12. You can stop here or you can run it through the ultimate upscaler (don't copy the upscaled image into the Img Load for this operation, because the upscaler will do this anyway)\r\n\r\nThis pretty much covers it all and there is some more info in the tutorial that you've seen. Let me know if you have any more questions. This is helpful as I'll know what to include in the tutorial."
      }
    ]
  }
]