[
  {
    "number": 268,
    "title": "ImportError: cannot import name 'BingBrowser' from 'lagent.actions'",
    "created_at": "2024-12-06T06:59:37Z",
    "closed_at": "2024-12-06T07:05:51Z",
    "labels": [],
    "url": "https://github.com/InternLM/MindSearch/issues/268",
    "body": "lagent库不支持",
    "comments_url": "https://api.github.com/repos/InternLM/MindSearch/issues/268/comments",
    "author": "usgDHJAKJD",
    "comments": [
      {
        "user": "MING-ZCH",
        "created_at": "2024-12-21T10:30:22Z",
        "body": "> lagent库不支持\r\n\r\nhi请问你是如何解决的呢？"
      }
    ]
  },
  {
    "number": 265,
    "title": "官方是不是就不想让跑起来不提供 python 版本",
    "created_at": "2024-12-03T09:09:20Z",
    "closed_at": "2024-12-05T08:20:45Z",
    "labels": [],
    "url": "https://github.com/InternLM/MindSearch/issues/265",
    "body": "- 如题：官方是不是就不想让跑起来不提供 python 版本",
    "comments_url": "https://api.github.com/repos/InternLM/MindSearch/issues/265/comments",
    "author": "netcore-jroger",
    "comments": [
      {
        "user": "Harold-lkk",
        "created_at": "2024-12-05T08:20:39Z",
        "body": "没特别测试过 Python 版本，我3.10 是可以的"
      }
    ]
  },
  {
    "number": 251,
    "title": "官方的demo基本可以稳定运行，为啥github上代码跑起来这么不稳定？",
    "created_at": "2024-11-13T08:47:52Z",
    "closed_at": "2024-12-05T08:21:08Z",
    "labels": [],
    "url": "https://github.com/InternLM/MindSearch/issues/251",
    "body": "官方的demo基本可以稳定运行，为啥github上代码跑起来这么不稳定？\r\nbug特别多，难道官方还有另一个库在维护？",
    "comments_url": "https://api.github.com/repos/InternLM/MindSearch/issues/251/comments",
    "author": "chuanzhubin",
    "comments": [
      {
        "user": "xiongvalerio",
        "created_at": "2024-11-13T09:19:34Z",
        "body": "> 官方的demo基本可以稳定运行，为啥github上代码跑起来这么不稳定？\n> bug特别多，难道官方还有另一个库在维护？\n\n我也这么感觉"
      },
      {
        "user": "Harold-lkk",
        "created_at": "2024-11-13T09:38:23Z",
        "body": "实际就是一套代码呀😕"
      },
      {
        "user": "HaishengLiang",
        "created_at": "2024-11-27T00:08:32Z",
        "body": "感觉官方的搜索比我本地的快好多啊，感觉都不像duckduckgo的底座了，是不是用了bing或者其他产品了"
      },
      {
        "user": "Harold-lkk",
        "created_at": "2024-11-27T01:52:18Z",
        "body": "我们 demo 用了付费的API"
      },
      {
        "user": "HaishengLiang",
        "created_at": "2024-11-29T05:43:47Z",
        "body": "新版的代码应该没开源 我对比了下编译产物的代码 \r\n跟目前github上的内容不完全匹配 giithub的代码至少落后了1-2个版本"
      },
      {
        "user": "Harold-lkk",
        "created_at": "2024-11-30T02:01:31Z",
        "body": "前端因为是官方平台 代码有一些适配可能有略微差异在，所有的后端代码均一致 启动后端的服务就我们提供的dockerfile "
      }
    ]
  },
  {
    "number": 250,
    "title": "请问有没有降低延迟的方法啊？",
    "created_at": "2024-11-13T07:36:58Z",
    "closed_at": "2024-12-05T08:21:17Z",
    "labels": [],
    "url": "https://github.com/InternLM/MindSearch/issues/250",
    "body": "每次输出很多中间过程很耗时，延迟很高，有什么好的办法吗？\r\n体验了perplexity ai，感觉他们的延迟就很低。\r\n谢谢！",
    "comments_url": "https://api.github.com/repos/InternLM/MindSearch/issues/250/comments",
    "author": "babytdream",
    "comments": [
      {
        "user": "Harold-lkk",
        "created_at": "2024-11-13T09:43:09Z",
        "body": "延迟时间是和问题复杂度(对应到mindsearch 节点数)以及阅读的网页数目线性相关的， 如果想提速可以减少浏览器搜索结果返回的数目"
      }
    ]
  },
  {
    "number": 230,
    "title": "feat: frontend for new version",
    "created_at": "2024-10-31T12:15:35Z",
    "closed_at": "2024-11-04T01:38:22Z",
    "labels": [],
    "url": "https://github.com/InternLM/MindSearch/pull/230",
    "body": "frontend for new version",
    "comments_url": "https://api.github.com/repos/InternLM/MindSearch/issues/230/comments",
    "author": "BetterSnail",
    "comments": [
      {
        "user": "chuanzhubin",
        "created_at": "2024-11-04T01:30:16Z",
        "body": "@BetterSnail 主库里React运行起来后，问答没有响应。 这个pl解决了这个bug了吗？"
      }
    ]
  },
  {
    "number": 221,
    "title": "请问不使用api_key的方式访问llm，怎么改成直接通过request方式的请求",
    "created_at": "2024-10-19T11:13:26Z",
    "closed_at": "2024-11-05T11:38:37Z",
    "labels": [],
    "url": "https://github.com/InternLM/MindSearch/issues/221",
    "body": "原代码通过在models.py里配置不同的模型，在env的环境变量配置api_key，现在想通过直接请求本地部署的request方式，如何修改代码呢？",
    "comments_url": "https://api.github.com/repos/InternLM/MindSearch/issues/221/comments",
    "author": "tianch2750",
    "comments": [
      {
        "user": "xmx666",
        "created_at": "2024-11-07T00:53:28Z",
        "body": "改package里的包"
      }
    ]
  },
  {
    "number": 217,
    "title": "本地大模型下，是不是不支持CPU下部署？",
    "created_at": "2024-10-11T08:19:46Z",
    "closed_at": "2024-11-05T11:38:36Z",
    "labels": [],
    "url": "https://github.com/InternLM/MindSearch/issues/217",
    "body": "    我安装lmdeploy通过cpu，报错：\r\nassert CUDA_PATH is not None, 'Can not find $env:CUDA_PATH'\r\nAssertionError: Can not find $env:CUDA_PATH",
    "comments_url": "https://api.github.com/repos/InternLM/MindSearch/issues/217/comments",
    "author": "cristianohello",
    "comments": [
      {
        "user": "aonoa",
        "created_at": "2024-10-25T05:40:40Z",
        "body": "你用其他工具部署大模型，然后用openai格式调用试试"
      }
    ]
  },
  {
    "number": 210,
    "title": "ms009,美化MindSearchGradio界面，添加examples。",
    "created_at": "2024-09-22T08:49:54Z",
    "closed_at": "2024-09-25T07:49:13Z",
    "labels": [],
    "url": "https://github.com/InternLM/MindSearch/pull/210",
    "body": null,
    "comments_url": "https://api.github.com/repos/InternLM/MindSearch/issues/210/comments",
    "author": "fak111",
    "comments": [
      {
        "user": "Harold-lkk",
        "created_at": "2024-09-24T08:10:28Z",
        "body": "代码过一些 pre-commit hook吧"
      }
    ]
  },
  {
    "number": 204,
    "title": "后端能跑起来，但执行 python mindsearch/terminal.py时报错ModuleNotFoundError: No module named 'mindsearch'",
    "created_at": "2024-09-13T15:47:59Z",
    "closed_at": "2024-11-05T11:38:34Z",
    "labels": [],
    "url": "https://github.com/InternLM/MindSearch/issues/204",
    "body": "错误信息：Traceback (most recent call last):\r\n  File \"D:\\code\\MindSearch-main\\mindsearch\\terminal.py\", line 6, in <module>\r\n    from mindsearch.agent.mindsearch_agent import (MindSearchAgent,\r\nModuleNotFoundError: No module named 'mindsearch'",
    "comments_url": "https://api.github.com/repos/InternLM/MindSearch/issues/204/comments",
    "author": "leon21c",
    "comments": [
      {
        "user": "Harold-lkk",
        "created_at": "2024-09-14T07:15:19Z",
        "body": "python -m mindsearch.terminal"
      }
    ]
  },
  {
    "number": 202,
    "title": "ImportError: cannot import name 'AutoRegister' from 'class_registry' (/opt/conda/envs/mindsearch/lib/python3.10/site-packages/class_registry/__init__.py)",
    "created_at": "2024-09-10T13:32:05Z",
    "closed_at": "2024-11-05T11:38:33Z",
    "labels": [],
    "url": "https://github.com/InternLM/MindSearch/issues/202",
    "body": " /workspaces/mindsearch/MindSearch (b832275) $ python -m mindsearch.app --lang cn --model_format internlm_silicon --search_engine DuckDuckGoSearch\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/envs/mindsearch/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\r\n    return _run_code(code, main_globals, None,\r\n  File \"/opt/conda/envs/mindsearch/lib/python3.10/runpy.py\", line 86, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/workspaces/mindsearch/MindSearch/mindsearch/app.py\", line 11, in <module>\r\n    from lagent.schema import AgentStatusCode\r\n  File \"/opt/conda/envs/mindsearch/lib/python3.10/site-packages/lagent/__init__.py\", line 2, in <module>\r\n    from .actions import *  # noqa: F401, F403\r\n  File \"/opt/conda/envs/mindsearch/lib/python3.10/site-packages/lagent/actions/__init__.py\", line 3, in <module>\r\n    from .action_executor import ActionExecutor\r\n  File \"/opt/conda/envs/mindsearch/lib/python3.10/site-packages/lagent/actions/action_executor.py\", line 4, in <module>\r\n    from .base_action import BaseAction\r\n  File \"/opt/conda/envs/mindsearch/lib/python3.10/site-packages/lagent/actions/base_action.py\", line 14, in <module>\r\n    from class_registry import AutoRegister, ClassRegistry\r\nImportError: cannot import name 'AutoRegister' from 'class_registry' (/opt/conda/envs/mindsearch/lib/python3.10/site-packages/class_registry/__init__.py)",
    "comments_url": "https://api.github.com/repos/InternLM/MindSearch/issues/202/comments",
    "author": "codefd",
    "comments": [
      {
        "user": "effectzhang",
        "created_at": "2024-09-11T02:55:23Z",
        "body": "我也遇到这个问题了，有解法吗"
      },
      {
        "user": "Ming-jiayou",
        "created_at": "2024-09-12T00:08:08Z",
        "body": "遇到一样的问题"
      },
      {
        "user": "daogu",
        "created_at": "2024-09-12T02:32:21Z",
        "body": "`from class_registry import AutoRegister, ClassRegistry`\r\n报错的AutoRegister 换成下面的\r\n`from class_registry.auto_register import AutoRegister`"
      },
      {
        "user": "leon21c",
        "created_at": "2024-09-13T14:52:09Z",
        "body": "要再安装个依赖 pip install class_registry"
      }
    ]
  },
  {
    "number": 196,
    "title": "支持第三方api key - Support for third-party API key",
    "created_at": "2024-09-06T13:51:35Z",
    "closed_at": "2024-11-05T11:38:32Z",
    "labels": [],
    "url": "https://github.com/InternLM/MindSearch/issues/196",
    "body": "希望云端模型可以使用第三方key，可以填base url（第三方接口地址）和api，谢谢。\r\nI hope cloud models can use third-party keys, with options to enter the base URL (third-party interface address) and API. Thanks.",
    "comments_url": "https://api.github.com/repos/InternLM/MindSearch/issues/196/comments",
    "author": "Cormac315",
    "comments": [
      {
        "user": "MING-ZCH",
        "created_at": "2024-09-10T13:37:42Z",
        "body": "同样需求+1，多谢"
      }
    ]
  },
  {
    "number": 188,
    "title": "你好，mindsearch能放到pip源吗（pypi）？",
    "created_at": "2024-09-02T02:27:11Z",
    "closed_at": "2024-11-05T11:38:32Z",
    "labels": [],
    "url": "https://github.com/InternLM/MindSearch/issues/188",
    "body": "求！",
    "comments_url": "https://api.github.com/repos/InternLM/MindSearch/issues/188/comments",
    "author": "datalee",
    "comments": [
      {
        "user": "Harold-lkk",
        "created_at": "2024-09-03T02:54:31Z",
        "body": "在什么情况下会需要当做 pypi 包用呀"
      },
      {
        "user": "datalee",
        "created_at": "2024-09-04T11:11:42Z",
        "body": "> 在什么情况下会需要当做 pypi 包用呀\r\n\r\n直接使用源码可能会面临代码引用的问题"
      }
    ]
  },
  {
    "number": 187,
    "title": "Pull Request: Integrate .env File Support and Add Backend Usage Example",
    "created_at": "2024-09-01T00:16:53Z",
    "closed_at": "2024-09-09T15:19:43Z",
    "labels": [],
    "url": "https://github.com/InternLM/MindSearch/pull/187",
    "body": "#### Description\r\n\r\nThis pull request introduces two enhancements to the MindSearch project:\r\n\r\n1. **Environment Variables Configuration**:\r\n   - Added support for managing environment variables using a `.env` file.\r\n   - Updated `models.py` to load environment variables using `python-dotenv`.\r\n   - Modified GPT-4 and Silicon model configurations to use values from the `.env` file or defaults.\r\n   - Updated `.gitignore` to exclude the `.env` file.\r\n   - Updated `requirements.txt` to include `python-dotenv`.\r\n\r\n2. **Backend Usage Example**:\r\n   - Added `backend_example.py` to demonstrate how to interact with the backend directly, without using the frontend.\r\n\r\n#### Changes\r\n\r\n- **.env.example**: Added with necessary environment variable placeholders.\r\n- **.gitignore**: Updated to exclude `.env` file.\r\n- **README.md**: Documented environment variable setup and backend usage example.\r\n- **backend_example.py**: New script for direct backend interaction.\r\n- **models.py**: Updated to load environment variables for model configurations.\r\n- **requirements.txt**: Added `python-dotenv` dependency.\r\n\r\n#### How to Test\r\n\r\n1. **Setup Environment Variables**:\r\n   - Rename `.env.example` to `.env` and fill in the required values.\r\n\r\n2. **Run Backend Example**:\r\n   - Ensure the backend is running.\r\n   - Execute `python backend_example.py` to test direct backend interaction.\r\n\r\n#### Additional Information\r\n\r\n- This update simplifies the configuration process and provides an example for users who prefer backend interaction without a frontend.\r\n- **Note**: The README currently refers to this as a \"forked version.\" If this pull request is accepted, I am happy to update the README to reflect the changes in the main repository.",
    "comments_url": "https://api.github.com/repos/InternLM/MindSearch/issues/187/comments",
    "author": "Jiayou-Chao",
    "comments": [
      {
        "user": "Harold-lkk",
        "created_at": "2024-09-03T02:56:28Z",
        "body": "Thanks for your contribution, we will review as soon as possible"
      }
    ]
  },
  {
    "number": 186,
    "title": "AssertionError: Can not find $env:CUDA_PATH",
    "created_at": "2024-08-30T06:21:30Z",
    "closed_at": "2024-11-05T02:32:47Z",
    "labels": [],
    "url": "https://github.com/InternLM/MindSearch/issues/186",
    "body": "搜索后出现这个path无法找到，应该在哪里去做配置\r\nAssertionError: Can not find $env:CUDA_PATH",
    "comments_url": "https://api.github.com/repos/InternLM/MindSearch/issues/186/comments",
    "author": "Ansrg123",
    "comments": [
      {
        "user": "Harold-lkk",
        "created_at": "2024-09-03T02:53:38Z",
        "body": "这个是应该 CUDA 环境配置的有问题，可以搜索一下相关的内容\r\n"
      }
    ]
  },
  {
    "number": 185,
    "title": "Refactor Docker Launch Method for MindSearch",
    "created_at": "2024-08-29T09:29:09Z",
    "closed_at": "2024-09-03T02:57:41Z",
    "labels": [],
    "url": "https://github.com/InternLM/MindSearch/pull/185",
    "body": "# Refactor Docker Launch Method for MindSearch\r\n\r\nIn this PR, I have undertaken a significant refactor of the Docker launch method for MindSearch, aimed at greatly simplifying the deployment process and making it more accessible to a wider audience. For detailed usage instructions, please refer to: /docker/README.md.\r\n\r\nKey Improvements and Underlying Principles:\r\n\r\nEnhanced Docker Launch Method:\r\n\r\nDeveloped a launcher named MSDL (MindSearch Docker Launcher), which is written in Python and serves as a Docker launch scaffold tool.\r\nDynamic Configuration Based on Deployment Choice:\r\n\r\nThe launcher dynamically generates the necessary Dockerfile and docker-compose.yaml files based on whether the user selects local or cloud model deployment.\r\nFor cloud model deployment, the launcher pulls a lightweight base image such as python:3.11.9-slim to construct the backend image. For local model deployment, the launcher pulls an image that includes the PyTorch environment with pre-installed lmdeploy dependencies, such as openmmlab/lmdeploy:latest-cu12.\r\nAdditionally, when deploying with a cloud model, the launcher ensures that no GPU resources are allocated to the container, optimizing resource utilization.\r\nCloud Model Deployment:\r\n\r\nThis PR also focuses on cloud model deployment, which removes the dependency on local hardware.\r\nUsers can now deploy MindSearch on home servers or small machines without worrying about hardware limitations, enabling more people to use this project and run a service comparable to Perplexity on their own servers.\r\nI believe these changes will contribute to the growth of the community. I would greatly appreciate it if you could take the time to review these changes, and I welcome any feedback or suggestions you might have.\r\n\r\nThank you for your time and attention.\r\n\r\n---\r\n# 重构 MindSearch 的 Docker 启动方法\r\n\r\n在本次 PR 中，我对 MindSearch 的 Docker 启动方法进行了重大重构，旨在大大简化用户的部署过程，让它可以进一步触及更多用户。具体的使用方法可查看：/docker/README.md\r\n\r\n**主要改进及其原理：**\r\n\r\n1. **增强的 Docker 启动方法：**\r\n   - 构建了一个名为 MSDL （MindSearch Docker Launcher）的启动器，该启动器由 Python 编写，作为一个 Docker 启动脚手架工具。\r\n\r\n2. **基于部署选择的动态配置：**\r\n   - 根据用户选择本地或云端模型部署的不同，启动器会动态生成所需的 Dockerfile 和 docker-compose.yaml 文件。\r\n   - 对于云端模型部署，启动器将拉取轻量级的基础镜像，如 `python:3.11.9-slim`，以构建后端镜像， 而对于本地模型部署的情况， 启动器将会拉取包含 PyTorch 环境以及预装 lmdeploy 依赖包的环境来作为基础镜像，如 `openmmlab/lmdeploy:latest-cu12`。\r\n   - 此外，在使用云端模型进行部署时，启动器确保不会为对应的容器分配任何 GPU 资源，从而优化资源利用。\r\n\r\n3. **云端模型部署：**\r\n   - 本次 PR 还着重于云端模型部署，消除了对本地硬件的依赖。\r\n   - 用户现在可以在家庭服务器或小型主机上部署 MindSearch，而无需担心硬件限制，这使得更多人能够使用该项目，在自己的服务器上运行一个媲美 Perplexity 的项目。\r\n\r\n我相信这些更改将有助于社区的成长，恳请各位抽空看看这些改动，如果有什么意见或建议，欢迎随时告诉我。\r\n感谢各位的时间和关注。",
    "comments_url": "https://api.github.com/repos/InternLM/MindSearch/issues/185/comments",
    "author": "lcolok",
    "comments": [
      {
        "user": "vansin",
        "created_at": "2024-08-31T01:20:03Z",
        "body": "thanks for your contribution to mindsearch, we invite you to join wechat group of  MindSearch Contributor, please add \"浦语小助手\" (Wechat ID: InternLM) to join the group"
      }
    ]
  },
  {
    "number": 181,
    "title": "ERROR: No matching distribution found for lmdeploy",
    "created_at": "2024-08-27T16:42:34Z",
    "closed_at": "2024-10-16T09:06:50Z",
    "labels": [],
    "url": "https://github.com/InternLM/MindSearch/issues/181",
    "body": "I'm getting this error when I try to run pip install -r requirements.txt",
    "comments_url": "https://api.github.com/repos/InternLM/MindSearch/issues/181/comments",
    "author": "deniswsrosa",
    "comments": [
      {
        "user": "Nuclear6",
        "created_at": "2024-08-29T09:49:43Z",
        "body": "What system are you using? Mac doesn’t seem to match it. I installed Ubuntu successfully."
      }
    ]
  },
  {
    "number": 179,
    "title": "需要的python版本号是多少",
    "created_at": "2024-08-26T09:17:45Z",
    "closed_at": "2024-08-27T10:35:00Z",
    "labels": [],
    "url": "https://github.com/InternLM/MindSearch/issues/179",
    "body": null,
    "comments_url": "https://api.github.com/repos/InternLM/MindSearch/issues/179/comments",
    "author": "Lambert6",
    "comments": [
      {
        "user": "mengrennwpu",
        "created_at": "2024-08-27T02:56:55Z",
        "body": "@Lambert6 底层用的Lmdeploy框架，可以看看里面的torch要求，\"torch<=2.3.1,>=2.0.0\""
      },
      {
        "user": "Harold-lkk",
        "created_at": "2024-08-27T10:34:59Z",
        "body": "Python3.8 及以上应该都可以跑起来"
      }
    ]
  },
  {
    "number": 167,
    "title": "SearcherAgent基于internlm2_5-7b-chat在总结信息时给出的引用不正确",
    "created_at": "2024-08-18T03:20:03Z",
    "closed_at": "2024-08-26T03:06:01Z",
    "labels": [],
    "url": "https://github.com/InternLM/MindSearch/issues/167",
    "body": "在构建graph并add_node的过程中，SearcherAgent会通过工具search并select所关注的网页内容，然后基于select到的网页内容总结得出相应结论，并给出支撑的引用。但是观察输入给模型的prompt，以及模型输出汇总的结论及支撑的引用，发现给出的引用所对应的content并不包含能支撑相应结论的事实。对于这种情况是否是因为模型internlm2_5-7b-chat在做总结引用的能力还有所欠缺，后续还需要对模型在这方面再进一步的调优。当前这种问题会导致最终输出的结论的可信度下降。",
    "comments_url": "https://api.github.com/repos/InternLM/MindSearch/issues/167/comments",
    "author": "liam1985",
    "comments": [
      {
        "user": "liujiangning30",
        "created_at": "2024-08-26T03:05:58Z",
        "body": "Thanks for your advice. We will continue to optimize the ability of the InternLM series model on mindsearch."
      }
    ]
  },
  {
    "number": 157,
    "title": "Typo in mindsearch\\app.py\", line 26",
    "created_at": "2024-08-14T16:52:05Z",
    "closed_at": "2024-08-15T07:13:28Z",
    "labels": [],
    "url": "https://github.com/InternLM/MindSearch/issues/157",
    "body": "mindsearch\\app.py\", line 26, in parse_arguments\r\n    parse.add_argument('--search_engine',\r\n    ^^^^^\r\nNameError: name 'parse' is not defined. Did you mean: 'parser'?\r\n\r\n**Yes, it should be parser**.",
    "comments_url": "https://api.github.com/repos/InternLM/MindSearch/issues/157/comments",
    "author": "vanetreg",
    "comments": [
      {
        "user": "wangr0031",
        "created_at": "2024-08-15T01:57:37Z",
        "body": "I have create the pull request #159 "
      }
    ]
  },
  {
    "number": 151,
    "title": "duckduckgo 不是要翻墙才能用吗，各位怎么解决的",
    "created_at": "2024-08-13T18:39:20Z",
    "closed_at": "2024-08-26T03:08:24Z",
    "labels": [],
    "url": "https://github.com/InternLM/MindSearch/issues/151",
    "body": "duckduckgo 不是要翻墙才能用吗，各位怎么解决的",
    "comments_url": "https://api.github.com/repos/InternLM/MindSearch/issues/151/comments",
    "author": "xkkjiayou",
    "comments": [
      {
        "user": "mengrennwpu",
        "created_at": "2024-08-23T10:04:25Z",
        "body": "duckduckgo可以设置代理，也可以自己挂个梯子"
      },
      {
        "user": "songsh",
        "created_at": "2024-11-28T07:53:25Z",
        "body": "代理怎么设？"
      }
    ]
  },
  {
    "number": 147,
    "title": "Code Acceleration",
    "created_at": "2024-08-13T06:59:45Z",
    "closed_at": "2024-11-05T02:52:46Z",
    "labels": [],
    "url": "https://github.com/InternLM/MindSearch/pull/147",
    "body": null,
    "comments_url": "https://api.github.com/repos/InternLM/MindSearch/issues/147/comments",
    "author": "liujiangning30",
    "comments": [
      {
        "user": "VersaceXcodes",
        "created_at": "2024-08-18T17:08:09Z",
        "body": "just following up on this @liujiangning30 any updates? thanks"
      }
    ]
  },
  {
    "number": 145,
    "title": "When i change the tab and return to it the process starts from the begging (this in React client)",
    "created_at": "2024-08-12T17:19:27Z",
    "closed_at": "2024-08-14T11:56:08Z",
    "labels": [],
    "url": "https://github.com/InternLM/MindSearch/issues/145",
    "body": "When i change the tab and return to it the process starts from the begging (this in React client)",
    "comments_url": "https://api.github.com/repos/InternLM/MindSearch/issues/145/comments",
    "author": "MohamedAliRashad",
    "comments": [
      {
        "user": "liujiangning30",
        "created_at": "2024-08-13T02:15:56Z",
        "body": "SSE (Server-Sent Events) has mechanisms to handle page visibility and reconnection after interruptions. If you switch away from the page during an active request and then return, SSE might re-establish the connection, causing the request to be repeated."
      },
      {
        "user": "MohamedAliRashad",
        "created_at": "2024-08-13T10:17:57Z",
        "body": "This shouldn't happen"
      },
      {
        "user": "liujiangning30",
        "created_at": "2024-08-14T11:56:05Z",
        "body": "We'll resolve this issue in upcoming iterations"
      }
    ]
  },
  {
    "number": 141,
    "title": "fix 调整openai_api_base的填写格式 和 支持命令行模式下选择搜索引擎",
    "created_at": "2024-08-12T08:51:54Z",
    "closed_at": "2024-08-14T11:26:51Z",
    "labels": [],
    "url": "https://github.com/InternLM/MindSearch/pull/141",
    "body": "主要修复内容：\r\n1. 使用gpt4时指定openai地址的格式，添加说明信息\r\n2. 命令行启动后端服务，可以指定搜索引擎\r\n\r\n---\r\nMain repair content:\r\n1. When using gpt4, specify the format of the openai address and add explanatory information\r\n2. Start the backend service from the command line and specify the search engine",
    "comments_url": "https://api.github.com/repos/InternLM/MindSearch/issues/141/comments",
    "author": "wangr0031",
    "comments": [
      {
        "user": "Harold-lkk",
        "created_at": "2024-08-13T04:02:35Z",
        "body": "Thanks for your contribution!! We will review as soon as possible"
      }
    ]
  },
  {
    "number": 137,
    "title": "ValueError: 'Financial Data Analytics Aspects' is not in list",
    "created_at": "2024-08-11T16:07:24Z",
    "closed_at": "2024-08-23T06:23:22Z",
    "labels": [],
    "url": "https://github.com/InternLM/MindSearch/issues/137",
    "body": "**Model: gpt-4o**\r\n**Search term: teach financial data analytics with Generative AI**\r\n\r\n\r\nError message:\r\n\r\nValueError: 'Financial Data Analytics Aspects' is not in list\r\nTraceback:\r\nFile \"C:\\Users\\xz035\\AppData\\Roaming\\Python\\Python312\\site-packages\\streamlit\\runtime\\scriptrunner\\exec_code.py\", line 85, in exec_func_with_error_handling\r\n    result = func()\r\n             ^^^^^^\r\nFile \"C:\\Users\\xz035\\AppData\\Roaming\\Python\\Python312\\site-packages\\streamlit\\runtime\\scriptrunner\\script_runner.py\", line 576, in code_to_exec\r\n    exec(code, module.__dict__)\r\nFile \"R:\\MindSearch\\frontend\\mindsearch_streamlit.py\", line 319, in <module>\r\n    main()\r\nFile \"R:\\MindSearch\\frontend\\mindsearch_streamlit.py\", line 315, in main\r\n    display_chat_history()\r\nFile \"R:\\MindSearch\\frontend\\mindsearch_streamlit.py\", line 269, in display_chat_history\r\n    )).index(st.session_state[selected_node_key]))\r\n       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^",
    "comments_url": "https://api.github.com/repos/InternLM/MindSearch/issues/137/comments",
    "author": "CinderZhang",
    "comments": [
      {
        "user": "liujiangning30",
        "created_at": "2024-08-14T12:25:03Z",
        "body": "Any more detailed logs?"
      }
    ]
  },
  {
    "number": 112,
    "title": "'module' object is not callable 应该怎么解决？",
    "created_at": "2024-08-07T14:07:40Z",
    "closed_at": "2024-08-08T06:19:27Z",
    "labels": [],
    "url": "https://github.com/InternLM/MindSearch/issues/112",
    "body": "INFO:     127.0.0.1:52752 - \"POST /solve HTTP/1.1\" 500 Internal Server Error\r\nERROR:    Exception in ASGI application\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\26641\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\uvicorn\\protocols\\http\\httptools_impl.py\", line 399, in run_asgi\r\n    result = await app(  # type: ignore[func-returns-value]\r\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"C:\\Users\\26641\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\uvicorn\\middleware\\proxy_headers.py\", line 70, in __call__\r\n    return await self.app(scope, receive, send)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"C:\\Users\\26641\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fastapi\\applications.py\", line 1054, in __call__\r\n    await super().__call__(scope, receive, send)\r\n  File \"C:\\Users\\26641\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\starlette\\applications.py\", line 123, in __call__\r\n    await self.middleware_stack(scope, receive, send)\r\n  File \"C:\\Users\\26641\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\starlette\\middleware\\errors.py\", line 186, in __call__\r\n    raise exc\r\n  File \"C:\\Users\\26641\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\starlette\\middleware\\errors.py\", line 164, in __call__\r\n    await self.app(scope, receive, _send)\r\n  File \"C:\\Users\\26641\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\starlette\\middleware\\cors.py\", line 93, in __call__\r\n    await self.simple_response(scope, receive, send, request_headers=headers)\r\n  File \"C:\\Users\\26641\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\starlette\\middleware\\cors.py\", line 148, in simple_response\r\n    await self.app(scope, receive, send)\r\n  File \"C:\\Users\\26641\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\starlette\\middleware\\exceptions.py\", line 65, in __call__\r\n    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\r\n  File \"C:\\Users\\26641\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 64, in wrapped_app\r\n    raise exc\r\n  File \"C:\\Users\\26641\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 53, in wrapped_app\r\n    await app(scope, receive, sender)\r\n  File \"C:\\Users\\26641\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\starlette\\routing.py\", line 756, in __call__\r\n    await self.middleware_stack(scope, receive, send)\r\n  File \"C:\\Users\\26641\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\starlette\\routing.py\", line 776, in app\r\n    await route.handle(scope, receive, send)\r\n  File \"C:\\Users\\26641\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\starlette\\routing.py\", line 297, in handle\r\n    await self.app(scope, receive, send)\r\n  File \"C:\\Users\\26641\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\starlette\\routing.py\", line 77, in app\r\n    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\r\n  File \"C:\\Users\\26641\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 64, in wrapped_app\r\n    raise exc\r\n  File \"C:\\Users\\26641\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\starlette\\_exception_handler.py\", line 53, in wrapped_app\r\n    await app(scope, receive, sender)\r\n  File \"C:\\Users\\26641\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\starlette\\routing.py\", line 72, in app\r\n    response = await func(request)\r\n               ^^^^^^^^^^^^^^^^^^^\r\n  File \"C:\\Users\\26641\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fastapi\\routing.py\", line 278, in app\r\n    raw_response = await run_endpoint_function(\r\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"C:\\Users\\26641\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fastapi\\routing.py\", line 191, in run_endpoint_function\r\n    return await dependant.call(**values)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"C:\\Users\\26641\\MindSearch\\mindsearch\\app.py\", line 126, in run\r\n    agent = init_agent(lang=args.lang, model_format=args.model_format)\r\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"C:\\Users\\26641\\MindSearch\\mindsearch\\agent\\__init__.py\", line 27, in init_agent\r\n    llm = llm_cfg.pop('type')(**llm_cfg)\r\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"C:\\Users\\26641\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lagent\\llms\\lmdeploy_wrapper.py\", line 311, in __init__\r\n    self.client = lmdeploy.serve(\r\n                  ^^^^^^^^^^^^^^^\r\nTypeError: 'module' object is not callable\r\n",
    "comments_url": "https://api.github.com/repos/InternLM/MindSearch/issues/112/comments",
    "author": "2664165718",
    "comments": [
      {
        "user": "liujiangning30",
        "created_at": "2024-08-08T02:49:02Z",
        "body": "#99 "
      },
      {
        "user": "2664165718",
        "created_at": "2024-08-08T02:53:02Z",
        "body": "可他那个没说怎么解决啊，而且他的原因好像和我不一样"
      },
      {
        "user": "liujiangning30",
        "created_at": "2024-08-08T02:58:43Z",
        "body": "macOS暂不支持，模型服务依赖CUDA"
      }
    ]
  },
  {
    "number": 105,
    "title": "仅仅返回一个响应之后就没有响应了，llm对接的gpt-4o",
    "created_at": "2024-08-07T02:45:49Z",
    "closed_at": "2024-08-12T08:54:36Z",
    "labels": [],
    "url": "https://github.com/InternLM/MindSearch/issues/105",
    "body": "{\"response\": {\"type\": \"planner\", \"content\": \"\", \"state\": 0, \"actions\": [], \"response\": \"\", \"inner_steps\": [{\"role\": \"user\", \"content\": \"中国\"}], \"nodes\": {}, \"adjacency_list\": [], \"references\": {}, \"errmsg\": null, \"adj\": {}}, \"current_node\": null}",
    "comments_url": "https://api.github.com/repos/InternLM/MindSearch/issues/105/comments",
    "author": "boxter007",
    "comments": [
      {
        "user": "liujiangning30",
        "created_at": "2024-08-07T05:25:18Z",
        "body": "麻烦贴一下打印的日志"
      }
    ]
  },
  {
    "number": 103,
    "title": "添加Docker Compose快速启动指南并优化配置 / Add Docker Compose Quick Start Guide and Optimize Configuration",
    "created_at": "2024-08-06T10:15:58Z",
    "closed_at": "2024-08-12T03:31:31Z",
    "labels": [],
    "url": "https://github.com/InternLM/MindSearch/pull/103",
    "body": "各位维护者好，\r\n\r\n我这次提交主要是为项目增加了一个 Docker Compose 快速启动指南，同时也对相关配置做了些优化。这些改动的目的是让 MindSearch 的部署过程变得更简单，提升用户体验，希望能吸引更多潜在用户。\r\n\r\n主要更新如下：\r\n\r\n1. 在 README 里新加了 Docker Compose 快速启动的部分，里面有详细的使用说明。\r\n2. 优化了 docker-compose.yaml 文件，现在可以自动传递一些关键的环境变量了（比如 OPENAI_API_KEY 和 OPENAI_API_BASE）。\r\n3. 更新了 GPU 支持的说明文档，现在涵盖了 NVIDIA、AMD。\r\n4. 简化了日常使用的命令说明，应该会让用户用起来更顺手。\r\n5. 加入了中英双语支持，希望能让项目更国际化一些。\r\n\r\n我觉得这些更新应该能让我们的项目更容易上手和部署，对项目会有不少帮助。恳请各位抽空看看这些改动，如果有什么意见或建议，欢迎随时告诉我。\r\n\r\n感谢各位的时间和关注。\r\n\r\n---\r\n\r\nDear maintainers,\r\n\r\nI would like to propose adding a Docker Compose quick start guide to our project and optimizing the related configurations. These changes aim to simplify the deployment process of MindSearch, improve user experience, and expand our potential user base.\r\n\r\nKey changes include:\r\n\r\n1. Added a new Docker Compose quick start section in the README with clear usage instructions.\r\n2. Optimized the docker-compose.yaml file to support automatic passing of key environment variables (e.g., OPENAI_API_KEY and OPENAI_API_BASE).\r\n3. Updated documentation on GPU support, covering NVIDIA, AMD.\r\n4. Simplified command instructions for daily use to enhance user-friendliness.\r\n5. Introduced bilingual support (Chinese and English) to improve international accessibility.\r\n\r\nI believe these updates will significantly benefit our project by making it more accessible and easier to deploy. I would greatly appreciate your review and feedback on these changes.\r\n\r\nThank you for your time and consideration.",
    "comments_url": "https://api.github.com/repos/InternLM/MindSearch/issues/103/comments",
    "author": "lcolok",
    "comments": [
      {
        "user": "Harold-lkk",
        "created_at": "2024-08-07T04:00:37Z",
        "body": "Thanks for your contribution !!!! Very clear"
      },
      {
        "user": "Harold-lkk",
        "created_at": "2024-08-08T06:59:21Z",
        "body": "Apologize for the late reply, could you please change all the Chinese comments to English?"
      },
      {
        "user": "lcolok",
        "created_at": "2024-08-09T06:03:48Z",
        "body": "> Apologize for the late reply, could you please change all the Chinese comments to English?\r\n\r\nSure."
      },
      {
        "user": "lcolok",
        "created_at": "2024-08-09T06:40:36Z",
        "body": "> Apologize for the late reply, could you please change all the Chinese comments to English?\r\n\r\nHi @Harold-lkk,\r\n\r\nThanks for the feedback! I've made the following updates:\r\n\r\n1. Translated all comments to English in the Dockerfile and docker-compose.yaml.\r\n2. Expanded the README with more details, especially about CORS considerations.\r\n3. Added separate README files in both Chinese and English.\r\n4. Clarified current limitations and future plans for the Docker Compose setup.\r\n5. Suggested temporary workarounds for potential CORS issues.\r\n\r\nThese changes should make the setup more accessible and user-friendly. Let me know if you need any further modifications!"
      }
    ]
  },
  {
    "number": 99,
    "title": "TypeError: 'module' object is not callable",
    "created_at": "2024-08-05T13:27:00Z",
    "closed_at": "2024-08-07T03:06:24Z",
    "labels": [],
    "url": "https://github.com/InternLM/MindSearch/issues/99",
    "body": "运行 python -m mindsearch.app --lang en --model_format internlm_server\r\n出现：self.client = lmdeploy.serve(\r\n                  ^^^^^^^^^^^^^^^\r\nTypeError: 'module' object is not callable 错误",
    "comments_url": "https://api.github.com/repos/InternLM/MindSearch/issues/99/comments",
    "author": "ydniuyongjie",
    "comments": [
      {
        "user": "liujiangning30",
        "created_at": "2024-08-06T02:21:02Z",
        "body": "能贴一下完整的日志吗？"
      },
      {
        "user": "ydniuyongjie",
        "created_at": "2024-08-06T02:24:39Z",
        "body": "从哪里可以看到日志？\n\n\n\n\n\n\n\n\n---- Replied Message ----\n| From | ***@***.***> |\n| Date | 8/6/2024 10:21 |\n| To | ***@***.***> |\n| Cc | Tom ***@***.***>,\n***@***.***> |\n| Subject | Re: [InternLM/MindSearch] TypeError: 'module' object is not callable (Issue #99) |\n\n能贴一下完整的日志吗？\n\n—\nReply to this email directly, view it on GitHub, or unsubscribe.\nYou are receiving this because you authored the thread.Message ID: ***@***.***>"
      },
      {
        "user": "liujiangning30",
        "created_at": "2024-08-06T02:52:09Z",
        "body": "终端只打印了你贴的日志？"
      },
      {
        "user": "ydniuyongjie",
        "created_at": "2024-08-06T03:39:10Z",
        "body": "我看了提示，好像是找不到CUDA，可能是因为我的计算机不支持CUDA的原因吧。\n\n\n\n\n\n\n---- Replied Message ----\n| From | ***@***.***> |\n| Date | 8/6/2024 10:52 |\n| To | ***@***.***> |\n| Cc | Tom ***@***.***>,\n***@***.***> |\n| Subject | Re: [InternLM/MindSearch] TypeError: 'module' object is not callable (Issue #99) |\n\n终端只打印了你贴的日志？\n\n—\nReply to this email directly, view it on GitHub, or unsubscribe.\nYou are receiving this because you authored the thread.Message ID: ***@***.***>"
      }
    ]
  },
  {
    "number": 97,
    "title": "Feat: support docker-compose",
    "created_at": "2024-08-05T11:55:13Z",
    "closed_at": "2024-11-05T02:52:45Z",
    "labels": [],
    "url": "https://github.com/InternLM/MindSearch/pull/97",
    "body": null,
    "comments_url": "https://api.github.com/repos/InternLM/MindSearch/issues/97/comments",
    "author": "liujiangning30",
    "comments": [
      {
        "user": "jsrdcht",
        "created_at": "2024-08-10T19:52:37Z",
        "body": "We need docker-compose!"
      }
    ]
  },
  {
    "number": 96,
    "title": "internlm_client异常",
    "created_at": "2024-08-05T11:50:22Z",
    "closed_at": "2024-08-08T03:36:07Z",
    "labels": [],
    "url": "https://github.com/InternLM/MindSearch/issues/96",
    "body": "使用internlm_server启动是正常的，但是在其他机器上用lmdeploy部署完模型后，使用internlm_client，异常",
    "comments_url": "https://api.github.com/repos/InternLM/MindSearch/issues/96/comments",
    "author": "jiangix-paper",
    "comments": [
      {
        "user": "liujiangning30",
        "created_at": "2024-08-05T12:08:30Z",
        "body": "具体什么问题呢？model_name需要与用lmdeploy起服务时配置的模型名称保持一致"
      },
      {
        "user": "jiangix-paper",
        "created_at": "2024-08-07T01:52:56Z",
        "body": "已解决"
      }
    ]
  },
  {
    "number": 93,
    "title": "执行命令python -m mindsearch.app --lang en --model_format internlm_server一直在下载模型文件正常么？",
    "created_at": "2024-08-05T08:45:56Z",
    "closed_at": "2024-08-05T08:52:12Z",
    "labels": [],
    "url": "https://github.com/InternLM/MindSearch/issues/93",
    "body": "执行命令python -m mindsearch.app --lang en --model_format internlm_server一直在下载模型文件正常么？\r\n\r\nmodel-00002-of-00008.safetensors:  74%|██▏| 1.45G/1.95G [2:44:39<28:20, 294kB/s]\r\n\r\n\r\nmodel-00005-of-00008.safetensors:  66%|█▉ | 1.30G/1.98G [2:36:31<38:17, 296kB/s]\r\nmodel-00005-of-00008.safetensors:  73%|██▏| 1.45G/1.98G [2:44:52<30:02, 296kB/s]\r\nmodel-00007-of-00008.safetensors:  49%|▉ | 965M/1.98G [2:44:46<1:26:49, 195kB/s]\r\nmodel-00008-of-00008.safetensors:  55%|█ | 965M/1.75G [2:44:49<1:05:26, 200kB/s]\r\n",
    "comments_url": "https://api.github.com/repos/InternLM/MindSearch/issues/93/comments",
    "author": "sunshineywz123",
    "comments": [
      {
        "user": "Harold-lkk",
        "created_at": "2024-08-05T08:52:12Z",
        "body": "正常的 这个是从HF上下载模型"
      }
    ]
  },
  {
    "number": 83,
    "title": "我觉得这个产品的思路有点问题，建议产品多考虑一下专业行业的特定问题解答思路",
    "created_at": "2024-08-05T03:21:59Z",
    "closed_at": "2024-08-05T05:27:18Z",
    "labels": [],
    "url": "https://github.com/InternLM/MindSearch/issues/83",
    "body": "提出一个好问题，答案就解决一半。\r\n在问题的分析上，咱们的分析策略应该做成用户可以自己填写或者选择。\r\n也就是拆分问题的时候，直接让用户进行参与。\r\n因为很多人没办法把问题描述清楚。但是真正的核心问题，是可以被引导出来的。\r\n所以我的第一建议是，把用户的问题进行拆分后，让用户参与选择他需要的哪些纬度。\r\n\r\n就比如，我在写自媒体的口播稿子时，我需要尝试从不同的角度来变换我提问的问题。以保证我的这个问题上的关键词，能涵盖到搜索引擎上的关键词。\r\n通常变换的问句，确实能够提供新的搜索结果，而我就可以用这种近似的结果来相互佐证内容是否是一致。\r\n\r\n但是通常我要完成稿子时，需要我问到非常多具体的问题，我才能将我的稿子写的内容详实。\r\n比如我有一期视频讲医疗信息化的发展历史，我最开始的搜索问句是，：医疗信息化发展历史、医疗软件、医院信息化、医生工作站、医院HIS系统，通过这些关键词，我找到了大量的企业发布的营销文。你看到的是他们把关键词罗列到这些文章上，这些罗列到关键词，你根本无法和发展历史结合一起的。\r\n然后我的搜索策略就变成了，我需要找到一个类似教科书的东西，把医院信息系统从那一年发展的、发展了什么、出了什么政策、有什么软件公司参与、产品形态是什么，一年一年的找出来。\r\n这种就在教科书、医院信息化简史、一文读懂医院信息软件，这些关键词里可以看到。\r\n\r\n在这些书籍和文章里，我会针对感兴趣的内容，继续在搜素引擎里深挖。并且我在这里加入了时间的纬度。\r\n即，医疗信息化发展+2001年至2002年，这种格式。\r\n这个格式的好处在于，2000年百度才出来，至少在那几年，能写这种文章的人，写的东西言之有物。\r\n同时搜索出来的内容，天然的会有当时的特色。而且这些内容里，不会出现未来的产品和公司。我就能在时间线上，把产品、市场的发展逻辑理清楚。\r\n\r\n因为我这个问题，想要知道的是医疗信息化行业的发展。在各种关键词和结果的引导下，自然而然的就会发现行业里的头部垂直网站叫什么，在垂直网站里，确实有很多高质量、垂直的内容。但是也因为网站开发的早，里面的搜索引擎是非常差的。\r\n十几家的垂直网站，提供了丰富的内容，当然这些网站都是在2012年之后建立的。具体原因和互联网发展节点有关。\r\n\r\n然后我为了让整理出来的内容，更具有真实性，我还在图书馆网、期刊网、医疗信息网，类似这种网站上，寻找当时信息科主任发布的登报文章。在通过文章里的引用材料看自己整理的内容是否有偏差。\r\n\r\n最后的一步就是，在政府网站上，我需要知道最近20年的政策，如何引导市场的发展。\r\n因为在医院这个行业里，政府政策占绝对的主导。政策落地的时间和内容，对医院信息产品的影响也巨大。往往政策在制定时，就是各大行业头部公司的行业专家去协作的。所以分析企业产品的发布时间和政策的发布时间，就能得到比较有趣的观点。\r\n\r\n上面是我在做一个深度内容时的搜索流。\r\n讲这些的意思是，你的产品既然想到了要先思考问题是什么，那么其实是可以让我自己来填写我是怎么思考这些问题的。\r\n当然这个填写或者是选择的方法，产品设计上不难，技术实现上有待考证。\r\n\r\n我第二个想要讨论的点是，在垂直领域里做深度搜索，比现在同质化做广度搜索要更有钱景。\r\n上面讲到我在制作深度内容，并且以视频形式发布出去，在视频一发布的时候，我就获得了大量的粉丝关注。粉丝里面的构成和我当时预想的一样。有教这个行业的老师、在学这个行业的学生、应用这个软件的医院、给医院开发软件的公司老板、员工和想要在这个行业进行创业的创业者。这让我觉得，内容搜索或者说内容整理是一个有非常大的钱景。\r\n因为我们的社会里发展的太快了，稍微没在注意到网络上的新闻内容，过后你就很难在找到。然后就会有我这样把信息差给抹平的人，帮助人们来了解、学习这个行业。\r\n也就是我，我完全可以通过搜索，将一个我不懂的行业，变成我很懂的行业，然后通过我的二次讲解，让这个行业的人认为我是行业专家。\r\n在我和粉丝互动的过程中，粉丝的更多需求在于，想要我手上的资料。准确的说，想要我已经整理好的结构化的资料。\r\n这对于我来说，就变成了可以持续盈利的点。知识付费嘛，一份资料多少钱，一个社群多少钱。\r\n但是我知道，最有价值的是我对于这个事情的搜索思路，而不是我搜索了多少资料。\r\n\r\n然后我就尝试了很多大模型的搜索，kimi、星火、ChatGPT，这些确实有提高效率，但是并不能让我把搜索思路更好的展示给我的学员、粉丝。\r\n直到最近发现了秘塔的搜索，我感觉搜索似乎有那个味道了\r\n但是这仍然是将一个问题的答案，直接输出给我，只是结构化了答案的来源。\r\n而我看到你的产品，我觉得你的方向是对的，而且在落地垂直行业上，已经有了初步雏形。\r\n\r\n如果让我作为产品经理去改，我就会往B端垂直行业上去优化产品。\r\n针对问题所属的行业，问题的形变，问题的延伸做一个思的自定义调整过程。\r\n然后针对答案来源的网站、资料在进行一个自定义的总结的过程。\r\n当把一个问题调通之后，就可以针对现有的各个行业出专业版搜索。\r\n\r\n\r\n",
    "comments_url": "https://api.github.com/repos/InternLM/MindSearch/issues/83/comments",
    "author": "ssrsybz",
    "comments": [
      {
        "user": "Harold-lkk",
        "created_at": "2024-08-05T04:48:41Z",
        "body": "说的很深刻，这也是我们想发展的方向之一，就是怎么提供`这个事情的搜索思路` 怎么让模型知道或者通过辅助知道专业人士的`思维方式`。这个涉及到模型要从开始从模拟人说话到模拟人思考的过程，对齐到专业人士的思考方式，思考路径或者说学会你这个`深度思考`的逻辑。"
      }
    ]
  },
  {
    "number": 72,
    "title": "[TM][WARNING] [RejectInvalidRequests] Skipping invalid infer request for id 302726, code = 6",
    "created_at": "2024-08-03T12:53:33Z",
    "closed_at": "2024-08-14T11:49:35Z",
    "labels": [],
    "url": "https://github.com/InternLM/MindSearch/issues/72",
    "body": "Just run the mindSearch.app according to the README, and I always get the above error message in the server when I send any message from the web UI monitored by the NPM server.",
    "comments_url": "https://api.github.com/repos/InternLM/MindSearch/issues/72/comments",
    "author": "LuckFXY",
    "comments": [
      {
        "user": "Harold-lkk",
        "created_at": "2024-08-06T01:56:05Z",
        "body": "This is a warning, not an error. Do you run successfully?"
      },
      {
        "user": "zhtgyx",
        "created_at": "2024-08-22T05:16:33Z",
        "body": "I also encountered the same problem. After waiting, there was no response or result output on the page. Why is this?"
      }
    ]
  },
  {
    "number": 65,
    "title": "anyone succesfully ran on ubuntu 22.04 ?",
    "created_at": "2024-08-02T12:26:16Z",
    "closed_at": "2024-08-06T08:46:01Z",
    "labels": [],
    "url": "https://github.com/InternLM/MindSearch/issues/65",
    "body": "\r\nubuntu 22.04 Quadro RTX 5000 16G\r\n\r\nstill struggling  vanilla setup run. It makes a huge friction to start.",
    "comments_url": "https://api.github.com/repos/InternLM/MindSearch/issues/65/comments",
    "author": "MyraBaba",
    "comments": [
      {
        "user": "Harold-lkk",
        "created_at": "2024-08-05T02:02:40Z",
        "body": "What issue are you encountering?"
      },
      {
        "user": "XYZliang",
        "created_at": "2024-08-06T07:32:40Z",
        "body": "I easily run on Ubuntu24. Why not specify your exact issue?"
      },
      {
        "user": "MyraBaba",
        "created_at": "2024-08-06T08:46:01Z",
        "body": "except local model its working now. "
      }
    ]
  },
  {
    "number": 50,
    "title": "how to configure FastAPI",
    "created_at": "2024-08-01T16:31:44Z",
    "closed_at": "2024-08-02T04:48:07Z",
    "labels": [],
    "url": "https://github.com/InternLM/MindSearch/issues/50",
    "body": "A wonderful work, but I don't know which API_KEY should be configured.\r\nCould you give some instructions?\r\nThank you!",
    "comments_url": "https://api.github.com/repos/InternLM/MindSearch/issues/50/comments",
    "author": "WindZh03",
    "comments": [
      {
        "user": "Harold-lkk",
        "created_at": "2024-08-02T01:25:33Z",
        "body": "Using the default command, you do not need to configure anything. We use a free search engine and open-source LLM\r\n"
      },
      {
        "user": "WindZh03",
        "created_at": "2024-08-02T08:55:27Z",
        "body": "Sorry to bother you again.\r\nDon't I need to set the OPENAI_API_KEY and BING_API_KEY?"
      },
      {
        "user": "WindZh03",
        "created_at": "2024-08-02T09:02:47Z",
        "body": "I got it, thanks."
      }
    ]
  },
  {
    "number": 36,
    "title": "【BUG】AttributeError: 'NoneType' object has no attribute 'searcher_resp_queue'`",
    "created_at": "2024-08-01T06:21:03Z",
    "closed_at": "2024-08-02T05:30:39Z",
    "labels": [],
    "url": "https://github.com/InternLM/MindSearch/issues/36",
    "body": "\r\n`首先，我们需要计算从2024年3月23日到2024年8月1日的天数。这可以通过计算两个日期之间的天数差来实现。<|action_start|><|interpreter|>\r\n```python\r\nfrom datetime import datetime\r\n\r\n# 定义起始日期和结束日期\r\nstart_date = datetime(2024, 3, 23)\r\nend_date = datetime(2024, 8, 1)\r\n\r\n# 计算天数差\r\ndays_difference = (end_date - start_date).days\r\ndays_difference\r\n```\r\nERROR:mindsearch.agent.mindsearch_agent:Error executing code: \r\nTraceback (most recent call last):\r\n  File \"/Mindsearch/tmp/pycharm_project_829/mindsearch/agent/mindsearch_agent.py\", line 349, in run_command\r\n    assert plan_graph is not None\r\n           ^^^^^^^^^^^^^^^^^^^^^^\r\nAssertionError\r\nERROR:asyncio:Future exception was never retrieved\r\nfuture: <Future finished exception=AttributeError(\"'NoneType' object has no attribute 'searcher_resp_queue'\")>\r\nTraceback (most recent call last):\r\n  File \"/anaconda311/lib/python3.11/concurrent/futures/thread.py\", line 58, in run\r\n    result = self.fn(*self.args, **self.kwargs)\r\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Mindsearch/tmp/pycharm_project_829/mindsearch/app.py\", line 68, in sync_generator_wrapper\r\n    for response in agent.stream_chat(inputs):\r\n  File \"/Mindsearch/tmp/pycharm_project_829/mindsearch/agent/mindsearch_agent.py\", line 234, in stream_chat\r\n    yield from self._process_code(\r\n  File \"/Mindsearch/tmp/pycharm_project_829/mindsearch/agent/mindsearch_agent.py\", line 260, in _process_code\r\n    for node_name, node, adj in self.execute_code(\r\n  File \"/Mindsearch/tmp/pycharm_project_829/mindsearch/agent/mindsearch_agent.py\", line 368, in execute_code\r\n    item = self.local_dict.get('graph').searcher_resp_queue.get(\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nAttributeError: 'NoneType' object has no attribute 'searcher_resp_queue'\r\n`",
    "comments_url": "https://api.github.com/repos/InternLM/MindSearch/issues/36/comments",
    "author": "datalee",
    "comments": [
      {
        "user": "Harold-lkk",
        "created_at": "2024-08-01T06:39:19Z",
        "body": "这个是 InternLM 模型的问题，因为 InternLM 本身也具备代码解释器的功能 触发Token 也是 <|interpreter|> 所以有点串台了，我们实现的代码里没有对这个内容做兼容，如果能够运行代码，并且拿到返回实际也是能得到正确结果的"
      },
      {
        "user": "datalee",
        "created_at": "2024-08-01T06:43:53Z",
        "body": "> 这个是 InternLM 模型的问题，因为 InternLM 本身也具备代码解释器的功能 触发Token 也是 <|interpreter|> 所以有点串台了，我们实现的代码里没有对这个内容做兼容，如果能够运行代码，并且拿到返回实际也是能得到正确结果的\r\n\r\n我发现写的代码最后没有print(days_difference),会导致exec(cmd, globals(), self.local_dict)没有结果返回，所以出现了问题"
      },
      {
        "user": "datalee",
        "created_at": "2024-08-01T07:22:41Z",
        "body": "这块代码执行的内核能否改成jupyter的"
      },
      {
        "user": "Harold-lkk",
        "created_at": "2024-08-01T07:24:41Z",
        "body": "我们现在拿 graph 这个句柄比较 trick 是在相同进程运行代码然后是共享的local和global dict然后去local dict 拿我们想要的字段，改成jupyter 实现起来有点麻烦"
      },
      {
        "user": "Harold-lkk",
        "created_at": "2024-08-01T07:25:28Z",
        "body": "实际你在local dict  那days_difference 这个变量还是有的"
      },
      {
        "user": "Harold-lkk",
        "created_at": "2024-08-02T01:34:57Z",
        "body": "这个好像如果hardcode 判断graph相关的操作在不在生成代码中，切换不同的执行环境是可以在做到的，可以实验一下，提个 PR 呀"
      }
    ]
  },
  {
    "number": 33,
    "title": "no results are shown",
    "created_at": "2024-07-31T16:04:09Z",
    "closed_at": "2024-08-01T03:26:31Z",
    "labels": [],
    "url": "https://github.com/InternLM/MindSearch/issues/33",
    "body": "I tried a few english queries on the playground, it's busy for some time but then a blank page. \r\n",
    "comments_url": "https://api.github.com/repos/InternLM/MindSearch/issues/33/comments",
    "author": "tfriedel",
    "comments": [
      {
        "user": "CharryLee0426",
        "created_at": "2024-08-01T01:06:23Z",
        "body": "Check your back end logging info. It maybe an error occured. I can't run it successfully."
      },
      {
        "user": "Harold-lkk",
        "created_at": "2024-08-01T01:31:56Z",
        "body": "We apologize for the poor experience. Our current concurrency is very low, and we are not in a commercial deployment. The usage is indeed quite high at the moment, which is causing the slowness."
      },
      {
        "user": "Harold-lkk",
        "created_at": "2024-08-01T02:12:20Z",
        "body": "It's easy to build locally. If you encounter any issues, feel free to ask at any time."
      },
      {
        "user": "Harold-lkk",
        "created_at": "2024-08-01T03:03:12Z",
        "body": "Maybe try again."
      }
    ]
  },
  {
    "number": 30,
    "title": "请问模型的话可以用多模态模型来执行操作么？ 例如 internvl-4B or 8B",
    "created_at": "2024-07-31T13:29:30Z",
    "closed_at": "2024-08-01T01:28:29Z",
    "labels": [],
    "url": "https://github.com/InternLM/MindSearch/issues/30",
    "body": "如题，非常感谢你们做的所有优秀的工作！\r\n\r\nxoxo\r\n\r\nLiz",
    "comments_url": "https://api.github.com/repos/InternLM/MindSearch/issues/30/comments",
    "author": "MicFizzy",
    "comments": [
      {
        "user": "Harold-lkk",
        "created_at": "2024-07-31T13:54:44Z",
        "body": "还没测试过。如果指令跟随的可以的话，纯用语言是可以的，我们现在的搜索结果是不包含图像的，如果能把图像返回可能效果会更好"
      }
    ]
  },
  {
    "number": 28,
    "title": "如下",
    "created_at": "2024-07-31T12:15:10Z",
    "closed_at": "2024-08-01T02:16:00Z",
    "labels": [],
    "url": "https://github.com/InternLM/MindSearch/issues/28",
    "body": "\r\n怎么解决了\r\n这个不需要配置搜索引擎吗 \r\n例如search serper等",
    "comments_url": "https://api.github.com/repos/InternLM/MindSearch/issues/28/comments",
    "author": "hsjlyj",
    "comments": [
      {
        "user": "Harold-lkk",
        "created_at": "2024-07-31T13:09:40Z",
        "body": "能提供一下你终端的日志么，以及你的key 暴露了 可以编辑一下内容"
      },
      {
        "user": "Harold-lkk",
        "created_at": "2024-07-31T13:10:12Z",
        "body": "搜索引擎默认配置了一个免费的引擎，不用配置"
      },
      {
        "user": "hsjlyj",
        "created_at": "2024-08-01T00:25:53Z",
        "body": "已经删了 后续能支持更多api的接入吗 目前也没详细的配置方法 one-api这种接入方式还是很普遍的 能不能像openweb-ui那样填入base_url和api key自动识别模型 可以自由选择搜索引擎 "
      },
      {
        "user": "Harold-lkk",
        "created_at": "2024-08-01T01:01:26Z",
        "body": "将来会接入更多的API的，现在实际各家模型在单纯的对话api比较对齐 但是在一些调用工具这些不太一致，我们也能适配各家api"
      }
    ]
  },
  {
    "number": 27,
    "title": "支持docker部署",
    "created_at": "2024-07-31T12:00:11Z",
    "closed_at": "2024-07-31T14:41:02Z",
    "labels": [],
    "url": "https://github.com/InternLM/MindSearch/issues/27",
    "body": null,
    "comments_url": "https://api.github.com/repos/InternLM/MindSearch/issues/27/comments",
    "author": "wwjCMP",
    "comments": [
      {
        "user": "Harold-lkk",
        "created_at": "2024-07-31T13:10:54Z",
        "body": "我们已经提供了 dockerfile\r\n"
      }
    ]
  },
  {
    "number": 26,
    "title": "书生2.5-7b模型在引用上的幻觉问题",
    "created_at": "2024-07-31T08:48:56Z",
    "closed_at": "2024-07-31T14:40:52Z",
    "labels": [],
    "url": "https://github.com/InternLM/MindSearch/issues/26",
    "body": "下面是searcher的结果：\r\n`RAG（Retrieval-Augmented Generation）作为一种基于检索增强生成的技术，其未来发展方向主要集中在以下几个方面：\r\n\r\n1. **多模态支持**：\r\n   RAG不仅限于文本生成，还可以应用于多模态领域，如图像、音频等。通过结合不同类型的数据，RAG可以生成更加丰富和多样化的内容。例如，微软研究院的新方法GraphRAG便是在查询时执行提示词的增强，利用私有数据集创建知识图谱，并将图谱与机器学习一同用于增强生成过程[[1]]。\r\n\r\n2. **领域专长**：\r\n   RAG能够利用特定领域或组织的内部知识库，而无需重新训练模型。这使得它在处理垂直、专业领域的任务时表现出色。例如，RAG可以结合特定领域的知识库，生成更加精准和专业的内容[[9]]。\r\n\r\n3. **高效性**：\r\n   RAG通过访问外部知识库，避免了重新训练模型的成本和时间消耗，是一种经济高效的改进方法。未来，RAG可能会进一步优化检索和增强过程，提高生成效率和质量[[9]]。\r\n\r\n4. **长上下文生成**：\r\n   未来的RAG系统将利用长上下文生成的能力，以提升最终性能。通过结合检索和生成技术，RAG可以生成更加连贯和逻辑性强的文本，从而提高生成文本的质量[[2]]。\r\n\r\n5. **知识冲突和解决**：\r\n   RAG在处理多源信息时可能会遇到知识冲突的问题。未来，RAG可能会发展出更高级的冲突解决机制，以确保生成内容的准确性和一致性。例如，清华大学、西湖大学和香港中文大学联合发布的论文探讨了RAG大模型知识冲突的问题，并提出了相应的解决方案[[15]]。\r\n\r\n6. **技术优化和提升**：\r\n   未来的研究方向将关注开发更先进的方法来提升和应用RAG。例如，检索器和生成器之间的结合方法、优化提升技术等都是未来研究的重要方向[[2]]。\r\n\r\n综上所述，RAG未来的发展方向包括多模态支持、领域专长、高效性、长上下文生成、知识冲突解决以及技术优化和提升。这些方向将推动RAG在生成内容的质量、效率和多样性方面取得更大的进步。`\r\n\r\n",
    "comments_url": "https://api.github.com/repos/InternLM/MindSearch/issues/26/comments",
    "author": "datalee",
    "comments": [
      {
        "user": "datalee",
        "created_at": "2024-07-31T08:49:55Z",
        "body": "然后，下面是最后planner的结果：\r\n`RAG（Retrieval-Augmented Generation）作为一种基于检索增强生成的技术，其未来发展方向主要集中在以下几个方面：\r\n\r\n1. **多模态支持**：\r\n   RAG不仅限于文本生成，还可以应用于多模态领域，如图像、音频等。通过结合不同类型的数据，RAG可以生成更加丰富和多样化的内容。例如，微软研究院的新方法GraphRAG便是在查询时执行提示词的增强，利用私有数据集创建知识图谱，并将图谱与机器学习一同用于增强生成过程[[11]]。\r\n\r\n2. **领域专长**：\r\n   RAG能够利用特定领域或组织的内部知识库，而无需重新训练模型。这使得它在处理垂直、专业领域的任务时表现出色。例如，RAG可以结合特定领域的知识库，生成更加精准和专业的内容[[19]]。\r\n\r\n3. **高效性**：\r\n   RAG通过访问外部知识库，避免了重新训练模型的成本和时间消耗，是一种经济高效的改进方法。未来，RAG可能会进一步优化检索和增强过程，提高生成效率和质量[[19]]。\r\n\r\n4. **长上下文生成**：\r\n   未来的RAG系统将利用长上下文生成的能力，以提升最终性能。通过结合检索和生成技术，RAG可以生成更加连贯和逻辑性强的文本，从而提高生成文本的质量[[12]]。\r\n\r\n5. **知识冲突和解决**：\r\n   RAG在处理多源信息时可能会遇到知识冲突的问题。未来，RAG可能会发展出更高级的冲突解决机制，以确保生成内容的准确性和一致性。例如，清华大学、西湖大学和香港中文大学联合发布的论文探讨了RAG大模型知识冲突的问题，并提出了相应的解决方案[[25]]。\r\n\r\n6. **技术优化和提升**：\r\n   未来的研究方向将关注开发更先进的方法来提升和应用RAG。例如，检索器和生成器之间的结合方法、优化提升技术等都是未来研究的重要方向[[12]]。\r\n\r\n综上所述，RAG未来的发展方向包括多模态支持、领域专长、高效性、长上下文生成、知识冲突解决以及技术优化和提升。这些方向将推动RAG在生成内容的质量、效率和多样性方面取得更大的进步。`\r\n\r\n### **引用2变成了12,15变成了25等**"
      },
      {
        "user": "Harold-lkk",
        "created_at": "2024-07-31T11:41:03Z",
        "body": "这个引用 Index Search 和 Planner 确实不是一样的，因为Planner 要见到很多 Searcher 的返回结果，每个Seacher的索引都是从 0 开始的，所以我们把Searcher 的结果给到 Planner时修改了索引 ID"
      },
      {
        "user": "datalee",
        "created_at": "2024-08-01T03:12:51Z",
        "body": "> 这个引用 Index Search 和 Planner 确实不是一样的，因为Planner 要见到很多 Searcher 的返回结果，每个Seacher的索引都是从 0 开始的，所以我们把Searcher 的结果给到 Planner时修改了索引 ID\r\n\r\n那如何对应起来？"
      }
    ]
  },
  {
    "number": 25,
    "title": "MindSearch只有除了web的搜索能力，可以做本地搜索吗？比如当做本地RAG，搭配搜索文档、向量等",
    "created_at": "2024-07-31T07:45:53Z",
    "closed_at": "2024-08-01T10:47:19Z",
    "labels": [],
    "url": "https://github.com/InternLM/MindSearch/issues/25",
    "body": null,
    "comments_url": "https://api.github.com/repos/InternLM/MindSearch/issues/25/comments",
    "author": "LIUKAI0815",
    "comments": [
      {
        "user": "Harold-lkk",
        "created_at": "2024-07-31T08:05:34Z",
        "body": "这部分我们没有实现，如果把多智能体中的 WebSearch 换成一个 RAG 系统应该是可以做到本地搜索的。 WebSearch 基本等价于利用网络知识做 RAG "
      },
      {
        "user": "datalee",
        "created_at": "2024-07-31T10:13:55Z",
        "body": "> 这部分我们没有实现，如果把多智能体中的 WebSearch 换成一个 RAG 系统应该是可以做到本地搜索的。 WebSearch 基本等价于利用网络知识做 RAG\r\n\r\n其实不用了，直接只改search的地方就行"
      },
      {
        "user": "LIUKAI0815",
        "created_at": "2024-07-31T10:32:14Z",
        "body": "@datalee 改成本地的知识库吗？"
      },
      {
        "user": "datalee",
        "created_at": "2024-08-01T03:19:01Z",
        "body": "> @datalee 改成本地的知识库吗？\r\n\r\n改成你本地知识库上构建的搜索api"
      }
    ]
  },
  {
    "number": 18,
    "title": "the models not has auto download features ",
    "created_at": "2024-07-30T19:48:04Z",
    "closed_at": "2024-07-31T08:07:38Z",
    "labels": [],
    "url": "https://github.com/InternLM/MindSearch/issues/18",
    "body": "i run the server used all options , but the models was not start downloading , then i downloaded them using transformer also not loaded any help or walk through",
    "comments_url": "https://api.github.com/repos/InternLM/MindSearch/issues/18/comments",
    "author": "al-swaiti",
    "comments": [
      {
        "user": "Harold-lkk",
        "created_at": "2024-07-31T02:00:14Z",
        "body": "Thank for your report, we will check it as soon as possible"
      },
      {
        "user": "Harold-lkk",
        "created_at": "2024-07-31T02:04:24Z",
        "body": "We will not load the model until you call the API in frontend. Do you call the api in frontend or fastapi page?"
      },
      {
        "user": "Harold-lkk",
        "created_at": "2024-07-31T08:07:38Z",
        "body": "Close this issue for not replying. Feel free to reopen it."
      }
    ]
  }
]