[
  {
    "number": 18,
    "title": "missing arguments",
    "created_at": "2024-11-18T02:15:10Z",
    "closed_at": "2024-11-26T07:09:38Z",
    "labels": [],
    "url": "https://github.com/bytedance/dplm/issues/18",
    "body": "I followed the instructions to redo the training, but I found an error: TypeError: __init__() missing 2 required positional arguments: 'criterion' and 'optimizer'. How can I solve this problem? Thank you!",
    "comments_url": "https://api.github.com/repos/bytedance/dplm/issues/18/comments",
    "author": "Yangfan-YU",
    "comments": [
      {
        "user": "wxy-nlp",
        "created_at": "2024-11-18T14:19:35Z",
        "body": "Hi @Yangfan-YU,\r\nCould you please provide the full error information? Thank you!"
      },
      {
        "user": "Yangfan-YU",
        "created_at": "2024-11-19T03:31:43Z",
        "body": "Error executing job with overrides: ['experiment=lm/dplm_650m', 'name=dplm_650m', 'datamodule.max_tokens=8192', 'trainer.accumulate_grad_batches=16']\r\nTraceback (most recent call last):\r\n  File \"/dplm/src/byprot/utils/config.py\", line 132, in instantiate_from_config\r\n    return target_cls(**cfg, **override_kwargs)\r\n  File \"/dplm/src/byprot/tasks/lm/dplm.py\", line 62, in __init__\r\n    self.build_model()\r\n  File \"/dplm/src/byprot/tasks/lm/dplm.py\", line 85, in build_model\r\n    self.model = utils.instantiate_from_config(cfg=self.hparams.model, group='model')\r\n  File \"/dplm/src/byprot/utils/config.py\", line 135, in instantiate_from_config\r\n    return target_cls(cfg)\r\n  File \"/dplm/src/byprot/models/lm/dplm.py\", line 41, in __init__\r\n    self.net = get_net(cfg) if net is None else net\r\n  File \"/dplm/src/byprot/models/lm/model_utils.py\", line 61, in get_net\r\n    if cfg.net.pretrain:\r\n  File \"/miniconda3/envs/dplm/lib/python3.9/site-packages/omegaconf/dictconfig.py\", line 355, in __getattr__\r\n    self._format_and_raise(\r\n  File \"/miniconda3/envs/dplm/lib/python3.9/site-packages/omegaconf/base.py\", line 231, in _format_and_raise\r\n    format_and_raise(\r\n  File \"/miniconda3/envs/dplm/lib/python3.9/site-packages/omegaconf/_utils.py\", line 899, in format_and_raise\r\n    _raise(ex, cause)\r\n  File \"/miniconda3/envs/dplm/lib/python3.9/site-packages/omegaconf/_utils.py\", line 797, in _raise\r\n    raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace\r\n  File \"/miniconda3/envs/dplm/lib/python3.9/site-packages/omegaconf/dictconfig.py\", line 351, in __getattr__\r\n    return self._get_impl(\r\n  File \"/miniconda3/envs/dplm/lib/python3.9/site-packages/omegaconf/dictconfig.py\", line 442, in _get_impl\r\n    node = self._get_child(\r\n  File \"/miniconda3/envs/dplm/lib/python3.9/site-packages/omegaconf/basecontainer.py\", line 73, in _get_child\r\n    child = self._get_node(\r\n  File \"/miniconda3/envs/dplm/lib/python3.9/site-packages/omegaconf/dictconfig.py\", line 480, in _get_node\r\n    raise ConfigKeyError(f\"Missing key {key!s}\")\r\nomegaconf.errors.ConfigAttributeError: Missing key pretrain\r\n    full_key: model.net.pretrain\r\n    object_type=dict\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/dplm/train.py\", line 59, in main\r\n    return train(config)\r\n  File \"/dplm/src/byprot/training_pipeline.py\", line 53, in train\r\n    datamodule, pl_module, logger, callbacks = utils.common_pipeline(config)\r\n  File \"/dplm/src/byprot/utils/__init__.py\", line 227, in common_pipeline\r\n    pl_module: LightningModule = instantiate_from_config(\r\n  File \"/dplm/src/byprot/utils/config.py\", line 135, in instantiate_from_config\r\n    return target_cls(cfg)\r\nTypeError: __init__() missing 2 required positional arguments: 'criterion' and 'optimizer'\r\n\r\nSet the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace."
      },
      {
        "user": "wxy-nlp",
        "created_at": "2024-11-19T06:24:03Z",
        "body": "Hi @Yangfan-YU ,\r\nAccording to the error information you provided, the real error is here:\r\n```\r\nTraceback (most recent call last):\r\nFile \"/dplm/src/byprot/utils/config.py\", line 132, in instantiate_from_config\r\nreturn target_cls(**cfg, **override_kwargs)\r\nFile \"/dplm/src/byprot/tasks/lm/dplm.py\", line 62, in init\r\nself.build_model()\r\nFile \"/dplm/src/byprot/tasks/lm/dplm.py\", line 85, in build_model\r\nself.model = utils.instantiate_from_config(cfg=self.hparams.model, group='model')\r\nFile \"/dplm/src/byprot/utils/config.py\", line 135, in instantiate_from_config\r\nreturn target_cls(cfg)\r\nFile \"/dplm/src/byprot/models/lm/dplm.py\", line 41, in init\r\nself.net = get_net(cfg) if net is None else net\r\nFile \"/dplm/src/byprot/models/lm/model_utils.py\", line 61, in get_net\r\nif cfg.net.pretrain:\r\nFile \"/miniconda3/envs/dplm/lib/python3.9/site-packages/omegaconf/dictconfig.py\", line 355, in getattr\r\nself._format_and_raise(\r\nFile \"/miniconda3/envs/dplm/lib/python3.9/site-packages/omegaconf/base.py\", line 231, in _format_and_raise\r\nformat_and_raise(\r\nFile \"/miniconda3/envs/dplm/lib/python3.9/site-packages/omegaconf/_utils.py\", line 899, in format_and_raise\r\n_raise(ex, cause)\r\nFile \"/miniconda3/envs/dplm/lib/python3.9/site-packages/omegaconf/_utils.py\", line 797, in _raise\r\nraise ex.with_traceback(sys.exc_info()[2]) # set env var OC_CAUSE=1 for full trace\r\nFile \"/miniconda3/envs/dplm/lib/python3.9/site-packages/omegaconf/dictconfig.py\", line 351, in getattr\r\nreturn self._get_impl(\r\nFile \"/miniconda3/envs/dplm/lib/python3.9/site-packages/omegaconf/dictconfig.py\", line 442, in _get_impl\r\nnode = self._get_child(\r\nFile \"/miniconda3/envs/dplm/lib/python3.9/site-packages/omegaconf/basecontainer.py\", line 73, in _get_child\r\nchild = self._get_node(\r\nFile \"/miniconda3/envs/dplm/lib/python3.9/site-packages/omegaconf/dictconfig.py\", line 480, in _get_node\r\nraise ConfigKeyError(f\"Missing key {key!s}\")\r\nomegaconf.errors.ConfigAttributeError: Missing key pretrain\r\nfull_key: model.net.pretrain\r\nobject_type=dict\r\n```\r\nIn \r\n```\r\nFile \"/dplm/src/byprot/models/lm/dplm.py\", line 41, in init\r\nself.net = get_net(cfg) if net is None else net\r\n```\r\nThe `cfg` is not updated, and it should be `self.cfg`. \r\nThank you for pointing out this error, I have updated the code, you can pull the latest commit and try again."
      }
    ]
  },
  {
    "number": 14,
    "title": "Question regarding the time taken for training and what type of compute that's been used",
    "created_at": "2024-10-16T15:39:01Z",
    "closed_at": "2024-10-25T08:20:29Z",
    "labels": [],
    "url": "https://github.com/bytedance/dplm/issues/14",
    "body": "Hi,\r\nCan you please answer the following questions\r\n\r\n1. How much time is taken for the DPLM to get trained on the datasets mentioned ?\r\n2. What are the memory requirements and on what type of GPU that you've performed the training on ?",
    "comments_url": "https://api.github.com/repos/bytedance/dplm/issues/14/comments",
    "author": "haresh121",
    "comments": [
      {
        "user": "wxy-nlp",
        "created_at": "2024-10-25T08:20:29Z",
        "body": "Hi @haresh121,\r\nSorry for the late reply. The time and memory cost during training is as below:\r\n1) DPLM 150M: \r\n- batch size on one GPU: 10240 tokens\r\n- gradient accumulation: 2\r\n- number of GPUs: 16\r\n- total batch size: 320K tokens \r\n- CUDA memory cost on one GPU: ~40G\r\nusing config 'dplm_150m_stage2' costs ~**22 hours** for 100k updates on 16 A100 GPUs.\r\n2) DPLM 650M: \r\n- batch size on one GPU: 8192 tokens\r\n- gradient accumulation: 4\r\n- number of GPUs: 32\r\n- total batch size: 1M tokens\r\n- CUDA memory cost on one GPU: ~70G\r\nusing config 'dplm 650m stage2' costs ~**3days** for 100k updates on 32 A100 GPUs."
      }
    ]
  },
  {
    "number": 11,
    "title": "fintuning DPLM results in worse generation",
    "created_at": "2024-10-08T14:14:52Z",
    "closed_at": "2024-11-22T20:28:55Z",
    "labels": [],
    "url": "https://github.com/bytedance/dplm/issues/11",
    "body": "Hi,\r\n\r\nI simply loaded the pretrain weight and fine-tuned it on the same dataset, and got the ckpt that generates more repetitive sequences then I thought. This is quite bizarre to me. Is there something wrong with the current training code or the released ckpts are too good?\r\n\r\n\r\ncc @zhengzx-nlp @wxy-nlp @leiyu-bytedance @lark ",
    "comments_url": "https://api.github.com/repos/bytedance/dplm/issues/11/comments",
    "author": "pengzhangzhi",
    "comments": [
      {
        "user": "wxy-nlp",
        "created_at": "2024-10-10T09:07:17Z",
        "body": "hello @pengzhangzhi ,\r\n\r\ncould you provide the generation results and the way you load the checkpoint?\r\n\r\nBy the way, if you use the config yaml in `config/experiment/lm` and continue train from the pretrained weight, the learning rate is large, which may result in the large change of pretrained weight and lead to a bad performance. So if you want to continue train, the learning rate starts from the ending rate, i.e., 1e-5, may be better."
      },
      {
        "user": "pengzhangzhi",
        "created_at": "2024-10-10T15:56:46Z",
        "body": "Hi @wxy-nlp ,\r\n\r\nThanks!! \r\nI load the ckpt from the path:\r\n```\r\nc=dplm/byprot-checkpoints/dplm_150m_finetune_lr_1e-8/checkpoints/last.ckpt\r\npython generate.py --model_name \"airkingbd/${model_name}\"         --seq_lens 100 --saveto ${output_dir} --num_seqs 100\r\n```\r\n\r\n\r\nI tried to set a smaller LR even 1e-8, but the fine-tuning would gradually degrade the pLDDT. Below is the comparison between the base DPLM-150M and the fine-tuned DPLM-150M with LR 1e-8:\r\n```\r\npLDDT:\r\nBase \r\n 69.44743\r\nfinetune\r\n 66.5991\r\n\r\n```\r\nIf I use LR 1e-5 or something larger than 1e-8, the generation is completely broken... : (\r\nIf you want to verify, you can simply set the LR to be 1e-5, load the ckpt, and fine-tune the mode for a couple thousand steps. \r\n\r\nAlso, could you please share the configs for DPLM-150M with us? I remember in the paper, you employ a two-stage training, I wonder the hyper-params for the two stages and the training steps. Would love to reproduce your training.\r\n\r\n"
      },
      {
        "user": "OrangeCat7777777",
        "created_at": "2024-12-25T13:00:18Z",
        "body": "I encounted the same problem with a degraded plddt after finetuning with lr 1e-5. The validation loss and ppl are both decreasing during the finetuning process, so this is not reasonable for me. @pengzhangzhi have you figured out anything?"
      },
      {
        "user": "pengzhangzhi",
        "created_at": "2024-12-25T16:53:54Z",
        "body": "i wasnt loading the ckpt properly. "
      },
      {
        "user": "wxy-nlp",
        "created_at": "2024-12-26T10:21:35Z",
        "body": "> I encounted the same problem with a degraded plddt after finetuning with lr 1e-5. The validation loss and ppl are both decreasing during the finetuning process, so this is not reasonable for me. @pengzhangzhi have you figured out anything?\r\n\r\nHi @OrangeCat7777777, \r\n\r\nCould you please provide your script of training and inference? I tried to continue finetuning on the pretrained 150M DPLM with lr=1e-5 and lr_end=5e-6, and the pLDDT is about 72 in length 100 and 85 in length 200~500, which seems normal. There is a possible reason that the model is incorrectly loaded during inference."
      },
      {
        "user": "pengzhangzhi",
        "created_at": "2024-12-26T15:41:28Z",
        "body": "Can attest to @wxy-nlp . It works; u just have to load the ckpt properly in ur finetuning."
      }
    ]
  },
  {
    "number": 10,
    "title": "how to output attentions from dplm model ?",
    "created_at": "2024-10-08T11:17:02Z",
    "closed_at": "2024-10-10T08:49:27Z",
    "labels": [],
    "url": "https://github.com/bytedance/dplm/issues/10",
    "body": " I want  get attentions from dplm model , here is the code:\r\n\r\n```\r\nseq = 'ELQLVESGGGLVQPGGTQVTVSS'\r\nmodel_name = \"airkingbd/dplm_150m\"\r\ndplm = DiffusionProteinLanguageModel.from_pretrained(model_name)\r\ntokenizers =  dplm.tokenizer\r\ninputs = tokenizers.encode_plus(seq, return_tensors=\"pt\")\r\n# print(\"dplm: \", inputs)\r\noutputs = dplm.net.esm.forward(**inputs, output_attentions=True)\r\nprint(outputs)\r\n```\r\nhowerer, i get the error from ModifiedEsmModel：\r\n\r\n```\r\n byprot/models/lm/esm_dplm.py\", line 220, in forward\r\n    encoder_outputs = self.encoder(\r\n  File \"py39/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\r\npy39/lib/python3.9/site-packages/transformers/models/esm/modeling_esm.py\", line 633, in forward\r\n    all_self_attentions = all_self_attentions + (layer_outputs[1],)\r\nIndexError: tuple index out of range\r\n```\r\n\r\n",
    "comments_url": "https://api.github.com/repos/bytedance/dplm/issues/10/comments",
    "author": "done520",
    "comments": [
      {
        "user": "done520",
        "created_at": "2024-10-08T11:48:51Z",
        "body": "I  find some  change in  EsmSelfAttention and I want to know ：**What is the main purpose of this modification and change?**\r\n\r\n```\r\n# The original in EsmSelfAttention is\r\noutputs = (context_layer, attention_probs) if output_attentions else (context_layer,)\r\n\r\n# dplm  use ModifiedEsmSelfAttention:\r\noutputs = (context_layer,)\r\n\r\n```\r\n"
      },
      {
        "user": "wxy-nlp",
        "created_at": "2024-10-10T08:49:27Z",
        "body": "hi @done520 ,\r\nI made this modification in one of my previous debugs, since there is no need for `attention_probs` in the training and sampling, the modification is kept. If you need output attentions, you can modify this line to the original implementation. Sorry for the inconvenience caused to you."
      }
    ]
  },
  {
    "number": 7,
    "title": "Codes for evaluating Diversity and Novelty Metrics",
    "created_at": "2024-08-16T06:08:15Z",
    "closed_at": "2024-10-10T08:51:23Z",
    "labels": [],
    "url": "https://github.com/bytedance/dplm/issues/7",
    "body": "Despite of pLDDT and pTM, I want other metrics in the paper difficult to follow. It would be appreciated that you could provide details calculating pdb-TM and innerTM, as well as settings of sampling(Are there any different from pLDDT 500steps & 40 candidates).\r\nI've tried to calculate inner-TM myself(mean of 1560 pairs for 40 candidates) but collected much lower value than reported in the paper.",
    "comments_url": "https://api.github.com/repos/bytedance/dplm/issues/7/comments",
    "author": "hhhhh789",
    "comments": [
      {
        "user": "wxy-nlp",
        "created_at": "2024-09-07T17:19:53Z",
        "body": "Hello @hhhhh789, there must be something weird because I didn't get notified of your issue so sorry for the late reply. I have updated the script of calculating the TMscore, you can calculate the TMscore for diversity like this:\r\n```\r\nquery_dir=./generation-results/dplm_650m/esmfold_pdb\r\nreference_dir=./generation-results/dplm_650m/esmfold_pdb\r\n# or the path of all pdb files to calculate the novelty\r\n\r\npython cal_tmscore.py --query_dir ${query_dir} --ref_dir ${ref_dir} --cal_type diversity\r\n```\r\n\r\nAfter this you can see the `diversity` folder in the `./generation-results/dplm_650m/` path, and you can plot the diversity in the `analysis/uncond_analysis.ipynb`."
      }
    ]
  },
  {
    "number": 6,
    "title": " No module named 'yaml_config_override'",
    "created_at": "2024-08-15T23:18:35Z",
    "closed_at": "2024-09-08T04:57:57Z",
    "labels": [],
    "url": "https://github.com/bytedance/dplm/issues/6",
    "body": "representationlearning:\r\n when run  \"python scripts/training.py --config ...\" get errors：\r\n\r\n```\r\n    from yaml_config_override import add_arguments\r\nModuleNotFoundError: No module named 'yaml_config_override'\r\n\r\n```",
    "comments_url": "https://api.github.com/repos/bytedance/dplm/issues/6/comments",
    "author": "done520",
    "comments": [
      {
        "user": "wxy-nlp",
        "created_at": "2024-08-16T10:12:05Z",
        "body": "Hi done520,\r\n\r\nThanks for pointing this and we have updated the \"environment.sh\" for installing environment.\r\nYou do not need to install all the packages again and can just use\r\n`pip install yaml-config-override==0.5`\r\n to solve this problem."
      }
    ]
  }
]