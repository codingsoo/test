[
  {
    "number": 261,
    "title": "[Bug]: Can't set minimum similiarity to a decimal",
    "created_at": "2025-02-15T18:53:14Z",
    "closed_at": "2025-02-16T01:46:42Z",
    "labels": [
      "bug"
    ],
    "url": "https://github.com/glowingjade/obsidian-smart-composer/issues/261",
    "body": "### Describe the bug\n\nWhen trying to put a decimal point into `RAG->Minimum Similiarity` setting. This character is removed. Thus it is impossible to set correct Minimum similiarity value.\n\n### Steps to reproduce\n\n1. Open Settings\n2. Open Smart Composer settings\n3. Go to RAG section\n4. Find Minimum Similiarity setting\n5. Try to set it to a decimal value\n\n### Operating System\n\nWindows\n\n### Obsidian Version\n\n1.8.4\n\n### Obsidian Installer Version\n\n1.8.4\n\n### Smart Composer Version\n\n1.1.5\n\n### Screenshots\n\n_No response_\n\n### Error logs\n\n```shell\n\n```\n\n### Additional context\n\n_No response_",
    "comments_url": "https://api.github.com/repos/glowingjade/obsidian-smart-composer/issues/261/comments",
    "author": "HighPriest",
    "comments": [
      {
        "user": "glowingjade",
        "created_at": "2025-02-15T23:51:16Z",
        "body": "I'll fix this soon. Thanks for reporting this!"
      },
      {
        "user": "glowingjade",
        "created_at": "2025-02-16T01:57:43Z",
        "body": "fixed in 1.1.6"
      }
    ]
  },
  {
    "number": 240,
    "title": "add providers: deepseek, open router, azure openai, lm studio",
    "created_at": "2025-02-05T14:25:23Z",
    "closed_at": "2025-02-05T15:30:26Z",
    "labels": [],
    "url": "https://github.com/glowingjade/obsidian-smart-composer/pull/240",
    "body": "## Description\r\n\r\nAdded providers OpenRouter, Azure OpenAI, LM Studio.\r\n\r\n## Checklist before requesting a review\r\n- [x] I have reviewed the [guidelines for contributing](../CONTRIBUTING.md) to this repository.\r\n- [x] I have performed a self-review of my code\r\n- [x] I have performed a code linting check and type check (by running `npm run lint:check` and `npm run type:check`)\r\n",
    "comments_url": "https://api.github.com/repos/glowingjade/obsidian-smart-composer/issues/240/comments",
    "author": "glowingjade",
    "comments": [
      {
        "user": "valDuarte",
        "created_at": "2025-02-16T04:38:22Z",
        "body": "@glowingjade LM Studio supports only the following request methods:\r\n\r\n```\r\nGET  /v1/models  \r\nPOST /v1/chat/completions  \r\nPOST /v1/embeddings  \r\nPOST /v1/completions  \r\n```\r\nI'm encountering the following error in LM Studio when trying to add a custom embedding  model from LM Studio:\r\n```\r\n[DEBUG] Received request: OPTIONS to /v1/embeddings  \r\n[ERROR] Unexpected endpoint or method. (OPTIONS /v1/embeddings). Returning 200 anyway  \r\n```\r\nAnd, as a result , a connection error in Obsidian.\r\n\r\nActually, I don't know if this is the cause because I'm encountering the following error in the chat:\r\n```\r\n[DEBUG] Received request: OPTIONS to /v1/chat/completions\r\n[ERROR] 'messages' field is required\r\n```\r\n\r\nI'm using Obsidian 1.8.4 and LM Studio 0.3.9"
      },
      {
        "user": "glowingjade",
        "created_at": "2025-02-16T23:45:33Z",
        "body": "@valDuarte I've tested this and it works fine on my machine. Could you check two things:\r\n\r\n1. Is a model loaded in LM Studio?\r\n2. Can you test with curl in your terminal to verify the server is responding correctly?"
      }
    ]
  },
  {
    "number": 227,
    "title": "mention (@) key is not working",
    "created_at": "2025-01-29T05:02:16Z",
    "closed_at": "2025-01-29T07:32:36Z",
    "labels": [],
    "url": "https://github.com/glowingjade/obsidian-smart-composer/issues/227",
    "body": "I don't know why the mentioned key(@) is not working in my obsidian environment.\nBut when I typed the @ key, the smart composer window was turned off.\nI checked the shortcut list, but 'shift + 2(@)' was empty.\nCould you give me some advice to solve this issue?\n\nThank you in advance for your kind response.",
    "comments_url": "https://api.github.com/repos/glowingjade/obsidian-smart-composer/issues/227/comments",
    "author": "StarSailor27",
    "comments": [
      {
        "user": "glowingjade",
        "created_at": "2025-01-29T05:33:29Z",
        "body": "Could you share the error message from the developer console? This will help us diagnose the issue.\n\nTo access developer tools in Obsidian, you can either:\n- Use View > Toggle Developer Tools in the menu bar\n- Or press:\n  - Mac: `Cmd + Option + I`\n  - Windows: `Ctrl + Shift + I`"
      },
      {
        "user": "StarSailor27",
        "created_at": "2025-01-29T07:15:18Z",
        "body": "Thank you for your quick response.\n\nI found the reason for this issue.\nI checked the logs in developer tools.\nThere are some crashes with make.md plugin.\nI updated the make.md to the latest version.\nThen, this issue was solved. \n\nThanks.\n"
      },
      {
        "user": "glowingjade",
        "created_at": "2025-01-29T07:32:33Z",
        "body": "Thanks for confirming the solution!"
      }
    ]
  },
  {
    "number": 206,
    "title": "[improvement] Improper formatting of artifacts",
    "created_at": "2025-01-11T15:21:42Z",
    "closed_at": "2025-02-06T09:55:59Z",
    "labels": [],
    "url": "https://github.com/glowingjade/obsidian-smart-composer/issues/206",
    "body": "Sometimes, when there are multiple codeblocks in the response, the artifacts don't form or they form around text that were not supposed to be within codeblocks in the first place.",
    "comments_url": "https://api.github.com/repos/glowingjade/obsidian-smart-composer/issues/206/comments",
    "author": "shayonpal",
    "comments": [
      {
        "user": "glowingjade",
        "created_at": "2025-01-12T02:41:39Z",
        "body": "Hi, could you help us better understand this issue by providing:\r\n\r\n1. A specific example showing:\r\n   - The input/prompt you used\r\n   - What response you received\r\n   - How the artifacts were incorrectly formatted\r\n   - What formatting you expected instead\r\n\r\n2. Are there specific types of codeblocks or content that consistently trigger this issue?\r\n\r\n3. Could you share the steps to reliably reproduce this behavior? This would help us investigate and fix the problem more effectively."
      },
      {
        "user": "glowingjade",
        "created_at": "2025-02-06T09:55:59Z",
        "body": "Closing this issue for now. If you're still experiencing formatting issues, please feel free to reopen with examples showing the input, output, and expected formatting - this would help us investigate and improve the behavior. Thanks for reporting!"
      }
    ]
  },
  {
    "number": 204,
    "title": "Aggressively Truncated Ollama Submissions",
    "created_at": "2025-01-10T08:26:33Z",
    "closed_at": "2025-02-06T09:54:33Z",
    "labels": [],
    "url": "https://github.com/glowingjade/obsidian-smart-composer/issues/204",
    "body": "I have tried to configure the plugin to use a 64k context window before chunking, but I am consistently seeing \r\n```\r\ntime=2025-01-10T08:13:47.938Z level=WARN source=runner.go:129 msg=\"truncating input prompt\" limit=2048 prompt=7948 keep=5 new=2048\r\n[GIN] 2025/01/10 - 08:13:50 | 200 |  4.768963448s |      172.17.0.1 | POST     \"/v1/chat/completions\"\r\n```\r\n\r\nIf I connect to Gemini, I am able to send the entire prompt.\r\nIf I use MSTY I am able to send the entire prompt to my Ollama instance.\r\n\r\nThis points to some form of implementation error in the plugin.",
    "comments_url": "https://api.github.com/repos/glowingjade/obsidian-smart-composer/issues/204/comments",
    "author": "deveyus",
    "comments": [
      {
        "user": "glowingjade",
        "created_at": "2025-01-11T06:49:59Z",
        "body": "Thanks for reporting this. We use the OpenAI SDK to communicate with Ollama and we don't set any token limits - there's no default token limit in the SDK as far as I know.\r\n\r\nI'm not sure why this error occurs.\r\n\r\nTo help diagnose:\r\n1. What Ollama version are you using?\r\n2. Which specific Ollama model?\r\n3. Could you share a sample chat/completion request that gets truncated?"
      },
      {
        "user": "glowingjade",
        "created_at": "2025-02-06T09:54:33Z",
        "body": "Closing this issue since we haven't received the details to help diagnose the problem. If you're still experiencing this issue, please reopen with details about your Ollama model, and a sample request. Thanks for reporting!"
      }
    ]
  },
  {
    "number": 192,
    "title": "gemini does not have the gemini-exp-1206 option.",
    "created_at": "2025-01-06T19:53:56Z",
    "closed_at": "2025-01-07T01:39:19Z",
    "labels": [],
    "url": "https://github.com/glowingjade/obsidian-smart-composer/issues/192",
    "body": "gemini does not have the gemini-exp-1206 option.\r\n",
    "comments_url": "https://api.github.com/repos/glowingjade/obsidian-smart-composer/issues/192/comments",
    "author": "Wooden-Gear",
    "comments": [
      {
        "user": "kevin-on",
        "created_at": "2025-01-07T01:19:35Z",
        "body": "Hi, I've just added the option in PR #193. Thanks for your request."
      },
      {
        "user": "Wooden-Gear",
        "created_at": "2025-01-07T18:42:05Z",
        "body": "> Hi, I've just added the option in PR #193. Thanks for your request.\r\n\r\nThis plugin is very useful, but the adding and switching of models is not flexible enough. I hope that multiple custom models can be added for easier switching.\r\n"
      },
      {
        "user": "glowingjade",
        "created_at": "2025-01-11T06:54:39Z",
        "body": "> This plugin is very useful, but the adding and switching of models is not flexible enough. I hope that multiple custom models can be added for easier switching.\r\n\r\nIt's definitely on our roadmap. Thanks for the feedback!"
      }
    ]
  },
  {
    "number": 179,
    "title": "[FR] Rendering mathematical formula",
    "created_at": "2024-12-26T12:13:04Z",
    "closed_at": "2024-12-31T02:10:10Z",
    "labels": [],
    "url": "https://github.com/glowingjade/obsidian-smart-composer/issues/179",
    "body": "Hope the plugin can render mathematical formulas that appear in the answers.",
    "comments_url": "https://api.github.com/repos/glowingjade/obsidian-smart-composer/issues/179/comments",
    "author": "wwjCMP",
    "comments": [
      {
        "user": "kevin-on",
        "created_at": "2024-12-26T12:31:06Z",
        "body": "Hi! Is this feature request similar to what was discussed in #144 ?"
      },
      {
        "user": "wwjCMP",
        "created_at": "2024-12-26T14:04:51Z",
        "body": "> Hi! Is this feature request similar to what was discussed in #144 ?\r\n\r\nyesï¼Œit is. "
      },
      {
        "user": "kevin-on",
        "created_at": "2024-12-31T02:09:42Z",
        "body": "We will close this issue as it is a duplicate of #144. Thank you for the request."
      }
    ]
  },
  {
    "number": 176,
    "title": "RAG Feature Inoperable Due to Korean Document Encoding Error(í•œê¸€ ë¬¸ì„œ ì¸ì½”ë”© ì˜¤ë¥˜ë¡œ ì¸í•œ RAG ê¸°ëŠ¥ ë¯¸ì‘ë™ ë¬¸ì œ)",
    "created_at": "2024-12-20T08:46:30Z",
    "closed_at": "2025-02-06T09:39:19Z",
    "labels": [],
    "url": "https://github.com/glowingjade/obsidian-smart-composer/issues/176",
    "body": "smart composer ì—ì„œ valt chatì„ ì‹œë„í•˜ë©´ ì¸ë±ì‹± ì‘ì—…ì„ í•˜ë‹¤ê°€ ë„ì¤‘ì— ë©ˆì¶”ë©´ì„œ `invalid byte sequence for encoding \"UTF8\":0x00` ë©”ì‹œì§€ê°€ ë‚˜ì˜µë‹ˆë‹¤. ì €ì˜ ë¬¸ì„œë“¤ì€ ë‹¤ í•œêµ­ì–´ ê¸°ë°˜ì˜ ë¬¸ì„œì…ë‹ˆë‹¤. ì¸ë±ì‹± ë„ì¤‘ í•œê¸€ ì¸ì½”ë”©ì—ì„œ ë¬¸ì œê°€ ë°œìƒí•œ ê²ƒ ê°™ì€ë° ì˜µì‹œë””ì–¸ ë²„ì „ê³¼ smart composer ë²„ì „ ëª¨ë‘ ìµœì‹ ë²„ì „ì…ë‹ˆë‹¤. ì¢‹ì€ í”„ë¡œê·¸ë¨ ë„ˆë¬´ ê°ì‚¬í•œë°, ê¸°ëŒ€í–ˆë˜ RAGê°€ ì•ˆë˜ë‹ˆ ì•„ì‰½ìŠµë‹ˆë‹¤. ê³§ ë¬¸ì œê°€ í•´ê²°ë˜ê¸°ë¥¼ ê¸°ëŒ€í•´ ë´…ë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤.\r\n\r\n===\r\n\r\nWhen I attempt to use Valt Chat in Smart Composer, the indexing process stops midway and displays the message: `invalid byte sequence for encoding \"UTF8\":0x00`. All my documents are Korean-based, so it seems thereâ€™s an issue with Korean encoding during indexing. Both the Obsidian and Smart Composer versions are up to date. Thank you for such an excellent program, but itâ€™s disappointing that the RAG feature I was looking forward to isnâ€™t working. I hope the issue gets resolved soon. Thank you.",
    "comments_url": "https://api.github.com/repos/glowingjade/obsidian-smart-composer/issues/176/comments",
    "author": "gandareman",
    "comments": [
      {
        "user": "glowingjade",
        "created_at": "2024-12-21T02:58:22Z",
        "body": "í˜¹ì‹œ ì‚¬ìš©í•˜ê³  ê³„ì‹  ì„ë² ë”© ëª¨ë¸ì´ ì–´ë–»ê²Œ ë˜ì‹¤ê¹Œìš”?\r\n\r\n---\r\n\r\nWhat embedding model are you currently using?"
      },
      {
        "user": "glowingjade",
        "created_at": "2025-02-06T09:39:19Z",
        "body": "ì´ìŠˆì— ëŒ€í•œ ë‹µë³€ì„ ë°›ì§€ ëª»í•´ ì¼ë‹¨ ë‹«ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. ê°™ì€ ë¬¸ì œê°€ ê³„ì† ë°œìƒí•˜ì‹¤ ê²½ìš°, ì‚¬ìš©ì¤‘ì¸ ì„ë² ë”© ëª¨ë¸ ì •ë³´ì™€ í•¨ê»˜ ìƒˆë¡œìš´ ì´ìŠˆë¥¼ ì—´ì–´ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\n\n---\n\nI'll close this issue as we haven't received a response about the embedding model being used. Feel free to reopen or create a new issue with these details if you're still experiencing the encoding problem."
      }
    ]
  },
  {
    "number": 155,
    "title": "bug report: response error 400",
    "created_at": "2024-12-05T04:01:59Z",
    "closed_at": "2024-12-05T05:36:01Z",
    "labels": [],
    "url": "https://github.com/glowingjade/obsidian-smart-composer/issues/155",
    "body": "Hi,\r\n\r\nWhen I chat with smart composer, there're error responses occasionally.\r\nThe error message says all messages must have non-empty content, but I just used the chat same as usual.\r\n\r\n```\r\nplugin:smart-composer:294 Failed to generate response Error: 400 {\"type\":\"error\",\"error\":{\"type\":\"invalid_request_error\",\"message\":\"messages.13: all messages must have non-empty content except for the optional final assistant message\"}}\r\n    at Me.generate (plugin:smart-composer:27:14174)\r\n    at Ze.makeStatusError (plugin:smart-composer:27:6347)\r\n    at Ze.makeRequest (plugin:smart-composer:27:7258)\r\n    at async Lb.streamResponse (plugin:smart-composer:41:2531)\r\n    at async nL.streamResponse (plugin:smart-composer:70:6783)\r\n    at async eval (plugin:smart-composer:70:9022)\r\n    at async Object.mutationFn (plugin:smart-composer:294:4189)\r\n```",
    "comments_url": "https://api.github.com/repos/glowingjade/obsidian-smart-composer/issues/155/comments",
    "author": "hanbyul-kim",
    "comments": [
      {
        "user": "kevin-on",
        "created_at": "2024-12-05T05:21:45Z",
        "body": "Hi, this error occurs when there are consecutive user messages, resulting in an empty assistant message. This is resolved by #156 . Thanks for reporting the issue."
      },
      {
        "user": "hanbyul-kim",
        "created_at": "2024-12-05T05:35:34Z",
        "body": "Thank you. I'm looking forward to the update!"
      }
    ]
  },
  {
    "number": 136,
    "title": "[FR] Allow deletion of individual AI Chat responses in the chat window",
    "created_at": "2024-11-24T11:57:48Z",
    "closed_at": "2024-11-24T14:07:08Z",
    "labels": [],
    "url": "https://github.com/glowingjade/obsidian-smart-composer/issues/136",
    "body": "As title says. Sometimes the AI responses are not quite what you were looking for, or you realize you should rephrase the latest chat request and then retry. It would be good to be able to delete individual AI responses from the Chat window.\r\n\r\nApologies for all the suggestions, I'm not a coder, but finding this plugin super useful already and just seeing all of these features that I think would be really useful. Thanks for the hard work of implementing these!",
    "comments_url": "https://api.github.com/repos/glowingjade/obsidian-smart-composer/issues/136/comments",
    "author": "maxthraxx",
    "comments": [
      {
        "user": "kevin-on",
        "created_at": "2024-11-24T13:37:36Z",
        "body": "You can edit any of your previous messages in the chat history and resubmit them. The conversation will automatically clear from that point forward and generate a new AI response based on your updated text.\r\nWe appreciate all feedback as it helps us improve the experience. Happy to hear you're finding it helpful!"
      },
      {
        "user": "maxthraxx",
        "created_at": "2024-11-24T14:07:08Z",
        "body": "Ok thanks, you're right, I see how to do it now. Appreciated!"
      }
    ]
  },
  {
    "number": 135,
    "title": "[FR] Allow setting of maximum output tokens for AI Chat responses",
    "created_at": "2024-11-24T11:53:32Z",
    "closed_at": "2024-11-26T03:53:31Z",
    "labels": [],
    "url": "https://github.com/glowingjade/obsidian-smart-composer/issues/135",
    "body": "As title says. I am not sure what the max is now, but sometimes longer responses would be better for suggestions (more extensive editing capability).",
    "comments_url": "https://api.github.com/repos/glowingjade/obsidian-smart-composer/issues/135/comments",
    "author": "maxthraxx",
    "comments": [
      {
        "user": "kevin-on",
        "created_at": "2024-11-24T13:30:08Z",
        "body": "Currently we are using 4096 token limit for Anthropic models and other models have no set maximum. Claude 3.5 Sonnet and Haiku supports 8192 output tokens so maybe we can increase it."
      }
    ]
  },
  {
    "number": 124,
    "title": "Allow renaming of old stored chats in chat history",
    "created_at": "2024-11-22T00:40:59Z",
    "closed_at": "2024-11-27T05:41:12Z",
    "labels": [],
    "url": "https://github.com/glowingjade/obsidian-smart-composer/issues/124",
    "body": "As title says. Being able to rename the chats would be most helpful.",
    "comments_url": "https://api.github.com/repos/glowingjade/obsidian-smart-composer/issues/124/comments",
    "author": "maxthraxx",
    "comments": [
      {
        "user": "kevin-on",
        "created_at": "2024-11-22T01:01:27Z",
        "body": "Good idea. I'll implement this soon."
      }
    ]
  },
  {
    "number": 112,
    "title": "refactor: restructure model configuration and settings",
    "created_at": "2024-11-20T01:28:02Z",
    "closed_at": "2024-11-20T07:16:27Z",
    "labels": [],
    "url": "https://github.com/glowingjade/obsidian-smart-composer/pull/112",
    "body": "- Introduce new model configuration system with provider-specific settings\r\n- Add support for Ollama and OpenAI-compatible services\r\n- Reorganize model IDs to include provider prefix (e.g. openai/, anthropic/, groq/)\r\n- Update settings UI to show provider-specific configuration fields\r\n- Refactor LLM manager and providers to use new model configuration\r\n- Rename vector tables to match new model ID format\r\n- Add migration for vector table renaming\r\n- Model updates\r\n  - Add `claude-3.5-haiku` option for apply model\r\n  - Remove `llama3-8b (Groq)` option for apply model",
    "comments_url": "https://api.github.com/repos/glowingjade/obsidian-smart-composer/issues/112/comments",
    "author": "kevin-on",
    "comments": [
      {
        "user": "glowingjade",
        "created_at": "2024-11-20T02:42:11Z",
        "body": "When a user sets it to ollama or an OpenAI-compatible model but leaves options like base URL and model name empty, it would be good to handle and display specific error messages for these cases."
      }
    ]
  },
  {
    "number": 103,
    "title": "Feature request: Support for Third-Party API Providers like OpenRouter",
    "created_at": "2024-11-16T13:52:37Z",
    "closed_at": "2024-11-20T07:16:28Z",
    "labels": [],
    "url": "https://github.com/glowingjade/obsidian-smart-composer/issues/103",
    "body": "Hey! ğŸ‘‹ Currently, the plugin works great (seriously smooth experience!), but I'm looking for better ways to connect with alternative API providers like OpenRouter.\r\n\r\nCan you develop some configuration methods or guidelines for users who want to use non-official API endpoints? It would be super helpful to have a flexible setup that allows easy connection to different providers.",
    "comments_url": "https://api.github.com/repos/glowingjade/obsidian-smart-composer/issues/103/comments",
    "author": "wewewexiao2008",
    "comments": [
      {
        "user": "kevin-on",
        "created_at": "2024-11-16T14:19:18Z",
        "body": "Thanks for the feedback! We'll add support for custom OpenAI endpoints soon. We'll update this issue when ready."
      }
    ]
  }
]