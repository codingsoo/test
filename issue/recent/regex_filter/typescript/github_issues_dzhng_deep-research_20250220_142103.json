[
  {
    "number": 86,
    "title": "Update README.md",
    "created_at": "2025-02-14T13:31:53Z",
    "closed_at": "2025-02-17T01:02:15Z",
    "labels": [],
    "url": "https://github.com/dzhng/deep-research/pull/86",
    "body": "While I first look to this project, it is about 2k stars.\r\nNow it has over 11k start.\r\nSo I think we can add a github star history.",
    "comments_url": "https://api.github.com/repos/dzhng/deep-research/issues/86/comments",
    "author": "treeleaves30760",
    "comments": [
      {
        "user": "dzhng",
        "created_at": "2025-02-17T01:02:15Z",
        "body": "this is cool, although I think we are probably past peak growth so I rather leave this off haha"
      }
    ]
  },
  {
    "number": 85,
    "title": "Enhanced Error Handling in run.ts",
    "created_at": "2025-02-14T09:14:24Z",
    "closed_at": "2025-02-17T01:14:28Z",
    "labels": [],
    "url": "https://github.com/dzhng/deep-research/pull/85",
    "body": "- Improved error handling in src/run.ts.\r\n\r\n- Added specific try-catch blocks for better error isolation. Enhanced logging for different error scenarios.\r\n\r\n- Ensured proper cleanup by closing the readline interface in case of errors.",
    "comments_url": "https://api.github.com/repos/dzhng/deep-research/issues/85/comments",
    "author": "sakibint",
    "comments": [
      {
        "user": "dzhng",
        "created_at": "2025-02-17T01:14:28Z",
        "body": "thanks for this. the try/catch is actually a bit overkill here, the main run function is already quite minimal. what will happen is that any thrown errors will be caught on the last catch on `run()`, the try/catch just adds an extra log statement which imo isn't worth the extra complexity to the code."
      }
    ]
  },
  {
    "number": 78,
    "title": "add .nvmrc (specify node version)",
    "created_at": "2025-02-12T14:45:07Z",
    "closed_at": "2025-02-17T01:02:39Z",
    "labels": [],
    "url": "https://github.com/dzhng/deep-research/pull/78",
    "body": "This allows users to simply run `nvm use && pnpm start` to start the program without worrying about the Node.js version.",
    "comments_url": "https://api.github.com/repos/dzhng/deep-research/issues/78/comments",
    "author": "guzus",
    "comments": [
      {
        "user": "dzhng",
        "created_at": "2025-02-17T01:02:37Z",
        "body": "thanks!"
      }
    ]
  },
  {
    "number": 70,
    "title": "docker and readme tweaks",
    "created_at": "2025-02-11T17:27:16Z",
    "closed_at": "2025-02-11T19:33:20Z",
    "labels": [],
    "url": "https://github.com/dzhng/deep-research/pull/70",
    "body": "Resubmitting this because my original PR introduced unnecessary changes that broke running deep-research on the host machine. The docker compose service was already mostly working, just tweaked the `docker-compose.yml` so that the `output.md` gets placed in the root directory as if it were running on the host machine. Also tweaked the README to make running the docker service a little more clearer. ",
    "comments_url": "https://api.github.com/repos/dzhng/deep-research/issues/70/comments",
    "author": "rowellz",
    "comments": [
      {
        "user": "dzhng",
        "created_at": "2025-02-11T19:32:39Z",
        "body": "thank you! I'm going to to change default model back to o3 just so that people who do have access sees potential right away (I'll build a better fallback in the future so it's smarter about this). but great work!"
      }
    ]
  },
  {
    "number": 68,
    "title": "Update README.md",
    "created_at": "2025-02-11T14:46:07Z",
    "closed_at": "2025-02-11T19:38:23Z",
    "labels": [],
    "url": "https://github.com/dzhng/deep-research/pull/68",
    "body": "fix: correct typos in documentation\r\n\r\n- Replace \"overtime\" with \"over time\": The term \"overtime\" typically refers to extra working hours, whereas \"over time\" correctly conveys the idea of gradual progression.\r\n\r\n- Replace \"sometime\" with \"sometimes\": \"Sometimes\" is the correct adverb form to indicate occasional occurrence, ensuring clarity in the documentation.",
    "comments_url": "https://api.github.com/repos/dzhng/deep-research/issues/68/comments",
    "author": "CharlesCNorton",
    "comments": [
      {
        "user": "dzhng",
        "created_at": "2025-02-11T19:38:21Z",
        "body": "thanks!"
      }
    ]
  },
  {
    "number": 60,
    "title": "Feature/shared docker volume and subfolder for saved reports",
    "created_at": "2025-02-10T17:39:41Z",
    "closed_at": "2025-02-11T19:35:04Z",
    "labels": [],
    "url": "https://github.com/dzhng/deep-research/pull/60",
    "body": "## Problems\r\n- Reports were not saved locally when using docker\r\n- Report file names were not unique\r\n\r\n## Solutions\r\n- A shared volume for all saved reports (`./reports`)\r\n- Unique path-safe file names that match the report title",
    "comments_url": "https://api.github.com/repos/dzhng/deep-research/issues/60/comments",
    "author": "AslanGoldenhour",
    "comments": [
      {
        "user": "0xDaksh",
        "created_at": "2025-02-10T23:43:23Z",
        "body": "Yeah, I was just gonna make a pr for this. Big issue if running from docker."
      },
      {
        "user": "dzhng",
        "created_at": "2025-02-11T19:35:04Z",
        "body": "latest updates fixes this"
      }
    ]
  },
  {
    "number": 59,
    "title": "Optimize Docker caching by reordering COPY and npm install steps",
    "created_at": "2025-02-10T17:08:37Z",
    "closed_at": "2025-02-11T19:34:52Z",
    "labels": [],
    "url": "https://github.com/dzhng/deep-research/pull/59",
    "body": "Changes Made:\r\n\r\n    Reordered COPY commands to copy package.json and package-lock.json first.\r\n    Moved npm install before copying the rest of the files to leverage Docker's layer caching.\r\n    Ensured that dependencies are only reinstalled when package.json changes and not for every minor change\r\n    in the repo, reducing build times.\r\n\r\nWhy This Change?\r\n\r\n  Previously, any change in the source code would trigger npm install, even if dependencies remained the same. \r\n  This optimization  ensures that dependencies are only reinstalled when necessary, \r\n  improving Docker build efficiency specially as the project scales and accumulates more dependencies.",
    "comments_url": "https://api.github.com/repos/dzhng/deep-research/issues/59/comments",
    "author": "H-C-21",
    "comments": [
      {
        "user": "dzhng",
        "created_at": "2025-02-11T19:34:52Z",
        "body": "pls see latest changes for docker config, I don't think this is needed anymore (although pls reopen if I'm wrong here)"
      }
    ]
  },
  {
    "number": 48,
    "title": "Progress Bar Improvements for Deep Research",
    "created_at": "2025-02-09T20:11:32Z",
    "closed_at": "2025-02-10T05:32:52Z",
    "labels": [],
    "url": "https://github.com/dzhng/deep-research/pull/48",
    "body": "\r\n## Changes Made\r\n- Added fixed-position progress bars at bottom of terminal\r\n- Implemented horizontal layout with color-coded indicators\r\n- Created OutputManager for coordinated console/progress output\r\n- Fixed terminal resize handling and cursor management\r\n- Added real-time progress updates during research\r\n\r\n## Technical Details\r\n- Terminal-safe output handling with ANSI escape sequences\r\n- Dynamic width calculation based on terminal size\r\n- Clean separation between progress and regular output\r\n- Improved API configuration and environment variables\r\n\r\n## Testing\r\n✅ Tested with:\r\n- Multiple research queries including \"Yalova history\"\r\n- Various terminal sizes and resize operations\r\n- API integration with gpt-4o model\r\n- Turkish language support\r\n- Progress tracking accuracy\r\n- Terminal output coordination\r\n\r\n## Implementation\r\n- New OutputManager class for centralized output control\r\n- Updated deep-research.ts for progress tracking\r\n- Modified run.ts for improved terminal handling\r\n- Added proper error handling and cleanup\r\n\r\nProgress Bar:\r\nDepth:    [██████████                    ] 33%\r\nBreadth:  [███████████████               ] 50%\r\nQueries:  [██████                        ] 20%\r\nCurrent:  Historical influence...",
    "comments_url": "https://api.github.com/repos/dzhng/deep-research/issues/48/comments",
    "author": "U-C4N",
    "comments": [
      {
        "user": "dzhng",
        "created_at": "2025-02-10T05:32:44Z",
        "body": "this looks cool! thanks!"
      }
    ]
  },
  {
    "number": 40,
    "title": "Using self-hosted Firecrawl",
    "created_at": "2025-02-09T05:28:16Z",
    "closed_at": "2025-02-09T05:43:48Z",
    "labels": [],
    "url": "https://github.com/dzhng/deep-research/issues/40",
    "body": "I've got Firecrawl setup locally, and it works for scraping and extracting, but it doesn't have search which it appears deep-research is using.  Has anyone found a work around for this?",
    "comments_url": "https://api.github.com/repos/dzhng/deep-research/issues/40/comments",
    "author": "JackrabbitTek",
    "comments": [
      {
        "user": "AlexB1337",
        "created_at": "2025-02-09T13:54:27Z",
        "body": "@JackrabbitTek  how did you solve it?"
      },
      {
        "user": "JackrabbitTek",
        "created_at": "2025-02-09T17:41:43Z",
        "body": "Turns out it was on Firecrawl side, it was actually working, but I was getting google search errors, which means I have to get a search API."
      }
    ]
  },
  {
    "number": 36,
    "title": "Expand instructions for local LLM integration",
    "created_at": "2025-02-08T23:47:20Z",
    "closed_at": "2025-02-09T01:45:42Z",
    "labels": [],
    "url": "https://github.com/dzhng/deep-research/pull/36",
    "body": "Adds instructions to setup section for configuring to use LM Studio or other local LLMs that provide an OpenAI-compatible API. Addresses #8 about LM Studio compatibility.",
    "comments_url": "https://api.github.com/repos/dzhng/deep-research/issues/36/comments",
    "author": "vekoada",
    "comments": [
      {
        "user": "dzhng",
        "created_at": "2025-02-09T01:45:49Z",
        "body": "Tbank you for this!"
      }
    ]
  },
  {
    "number": 34,
    "title": "Enhance text-splitter.test.ts with better coverage and maintainability",
    "created_at": "2025-02-08T20:29:05Z",
    "closed_at": "2025-02-09T03:31:20Z",
    "labels": [],
    "url": "https://github.com/dzhng/deep-research/pull/34",
    "body": "## Problem\r\nThe current test file for the text splitter (`src/ai/text-splitter.test.ts`) had several limitations:\r\n- Lacked comprehensive test coverage for edge cases\r\n- Had repeated code setup in multiple test cases\r\n- Missing explanatory comments for test scenarios\r\n- Limited assertion coverage for boundary conditions\r\n\r\n## Changes Made\r\n1. **Improved Test Coverage:**\r\n   - Added new test cases for special characters and large texts\r\n   - Added boundary condition tests for chunkSize and chunkOverlap\r\n   - Enhanced existing test cases with more assertions\r\n\r\n2. **Code Refactoring:**\r\n   - Extracted common setup code into `beforeEach` block\r\n   - Improved variable naming for better clarity\r\n   - Added descriptive comments explaining test scenarios\r\n\r\n3. **Better Error Handling:**\r\n   - Added explicit test for invalid configuration (chunkSize equal to chunkOverlap)\r\n   - Enhanced assertion messages for better debugging\r\n\r\n## Testing\r\n- All existing tests pass\r\n- New test cases validate edge scenarios\r\n- Boundary conditions are properly tested\r\n\r\n## Related Issues\r\nCloses #[issue_number] (if applicable)",
    "comments_url": "https://api.github.com/repos/dzhng/deep-research/issues/34/comments",
    "author": "wowrakibul",
    "comments": [
      {
        "user": "dzhng",
        "created_at": "2025-02-09T03:31:26Z",
        "body": "nice! thanks!"
      }
    ]
  },
  {
    "number": 33,
    "title": "chore: update deep-research.ts",
    "created_at": "2025-02-08T19:29:02Z",
    "closed_at": "2025-02-08T21:08:36Z",
    "labels": [],
    "url": "https://github.com/dzhng/deep-research/pull/33",
    "body": "infromation -> information",
    "comments_url": "https://api.github.com/repos/dzhng/deep-research/issues/33/comments",
    "author": "eltociear",
    "comments": [
      {
        "user": "dzhng",
        "created_at": "2025-02-08T21:08:33Z",
        "body": "Good catch! Thanks!"
      }
    ]
  },
  {
    "number": 32,
    "title": "Use Azure Open AI models",
    "created_at": "2025-02-08T17:54:43Z",
    "closed_at": "2025-02-09T03:46:53Z",
    "labels": [],
    "url": "https://github.com/dzhng/deep-research/issues/32",
    "body": "404 error resource not found when attempting to use azure open ai endpoint and o3-mini model. ",
    "comments_url": "https://api.github.com/repos/dzhng/deep-research/issues/32/comments",
    "author": "AlexB1337",
    "comments": [
      {
        "user": "dzhng",
        "created_at": "2025-02-09T03:33:49Z",
        "body": "I think you may need to use an azure specific endpoint and model string, I'm not super familiar with how azure is setup but I do know it's not a simple switching over of endpoint"
      }
    ]
  },
  {
    "number": 28,
    "title": "how to train model with RL",
    "created_at": "2025-02-08T09:35:04Z",
    "closed_at": "2025-02-09T03:50:00Z",
    "labels": [],
    "url": "https://github.com/dzhng/deep-research/issues/28",
    "body": "thanks for your great work. \n\ni wonder how openai train o3 model with rl for this deep research? i see your implementation needs tree-structure search process but not chain-structure, could this kind of structure be utilized for rl process?\n",
    "comments_url": "https://api.github.com/repos/dzhng/deep-research/issues/28/comments",
    "author": "David-Lee-1990",
    "comments": [
      {
        "user": "dzhng",
        "created_at": "2025-02-09T03:50:00Z",
        "body": "sorry but this is a bit beyond the scope of this repo. I'm not familiar enough with the reasoning models' RL process to answer this."
      }
    ]
  },
  {
    "number": 26,
    "title": "[Locally Hosted] Timeout Issue with Local LLMs",
    "created_at": "2025-02-08T05:02:32Z",
    "closed_at": "2025-02-09T17:38:28Z",
    "labels": [],
    "url": "https://github.com/dzhng/deep-research/issues/26",
    "body": "### **Issue:** \n\nRunning deep-research using firecrawl API and LM studio endpoint using the deepseek-r1-distill-llama-8b model. Timeout happens at about 30 seconds. \n\n```Ran What is the current state of lunar regolith composition and its implications for future space exploration, found 5 contents\nError running query: What is the current state of lunar regolith composition and its implications for future space exploration:  \n\nDOMException [TimeoutError]: The operation was aborted due to timeout  \n    at node:internal/deps/undici/undici:12625:11  \n    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)  \n    at postToApi (/app/node_modules/@ai-sdk/provider-utils/src/post-to-api.ts:65:22)  \n    at OpenAIChatLanguageModel.doGenerate (/app/node_modules/@ai-sdk/openai/src/openai-chat-language-model.ts:367:50)  \n    at fn (/app/node_modules/ai/core/generate-object/generate-object.ts:489:32)  \n    at <anonymous> (/app/node_modules/ai/core/telemetry/record-span.ts:18:22)  \n    at _retryWithExponentialBackoff (/app/node_modules/ai/util/retry-with-exponential-backoff.ts:36:12)  \n    at fn (/app/node_modules/ai/core/generate-object/generate-object.ts:457:34)  \n    at <anonymous> (/app/node_modules/ai/core/telemetry/record-span.ts:18:22)  \n    at processSerpResult (/app/src/deep-research.ts:86:15)\n```\nLM Studio log\n```\n2025-02-08 13:55:46 [DEBUG] PromptProcessing: 22.7597\n2025-02-08 13:55:50 [DEBUG] PromptProcessing: 23.7942\n2025-02-08 13:55:52  [INFO] [LM STUDIO SERVER] Client disconnected. Stopping generation... (If the model is busy processing the prompt, it will finish first.)\n```\n### **Steps Taken to Fix:**\nI'm not a TS dev so I did what I could. I removed the timeouts and abort signal code in deep-research.ts, but that did nothing. Extended timeouts and abort signals, also nothing.  \n\n### **Potential Reason:**\n\nIt obviously is expecting an openai response which is much faster than a local LLM can provide. I assume the fetch in postToApi has a default timeout also, which is why removing timeouts in deep-research.ts didn't work. \n\nUnfortunately, I don't have the skills/expertise in this area to troubleshoot further. I already spent 125 credits trying. ",
    "comments_url": "https://api.github.com/repos/dzhng/deep-research/issues/26/comments",
    "author": "Explosivedoor",
    "comments": [
      {
        "user": "FeindorT",
        "created_at": "2025-02-08T17:56:19Z",
        "body": "Had the same Issue when running the model with deepseek-r1:32b. For me setting\n```javascript\nabortSignal: AbortSignal.timeout(6_000_000),\n````\nin deep-research.ts fixed it"
      },
      {
        "user": "Explosivedoor",
        "created_at": "2025-02-08T18:32:09Z",
        "body": "> Had the same Issue when running the model with deepseek-r1:32b. For me setting\n> \n> abortSignal: AbortSignal.timeout(6_000_000),\n> in deep-research.ts fixed it\n\nUnfortunately, this still didn't work. It did however get further along before failing. I also tried to set the timeout to be much longer, still didn't work. This might work for those with faster computers. The outputs don't take longer than a minute or 2 so, theoretically that timeout should work but doesn't. \n\nLM Studio log\n```2025-02-09 03:16:07 [DEBUG] PromptProcessing: 100\nFinishedProcessingPrompt. Progress: 100\n2025-02-09 03:16:07  [INFO] [LM STUDIO SERVER] Accumulating tokens ... (stream = false)\n2025-02-09 03:16:07 [DEBUG] [deepseek-r1-distill-llama-8b] Accumulated 1 tokens {\\n\n...\n2025-02-09 03:16:16  [INFO] [LM STUDIO SERVER] Client disconnected. Stopping generation... (If the model is busy processing the prompt, it will finish first.)\n```\n\nSame error as in original post. \n"
      },
      {
        "user": "Explosivedoor",
        "created_at": "2025-02-09T17:38:28Z",
        "body": "This does in fact work. I am just an idiot and forgot to rebuild the docker image when I made my changes originally. \n\n```docker compose run --build --rm deep-research```\n\nClosing."
      }
    ]
  },
  {
    "number": 21,
    "title": "Fix docker config",
    "created_at": "2025-02-07T17:35:03Z",
    "closed_at": "2025-02-08T00:23:44Z",
    "labels": [],
    "url": "https://github.com/dzhng/deep-research/pull/21",
    "body": "After some thinking I actually managed to get a better idea than copying `package.json.docker` which was stupid and made too quickly.\r\nNow installing new packages will be instantly addressed within docker image",
    "comments_url": "https://api.github.com/repos/dzhng/deep-research/issues/21/comments",
    "author": "238SAMIxD",
    "comments": [
      {
        "user": "dzhng",
        "created_at": "2025-02-08T00:23:49Z",
        "body": "thanks, updated"
      }
    ]
  },
  {
    "number": 18,
    "title": "add a parameter to control firecrawl.search rate within free quota (5/minute)",
    "created_at": "2025-02-07T14:02:17Z",
    "closed_at": "2025-02-07T16:47:49Z",
    "labels": [],
    "url": "https://github.com/dzhng/deep-research/issues/18",
    "body": "using firecrawl free account (not self hosted), the tool hits rate limit error due to the firecrawl quota. \n\nIn src/deep-research.ts, I tried changing this:\nconst limit = pLimit(ConcurrencyLimit);\n\nto this:\n  // Create a rate limiter that allows 5 requests per minute (60 seconds)\n  const limit = pLimit({\n    concurrency: ConcurrencyLimit, // Max concurrent requests\n    interval: 60 * 1000, // Interval of 60 seconds (1 minute)\n    intervalUnit: 'millisecond' // Important: specify the interval unit\n  });\n\nbut the tool still encounters many status code 429. Error: Rate limit exceeded resulting in missing data input to reasoning steps.\n\ncould it be possible to integrate such improved limit parameter ?",
    "comments_url": "https://api.github.com/repos/dzhng/deep-research/issues/18/comments",
    "author": "LaurentVeyssier",
    "comments": [
      {
        "user": "dzhng",
        "created_at": "2025-02-07T16:47:49Z",
        "body": "I think the proper way is with with p-throttle, anyone want to do a PR?\n\nfor now, pls try setting `ConcurrencyLimit` to 1"
      }
    ]
  },
  {
    "number": 17,
    "title": "Is there any way to make this work without o3-mini?",
    "created_at": "2025-02-07T13:19:47Z",
    "closed_at": "2025-02-07T16:44:23Z",
    "labels": [],
    "url": "https://github.com/dzhng/deep-research/issues/17",
    "body": "I checked the tiering on the OpenAI website, and the problem is that they only offer the o3-mini model to tier 3 users, which requires $100+ spent and I currently don't have that kind of money. Is there a lower tier model that can still work the same way and provide quality answers?",
    "comments_url": "https://api.github.com/repos/dzhng/deep-research/issues/17/comments",
    "author": "BajekekButLost",
    "comments": [
      {
        "user": "dzhng",
        "created_at": "2025-02-07T16:44:23Z",
        "body": "there are people who had lots of lock with r1, you can give that a try, you can configure it to use any openai compatible api endpoints"
      }
    ]
  },
  {
    "number": 11,
    "title": "Add Dockerfile and docker compose",
    "created_at": "2025-02-07T01:57:02Z",
    "closed_at": "2025-02-07T16:37:53Z",
    "labels": [],
    "url": "https://github.com/dzhng/deep-research/pull/11",
    "body": "* created `Dockerfile`\r\n* created `docker-compose.yml`\r\n* added `.env.example`\r\n* edited `README.md` to include docker instructions\r\n* created `package.json.docker` to edit one line in `package.json`",
    "comments_url": "https://api.github.com/repos/dzhng/deep-research/issues/11/comments",
    "author": "238SAMIxD",
    "comments": [
      {
        "user": "dzhng",
        "created_at": "2025-02-07T16:37:48Z",
        "body": "thank you!"
      }
    ]
  },
  {
    "number": 10,
    "title": "feat: add custom OpenAI endpoint and custom model support",
    "created_at": "2025-02-06T23:38:46Z",
    "closed_at": "2025-02-07T16:39:45Z",
    "labels": [],
    "url": "https://github.com/dzhng/deep-research/pull/10",
    "body": "- Added OPENAI_ENDPOINT in .env.local and retained default keys.\r\n- Updated providers.ts to use baseURL from OPENAI_ENDPOINT.\r\n- Conditionally override model names with OPENAI_MODEL when a custom endpoint is set.\r\n- Supports custom provider configuration for local models via environment variables.",
    "comments_url": "https://api.github.com/repos/dzhng/deep-research/issues/10/comments",
    "author": "nasedkinpv",
    "comments": [
      {
        "user": "dzhng",
        "created_at": "2025-02-07T16:39:42Z",
        "body": "thank you!"
      },
      {
        "user": "Mealonex",
        "created_at": "2025-02-11T11:23:10Z",
        "body": "> thank you!\r\n\r\nWlc\r\n"
      }
    ]
  },
  {
    "number": 7,
    "title": "OpenAI key missing even though it's in the .env.local file",
    "created_at": "2025-02-06T17:41:54Z",
    "closed_at": "2025-02-06T18:08:17Z",
    "labels": [],
    "url": "https://github.com/dzhng/deep-research/issues/7",
    "body": "here's the sample output\n\n```\nEnter research breadth (recommended 2-10, default 4): 4\nEnter research depth (recommended 1-5, default 2): 2\nCreating research plan...\nLoadAPIKeyError [AI_LoadAPIKeyError]: OpenAI API key is missing. Pass it using the 'apiKey' parameter or the OPENAI_API_KEY environment variable.\n```\n\nmy .env.local (keys removed obv lol)\n\n```\nFIRECRAWL_KEY=  <key>\nOPENAI_API_KEY = <key2>\n\n```",
    "comments_url": "https://api.github.com/repos/dzhng/deep-research/issues/7/comments",
    "author": "thewildofficial",
    "comments": [
      {
        "user": "dzhng",
        "created_at": "2025-02-06T17:43:23Z",
        "body": "rename it to `OPENAI_KEY` (not `OPENAI_API_KEY`)"
      },
      {
        "user": "thewildofficial",
        "created_at": "2025-02-06T18:08:17Z",
        "body": "had to update my node version, that fixed the error!"
      }
    ]
  },
  {
    "number": 6,
    "title": "Not starting",
    "created_at": "2025-02-06T12:41:06Z",
    "closed_at": "2025-02-07T16:46:24Z",
    "labels": [],
    "url": "https://github.com/dzhng/deep-research/issues/6",
    "body": "Hi, I get \n`> open-deep-research@0.0.1 start\n> tsx --env-file=.env.local src/run.ts` on start and it exits (on Windows)",
    "comments_url": "https://api.github.com/repos/dzhng/deep-research/issues/6/comments",
    "author": "korzen",
    "comments": [
      {
        "user": "dzhng",
        "created_at": "2025-02-06T17:37:57Z",
        "body": "what environment are you running this in?"
      },
      {
        "user": "UOW37",
        "created_at": "2025-02-07T14:30:40Z",
        "body": "You may want to upgrade your Node.js to the latest version or to a version that supports dotenv out of the box."
      },
      {
        "user": "dzhng",
        "created_at": "2025-02-07T16:46:38Z",
        "body": "yea check you're running >node 22 pls"
      },
      {
        "user": "korzen",
        "created_at": "2025-02-07T20:12:08Z",
        "body": "OK, it worked! However I see that the code is hardcoded to o3-mini and, for some reason, I don't have access to it in  OpenAI's API."
      }
    ]
  },
  {
    "number": 4,
    "title": "Remove report.md and add it to .gitignore",
    "created_at": "2025-02-05T17:04:55Z",
    "closed_at": "2025-02-05T17:09:39Z",
    "labels": [],
    "url": "https://github.com/dzhng/deep-research/pull/4",
    "body": "report.md is generated every time we run a research on a new topic",
    "comments_url": "https://api.github.com/repos/dzhng/deep-research/issues/4/comments",
    "author": "tonyjzhou",
    "comments": [
      {
        "user": "dzhng",
        "created_at": "2025-02-05T17:09:39Z",
        "body": "I want to keep report.md since that's an example output for people (that already has a ton of external links). But I changed it so it outputs to a different file which is git ignored. Thanks for the suggestion!"
      }
    ]
  },
  {
    "number": 3,
    "title": "Add Support for Openrouter as API router & Anthropic Claude Sonnet",
    "created_at": "2025-02-04T10:11:00Z",
    "closed_at": "2025-02-07T16:48:42Z",
    "labels": [],
    "url": "https://github.com/dzhng/deep-research/pull/3",
    "body": "I tried using claude sonnet via openrouter api and it works great also the report results was quite decent. \r\n\r\nOther models on openrouter, I havent try it but the openai one need tier 3 one also for deepseek model integration one especially R1 might need some adjustment",
    "comments_url": "https://api.github.com/repos/dzhng/deep-research/issues/3/comments",
    "author": "0xrsydn",
    "comments": [
      {
        "user": "freezscholte",
        "created_at": "2025-02-04T11:05:24Z",
        "body": "what also would be cool to capture the R1 tough part and let another agent review this? just a brain dump was playing around with this idea that it sort of automatically self improves.."
      },
      {
        "user": "0xrsydn",
        "created_at": "2025-02-04T16:13:23Z",
        "body": "> what also would be cool to capture the R1 tough part and let another agent review this? just a brain dump was playing around with this idea that it sort of automatically self improves..\r\n\r\nyeah i have tried using r1 one, apparently i have to change how the code works too as i have to parse <think></think> process of r1 also how r1 handle the code (i tried it with openrouter api, think doesnt work on this code especially generateObject one)"
      },
      {
        "user": "bhupesh-sf",
        "created_at": "2025-02-05T03:17:55Z",
        "body": "allow configurable openai base url"
      },
      {
        "user": "dzhng",
        "created_at": "2025-02-05T16:27:45Z",
        "body": "I really want to keep this repo simple and <500 LoC so it's easy for people to come in and understand. mind that I don't merge this and just keep this PR open so anyone who wants to do this can get a good reference implementation"
      },
      {
        "user": "dzhng",
        "created_at": "2025-02-07T16:48:42Z",
        "body": "FYI latest version supports custom endpoints & models via env vars, which also let's you support openrouter (since they're openai api compatible). I think that's cleaner so going to close this PR"
      }
    ]
  },
  {
    "number": 2,
    "title": "Add support for requesty.ai as API router",
    "created_at": "2025-02-04T09:15:24Z",
    "closed_at": "2025-02-07T16:49:33Z",
    "labels": [],
    "url": "https://github.com/dzhng/deep-research/pull/2",
    "body": "I also wanted to add openrouter bus you still need to provide your own Tier3 OpenApi key. Which a lot of people do not have. Requesty.ai does have the ability to provide o3mini and also to specify the reasoning level. \r\nYou probably want to change the code structure / syntax that it alligns more to your standards otherwise i would say pull this one in ;)",
    "comments_url": "https://api.github.com/repos/dzhng/deep-research/issues/2/comments",
    "author": "freezscholte",
    "comments": [
      {
        "user": "dzhng",
        "created_at": "2025-02-05T16:28:58Z",
        "body": "Hey, same comment as the last pr, I really want to keep this repo simple and <500 LoC so it's easy for people to come in and understand. mind that I don't merge this and just keep this PR open so anyone who wants to do this can get a good reference implementation\r\n"
      },
      {
        "user": "dzhng",
        "created_at": "2025-02-07T16:49:33Z",
        "body": "latest version now has configurable api endpoint and models via env vars, which lets you support any openai compat endpoints. going to close this pr"
      }
    ]
  }
]