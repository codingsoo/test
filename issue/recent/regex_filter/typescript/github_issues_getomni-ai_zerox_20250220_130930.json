[
  {
    "number": 140,
    "title": "Remove unnecessary warning for custom system prompt assignment",
    "created_at": "2025-02-11T08:51:40Z",
    "closed_at": "2025-02-11T19:05:49Z",
    "labels": [],
    "url": "https://github.com/getomni-ai/zerox/pull/140",
    "body": "The warning in the system_prompt setter has been removed because it is unnecessary. The custom_system_prompt is explicitly assigned by the user, making the warning redundant. Keeping this warning adds unnecessary noise to logs without providing meaningful value.\r\n\r\nSince setting a custom system prompt is an intentional action, users do not need to be notified via a warning. This change improves code clarity and reduces log clutter.",
    "comments_url": "https://api.github.com/repos/getomni-ai/zerox/issues/140/comments",
    "author": "keenranger",
    "comments": [
      {
        "user": "tylermaran",
        "created_at": "2025-02-11T19:18:30Z",
        "body": "Thanks for the PR. Agreed that would just get noisy. \r\n\r\nWe'll release a new version of the Python library this afternoon!"
      },
      {
        "user": "keenranger",
        "created_at": "2025-02-12T07:18:46Z",
        "body": "@tylermaran Awesome! Looking forward to the new release. Thanks for the quick update!â€"
      }
    ]
  },
  {
    "number": 131,
    "title": "Is there a parameter to control the sensitive fields like name , password in PDF file?",
    "created_at": "2024-12-31T04:20:11Z",
    "closed_at": "2025-01-07T01:00:48Z",
    "labels": [],
    "url": "https://github.com/getomni-ai/zerox/issues/131",
    "body": "Same as the title, I have succeeded parsing my pdf file and obtain the content \r\n\r\nEverything looks good and I think 90% information was correct. But the key field \"name\" of customer person always parsed wrong.\r\n\r\nI am using gpt-4o-mini model, I think the model should have the ability to recognize the filed \"name\" as other fields like \"price\",\"date\",\"address\" etc.\r\n\r\nSo does zerox have some parameter to help recognize the \"sensitive\" fields? as I guess",
    "comments_url": "https://api.github.com/repos/getomni-ai/zerox/issues/131/comments",
    "author": "Matrix-X",
    "comments": [
      {
        "user": "James4Ever0",
        "created_at": "2025-01-03T00:12:33Z",
        "body": "It depends on the performance of the model, or simply because the image tiles are so blurry that no such model exists for extracting all info out of them.\n\nYou would look for DPI parameters, or you could combine other OCR tools along with Zerox, which might require extensive programming and experiments.\n\nTo confirm those assumptions, you could record HTTP requests made by Zerox, trace the code by execution or function calls, etc.\n\nModel specific implementation would vary, so you could look for image processing details in docs by model providers to get a better understanding."
      },
      {
        "user": "Matrix-X",
        "created_at": "2025-01-07T01:00:46Z",
        "body": "thank you for you clarification, and I will try your recommended solutions"
      }
    ]
  },
  {
    "number": 122,
    "title": "Prompt improvements",
    "created_at": "2024-12-10T19:51:45Z",
    "closed_at": "2024-12-18T01:06:07Z",
    "labels": [],
    "url": "https://github.com/getomni-ai/zerox/pull/122",
    "body": "Prompt improvements",
    "comments_url": "https://api.github.com/repos/getomni-ai/zerox/issues/122/comments",
    "author": "fabiocavalcantti",
    "comments": [
      {
        "user": "tylermaran",
        "created_at": "2024-12-10T20:00:02Z",
        "body": "Hey @fabiocavalcantti, looks like there's a lot of conflicts in the PR (142 files). \r\n\r\nLooking specifically at the prompt update, this won't work as intended. Since the model looks at documents one page at a time. \r\n\r\n```git\r\n    Convert the following PDF page to markdown.\r\n    Return only the markdown with no explanation text.\r\n    Do not exclude any content from the page.\r\n  + If there is more than one document in the same PDF\r\n  + or image, separate the Markdown for each document as\r\n  + separate sections.\r\n    \"\"\"\r\n```"
      },
      {
        "user": "fabiocavalcantti",
        "created_at": "2024-12-10T20:06:13Z",
        "body": "> Hey @fabiocavalcantti, looks like there's a lot of conflicts in the PR (142 files).\r\n> \r\n> Looking specifically at the prompt update, this won't work as intended. Since the model looks at documents one page at a time.\r\n> \r\n> ```\r\n>     Convert the following PDF page to markdown.\r\n>     Return only the markdown with no explanation text.\r\n>     Do not exclude any content from the page.\r\n>   + If there is more than one document in the same PDF\r\n>   + or image, separate the Markdown for each document as\r\n>   + separate sections.\r\n>     \"\"\"\r\n> ```\r\n\r\nThis is for if the person sends a PDF or photo with 2 documents on the same page or photo"
      }
    ]
  },
  {
    "number": 120,
    "title": "Update py-zerox installation instructions for clarity",
    "created_at": "2024-12-05T23:03:18Z",
    "closed_at": "2024-12-09T21:31:39Z",
    "labels": [],
    "url": "https://github.com/getomni-ai/zerox/pull/120",
    "body": "I made a little tweak to the installation instructions; currently they say install **poppler-utils**. A google search for that sends you to a python package on PyPI from 2020 which isn't maintained anymore. \r\n\r\nI think what's actually needed is an install of **poppler**; at least, that's what the dependency `pdf2image` said in its documentation. I linked to those docs for further instructions. After installing poppler with brew, my py-zerox install is working properly.",
    "comments_url": "https://api.github.com/repos/getomni-ai/zerox/issues/120/comments",
    "author": "bjlange",
    "comments": [
      {
        "user": "tylermaran",
        "created_at": "2024-12-09T21:31:32Z",
        "body": "Great update! Thanks @bjlange "
      }
    ]
  },
  {
    "number": 115,
    "title": "does zerox work on client side",
    "created_at": "2024-12-04T17:10:44Z",
    "closed_at": "2024-12-04T18:48:12Z",
    "labels": [],
    "url": "https://github.com/getomni-ai/zerox/issues/115",
    "body": "When I try to use zerox on the browser, it throws an error saying it needs modules that are found only in a node.js env so I need to move zerox to a api route or to a server component.",
    "comments_url": "https://api.github.com/repos/getomni-ai/zerox/issues/115/comments",
    "author": "alexander-densley",
    "comments": [
      {
        "user": "alexander-densley",
        "created_at": "2024-12-04T17:10:51Z",
        "body": "working with nextjs 14\r\n"
      },
      {
        "user": "tylermaran",
        "created_at": "2024-12-04T18:48:13Z",
        "body": "Hey @alexander-densley, correct. Zerox will only work within a node API or a nextjs server component. \r\n\r\nYou could do something like: \r\n\r\n`pages/api/process-pdf.js`\r\n\r\n```js\r\nimport { zerox } from \"zerox\";\r\n\r\nexport default async function handler(req, res) {\r\n  try {\r\n    // Use file URL or local path\r\n    const filePath = req.body.filePath; // Expect filePath in the POST request body\r\n\r\n    if (!filePath) {\r\n      return res.status(400).json({ error: \"filePath is required\" });\r\n    }\r\n\r\n    // Process the file with zerox\r\n    const result = await zerox({\r\n      filePath,\r\n      openaiAPIKey: process.env.OPENAI_API_KEY, // Set this in you env variables\r\n    });\r\n\r\n    return res.status(200).json({ success: true, result });\r\n  } catch (error) {\r\n    console.error(\"Error processing file:\", error);\r\n    return res.status(500).json({ error: \"An error occurred while processing the file\" });\r\n  }\r\n}\r\n```"
      }
    ]
  },
  {
    "number": 102,
    "title": "Use uuid as file name",
    "created_at": "2024-11-21T15:22:31Z",
    "closed_at": "2024-11-21T19:34:49Z",
    "labels": [],
    "url": "https://github.com/getomni-ai/zerox/pull/102",
    "body": "If the file names are long, especially when the PDF has unicode file name & its name is url encoded, it might exceed the max allowed filename length in linux (and probably other OSes) which is 255 characters.\r\n\r\nThis would be fine in s3 as that has a file name limit of 1024 characters, but would result in `ENAMETOOLONG` errors when Zerox tries to download and write to the disk.\r\n\r\nThis PR prevents `ENAMETOOLONG` errors by using a UUIDv4 as the file name.",
    "comments_url": "https://api.github.com/repos/getomni-ai/zerox/issues/102/comments",
    "author": "ZeeshanZulfiqarAli",
    "comments": [
      {
        "user": "annapo23",
        "created_at": "2024-11-21T18:00:14Z",
        "body": "One small comment! Otherwise, LGTM! ðŸš€"
      }
    ]
  },
  {
    "number": 95,
    "title": "Azure OpenAI",
    "created_at": "2024-11-12T08:45:29Z",
    "closed_at": "2024-11-12T08:46:59Z",
    "labels": [],
    "url": "https://github.com/getomni-ai/zerox/issues/95",
    "body": "In Azure, deployments are often named other things than the model names, for instance \"gpt-4o\" could be named \"wrapper-api-gpt-4o\". This causes the mapping to not recognise the model since it is not in the mapping json.\r\n\r\nI would suggest an additional parameter that differentiates the deployment name used for querying the api vs the model selector.",
    "comments_url": "https://api.github.com/repos/getomni-ai/zerox/issues/95/comments",
    "author": "AlexVialaBellander",
    "comments": [
      {
        "user": "tylermaran",
        "created_at": "2024-11-12T18:38:59Z",
        "body": "Hey @AlexVialaBellander. Were you able to resolve this? Let me know if theres anything I can add to the documentation. "
      }
    ]
  },
  {
    "number": 90,
    "title": "[Error] Gemini models are not working ",
    "created_at": "2024-11-07T13:23:23Z",
    "closed_at": "2024-11-26T17:12:53Z",
    "labels": [],
    "url": "https://github.com/getomni-ai/zerox/issues/90",
    "body": "Hi, I'm trying to use gemini models for vertex (`vertex_ai/gemini-1.5-flash`, `vertex_aigemini-1.5-flash-001`, `vertex_ai/gemini-1.5-flash-8b`) and `gemini/gpt-4o-mini`, but it returns an error that this is not a vision model.\r\n\r\n## Errors\r\n```bash\r\nThe provided model is not a vision model. Please provide a vision model.\r\n     (Extra Info: {'model': 'gemini/gpt-4o-mini'})\r\n```\r\n```bash\r\nThe provided model is not a vision model. Please provide a vision model.\r\n     (Extra Info: {'model': 'vertex_ai/gemini-1.5-flash-001'})\r\n```\r\n\r\n## Source code:\r\n```python\r\nfrom pyzerox import zerox\r\nimport os\r\nimport asyncio\r\n\r\nqwargs = {}\r\ncustom_system_prompt = None\r\n\r\nmodel = \"gemini/gpt-4o-mini\"\r\nos.environ['GEMINI_API_KEY'] = os.getenv('GEMINI_API_KEY')\r\n\r\nmodel = \"vertex_ai/gemini-1.5-flash-001\" \r\nos.environ['VERTEXAI_PROJECT']  = os.getenv('PROJECT_ID')\r\nos.environ['VERTEXAI_LOCATION']  = os.getenv('PROJECT_REGION')\r\n\r\nasync def main():\r\n    file_path = \"./test.pdf\"\r\n\r\n    select_pages = None\r\n\r\n    output_dir = \"./results\"\r\n    result = await zerox(file_path=file_path, model=model, output_dir=output_dir,\r\n                        custom_system_prompt=custom_system_prompt,select_pages=select_pages, **qwargs)\r\n    \r\n    print(result)\r\n    \r\n    return result\r\n\r\nresult = asyncio.run(main())\r\n```\r\n\r\nThanks for help ðŸ‘",
    "comments_url": "https://api.github.com/repos/getomni-ai/zerox/issues/90/comments",
    "author": "eugeek",
    "comments": [
      {
        "user": "thonglv21",
        "created_at": "2024-11-26T07:33:09Z",
        "body": "`openai/gpt-4o-mini`, `gemini/gemini-1.5-flash`, `gemini/gemini-1.5-flash-001`,.."
      }
    ]
  },
  {
    "number": 73,
    "title": "Fix",
    "created_at": "2024-10-23T22:18:05Z",
    "closed_at": "2024-10-23T22:18:13Z",
    "labels": [],
    "url": "https://github.com/getomni-ai/zerox/pull/73",
    "body": null,
    "comments_url": "https://api.github.com/repos/getomni-ai/zerox/issues/73/comments",
    "author": "eric-z-wang",
    "comments": [
      {
        "user": "tylermaran",
        "created_at": "2024-10-23T22:42:25Z",
        "body": "Hey @eric-z-wang and @snferguson. Just to clarify this should be this fixed in the latest python version. Seems like it was resolved when you pulled in main. Let me know if you're still having any issues. "
      }
    ]
  },
  {
    "number": 68,
    "title": "docs: update README.md",
    "created_at": "2024-10-22T08:17:54Z",
    "closed_at": "2024-10-23T22:43:02Z",
    "labels": [],
    "url": "https://github.com/getomni-ai/zerox/pull/68",
    "body": "somthing -> something",
    "comments_url": "https://api.github.com/repos/getomni-ai/zerox/issues/68/comments",
    "author": "eltociear",
    "comments": [
      {
        "user": "tylermaran",
        "created_at": "2024-10-23T22:42:57Z",
        "body": "you got it ðŸ˜†"
      }
    ]
  },
  {
    "number": 59,
    "title": "Update README.md for graphicsmagick install, otherwise npm throws an error",
    "created_at": "2024-10-20T21:25:12Z",
    "closed_at": "2024-10-21T16:04:12Z",
    "labels": [],
    "url": "https://github.com/getomni-ai/zerox/pull/59",
    "body": "\r\nAdding in the linux commands with sudo privileges.",
    "comments_url": "https://api.github.com/repos/getomni-ai/zerox/issues/59/comments",
    "author": "masparasol",
    "comments": [
      {
        "user": "tylermaran",
        "created_at": "2024-10-21T16:04:09Z",
        "body": "Looks good to me!"
      }
    ]
  },
  {
    "number": 53,
    "title": "fix: allow empty select_pages again",
    "created_at": "2024-10-16T12:54:18Z",
    "closed_at": "2024-10-18T04:42:35Z",
    "labels": [],
    "url": "https://github.com/getomni-ai/zerox/pull/53",
    "body": "Restores operation of examples where `select_pages` was empty (= use all pages).\r\n\r\nFixes #42.",
    "comments_url": "https://api.github.com/repos/getomni-ai/zerox/issues/53/comments",
    "author": "mg6",
    "comments": [
      {
        "user": "mikewadhera",
        "created_at": "2024-10-16T21:22:37Z",
        "body": "Can we please get this merged? The current `README` instructions are broken (have pages set to `None`)"
      },
      {
        "user": "tylermaran",
        "created_at": "2024-10-18T04:42:29Z",
        "body": "I see. This looks good to me. I'll merge and redeploy the pip package."
      }
    ]
  },
  {
    "number": 51,
    "title": "Existing workflows to handle images in PDF.",
    "created_at": "2024-10-10T16:01:44Z",
    "closed_at": "2024-10-18T09:37:59Z",
    "labels": [],
    "url": "https://github.com/getomni-ai/zerox/issues/51",
    "body": "Hi, thanks for the great tool. I had good success with it, especially when the PDF has code snippets in them.\r\n\r\nI would like to know if there are existing features/workflows to handle images in certain pages. I was wondering if it could be extracted into an SVG or base64 encoded image and embedded in the markdown itself, hoping it would be rendered by certain markdown viewers.",
    "comments_url": "https://api.github.com/repos/getomni-ai/zerox/issues/51/comments",
    "author": "rajaravivarma-r",
    "comments": [
      {
        "user": "tylermaran",
        "created_at": "2024-10-10T23:29:06Z",
        "body": "Hey @rajaravivarma-r, this is something we've been interested in as well. \r\n\r\nI'm thinking we could extract the images as a local file path and return them in an array after the response. Something like: \r\n\r\n```js\r\n{\r\n  completionTime: 10038,\r\n  fileName: 'invoice_36258',\r\n  inputTokens: 25543,\r\n  outputTokens: 210,\r\n  pages: [\r\n    {\r\n      content: '# INVOICE # 36258\\n' +\r\n        '**Date:** Mar 06 2012  \\n' +\r\n        '**Ship Mode:** First Class  \\n' +\r\n        '**Balance Due:** $50.10  \\n' +\r\n        '## Product Image:\\n' +\r\n        '[image](1234):'\r\n      page: 1,\r\n      contentLength: 747\r\n    }\r\n  ],\r\n  images: [\r\n    {\r\n      id: 1234,\r\n      localUrl: 'path/to/image.png'\r\n    }\r\n  ]\r\n}\r\n```\r\n\r\nNeed to think through how we would correctly tag the image inside the markdown response (especially if there are a lot of them). "
      },
      {
        "user": "rajaravivarma-r",
        "created_at": "2024-10-17T19:30:13Z",
        "body": "@tylermaran Thank you. I would be interested in converting the pages into HTML, so that it can be converted to epub. Is that possible?"
      },
      {
        "user": "tylermaran",
        "created_at": "2024-10-18T04:50:57Z",
        "body": "Hey @rajaravivarma-r. I don't think html export would be something we officially support in the library. But it should be a pretty quick conversion from the zerox results.\r\n\r\nSince the content is markdown, you can use a markdown => html library to render the results. \r\n\r\n```py\r\nimport markdown\r\n\r\n# zerox_response = zerox(...)\r\n\r\nfor page in zerox_response['pages']:\r\n    content = page['content']\r\n    html = markdown.markdown(content)\r\n\r\n    file_name = f\"{data['fileName']}.html\"\r\n    with open(file_name, 'w') as f:\r\n        f.write(html)\r\n\r\n    print(f\"HTML content saved to {file_name}\")\r\n```\r\n\r\nalso are you thinking of using zerox to scan pages (with extracted images) into an epub file? I love the use case!"
      },
      {
        "user": "rajaravivarma-r",
        "created_at": "2024-10-18T09:37:59Z",
        "body": "Huh! How did I not think of that. Thank you @tylermaran "
      }
    ]
  },
  {
    "number": 36,
    "title": "minor typo fix",
    "created_at": "2024-09-13T10:16:02Z",
    "closed_at": "2024-09-13T18:13:37Z",
    "labels": [],
    "url": "https://github.com/getomni-ai/zerox/pull/36",
    "body": null,
    "comments_url": "https://api.github.com/repos/getomni-ai/zerox/issues/36/comments",
    "author": "pradhyumna85",
    "comments": [
      {
        "user": "tylermaran",
        "created_at": "2024-09-13T18:13:34Z",
        "body": "looks good to me ðŸ¤“ "
      }
    ]
  },
  {
    "number": 32,
    "title": "fix - missing total token count calculation for maintain_format = False",
    "created_at": "2024-09-11T16:00:16Z",
    "closed_at": "2024-09-12T04:44:53Z",
    "labels": [],
    "url": "https://github.com/getomni-ai/zerox/pull/32",
    "body": "Fixes #31 ",
    "comments_url": "https://api.github.com/repos/getomni-ai/zerox/issues/32/comments",
    "author": "pradhyumna85",
    "comments": [
      {
        "user": "pradhyumna85",
        "created_at": "2024-09-11T16:01:24Z",
        "body": "@annapo23, @tylermaran, @xdotli  Could you please review this PR?"
      },
      {
        "user": "xdotli",
        "created_at": "2024-09-11T23:44:35Z",
        "body": "> @annapo23, @tylermaran, @xdotli Could you please review this PR?\r\n\r\n@pradhyumna85 taking a look now"
      }
    ]
  },
  {
    "number": 27,
    "title": "ReferenceError while installing the zerox package using npm",
    "created_at": "2024-09-10T08:56:47Z",
    "closed_at": "2024-09-11T02:57:18Z",
    "labels": [],
    "url": "https://github.com/getomni-ai/zerox/issues/27",
    "body": "When i tried to install the package using `npm install zerox`, i got reference error. Below is the logs for reference\r\n\r\nazureuser@pjsip:~/ZEROX$ sudo npm install zerox\r\nnpm error code 1\r\nnpm error path /home/azureuser/ZEROX/node_modules/zerox\r\nnpm error command failed\r\nnpm error command sh -c node node-zerox/scripts/install-dependencies.js\r\nnpm error /home/azureuser/ZEROX/node_modules/zerox/node-zerox/scripts/install-dependencies.js:80\r\nnpm error       const command = sudoAvailable\r\nnpm error                       ^\r\nnpm error\r\nnpm error ReferenceError: sudoAvailable is not defined\r\nnpm error     at checkAndInstall (/home/azureuser/ZEROX/node_modules/zerox/node-zerox/scripts/install-dependencies.js:80:23)\r\nnpm error\r\nnpm error Node.js v22.8.0\r\nnpm error A complete log of this run can be found in: /root/.npm/_logs/2024-09-10T08_48_53_985Z-debug-0.log\r\n\r\nI am using a VM with OS as Linux (ubuntu 22.04)",
    "comments_url": "https://api.github.com/repos/getomni-ai/zerox/issues/27/comments",
    "author": "mitul-asodariya",
    "comments": [
      {
        "user": "tylermaran",
        "created_at": "2024-09-10T18:15:17Z",
        "body": "Good find! Quick fix, the variable was not included in the same scope as the libreoffice postinstall script. "
      },
      {
        "user": "tylermaran",
        "created_at": "2024-09-10T18:41:39Z",
        "body": "Merged and re-released on version `1.0.26`. Please test it out and let me know if that works!"
      },
      {
        "user": "mitul-asodariya",
        "created_at": "2024-09-11T02:57:18Z",
        "body": "Thanks for the fix! It is working "
      }
    ]
  },
  {
    "number": 5,
    "title": "Unable to copy files",
    "created_at": "2024-07-29T15:45:01Z",
    "closed_at": "2024-09-05T05:46:55Z",
    "labels": [
      "bug"
    ],
    "url": "https://github.com/getomni-ai/zerox/issues/5",
    "body": "When trying this I get the error `operation not permitted`\r\n\r\n```\r\n[Error: EPERM: operation not permitted, copyfile '/home/uber.pdf' -> 'tmp/your-app-temp/uber.pdf'] {\r\n  errno: -1,\r\n  code: 'EPERM',\r\n  syscall: 'copyfile',\r\n  path: '/home/uber.pdf',\r\n  dest: 'tmp/your-app-temp/uber.pdf'\r\n}\r\n```",
    "comments_url": "https://api.github.com/repos/getomni-ai/zerox/issues/5/comments",
    "author": "edishu",
    "comments": [
      {
        "user": "tylermaran",
        "created_at": "2024-07-29T17:42:26Z",
        "body": "hey @edishu, can you share the code snippit you're using to call zerox? I'd like to see if I can replicate. \r\n\r\nWe run an `ensureDir` check on the temp folder the app uses, but there might be some permission errors. "
      }
    ]
  }
]