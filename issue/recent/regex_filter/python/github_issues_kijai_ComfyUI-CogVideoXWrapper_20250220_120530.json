[
  {
    "number": 350,
    "title": "SageAttention: Input tensors must be in dtype of torch.float16 or torch.bfloat16",
    "created_at": "2025-01-14T02:13:29Z",
    "closed_at": "2025-01-14T03:03:38Z",
    "labels": [],
    "url": "https://github.com/kijai/ComfyUI-CogVideoXWrapper/issues/350",
    "body": "Trying to use Fun-v1.1-5b-InP model with sageattn gives this:\r\n\r\n```\r\n!!! Exception during processing !!! Input tensors must be in dtype of torch.float16 or torch.bfloat16\r\nTraceback (most recent call last):\r\n  File \"/root/ComfyUI/execution.py\", line 327, in execute\r\n    output_data, output_ui, has_subgraph = get_output_data(obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\r\n                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/root/ComfyUI/execution.py\", line 202, in get_output_data\r\n    return_values = _map_node_over_list(obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\r\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/root/ComfyUI/execution.py\", line 174, in _map_node_over_list\r\n    process_inputs(input_dict, i)\r\n  File \"/root/ComfyUI/execution.py\", line 163, in process_inputs\r\n    results.append(getattr(obj, func)(**inputs))\r\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/root/ComfyUI/custom_nodes/comfyui-cogvideoxwrapper/nodes.py\", line 689, in process\r\n    latents = model[\"pipe\"](\r\n              ^^^^^^^^^^^^^^\r\n  File \"/root/ComfyUI/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\r\n    return func(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/root/ComfyUI/custom_nodes/comfyui-cogvideoxwrapper/pipeline_cogvideox.py\", line 751, in __call__\r\n    noise_pred = self.transformer(\r\n                 ^^^^^^^^^^^^^^^^^\r\n  File \"/root/ComfyUI/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\r\n    return self._call_impl(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/root/ComfyUI/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/root/ComfyUI/custom_nodes/comfyui-cogvideoxwrapper/custom_cogvideox_transformer_3d.py\", line 684, in forward\r\n    hidden_states, encoder_hidden_states = block(\r\n                                           ^^^^^^\r\n  File \"/root/ComfyUI/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\r\n    return self._call_impl(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/root/ComfyUI/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/root/ComfyUI/custom_nodes/comfyui-cogvideoxwrapper/custom_cogvideox_transformer_3d.py\", line 281, in forward\r\n    attn_hidden_states, attn_encoder_hidden_states = self.attn1(\r\n                                                     ^^^^^^^^^^^\r\n  File \"/root/ComfyUI/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\r\n    return self._call_impl(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/root/ComfyUI/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/root/ComfyUI/.venv/lib/python3.11/site-packages/diffusers/models/attention_processor.py\", line 588, in forward\r\n    return self.processor(\r\n           ^^^^^^^^^^^^^^^\r\n  File \"/root/ComfyUI/custom_nodes/comfyui-cogvideoxwrapper/custom_cogvideox_transformer_3d.py\", line 128, in __call__\r\n    hidden_states = sageattn_func(query, key, value, attn_mask=attention_mask, dropout_p=0.0,is_causal=False)\r\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/root/ComfyUI/.venv/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py\", line 632, in _fn\r\n    return fn(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^\r\n  File \"/root/ComfyUI/custom_nodes/comfyui-cogvideoxwrapper/custom_cogvideox_transformer_3d.py\", line 50, in sageattn_func\r\n    return sageattn(query, key, value, attn_mask=attn_mask, dropout_p=dropout_p,is_causal=is_causal)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/root/ComfyUI/.venv/lib/python3.11/site-packages/sageattention-2.0.1-py3.11-linux-x86_64.egg/sageattention/core.py\", line 116, in sageattn\r\n    return sageattn_qk_int8_pv_fp8_cuda(q, k, v, tensor_layout=tensor_layout, is_causal=is_causal, sm_scale=sm_scale, return_lse=return_lse, pv_accum_dtype=\"fp32+fp32\")\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/root/ComfyUI/.venv/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py\", line 632, in _fn\r\n    return fn(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^\r\n  File \"/root/ComfyUI/.venv/lib/python3.11/site-packages/sageattention-2.0.1-py3.11-linux-x86_64.egg/sageattention/core.py\", line 651, in sageattn_qk_int8_pv_fp8_cuda\r\n    assert dtype in [torch.float16, torch.bfloat16], \"Input tensors must be in dtype of torch.float16 or torch.bfloat16\"\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nAssertionError: Input tensors must be in dtype of torch.float16 or torch.bfloat16\r\n\r\nPrompt executed in 36.57 seconds\r\ngot prompt\r\nFailed to validate prompt for output 270:\r\n* UpscaleModelLoader 274:\r\n  - Value not in list: model_name: '4xUltrasharp.pth' not in ['4x-UltraSharp.pth']\r\nOutput will be ignored\r\nThe config attributes {'add_noise_in_inpaint_model': True} were passed to CogVideoXTransformer3DModel, but are not expected and will be ignored. Please verify your config.json configuration file.\r\nreceived 7 trajectorie(s)\r\nvideo_flow shape after encoding: torch.Size([1, 16, 9, 64, 64])\r\ninput_image shape:  torch.Size([1, 3, 33, 512, 512])\r\nmask_pixel_values_bs:  torch.Size([1, 32, 9, 64, 64])\r\nmask_pixel_values_bs:  torch.Size([1, 16, 9, 64, 64]) tensor(-3.9062, device='cuda:0', dtype=torch.bfloat16) tensor(3.4375, device='cuda:0', dtype=torch.bfloat16)\r\nEncoded latents shape: torch.Size([1, 9, 16, 64, 64])\r\nFasterCache enabled for 16 blocks out of 42\r\nReceived 9 image conditioning frames\r\nContext schedule disabled\r\nTora trajectory length: 9\r\nSampling 33 frames in 9 latent frames at 512x512 with 12 inference steps\r\n  0%|                                                                         | 0/12 [00:00<?, ?it/s]\r\n!!! Exception during processing !!! Input tensors must be in dtype of torch.float16 or torch.bfloat16\r\nTraceback (most recent call last):\r\n  File \"/root/ComfyUI/execution.py\", line 327, in execute\r\n    output_data, output_ui, has_subgraph = get_output_data(obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\r\n                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/root/ComfyUI/execution.py\", line 202, in get_output_data\r\n    return_values = _map_node_over_list(obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\r\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/root/ComfyUI/execution.py\", line 174, in _map_node_over_list\r\n    process_inputs(input_dict, i)\r\n  File \"/root/ComfyUI/execution.py\", line 163, in process_inputs\r\n    results.append(getattr(obj, func)(**inputs))\r\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/root/ComfyUI/custom_nodes/comfyui-cogvideoxwrapper/nodes.py\", line 689, in process\r\n    latents = model[\"pipe\"](\r\n              ^^^^^^^^^^^^^^\r\n  File \"/root/ComfyUI/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\r\n    return func(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/root/ComfyUI/custom_nodes/comfyui-cogvideoxwrapper/pipeline_cogvideox.py\", line 751, in __call__\r\n    noise_pred = self.transformer(\r\n                 ^^^^^^^^^^^^^^^^^\r\n  File \"/root/ComfyUI/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\r\n    return self._call_impl(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/root/ComfyUI/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/root/ComfyUI/custom_nodes/comfyui-cogvideoxwrapper/custom_cogvideox_transformer_3d.py\", line 684, in forward\r\n    hidden_states, encoder_hidden_states = block(\r\n                                           ^^^^^^\r\n  File \"/root/ComfyUI/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\r\n    return self._call_impl(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/root/ComfyUI/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/root/ComfyUI/custom_nodes/comfyui-cogvideoxwrapper/custom_cogvideox_transformer_3d.py\", line 281, in forward\r\n    attn_hidden_states, attn_encoder_hidden_states = self.attn1(\r\n                                                     ^^^^^^^^^^^\r\n  File \"/root/ComfyUI/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\r\n    return self._call_impl(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/root/ComfyUI/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/root/ComfyUI/.venv/lib/python3.11/site-packages/diffusers/models/attention_processor.py\", line 588, in forward\r\n    return self.processor(\r\n           ^^^^^^^^^^^^^^^\r\n  File \"/root/ComfyUI/custom_nodes/comfyui-cogvideoxwrapper/custom_cogvideox_transformer_3d.py\", line 128, in __call__\r\n    hidden_states = sageattn_func(query, key, value, attn_mask=attention_mask, dropout_p=0.0,is_causal=False)\r\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/root/ComfyUI/.venv/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py\", line 632, in _fn\r\n    return fn(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^\r\n  File \"/root/ComfyUI/custom_nodes/comfyui-cogvideoxwrapper/custom_cogvideox_transformer_3d.py\", line 50, in sageattn_func\r\n    return sageattn(query, key, value, attn_mask=attn_mask, dropout_p=dropout_p,is_causal=is_causal)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/root/ComfyUI/.venv/lib/python3.11/site-packages/sageattention-2.0.1-py3.11-linux-x86_64.egg/sageattention/core.py\", line 116, in sageattn\r\n    return sageattn_qk_int8_pv_fp8_cuda(q, k, v, tensor_layout=tensor_layout, is_causal=is_causal, sm_scale=sm_scale, return_lse=return_lse, pv_accum_dtype=\"fp32+fp32\")\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/root/ComfyUI/.venv/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py\", line 632, in _fn\r\n    return fn(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^\r\n  File \"/root/ComfyUI/.venv/lib/python3.11/site-packages/sageattention-2.0.1-py3.11-linux-x86_64.egg/sageattention/core.py\", line 651, in sageattn_qk_int8_pv_fp8_cuda\r\n    assert dtype in [torch.float16, torch.bfloat16], \"Input tensors must be in dtype of torch.float16 or torch.bfloat16\"\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nAssertionError: Input tensors must be in dtype of torch.float16 or torch.bfloat16\r\n```\r\n\r\nIt used to work for this workflow and the same type of hardware (RTX 4090) installed roughly 2-3 weeks ago (it was a version where there still was enhance feta node) but after I've changed a VM and reinstalled the env it broke.  Will appreciate help in debugging!\r\n\r\nenv:\r\n```\r\nsageattention==2.0.1\r\ntorch==2.5.1+cu121\r\ntorchaudio==2.5.1+cu121\r\ntorchsde==0.2.6\r\ntorchvision==0.20.1+cu121\r\n```\r\n\r\ncogvideox-wrapper version:\r\n1f1c7b7b5673fac3d3d38a1291ed1171f6cdc3eb",
    "comments_url": "https://api.github.com/repos/kijai/ComfyUI-CogVideoXWrapper/issues/350/comments",
    "author": "mrdrprofuroboros",
    "comments": [
      {
        "user": "mrdrprofuroboros",
        "created_at": "2025-01-14T03:03:38Z",
        "body": "Hm, apparently comfy manager installed me some old version of the node from parallel universe. installing it manually solves the issue"
      },
      {
        "user": "jasoncow007",
        "created_at": "2025-01-20T06:26:15Z",
        "body": "same here"
      }
    ]
  },
  {
    "number": 292,
    "title": "KiJai, do you notice LTX Video?",
    "created_at": "2024-11-24T07:04:59Z",
    "closed_at": "2024-11-24T12:44:06Z",
    "labels": [],
    "url": "https://github.com/kijai/ComfyUI-CogVideoXWrapper/issues/292",
    "body": "it a 2b video model, I tested it, its i2v is about 10 times faster than cogvideo 5b with faster cache enabled, and the quality is better than cogvideo fun 2b, even better than cogvideo fun 5b.\r\n\r\non my 4060ti 16G, create a 576x1024, 25 frame, 30 steps, the time of whole process  is about 28 seconds, cogvideo 1.5 5b + faster cache needs more than 200 seconds.\r\n\r\n",
    "comments_url": "https://api.github.com/repos/kijai/ComfyUI-CogVideoXWrapper/issues/292/comments",
    "author": "dummyapps",
    "comments": [
      {
        "user": "kijai",
        "created_at": "2024-11-24T12:44:06Z",
        "body": "I'm in the test group yes, it is fast and promising, can't agree with the quality being on par with 5b though, it's fine on some stuff but being smaller model it can't do everything as well (yet). What ultimately matters most is how it will be to further rain, LoRAs and control methods especially as they are the most interesting things we have available for CogVideoX."
      },
      {
        "user": "cheezecrisp",
        "created_at": "2024-11-24T17:20:34Z",
        "body": "Tried it too but found not so good. For i2v it probably produces static videos no matter what the prompt is, I think the cogvideox 2b i2v (not the fun version) dose better in i2v task."
      },
      {
        "user": "zazoum-art",
        "created_at": "2024-11-24T17:45:59Z",
        "body": "Just tried it. I can't get as much direction as I can with 1.5, but that doesn't mean necessary that the LTX is bad. It is new and it could probably be me not knowing how to prompt it.\r\nWhat is important for me, (I'm talking about myself specifically and ONLY) is the models to be trained in low res footage, and get good results. I do max 213 frames in one run with a clean 4090 at 624x624, taking 17:50 minutes (no off-load) in 1.5. That's what can fit in a 4090. I up-scale with Topaz to whatever res I want. Below 624px 1.5 it just doesn't work.\r\nWell, LTX beats that by FAR.\r\nSo, what remains is the direction quality, for which, I repeat, LTX is still new.\r\n\r\nI'm a fan of whatever can do uncensored content open-source locally. No matter what the well-known companies do, no matter what they achieve, it is useless just by the fact they censor blood and nudity."
      },
      {
        "user": "dummyapps",
        "created_at": "2024-11-25T03:25:26Z",
        "body": "> Tried it too but found not so good. For i2v it probably produces static videos no matter what the prompt is, I think the cogvideox 2b i2v (not the fun version) dose better in i2v task.\r\n\r\n\r\nIt has a relatively good effect on standing postures and sitting postures.it seems that It only works on single-person photos.\r\n"
      },
      {
        "user": "dummyapps",
        "created_at": "2024-11-25T03:31:11Z",
        "body": "> Just tried it. I can't get as much direction as I can with 1.5, but that doesn't mean necessary that the LTX is bad. It is new \r\n\r\nCogVideo 1.5 is much better than LTX Video at present. but I feel  LTX is much better than cogvideo 2b fun, it is useful when I try to animate photo just for fun because it is so fast, happy to see that i2v could be so fast,This has made me have great hopes for AI videos."
      },
      {
        "user": "zazoum-art",
        "created_at": "2024-11-25T06:57:46Z",
        "body": "> > Just tried it. I can't get as much direction as I can with 1.5, but that doesn't mean necessary that the LTX is bad. It is new\r\n> \r\n>This has made me have great hopes for AI videos.\r\n\r\nThis, TOTALLY this is my feeling as well.\r\nAs a Msc. on multimedia holder I have one clean 4090 running cog 1.5 24/7 almost 3 weeks for my true wish for my life (participation on Short Film Festivals), and one clean 4090 for cg boring job (such as porn industry, and marketing companies in a country that has NO single idea on what AI can do -no antagonism) that is funding my wish expenses. Kijai and others I follow (I don't know if I can mention them here) are very important people for me.\r\nAnd now comes LTX. I hope both uncensored models to be developed even further. And they will. And more new models will come.\r\n\r\nEDIT: Just to inform Kijai if he hasn't noticed it, SAMURAI AI has been released for 100% subject tracking. Bye-bye rotoscoping!"
      }
    ]
  },
  {
    "number": 287,
    "title": " cogvideox-2b-img2vid not working",
    "created_at": "2024-11-22T20:35:52Z",
    "closed_at": "2024-12-08T09:52:38Z",
    "labels": [],
    "url": "https://github.com/kijai/ComfyUI-CogVideoXWrapper/issues/287",
    "body": "[cogvideox-2b-img2vid does not work anymore \r\n\r\nthis is all I get\r\n\r\nComfyUI\\custom_nodes\\ComfyUI-CogVideoXWrapper\\nodes.py\", line 617, in process\r\n    assert supports_image_conds, \"Image condition latents only supported for I2V and Interpolation models\"\r\nAssertionError: Image condition latents only supported for I2V and Interpolation models",
    "comments_url": "https://api.github.com/repos/kijai/ComfyUI-CogVideoXWrapper/issues/287/comments",
    "author": "MJAnderson1",
    "comments": [
      {
        "user": "kijai",
        "created_at": "2024-11-22T21:16:45Z",
        "body": "Should be fixed now."
      }
    ]
  },
  {
    "number": 267,
    "title": "Error using Tora example workflow: RuntimeError: Input type (struct c10::BFloat16) and bias type (struct c10::Half) should be the same",
    "created_at": "2024-11-20T14:27:54Z",
    "closed_at": "2024-11-20T15:27:21Z",
    "labels": [],
    "url": "https://github.com/kijai/ComfyUI-CogVideoXWrapper/issues/267",
    "body": "Hi,\r\nThanks for all of your work on this! \r\nI am fully updated as of 30 minutes ago, and other workflows I've tried are working well. However when trying the Tora example workflow in your repository, I get the below error.\r\nIf it matters, I am on Python 3.11.9, Torch 2.51, and CUDA 12.4. \r\nThank you!\r\n\r\n```\r\nDownloading model to: D:\\ComfyUI\\models\\CogVideo\\CogVideoX-Fun-V1.1-5b-InP\r\nFetching 5 files: 100%|███████████████████████████████████████████████████████████████████████████████| 5/5 [04:25<00:00, 53.12s/it]\r\nThe config attributes {'add_noise_in_inpaint_model': True} were passed to CogVideoXTransformer3DModel, but are not expected and will be ignored. Please verify your config.json configuration file.\r\nend_vram - start_vram: 13008260046 - 1867276110 = 11140983936\r\n#80 [DownloadAndLoadCogVideoModel]: 274.52s - vram 11140983936b\r\nDownloading Fuser model to: D:\\ComfyUI\\models\\CogVideo\\CogVideoX-5b-Tora\\fuser\\fuser.safetensors\r\nFetching 1 files: 100%|███████████████████████████████████████████████████████████████████████████████| 1/1 [00:32<00:00, 32.42s/it]\r\nDownloading trajectory extractor model to: D:\\ComfyUI\\models\\CogVideo\\CogVideoX-5b-Tora\\traj_extractor\\traj_extractor.safetensors\r\nFetching 1 files: 100%|███████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.51s/it]\r\nend_vram - start_vram: 14446958702 - 13008260046 = 1438698656\r\n#75 [DownloadAndLoadToraModel]: 35.23s - vram 1438698656b\r\nend_vram - start_vram: 14446958702 - 14446958702 = 0\r\n#72 [LoadImage]: 0.02s - vram 0b\r\nend_vram - start_vram: 14446958702 - 14446958702 = 0\r\n#73 [ImageResizeKJ]: 0.00s - vram 0b\r\nend_vram - start_vram: 14446958702 - 14446958702 = 0\r\n#60 [SplineEditor]: 0.11s - vram 0b\r\nend_vram - start_vram: 14446958702 - 14446958702 = 0\r\n#67 [GetMaskSizeAndCount]: 0.00s - vram 0b\r\nend_vram - start_vram: 14446958702 - 14446958702 = 0\r\n#85 [SplineEditor]: 0.07s - vram 0b\r\nend_vram - start_vram: 14446958702 - 14446958702 = 0\r\n#82 [SplineEditor]: 0.07s - vram 0b\r\nend_vram - start_vram: 14446958702 - 14446958702 = 0\r\n#83 [AppendStringsToList]: 0.00s - vram 0b\r\nend_vram - start_vram: 14446958702 - 14446958702 = 0\r\n#86 [AppendStringsToList]: 0.00s - vram 0b\r\nreceived 3 trajectorie(s)\r\nvideo_flow shape after encoding: torch.Size([1, 16, 13, 60, 90])\r\nend_vram - start_vram: 16117826884 - 14446958702 = 1670868182\r\n#78 [ToraEncodeTrajectory]: 4.74s - vram 1670868182b\r\nend_vram - start_vram: 14724537294 - 14724537294 = 0\r\n#66 [VHS_VideoCombine]: 0.32s - vram 0b\r\nend_vram - start_vram: 14724537294 - 14724537294 = 0\r\n#65 [CreateShapeImageOnPath]: 0.21s - vram 0b\r\nEncoded latents shape: torch.Size([1, 13, 16, 60, 90])\r\nend_vram - start_vram: 16395405476 - 14724537294 = 1670868182\r\n#93 [CogVideoImageEncodeFunInP]: 3.57s - vram 1670868182b\r\nend_vram - start_vram: 14726924094 - 14726924094 = 0\r\n#20 [CLIPLoader]: 2.17s - vram 0b\r\nRequested to load SD3ClipModel_\r\nLoading 1 new model\r\nloaded partially 64.0 32.38671875 0\r\nend_vram - start_vram: 24471274066 - 14726924094 = 9744349972\r\n#30 [CogVideoTextEncode]: 12.29s - vram 9744349972b\r\nUnloading models for lowram load.\r\n1 models unloaded.\r\nLoading 1 new model\r\nloaded partially 6805.310731887817 6779.38671875 0\r\nend_vram - start_vram: 24251545410 - 24251545410 = 0\r\n#31 [CogVideoTextEncode]: 5.73s - vram 0b\r\nReceived 13 image conditioning frames\r\nContext schedule disabled\r\nTora trajectory length: 13\r\nSampling 49 frames in 13 latent frames at 720x480 with 40 inference steps\r\n  0%|                                                                                                        | 0/40 [00:00<?, ?it/s]\r\n!!! Exception during processing !!! Input type (struct c10::BFloat16) and bias type (struct c10::Half) should be the same\r\nTraceback (most recent call last):\r\n  File \"D:\\ComfyUI\\execution.py\", line 323, in execute\r\n    output_data, output_ui, has_subgraph = get_output_data(obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\r\n                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\ComfyUI\\execution.py\", line 198, in get_output_data\r\n    return_values = _map_node_over_list(obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\r\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\ComfyUI\\execution.py\", line 169, in _map_node_over_list\r\n    process_inputs(input_dict, i)\r\n  File \"D:\\ComfyUI\\execution.py\", line 158, in process_inputs\r\n    results.append(getattr(obj, func)(**inputs))\r\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\ComfyUI\\custom_nodes\\ComfyUI-CogVideoXWrapper\\nodes.py\", line 696, in process\r\n    latents = model[\"pipe\"](\r\n              ^^^^^^^^^^^^^^\r\n  File \"D:\\ComfyUI\\venv\\Lib\\site-packages\\torch\\utils\\_contextlib.py\", line 116, in decorate_context\r\n    return func(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\ComfyUI\\custom_nodes\\ComfyUI-CogVideoXWrapper\\pipeline_cogvideox.py\", line 757, in __call__\r\n    noise_pred = self.transformer(\r\n                 ^^^^^^^^^^^^^^^^^\r\n  File \"D:\\ComfyUI\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1736, in _wrapped_call_impl\r\n    return self._call_impl(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\ComfyUI\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1747, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\ComfyUI\\custom_nodes\\ComfyUI-CogVideoXWrapper\\custom_cogvideox_transformer_3d.py\", line 688, in forward\r\n    hidden_states, encoder_hidden_states = block(\r\n                                           ^^^^^^\r\n  File \"D:\\ComfyUI\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1736, in _wrapped_call_impl\r\n    return self._call_impl(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\ComfyUI\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1747, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\ComfyUI\\custom_nodes\\ComfyUI-CogVideoXWrapper\\custom_cogvideox_transformer_3d.py\", line 266, in forward\r\n    h = fuser(h, video_flow_feature.to(h), T=T)\r\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\ComfyUI\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1736, in _wrapped_call_impl\r\n    return self._call_impl(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\ComfyUI\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1747, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\ComfyUI\\custom_nodes\\ComfyUI-CogVideoXWrapper\\tora\\traj_module.py\", line 287, in forward\r\n    gamma_flow = self.flow_gamma_spatial(flow)\r\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\ComfyUI\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1736, in _wrapped_call_impl\r\n    return self._call_impl(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\ComfyUI\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1747, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\ComfyUI\\venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py\", line 554, in forward\r\n    return self._conv_forward(input, self.weight, self.bias)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\ComfyUI\\venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py\", line 549, in _conv_forward\r\n    return F.conv2d(\r\n           ^^^^^^^^^\r\nRuntimeError: Input type (struct c10::BFloat16) and bias type (struct c10::Half) should be the same\r\n\r\nend_vram - start_vram: 16169275134 - 14726924094 = 1442351040\r\n#79 [CogVideoSampler]: 0.66s - vram 1442351040b\r\n```",
    "comments_url": "https://api.github.com/repos/kijai/ComfyUI-CogVideoXWrapper/issues/267/comments",
    "author": "EnragedAntelope",
    "comments": [
      {
        "user": "kijai",
        "created_at": "2024-11-20T14:42:15Z",
        "body": "Thanks for the report, indeed I broke it with last update, should be fixed now."
      },
      {
        "user": "EnragedAntelope",
        "created_at": "2024-11-20T15:27:21Z",
        "body": "Confirmed fixed, thank you!"
      }
    ]
  },
  {
    "number": 261,
    "title": "Fix fused sdpa",
    "created_at": "2024-11-20T09:40:58Z",
    "closed_at": "2024-11-20T10:37:26Z",
    "labels": [],
    "url": "https://github.com/kijai/ComfyUI-CogVideoXWrapper/pull/261",
    "body": null,
    "comments_url": "https://api.github.com/repos/kijai/ComfyUI-CogVideoXWrapper/issues/261/comments",
    "author": "Dango233",
    "comments": [
      {
        "user": "kijai",
        "created_at": "2024-11-20T10:37:29Z",
        "body": "Thanks"
      }
    ]
  },
  {
    "number": 250,
    "title": "Getting the Sizes of tensors must match error on the 1.5 test branch for image to video on new 1.5 model",
    "created_at": "2024-11-19T10:49:40Z",
    "closed_at": "2024-11-19T17:29:26Z",
    "labels": [],
    "url": "https://github.com/kijai/ComfyUI-CogVideoXWrapper/issues/250",
    "body": "\r\n\r\ngot prompt\r\nOnly one image conditioning frame received, img2vid\r\n!!! Exception during processing !!! Sizes of tensors must match except in dimension 1. Expected size 60 but got size 170 for tensor number 1 in the list.\r\nTraceback (most recent call last):\r\n  File \"C:\\SD\\ComfyUI2\\New\\ComfyUI_windows_portable\\ComfyUI\\execution.py\", line 323, in execute\r\n    output_data, output_ui, has_subgraph = get_output_data(obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\r\n                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"C:\\SD\\ComfyUI2\\New\\ComfyUI_windows_portable\\ComfyUI\\execution.py\", line 198, in get_output_data\r\n    return_values = _map_node_over_list(obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\r\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"C:\\SD\\ComfyUI2\\New\\ComfyUI_windows_portable\\ComfyUI\\execution.py\", line 169, in _map_node_over_list\r\n    process_inputs(input_dict, i)\r\n  File \"C:\\SD\\ComfyUI2\\New\\ComfyUI_windows_portable\\ComfyUI\\execution.py\", line 158, in process_inputs\r\n    results.append(getattr(obj, func)(**inputs))\r\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"C:\\SD\\ComfyUI2\\New\\ComfyUI_windows_portable\\ComfyUI\\custom_nodes\\ComfyUI-CogVideoXWrapper\\nodes.py\", line 875, in process\r\n    latents = pipeline[\"pipe\"](\r\n              ^^^^^^^^^^^^^^^^^\r\n  File \"C:\\SD\\ComfyUI2\\New\\ComfyUI_windows_portable\\python_embeded\\Lib\\site-packages\\torch\\utils\\_contextlib.py\", line 116, in decorate_context\r\n    return func(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^\r\n  File \"C:\\SD\\ComfyUI2\\New\\ComfyUI_windows_portable\\ComfyUI\\custom_nodes\\ComfyUI-CogVideoXWrapper\\pipeline_cogvideox.py\", line 525, in __call__\r\n    image_cond_latents = torch.cat([image_cond_latents, latent_padding], dim=1)\r\n                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nRuntimeError: Sizes of tensors must match except in dimension 1. Expected size 60 but got size 170 for tensor number 1 in the list.",
    "comments_url": "https://api.github.com/repos/kijai/ComfyUI-CogVideoXWrapper/issues/250/comments",
    "author": "tcla75",
    "comments": [
      {
        "user": "kijai",
        "created_at": "2024-11-19T17:29:26Z",
        "body": "This was probably due to me changing the nodes, lots of stuff has changed so this issue as it is becomes redundant."
      }
    ]
  },
  {
    "number": 245,
    "title": "1.5test branch AssertionError('First input (fp16) and second input (bf16) must have the same dtype!')",
    "created_at": "2024-11-18T08:00:10Z",
    "closed_at": "2024-11-18T08:13:45Z",
    "labels": [],
    "url": "https://github.com/kijai/ComfyUI-CogVideoXWrapper/issues/245",
    "body": "   noise_pred = self.transformer(\r\n                 ^^^^^^^^^^^^^^^^^\r\n  File \"/data/wangxi/miniconda3/envs/comfyuimain/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\r\n    return self._call_impl(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/data/wangxi/miniconda3/envs/comfyuimain/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/data/wangxi/ComfyUI/custom_nodes/ComfyUI-CogVideoXWrapper/custom_cogvideox_transformer_3d.py\", line 685, in forward\r\n    hidden_states, encoder_hidden_states = block(\r\n                                           ^^^^^^\r\n  File \"/data/wangxi/miniconda3/envs/comfyuimain/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\r\n    return self._call_impl(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/data/wangxi/miniconda3/envs/comfyuimain/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/data/wangxi/ComfyUI/custom_nodes/ComfyUI-CogVideoXWrapper/custom_cogvideox_transformer_3d.py\", line 282, in forward\r\n    attn_hidden_states, attn_encoder_hidden_states = self.attn1(\r\n                                                     ^^^^^^^^^^^\r\n  File \"/data/wangxi/miniconda3/envs/comfyuimain/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\r\n    return self._call_impl(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/data/wangxi/miniconda3/envs/comfyuimain/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/data/wangxi/miniconda3/envs/comfyuimain/lib/python3.11/site-packages/diffusers/models/attention_processor.py\", line 495, in forward\r\n    return self.processor(\r\n           ^^^^^^^^^^^^^^^\r\n  File \"/data/wangxi/ComfyUI/custom_nodes/ComfyUI-CogVideoXWrapper/custom_cogvideox_transformer_3d.py\", line 129, in __call__\r\n    hidden_states = sageattn_func(query, key, value, attn_mask=attention_mask, dropout_p=0.0,is_causal=False)\r\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/data/wangxi/miniconda3/envs/comfyuimain/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py\", line 451, in _fn\r\n    return fn(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^\r\n  File \"/data/wangxi/ComfyUI/custom_nodes/ComfyUI-CogVideoXWrapper/custom_cogvideox_transformer_3d.py\", line 50, in sageattn_func\r\n    return sageattn(query, key, value, attn_mask=attn_mask, dropout_p=dropout_p,is_causal=is_causal)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/data/wangxi/miniconda3/envs/comfyuimain/lib/python3.11/site-packages/sageattention/core.py\", line 106, in sageattn\r\n    o = attn_true(q_int8, k_int8, v, q_scale, k_scale, tensor_layout=tensor_layout, output_dtype=dtype)\r\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/data/wangxi/miniconda3/envs/comfyuimain/lib/python3.11/site-packages/sageattention/attn_qk_int8_per_block.py\", line 113, in forward\r\n    _attn_fwd[grid](\r\n  File \"/data/wangxi/miniconda3/envs/comfyuimain/lib/python3.11/site-packages/triton/runtime/jit.py\", line 167, in <lambda>\r\n    return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)\r\n                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/data/wangxi/miniconda3/envs/comfyuimain/lib/python3.11/site-packages/triton/runtime/jit.py\", line 416, in run\r\n    self.cache[device][key] = compile(\r\n                              ^^^^^^^^\r\n  File \"/data/wangxi/miniconda3/envs/comfyuimain/lib/python3.11/site-packages/triton/compiler/compiler.py\", line 191, in compile\r\n    module = src.make_ir(options)\r\n             ^^^^^^^^^^^^^^^^^^^^\r\n  File \"/data/wangxi/miniconda3/envs/comfyuimain/lib/python3.11/site-packages/triton/compiler/compiler.py\", line 117, in make_ir\r\n    return ast_to_ttir(self.fn, self, options=options)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/data/wangxi/miniconda3/envs/comfyuimain/lib/python3.11/site-packages/triton/compiler/code_generator.py\", line 1231, in ast_to_ttir\r\n    raise CompilationError(fn.src, node, repr(e)) from e\r\ntriton.compiler.errors.CompilationError: at 39:55:    O_block_ptr = Out + (off_z * stride_oz + off_h * stride_oh) + offs_m[:, None] * stride_on + offs_k[None, :]\r\n\r\n    m_i = tl.zeros([BLOCK_M], dtype=tl.float32) - float(\"inf\")\r\n    l_i = tl.zeros([BLOCK_M], dtype=tl.float32) + 1.0\r\n    acc = tl.zeros([BLOCK_M, HEAD_DIM], dtype=tl.float32)\r\n\r\n    q = tl.load(Q_ptrs, mask = offs_m[:, None] < qo_len)\r\n    q_scale = tl.load(Q_scale_ptr)\r\n    acc, l_i = _attn_fwd_inner(acc, l_i, m_i, q, q_scale, kv_len, K_ptrs, K_scale_ptr, V_ptrs, stride_kn, stride_vn,\r\n                                    start_m,\r\n                                    BLOCK_M, HEAD_DIM, BLOCK_N,\r\n                                    4 - STAGE, offs_m, offs_n\r\n                                                       ^\r\nAssertionError('First input (fp16) and second input (bf16) must have the same dtype!')\r\n\r\ncommit 6f9e4ff6477d51ef29e2f7eea9ff2bbd6986b007 (HEAD -> 1.5_test, origin/1.5_test)\r\nAuthor: kijai <40791699+kijai@users.noreply.github.com>\r\nDate:   Sun Nov 17 22:23:40 2024 +0200\r\n\r\n    Update custom_cogvideox_transformer_3d.py\r\n\r\ncommit e70da23ac2b4724624537e503b0cdaf93d24a74e\r\nAuthor: kijai <40791699+kijai@users.noreply.",
    "comments_url": "https://api.github.com/repos/kijai/ComfyUI-CogVideoXWrapper/issues/245/comments",
    "author": "magicwang1111",
    "comments": [
      {
        "user": "kijai",
        "created_at": "2024-11-18T08:09:53Z",
        "body": "I think I had this too with sageattention 1.0.5, reverting back to 1.0.3 made it work again. "
      },
      {
        "user": "magicwang1111",
        "created_at": "2024-11-18T08:13:33Z",
        "body": "> I think I had this too with sageattention 1.0.5, reverting back to 1.0.3 made it work again.\r\n\r\nthx,this error is fixed.you can add it in requirements."
      }
    ]
  },
  {
    "number": 244,
    "title": "speed of sageattention is same as sdp",
    "created_at": "2024-11-18T02:55:35Z",
    "closed_at": "2024-11-19T17:29:48Z",
    "labels": [],
    "url": "https://github.com/kijai/ComfyUI-CogVideoXWrapper/issues/244",
    "body": "Running CogVideox1.5 i2v, compare sdpa and sageattention for several times, almost same speed. Is there something wrong?\r\nbtw, torch compile is off, because it always throws an error.\r\n\r\nsystem info\r\ngpu: 3090\r\ntorch: 2.5.1+cu124\r\ntriton: 3.1.0\r\nsageattention: 1.0.5",
    "comments_url": "https://api.github.com/repos/kijai/ComfyUI-CogVideoXWrapper/issues/244/comments",
    "author": "cheezecrisp",
    "comments": [
      {
        "user": "cheezecrisp",
        "created_at": "2024-11-18T03:15:00Z",
        "body": "Ah almost forgot to mention, running on windows 10"
      },
      {
        "user": "kijai",
        "created_at": "2024-11-19T08:22:15Z",
        "body": "I had a mistake in the code and it was not used at all, but also turns out it doesn't work with 1.5. I also am having issues running the 1.0.5 version while 1.0.3 works with the non-1.5 models just fine."
      }
    ]
  },
  {
    "number": 232,
    "title": "AttributeError: module 'torch' has no attribute 'compiler'",
    "created_at": "2024-11-14T13:40:19Z",
    "closed_at": "2024-11-14T15:22:25Z",
    "labels": [],
    "url": "https://github.com/kijai/ComfyUI-CogVideoXWrapper/issues/232",
    "body": "Hello,  I'm receiving this error trying to install this custom node using ComfyUI Manager.\r\n\r\nsageattn not found, using sdpa\r\nTraceback (most recent call last):\r\n  File \"F:\\Standard Diffusion Base Folder\\ComfyUI_windows_portable\\ComfyUI\\nodes.py\", line 2022, in load_custom_node\r\n    module_spec.loader.exec_module(module)\r\n  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\r\n  File \"F:\\Standard Diffusion Base Folder\\ComfyUI_windows_portable\\ComfyUI\\custom_nodes\\ComfyUI-CogVideoXWrapper\\__init__.py\", line 2, in <module>\r\n    from .model_loading import NODE_CLASS_MAPPINGS as MODEL_CLASS, NODE_DISPLAY_NAME_MAPPINGS as MODEL_DISPLAY\r\n  File \"F:\\Standard Diffusion Base Folder\\ComfyUI_windows_portable\\ComfyUI\\custom_nodes\\ComfyUI-CogVideoXWrapper\\model_loading.py\", line 12, in <module>\r\n    from .custom_cogvideox_transformer_3d import CogVideoXTransformer3DModel\r\n  File \"F:\\Standard Diffusion Base Folder\\ComfyUI_windows_portable\\ComfyUI\\custom_nodes\\ComfyUI-CogVideoXWrapper\\custom_cogvideox_transformer_3d.py\", line 64, in <module>\r\n    class CogVideoXAttnProcessor2_0:\r\n  File \"F:\\Standard Diffusion Base Folder\\ComfyUI_windows_portable\\ComfyUI\\custom_nodes\\ComfyUI-CogVideoXWrapper\\custom_cogvideox_transformer_3d.py\", line 73, in CogVideoXAttnProcessor2_0\r\n    @torch.compiler.disable()\r\nAttributeError: module 'torch' has no attribute 'compiler'\r\n\r\nCannot import F:\\Standard Diffusion Base Folder\\ComfyUI_windows_portable\\ComfyUI\\custom_nodes\\ComfyUI-CogVideoXWrapper module for custom nodes: module 'torch' has no attribute 'compiler'\r\n\r\n\r\n",
    "comments_url": "https://api.github.com/repos/kijai/ComfyUI-CogVideoXWrapper/issues/232/comments",
    "author": "AllanBlackwater",
    "comments": [
      {
        "user": "kijai",
        "created_at": "2024-11-14T14:30:15Z",
        "body": "Your torch version must be really old, definitely in need of an update."
      },
      {
        "user": "AllanBlackwater",
        "created_at": "2024-11-14T14:52:37Z",
        "body": "I ran update_comfyui_and_python_dependencies.bat to update it before posting this issue, thinking it updated that, but yeah looks like it's using\r\n\r\npytorch version: 2.0.1+cu118\r\n\r\nI'll work on figuring out why that's not updating. \r\n\r\n"
      }
    ]
  },
  {
    "number": 223,
    "title": "Adding comfy attention mode like in MochiWrapper",
    "created_at": "2024-11-12T07:50:51Z",
    "closed_at": "2024-11-19T17:56:03Z",
    "labels": [],
    "url": "https://github.com/kijai/ComfyUI-CogVideoXWrapper/issues/223",
    "body": "Could we possibly get comfy attention mode in the \"(Down)load CogVideo Model\" node as we have for \"(Down)load Mochi Model\" node in MochiWrapper? Or does this model work differently/not support other attention_modes? Thanks!",
    "comments_url": "https://api.github.com/repos/kijai/ComfyUI-CogVideoXWrapper/issues/223/comments",
    "author": "gitanon112",
    "comments": [
      {
        "user": "kijai",
        "created_at": "2024-11-19T17:56:03Z",
        "body": "Added."
      }
    ]
  },
  {
    "number": 213,
    "title": "Error when the CogVideoXFUN sampler uses the PAB",
    "created_at": "2024-11-09T03:40:43Z",
    "closed_at": "2024-11-19T17:49:52Z",
    "labels": [],
    "url": "https://github.com/kijai/ComfyUI-CogVideoXWrapper/issues/213",
    "body": "I think this is a new issue with some recent update, as it was running fine before.\r\nBTW, it's no problem with CogVideo Sampler.\r\n\r\nInit Pyramid Attention Broadcast. steps: 50. spatial broadcast: True, spatial range: 2, spatial threshold: [100, 850]. temporal broadcast: False, temporal range: 4, temporal_threshold: [100, 850]. cross broadcast: False, cross range: 6, cross threshold: [100, 850]. mlp broadcast: False.\r\nTemporal tiling and context schedule disabled\r\n  0%|                                                                                           | 0/20 [00:01<?, ?it/s]\r\n!!! Exception during processing !!! CogVideoXTransformer3DModel.forward() got an unexpected keyword argument 'video_flow_features'\r\nTraceback (most recent call last):\r\n  File \"D:\\AI\\ComfyUI_windows_portable\\ComfyUI\\execution.py\", line 323, in execute\r\n    output_data, output_ui, has_subgraph = get_output_data(obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\r\n                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\AI\\ComfyUI_windows_portable\\ComfyUI\\execution.py\", line 198, in get_output_data\r\n    return_values = _map_node_over_list(obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\r\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\AI\\ComfyUI_windows_portable\\ComfyUI\\execution.py\", line 169, in _map_node_over_list\r\n    process_inputs(input_dict, i)\r\n  File \"D:\\AI\\ComfyUI_windows_portable\\ComfyUI\\execution.py\", line 158, in process_inputs\r\n    results.append(getattr(obj, func)(**inputs))\r\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\AI\\ComfyUI_windows_portable\\ComfyUI\\custom_nodes\\ComfyUI-CogVideoXWrapper\\nodes.py\", line 1154, in process\r\n    latents = pipe(\r\n              ^^^^^\r\n  File \"D:\\AI\\ComfyUI_windows_portable\\python_embeded\\Lib\\site-packages\\torch\\utils\\_contextlib.py\", line 116, in decorate_context\r\n    return func(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\AI\\ComfyUI_windows_portable\\ComfyUI\\custom_nodes\\ComfyUI-CogVideoXWrapper\\cogvideox_fun\\pipeline_cogvideox_inpaint.py\", line 1092, in __call__\r\n    noise_pred = self.transformer(\r\n                 ^^^^^^^^^^^^^^^^^\r\n  File \"D:\\AI\\ComfyUI_windows_portable\\python_embeded\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1736, in _wrapped_call_impl\r\n    return self._call_impl(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\AI\\ComfyUI_windows_portable\\python_embeded\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1747, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\AI\\ComfyUI_windows_portable\\python_embeded\\Lib\\site-packages\\accelerate\\hooks.py\", line 169, in new_forward\r\n    output = module._old_forward(*args, **kwargs)\r\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nTypeError: CogVideoXTransformer3DModel.forward() got an unexpected keyword argument 'video_flow_features'\r\n\r\nPrompt executed in 26.90 seconds",
    "comments_url": "https://api.github.com/repos/kijai/ComfyUI-CogVideoXWrapper/issues/213/comments",
    "author": "cheezecrisp",
    "comments": [
      {
        "user": "kijai",
        "created_at": "2024-11-09T08:53:39Z",
        "body": "I'm actually aware of this yes, what I'm considering at this point however is dropping PAB altogether in favour of FasterCache, which seems to do same thing but...well, faster. "
      },
      {
        "user": "cheezecrisp",
        "created_at": "2024-11-09T14:36:13Z",
        "body": "> I'm actually aware of this yes, what I'm considering at this point however is dropping PAB altogether in favour of FasterCache, which seems to do same thing but...well, faster.\r\n\r\nI guess the FasterCache is useful for 50 steps, but how to set proper paramters for as low as 20 steps?"
      },
      {
        "user": "kijai",
        "created_at": "2024-11-09T14:38:36Z",
        "body": "> > I'm actually aware of this yes, what I'm considering at this point however is dropping PAB altogether in favour of FasterCache, which seems to do same thing but...well, faster.\r\n> \r\n> I guess the FasterCache is useful for 50 steps, but how to set proper paramters for as low as 20 steps?\r\n\r\nDon't know the exact math, but something like start at step 5-7, HF to around middle and LF near end, like with the 50 step defaults."
      }
    ]
  },
  {
    "number": 211,
    "title": "LLMLoader ckpt_name is undefined",
    "created_at": "2024-11-09T01:14:22Z",
    "closed_at": "2024-11-19T17:49:33Z",
    "labels": [],
    "url": "https://github.com/kijai/ComfyUI-CogVideoXWrapper/issues/211",
    "body": "I've attempted to download the llm and place it in the models/llm folder but does nto show up - nor do any other llms I put there to test to see if they show up.\r\nIs there a nother folder that LLMLoader is pulling from?\r\n\r\nThank you",
    "comments_url": "https://api.github.com/repos/kijai/ComfyUI-CogVideoXWrapper/issues/211/comments",
    "author": "gjnave",
    "comments": [
      {
        "user": "kijai",
        "created_at": "2024-11-09T02:20:19Z",
        "body": "You probably posted this to the wrong repository."
      }
    ]
  },
  {
    "number": 180,
    "title": "can you tell me your torch version?",
    "created_at": "2024-10-25T04:22:37Z",
    "closed_at": "2024-10-29T17:59:09Z",
    "labels": [],
    "url": "https://github.com/kijai/ComfyUI-CogVideoXWrapper/issues/180",
    "body": null,
    "comments_url": "https://api.github.com/repos/kijai/ComfyUI-CogVideoXWrapper/issues/180/comments",
    "author": "zzddwyff",
    "comments": [
      {
        "user": "kijai",
        "created_at": "2024-10-25T08:05:10Z",
        "body": "You should have 2.4.1 minimum, 2.5.0 works well too and is recommended."
      }
    ]
  },
  {
    "number": 171,
    "title": "AutoencoderKLCogVideoX error",
    "created_at": "2024-10-22T20:16:25Z",
    "closed_at": "2024-10-29T18:02:33Z",
    "labels": [],
    "url": "https://github.com/kijai/ComfyUI-CogVideoXWrapper/issues/171",
    "body": "Hi Kijai, I'm getting a brand new, showstopper error with CogVideoDecode and CogVideoImageInterpolationEncode (haven't tested all workflows yet):\r\n\r\n`'AutoencoderKLCogVideoX' object has no attribute '_clear_fake_context_parallel_cache'`\r\n\r\nAny ideas? It's happening right after hitting 100%. Windows 11, 24GB VRAM.\r\n\r\nThanks for any advice helping to solve this and your outstanding dedication to this project!",
    "comments_url": "https://api.github.com/repos/kijai/ComfyUI-CogVideoXWrapper/issues/171/comments",
    "author": "dcalabrez",
    "comments": [
      {
        "user": "dcalabrez",
        "created_at": "2024-10-22T21:26:06Z",
        "body": "I think this may have been diffuser-related as the error seems to be gone after the latest update (hopefully). Now getting a different error related to assembling the completed frames between CogVideoDecode and Video Combine, accompanied by a black output:\r\n\r\n```\r\n...videohelpersuite\\nodes.py:102: RuntimeWarning: invalid value encountered in cast\r\n  return tensor_to_int(tensor, 8).astype(np.uint8)\r\n```"
      },
      {
        "user": "simonwalkersamuel",
        "created_at": "2024-10-23T12:14:30Z",
        "body": "Also finding the same error. Updating diffuser didn't help..."
      },
      {
        "user": "monmonja",
        "created_at": "2024-10-23T16:52:26Z",
        "body": "Same here, updated diffuser and getting the same error on linux"
      },
      {
        "user": "monmonja",
        "created_at": "2024-10-24T02:46:46Z",
        "body": "Managed to fix it, you have to go to the requirement.txt and instead of >=0.30.3 make it ==0.30.3, i also did the same with accelarate. Then pip install -r requirement.txt"
      },
      {
        "user": "FDoKE",
        "created_at": "2024-10-24T04:13:36Z",
        "body": "@kijai can confirm too - not working on actual diffusers ==0.30.3 fixes the problem"
      },
      {
        "user": "kijai",
        "created_at": "2024-10-24T08:08:58Z",
        "body": "> @kijai can confirm too - not working on actual diffusers ==0.30.3 fixes the problem\r\n\r\nOr just update the nodes as I fixed diffusers 0.31.0 support when it came out already."
      }
    ]
  },
  {
    "number": 169,
    "title": "one diff implementation on python code",
    "created_at": "2024-10-22T12:20:19Z",
    "closed_at": "2024-10-23T13:11:38Z",
    "labels": [],
    "url": "https://github.com/kijai/ComfyUI-CogVideoXWrapper/issues/169",
    "body": "how can ı use onediff on cogvideox5b implementation on python ? ",
    "comments_url": "https://api.github.com/repos/kijai/ComfyUI-CogVideoXWrapper/issues/169/comments",
    "author": "kursatdinc",
    "comments": [
      {
        "user": "kijai",
        "created_at": "2024-10-23T13:04:49Z",
        "body": "I don't understand, this is python code?"
      }
    ]
  },
  {
    "number": 164,
    "title": "CogVideo sampler node in video2video workflow missing width/height/num_frames",
    "created_at": "2024-10-21T16:20:47Z",
    "closed_at": "2024-10-21T18:16:45Z",
    "labels": [],
    "url": "https://github.com/kijai/ComfyUI-CogVideoXWrapper/issues/164",
    "body": "The CogVideo sampler node is missing width, height and num_frames nodes, and throws an error when the workflow is run:\r\n\r\n> Prompt outputs failed validation\r\n> CogVideoSampler:\r\n> - Required input is missing: num_frames\r\n> - Required input is missing: width\r\n> - Required input is missing: height\r\n\r\nIn place of those inputs are image_cond_latents, context_options and controlnet. Is there another way of passing the width/height/num_frame values to the node?",
    "comments_url": "https://api.github.com/repos/kijai/ComfyUI-CogVideoXWrapper/issues/164/comments",
    "author": "simonwalkersamuel",
    "comments": [
      {
        "user": "kijai",
        "created_at": "2024-10-21T16:47:33Z",
        "body": "The node is just outdated, haven't updated the workflow. You can recreate (right click and Fix node).\r\n\r\nI also just uploaded updated version of that workflow with the node fixed up."
      }
    ]
  },
  {
    "number": 163,
    "title": "Can we perform parallel inference like llama.cpp does?",
    "created_at": "2024-10-21T09:49:46Z",
    "closed_at": "2024-11-19T18:00:12Z",
    "labels": [],
    "url": "https://github.com/kijai/ComfyUI-CogVideoXWrapper/issues/163",
    "body": "Can we perform parallel inference like llama.cpp does?",
    "comments_url": "https://api.github.com/repos/kijai/ComfyUI-CogVideoXWrapper/issues/163/comments",
    "author": "WOAI704",
    "comments": [
      {
        "user": "kijai",
        "created_at": "2024-11-19T18:00:12Z",
        "body": "There are some ways, just not in comfy and as I don't have multiple GPUs available it's not something I will work towards at this time."
      }
    ]
  },
  {
    "number": 156,
    "title": "\"Max 49 frames\" but ECNU-CILab/ExVideo-CogVideoX-LoRA-129f-v1",
    "created_at": "2024-10-17T10:34:47Z",
    "closed_at": "2024-10-17T20:14:55Z",
    "labels": [],
    "url": "https://github.com/kijai/ComfyUI-CogVideoXWrapper/issues/156",
    "body": "I see a lot of reference to this lora in closed issues but I have been unable to get it to work in my environment due to behaviors of the custom nodes.\r\n\r\nAm I missing something obvious?",
    "comments_url": "https://api.github.com/repos/kijai/ComfyUI-CogVideoXWrapper/issues/156/comments",
    "author": "sl33pyC01E",
    "comments": [
      {
        "user": "kijai",
        "created_at": "2024-10-17T13:24:23Z",
        "body": "> I see a lot of reference to this lora in closed issues but I have been unable to get it to work in my environment due to behaviors of the custom nodes.\n> \n> Am I missing something obvious?\n\nIt's a LoRa for the text2video, not image2video."
      },
      {
        "user": "sl33pyC01E",
        "created_at": "2024-10-17T20:14:37Z",
        "body": "i was able to resolve the error readout by recreating the nodes 😅\n\nyou are also correct I believe "
      }
    ]
  },
  {
    "number": 147,
    "title": "Help......can't import the node after updata today.",
    "created_at": "2024-10-14T03:51:43Z",
    "closed_at": "2024-10-14T12:41:38Z",
    "labels": [],
    "url": "https://github.com/kijai/ComfyUI-CogVideoXWrapper/issues/147",
    "body": "Traceback (most recent call last):\r\n  File \"H:\\ComfyUI-qiuye\\ComfyUI\\nodes.py\", line 2001, in load_custom_node\r\n    module_spec.loader.exec_module(module)\r\n  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\r\n  File \"H:\\ComfyUI-qiuye\\ComfyUI\\custom_nodes\\ComfyUI-CogVideoXWrapper\\__init__.py\", line 1, in <module>\r\n    from .nodes import NODE_CLASS_MAPPINGS, NODE_DISPLAY_NAME_MAPPINGS\r\n  File \"H:\\ComfyUI-qiuye\\ComfyUI\\custom_nodes\\ComfyUI-CogVideoXWrapper\\nodes.py\", line 18, in <module>\r\n    from diffusers.schedulers import (\r\nImportError: cannot import name 'CogVideoXDDIMScheduler' from 'diffusers.schedulers' (H:\\ComfyUI-qiuye\\ComfyUI\\.ext\\Lib\\site-packages\\diffusers\\schedulers\\__init__.py)\r\n\r\nCannot import H:\\ComfyUI-qiuye\\ComfyUI\\custom_nodes\\ComfyUI-CogVideoXWrapper module for custom nodes: cannot import name 'CogVideoXDDIMScheduler' from 'diffusers.schedulers' (H:\\ComfyUI-qiuye\\ComfyUI\\.ext\\Lib\\site-packages\\diffusers\\schedulers\\__init__.py)",
    "comments_url": "https://api.github.com/repos/kijai/ComfyUI-CogVideoXWrapper/issues/147/comments",
    "author": "K-O-N-B",
    "comments": [
      {
        "user": "kijai",
        "created_at": "2024-10-14T07:19:45Z",
        "body": "After what update? That error suggests your diffusers version is too old."
      },
      {
        "user": "K-O-N-B",
        "created_at": "2024-10-14T12:41:39Z",
        "body": "Found the cause, various plug-ins causing confusion in the environment"
      }
    ]
  },
  {
    "number": 136,
    "title": "Error when running fastmode",
    "created_at": "2024-10-07T12:06:11Z",
    "closed_at": "2024-10-07T18:06:43Z",
    "labels": [],
    "url": "https://github.com/kijai/ComfyUI-CogVideoXWrapper/issues/136",
    "body": "When I try activating fastmode, I get the error CUDA error: \r\n\r\nCUBLAS_STATUS_NOT_SUPPORTED when calling `cublasLtMatmulAlgoGetHeuristic( ltHandle, computeDesc.descriptor(), Adesc.descriptor(), Bdesc.descriptor(), Cdesc.descriptor(), Ddesc.descriptor(), preference.descriptor(), 1, &heuristicResult, &returnedResult)`.\r\n\r\nI suspect my CUDA version is not correct, I have v11.8. Which one do I need?\r\n\r\nRTX 4090, Windows 11.",
    "comments_url": "https://api.github.com/repos/kijai/ComfyUI-CogVideoXWrapper/issues/136/comments",
    "author": "jpgallegoar",
    "comments": [
      {
        "user": "kijai",
        "created_at": "2024-10-07T12:41:03Z",
        "body": "You need torch that's compiled for cuda 124."
      },
      {
        "user": "jpgallegoar",
        "created_at": "2024-10-07T17:19:04Z",
        "body": "> You need torch that's compiled for cuda 124.\r\n\r\nThank you, that worked."
      }
    ]
  },
  {
    "number": 133,
    "title": "Sageattention breaks compiling with onediff.",
    "created_at": "2024-10-07T02:31:27Z",
    "closed_at": "2024-11-19T17:32:05Z",
    "labels": [],
    "url": "https://github.com/kijai/ComfyUI-CogVideoXWrapper/issues/133",
    "body": "Installed sageattention. It gave a speed boost. Even if I don't use fp8 quant, compile with onediff fails. Says cannot find a compatible kernel from triton. Uninstalling sageattention works but then it can't be used otherwise. 3090 on linux.",
    "comments_url": "https://api.github.com/repos/kijai/ComfyUI-CogVideoXWrapper/issues/133/comments",
    "author": "Ph0rk0z",
    "comments": [
      {
        "user": "kijai",
        "created_at": "2024-10-07T06:11:31Z",
        "body": "I think this is to be expected, I doubt it can work with onediff without specific support from them, I don't know enough of this to say if it's something that will be possible."
      },
      {
        "user": "Ph0rk0z",
        "created_at": "2024-10-07T11:30:14Z",
        "body": "I think the fix would be to not have it use sageattention when onediff compile is on, rather than making them work together. Right now it's beating both compilation methods anyways. I get down to 9s/it.\r\n\r\nSpeaking of compile, the torch.compile also fails on the 2nd gen when the seed is changed. I'd like to try compiling with it that way, but I never get to enjoy the fruits of my labor for this reason.\r\n\r\nHave you tried their other onediff backend or is it incompatible with the model arch?"
      },
      {
        "user": "kijai",
        "created_at": "2024-10-07T12:40:24Z",
        "body": "Nexfort is the only one I've gotten to work, never got torch.compile to work at all."
      },
      {
        "user": "Ph0rk0z",
        "created_at": "2024-10-07T13:06:59Z",
        "body": "I guess I will try oneflow and see if it errors out.\r\n\r\nedit: played with some of the options you send to nexfort and they speed things up when not using fp8. when the first one was set false, compiling was almost slower than not."
      },
      {
        "user": "kijai",
        "created_at": "2024-10-07T14:32:48Z",
        "body": "> I guess I will try oneflow and see if it errors out.\r\n> \r\n> edit: played with some of the options you send to nexfort and they speed things up when not using fp8. when the first one was set false, compiling was almost slower than not.\r\n\r\nThat's curious, it makes no difference to me, but someone else told the same that it's slower... it was taken from the CogVideo example on the onediff repo, probably best to change it then.\r\nYou mean the `inductor.optimize_linear_epilogue` right?"
      },
      {
        "user": "Ph0rk0z",
        "created_at": "2024-10-07T23:28:13Z",
        "body": "Yup, I turned on the other one too, but I don't think that makes a difference in speed. Made the videos less blurry when using the LCM scheduler.\r\n\r\nI seem to get the best perf when setting things to FP16 but then I get a black image. Its as if there are NaN in the output. maybe it's so fast because it's multiplying 0's?\r\n\r\nI also tried to use ondiff, but it fails on the attention function. The 2 shapes it torch.cat's at line ~63 are not compatible."
      },
      {
        "user": "tavyscrolls",
        "created_at": "2024-10-10T05:16:56Z",
        "body": "> Nexfort is the only one I've gotten to work, never got torch.compile to work at all.\r\n\r\nDoes this mean you also get a mosaic of pixel patches with sageattention installed? Fresh environment, all python versions none of them produce images but removing sageattention fixes it"
      },
      {
        "user": "kijai",
        "created_at": "2024-10-10T08:15:32Z",
        "body": "> > Nexfort is the only one I've gotten to work, never got torch.compile to work at all.\r\n> \r\n> Does this mean you also get a mosaic of pixel patches with sageattention installed? Fresh environment, all python versions none of them produce images but removing sageattention fixes it\r\n\r\nI haven't tried it with onediff, otherwise it's been working fine and I don't see any quality changes."
      }
    ]
  },
  {
    "number": 128,
    "title": "No module named peft",
    "created_at": "2024-10-06T01:54:58Z",
    "closed_at": "2024-10-06T09:00:32Z",
    "labels": [],
    "url": "https://github.com/kijai/ComfyUI-CogVideoXWrapper/issues/128",
    "body": "getting this error on the model loader currently\r\n",
    "comments_url": "https://api.github.com/repos/kijai/ComfyUI-CogVideoXWrapper/issues/128/comments",
    "author": "itspoidaman",
    "comments": [
      {
        "user": "kijai",
        "created_at": "2024-10-06T09:00:32Z",
        "body": "Should be fixed now."
      }
    ]
  },
  {
    "number": 126,
    "title": "onediff support",
    "created_at": "2024-10-05T06:40:59Z",
    "closed_at": "2024-10-05T13:33:21Z",
    "labels": [],
    "url": "https://github.com/kijai/ComfyUI-CogVideoXWrapper/issues/126",
    "body": "Is onediff supported in Comfy portable + windows? i haven't found any useful tutorial on how to install it properly, or what platform is it compatible with, i've seen old reddit posts showing the performance improvements, but no guide on how to do it.\r\n\r\nThat's my last issue for a while, i do want that 40% speed increase if it's possible :/",
    "comments_url": "https://api.github.com/repos/kijai/ComfyUI-CogVideoXWrapper/issues/126/comments",
    "author": "hassakajin",
    "comments": [
      {
        "user": "kijai",
        "created_at": "2024-10-05T06:47:24Z",
        "body": "Onediff itself is not supported in Windows."
      },
      {
        "user": "hassakajin",
        "created_at": "2024-10-05T13:33:21Z",
        "body": "Oh man this is sad,  i thought it was. \r\nBig Thanks though!"
      }
    ]
  },
  {
    "number": 123,
    "title": "Can you create a text to video flowchart for CogVideoX-Fun?",
    "created_at": "2024-10-02T16:05:40Z",
    "closed_at": "2024-10-09T18:06:15Z",
    "labels": [],
    "url": "https://github.com/kijai/ComfyUI-CogVideoXWrapper/issues/123",
    "body": "I need CogVideoX-Fun's text to video flow but I don't know how to create it",
    "comments_url": "https://api.github.com/repos/kijai/ComfyUI-CogVideoXWrapper/issues/123/comments",
    "author": "q80192",
    "comments": [
      {
        "user": "kijai",
        "created_at": "2024-10-09T18:06:15Z",
        "body": "If you mean a workflow, they are in the examples folder."
      }
    ]
  },
  {
    "number": 122,
    "title": "cuda error: an illegal memory access was encountered",
    "created_at": "2024-10-02T14:55:13Z",
    "closed_at": "2024-10-03T03:35:05Z",
    "labels": [],
    "url": "https://github.com/kijai/ComfyUI-CogVideoXWrapper/issues/122",
    "body": "I updated the CogVideoXWrapper about 10 hours ago. after this update it keep showing this error when the workflow comes to Cogvideo Decode. I tried i2v and the Pose workflow, they both showed the same error. the error is only shown on the cmd window, and the Cogvideo Decode node is stuck since then.  the  full log is as follows:\r\ngot prompt\r\nTemporal tiling disabled\r\nException in thread Thread-22 (prompt_worker):\r\nTraceback (most recent call last):\r\n  File \"I:\\stable_diffusion\\ComfyUI-aki-v1.2\\ComfyUI-aki-v1.2\\execution.py\", line 317, in execute\r\n    output_data, output_ui, has_subgraph = get_output_data(obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\r\n  File \"I:\\stable_diffusion\\ComfyUI-aki-v1.2\\ComfyUI-aki-v1.2\\execution.py\", line 192, in get_output_data\r\n    return_values = _map_node_over_list(obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\r\n  File \"I:\\stable_diffusion\\ComfyUI-aki-v1.2\\ComfyUI-aki-v1.2\\execution.py\", line 169, in _map_node_over_list\r\n    process_inputs(input_dict, i)\r\n  File \"I:\\stable_diffusion\\ComfyUI-aki-v1.2\\ComfyUI-aki-v1.2\\execution.py\", line 158, in process_inputs\r\n    results.append(getattr(obj, func)(**inputs))\r\n  File \"I:\\stable_diffusion\\ComfyUI-aki-v1.2\\ComfyUI-aki-v1.2\\custom_nodes\\ComfyUI-CogVideoXWrapper\\nodes.py\", line 926, in decode\r\n    frames = vae.decode(latents).sample\r\n  File \"I:\\stable_diffusion\\ComfyUI-aki-v1.2\\ComfyUI-aki-v1.2\\python\\lib\\site-packages\\diffusers\\utils\\accelerate_utils.py\", line 46, in wrapper\r\n    return method(self, *args, **kwargs)\r\n  File \"I:\\stable_diffusion\\ComfyUI-aki-v1.2\\ComfyUI-aki-v1.2\\python\\lib\\site-packages\\diffusers\\models\\autoencoders\\autoencoder_kl_cogvideox.py\", line 1184, in decode\r\n    decoded = self._decode(z).sample\r\n  File \"I:\\stable_diffusion\\ComfyUI-aki-v1.2\\ComfyUI-aki-v1.2\\python\\lib\\site-packages\\diffusers\\models\\autoencoders\\autoencoder_kl_cogvideox.py\", line 1142, in _decode\r\n    return self.tiled_decode(z, return_dict=return_dict)\r\n\r\n  File \"I:\\stable_diffusion\\ComfyUI-aki-v1.2\\ComfyUI-aki-v1.2\\python\\lib\\site-packages\\diffusers\\models\\autoencoders\\autoencoder_kl_cogvideox.py\", line 1332, in tiled_decode\r\n    tile = self.decoder(tile)\r\n  File \"I:\\stable_diffusion\\ComfyUI-aki-v1.2\\ComfyUI-aki-v1.2\\python\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1511, in _wrapped_call_impl\r\n    return self._call_impl(*args, **kwargs)\r\n  File \"I:\\stable_diffusion\\ComfyUI-aki-v1.2\\ComfyUI-aki-v1.2\\python\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1520, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n  File \"I:\\stable_diffusion\\ComfyUI-aki-v1.2\\ComfyUI-aki-v1.2\\python\\lib\\site-packages\\diffusers\\models\\autoencoders\\autoencoder_kl_cogvideox.py\", line 877, in forward\r\n    hidden_states = up_block(hidden_states, temb, sample)\r\n  File \"I:\\stable_diffusion\\ComfyUI-aki-v1.2\\ComfyUI-aki-v1.2\\python\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1511, in _wrapped_call_impl\r\n    return self._call_impl(*args, **kwargs)\r\n  File \"I:\\stable_diffusion\\ComfyUI-aki-v1.2\\ComfyUI-aki-v1.2\\python\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1520, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n  File \"I:\\stable_diffusion\\ComfyUI-aki-v1.2\\ComfyUI-aki-v1.2\\python\\lib\\site-packages\\diffusers\\models\\autoencoders\\autoencoder_kl_cogvideox.py\", line 602, in forward\r\n    hidden_states = resnet(hidden_states, temb, zq)\r\n  File \"I:\\stable_diffusion\\ComfyUI-aki-v1.2\\ComfyUI-aki-v1.2\\python\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1511, in _wrapped_call_impl\r\n    return self._call_impl(*args, **kwargs)\r\n  File \"I:\\stable_diffusion\\ComfyUI-aki-v1.2\\ComfyUI-aki-v1.2\\python\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1520, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n  File \"I:\\stable_diffusion\\ComfyUI-aki-v1.2\\ComfyUI-aki-v1.2\\python\\lib\\site-packages\\diffusers\\models\\autoencoders\\autoencoder_kl_cogvideox.py\", line 303, in forward\r\n    hidden_states = self.conv2(hidden_states)\r\n  File \"I:\\stable_diffusion\\ComfyUI-aki-v1.2\\ComfyUI-aki-v1.2\\python\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1511, in _wrapped_call_impl\r\n    return self._call_impl(*args, **kwargs)\r\n  File \"I:\\stable_diffusion\\ComfyUI-aki-v1.2\\ComfyUI-aki-v1.2\\python\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1520, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n  File \"I:\\stable_diffusion\\ComfyUI-aki-v1.2\\ComfyUI-aki-v1.2\\python\\lib\\site-packages\\diffusers\\models\\autoencoders\\autoencoder_kl_cogvideox.py\", line 144, in forward\r\n    output = self.conv(inputs)\r\n\r\n  File \"I:\\stable_diffusion\\ComfyUI-aki-v1.2\\ComfyUI-aki-v1.2\\python\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1511, in _wrapped_call_impl\r\n    return self._call_impl(*args, **kwargs)\r\n  File \"I:\\stable_diffusion\\ComfyUI-aki-v1.2\\ComfyUI-aki-v1.2\\python\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1520, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n  File \"I:\\stable_diffusion\\ComfyUI-aki-v1.2\\ComfyUI-aki-v1.2\\python\\lib\\site-packages\\diffusers\\models\\autoencoders\\autoencoder_kl_cogvideox.py\", line 64, in forward\r\n    return super().forward(input)\r\n  File \"I:\\stable_diffusion\\ComfyUI-aki-v1.2\\ComfyUI-aki-v1.2\\python\\lib\\site-packages\\torch\\nn\\modules\\conv.py\", line 610, in forward\r\n    return self._conv_forward(input, self.weight, self.bias)\r\n  File \"I:\\stable_diffusion\\ComfyUI-aki-v1.2\\ComfyUI-aki-v1.2\\python\\lib\\site-packages\\torch\\nn\\modules\\conv.py\", line 605, in _conv_forward\r\n    return F.conv3d(\r\nRuntimeError: CUDA error: an illegal memory access was encountered\r\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\r\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\r\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"I:\\stable_diffusion\\ComfyUI-aki-v1.2\\ComfyUI-aki-v1.2\\python\\lib\\threading.py\", line 1016, in _bootstrap_inner\r\n    self.run()\r\n  File \"<enhanced_experience vendors.sentry_sdk.integrations.threading>\", line 99, in run\r\n  File \"<enhanced_experience vendors.sentry_sdk.integrations.threading>\", line 94, in _run_old_run_func\r\n  File \"<enhanced_experience vendors.sentry_sdk.utils>\", line 1649, in reraise\r\n  File \"<enhanced_experience vendors.sentry_sdk.integrations.threading>\", line 92, in _run_old_run_func\r\n  File \"I:\\stable_diffusion\\ComfyUI-aki-v1.2\\ComfyUI-aki-v1.2\\python\\lib\\threading.py\", line 953, in run\r\n    self._target(*self._args, **self._kwargs)\r\n  File \"I:\\stable_diffusion\\ComfyUI-aki-v1.2\\ComfyUI-aki-v1.2\\main.py\", line 125, in prompt_worker\r\n    e.execute(item[2], prompt_id, item[3], item[4])\r\n  File \"I:\\stable_diffusion\\ComfyUI-aki-v1.2\\ComfyUI-aki-v1.2\\custom_nodes\\rgthree-comfy\\__init__.py\", line 211, in rgthree_execute\r\n    return self.rgthree_old_execute(*args, **kwargs)\r\n  File \"I:\\stable_diffusion\\ComfyUI-aki-v1.2\\ComfyUI-aki-v1.2\\execution.py\", line 494, in execute\r\n    result, error, ex = execute(self.server, dynamic_prompt, self.caches, node_id, extra_data, executed, prompt_id, execution_list, pending_subgraph_results)\r\n  File \"I:\\stable_diffusion\\ComfyUI-aki-v1.2\\ComfyUI-aki-v1.2\\execution.py\", line 384, in execute\r\n    input_data_formatted[name] = [format_value(x) for x in inputs]\r\n  File \"I:\\stable_diffusion\\ComfyUI-aki-v1.2\\ComfyUI-aki-v1.2\\execution.py\", line 384, in <listcomp>\r\n    input_data_formatted[name] = [format_value(x) for x in inputs]\r\n  File \"I:\\stable_diffusion\\ComfyUI-aki-v1.2\\ComfyUI-aki-v1.2\\execution.py\", line 236, in format_value\r\n    return str(x)\r\n  File \"I:\\stable_diffusion\\ComfyUI-aki-v1.2\\ComfyUI-aki-v1.2\\python\\lib\\site-packages\\torch\\_tensor.py\", line 461, in __repr__\r\n    return torch._tensor_str._str(self, tensor_contents=tensor_contents)\r\n  File \"I:\\stable_diffusion\\ComfyUI-aki-v1.2\\ComfyUI-aki-v1.2\\python\\lib\\site-packages\\torch\\_tensor_str.py\", line 677, in _str\r\n------------------------\r\nFault Traceback: \r\nNot Available",
    "comments_url": "https://api.github.com/repos/kijai/ComfyUI-CogVideoXWrapper/issues/122/comments",
    "author": "tdrminglin",
    "comments": [
      {
        "user": "kijai",
        "created_at": "2024-10-02T15:43:11Z",
        "body": "Is this with vae_tiling enabled or not?"
      },
      {
        "user": "tdrminglin",
        "created_at": "2024-10-02T17:45:03Z",
        "body": "> Is this with vae_tiling enabled or not?\r\n\r\nThanks for replying. vae_tiling is enabled."
      },
      {
        "user": "kijai",
        "created_at": "2024-10-02T18:01:37Z",
        "body": "> > Is this with vae_tiling enabled or not?\n> \n> Thanks for replying. vae_tiling is enabled.\n\nI don't really know the cause for that error, but if it worked before then try disabling the auto_tile_size as that's what I changed."
      },
      {
        "user": "tdrminglin",
        "created_at": "2024-10-03T03:11:28Z",
        "body": "1.I deleted \"vae._clear_fake_context_parallel_cache()\" \r\n2. replaced the vae_tiling  codes by those from the last version \r\n3. changed tiling settings to last version\r\nI don't know which step worked, but  the error is gone. Thanks again."
      }
    ]
  },
  {
    "number": 121,
    "title": "How do I enable temporal Tiling?",
    "created_at": "2024-10-02T13:31:19Z",
    "closed_at": "2024-10-02T17:25:00Z",
    "labels": [],
    "url": "https://github.com/kijai/ComfyUI-CogVideoXWrapper/issues/121",
    "body": "Sorry to ask here, but I could not find it anywhere.",
    "comments_url": "https://api.github.com/repos/kijai/ComfyUI-CogVideoXWrapper/issues/121/comments",
    "author": "scofano",
    "comments": [
      {
        "user": "kijai",
        "created_at": "2024-10-02T15:42:27Z",
        "body": "There's example workflow using it, I haven't really implemented it further for every possible model/pipeline though."
      },
      {
        "user": "scofano",
        "created_at": "2024-10-02T17:25:00Z",
        "body": "Oh, I see it now. Thanks a lot!"
      }
    ]
  },
  {
    "number": 120,
    "title": "CogVideoX-Fun-V1.1-5b-InP -> Sizes of tensors must match except in dimension 2. Expected size 480 but got size 576 for tensor number 1 in the list.",
    "created_at": "2024-10-01T22:20:17Z",
    "closed_at": "2024-10-05T10:43:06Z",
    "labels": [],
    "url": "https://github.com/kijai/ComfyUI-CogVideoXWrapper/issues/120",
    "body": "Tried to load up the new CogVideoX-Fun-V1.1-5b-InP into CogVideoXFun Sample and got : Sizes of tensors must match except in dimension 2. Expected size 480 but got size 576 for tensor number 1 in the list.\r\n\r\nThe 480 was constant but the 576 varies based on how I set the Base Resolution. Did some quick math and to get it to equal 480 I needed value to be 640, so I altered nodes.py with the below and it worked. Not sure if pull request is needed to update list to add 640 or if I did something wrong with the existing nodes?\r\n\r\nclass CogVideoXFunSampler:\r\n    @classmethod\r\n    def INPUT_TYPES(s):\r\n        return {\r\n            \"required\": {\r\n                \"pipeline\": (\"COGVIDEOPIPE\",),\r\n                \"positive\": (\"CONDITIONING\", ),\r\n                \"negative\": (\"CONDITIONING\", ),\r\n                \"video_length\": (\"INT\", {\"default\": 49, \"min\": 5, \"max\": 49, \"step\": 4}),\r\n                \"base_resolution\": (\r\n                    [ \r\n                        256,\r\n                        320,\r\n                        384,\r\n                        448,\r\n                        512,\r\n\t\t\t\t\t\t640,  <-----------\r\n                        768,\r\n                        960,\r\n                        1024,\r\n                    ], {\"default\": 768}\r\n                ),",
    "comments_url": "https://api.github.com/repos/kijai/ComfyUI-CogVideoXWrapper/issues/120/comments",
    "author": "tdtrumble",
    "comments": [
      {
        "user": "K-Max-Me",
        "created_at": "2024-10-02T15:29:35Z",
        "body": "Can confirm this fixed my issue too. I thought this model can accept varied resolutions. "
      },
      {
        "user": "kijai",
        "created_at": "2024-10-02T15:37:40Z",
        "body": "In the original code they have only 4 base resolutions to choose from, not sure it makes any sense, I can just change that input to be int with step of 64."
      },
      {
        "user": "tdtrumble",
        "created_at": "2024-10-02T20:51:37Z",
        "body": "> In the original code they have only 4 base resolutions to choose from, not sure it makes any sense, I can just change that input to be int with step of 64.\n\nMakes sense, seems like it would be the most future proof solution."
      }
    ]
  },
  {
    "number": 119,
    "title": "CogVideoX-Fun-V1.1",
    "created_at": "2024-10-01T21:00:40Z",
    "closed_at": "2024-10-03T18:05:59Z",
    "labels": [],
    "url": "https://github.com/kijai/ComfyUI-CogVideoXWrapper/issues/119",
    "body": "is the CogVideoX-Fun-V1.1 not compatible with I2V like the first one? it completely distorts and warps images, no matter the noise strength \"wich i have no idea how it works\" or cfg, i had a poor cat turn into a strange matter akin to a demon from the depths of hell so many times that i had to delete the poor thing, i downloaded the model directly from HF, could that be the reason tho? i might re-download it from the loader tomorrow maybe.",
    "comments_url": "https://api.github.com/repos/kijai/ComfyUI-CogVideoXWrapper/issues/119/comments",
    "author": "hassakajin",
    "comments": [
      {
        "user": "kijai",
        "created_at": "2024-10-01T21:08:41Z",
        "body": "It's a lot stronger because of that noise, less noise would make it more stable. Generally the issue with the 1.0 was that it most of the time just generated no motion at all, just slow zooms, and their 1.1 was mostly to address this. I can't say I've seen anything like you describe yet though, but there's been some results with pretty much garbled motion.\r\n\r\nThat said, if you can run the model then it's working as intended, if there was any issue with download etc. it would simply error out."
      },
      {
        "user": "hassakajin",
        "created_at": "2024-10-01T21:38:00Z",
        "body": "> It's a lot stronger because of that noise, less noise would make it more stable. \r\n\r\nyeah really cranking the noise down + lowering cfg made it way more stable, thanks! i had the idea that normal noise would be like 0.4, but around 0.010 it started getting better!\r\n\r\n> Generally the issue with the 1.0 was that it most of the time just generated no motion at all, just slow zooms, and their 1.1 was mostly to address this.\r\n\r\nyeah that was truly an issue, though i think 1.1 was a bit overtuned in that aspect, maybe that's just me... 2b works wonders though strangely, time to get testing everything that works again i guess."
      },
      {
        "user": "cheezecrisp",
        "created_at": "2024-10-02T08:15:16Z",
        "body": "The v1.1 model does produce more significant human dynamics, but is unable to maintain proper human body structure. Attempted to reduce the 'noise_aug_strength' were not effective in improving this, and perhaps the v1.1 model needs further training."
      },
      {
        "user": "hassakajin",
        "created_at": "2024-10-03T06:35:30Z",
        "body": "Before anything else... what is the default \"noise_aug_strength\"? I've been trying to figure this out for the first fun5b model release, is it 0.7 or straight up 0? for me so far the previous model were giving me nice motion, so there is a little trick to it. Perhaps when i'm done setting up my workflow i can share with you, to use it however you like it.\r\n\r\nAlso in regards to the v1.1 version, it works well in pair with caption models like florence, it gives the image motion enough to no be still, but inputting any type of human motion like jumping or walking warps everything,"
      },
      {
        "user": "kijai",
        "created_at": "2024-10-03T09:01:26Z",
        "body": "> Before anything else... what is the default \"noise_aug_strength\"? I've been trying to figure this out for the first fun5b model release, is it 0.7 or straight up 0? for me so far the previous model were giving me nice motion, so there is a little trick to it. Perhaps when i'm done setting up my workflow i can share with you, to use it however you like it.\r\n> \r\n> Also in regards to the v1.1 version, it works well in pair with caption models like florence, it gives the image motion enough to no be still, but inputting any type of human motion like jumping or walking warps everything,\r\n\r\nThe default is the default when you create the node, so 0.056. The value is from the original code."
      },
      {
        "user": "hassakajin",
        "created_at": "2024-10-03T18:05:59Z",
        "body": "thanks"
      }
    ]
  },
  {
    "number": 100,
    "title": "Base model and the GGUF model differences?",
    "created_at": "2024-09-27T22:23:00Z",
    "closed_at": "2024-10-01T01:57:34Z",
    "labels": [],
    "url": "https://github.com/kijai/ComfyUI-CogVideoXWrapper/issues/100",
    "body": "What's the difference between a 5bFun model and the 5bfun-GGUF model? i get images more vivid and darker with GGUF versions, is that the only thing it's for? i am so confused about these model versions, is there a description for each somewhere?",
    "comments_url": "https://api.github.com/repos/kijai/ComfyUI-CogVideoXWrapper/issues/100/comments",
    "author": "hassakajin",
    "comments": [
      {
        "user": "kijai",
        "created_at": "2024-09-27T23:22:10Z",
        "body": "GGUF is just different way to optimize the model by quantization, results are a bit different, but main thing is that it uses less VRAM, and is slightly slower."
      },
      {
        "user": "hassakajin",
        "created_at": "2024-09-28T06:11:54Z",
        "body": "well that's interesting, thanks for the reply!"
      }
    ]
  },
  {
    "number": 97,
    "title": "1Torch was not compiled with flash attention",
    "created_at": "2024-09-25T06:30:07Z",
    "closed_at": "2024-10-01T02:07:44Z",
    "labels": [],
    "url": "https://github.com/kijai/ComfyUI-CogVideoXWrapper/issues/97",
    "body": "I know this most likely has nothing to do with Cog, but I'm getting the following:\r\n```ComfyUI\\comfy\\ldm\\modules\\attention.py:407: UserWarning: 1Torch was not compiled with flash attention.```\r\nIt still runs okay, I'm just wondering if this is compromising my quality or speed or anything.\r\n\r\nThanks in advance for any help.",
    "comments_url": "https://api.github.com/repos/kijai/ComfyUI-CogVideoXWrapper/issues/97/comments",
    "author": "Vektor369",
    "comments": [
      {
        "user": "kijai",
        "created_at": "2024-09-25T06:35:05Z",
        "body": "It's normal for Windows currently as flash_attn isn't supported by the prebuilt torch installs. CogVideoX itself doesn't benefit from it either, as far as I know."
      },
      {
        "user": "Vektor369",
        "created_at": "2024-09-25T06:52:35Z",
        "body": "Awesome! Thank you so much kijai!"
      }
    ]
  },
  {
    "number": 96,
    "title": "Low VRAM Workflow for IMG2VID GGUF?",
    "created_at": "2024-09-24T22:02:45Z",
    "closed_at": "2024-09-24T22:36:30Z",
    "labels": [],
    "url": "https://github.com/kijai/ComfyUI-CogVideoXWrapper/issues/96",
    "body": "I was wondering if it is possible to lower the resolution on regular CogvideoX img2vid sampling in some way to increase inference? \r\n\r\nI know CogvideoX fun works, but it does not give the greatest results compared to the regular i2v model. If it is not possible, I will just have to wait for my upgrade.. Then I will stick to CogvideoXfun at 320p for now.",
    "comments_url": "https://api.github.com/repos/kijai/ComfyUI-CogVideoXWrapper/issues/96/comments",
    "author": "FemBoxbrawl",
    "comments": [
      {
        "user": "FemBoxbrawl",
        "created_at": "2024-09-24T22:02:58Z",
        "body": "I get errors when trying to lower res"
      },
      {
        "user": "kijai",
        "created_at": "2024-09-24T22:21:01Z",
        "body": "Nope, it's locked to 49 frames at 720x480, just how the model is trained, nothing to be done about it currently."
      }
    ]
  },
  {
    "number": 95,
    "title": "OneDiff Support",
    "created_at": "2024-09-24T17:03:29Z",
    "closed_at": "2024-09-30T22:39:48Z",
    "labels": [],
    "url": "https://github.com/kijai/ComfyUI-CogVideoXWrapper/issues/95",
    "body": "Hello! \r\nI was running all sample workflows on my system (Linux, PyTorch 2.4, onediff, RTX 4090). \r\nThey all work, but onediff is not being used. \r\n\r\nWhat do I need to trigger it? \r\n\r\nThank you! ",
    "comments_url": "https://api.github.com/repos/kijai/ComfyUI-CogVideoXWrapper/issues/95/comments",
    "author": "sandor-lisn",
    "comments": [
      {
        "user": "kijai",
        "created_at": "2024-09-24T17:06:27Z",
        "body": "You have enabled onediff as the compile option in the model loader node? Note that onediff doesn't work with GGUF so it's only available in the normal model loader node."
      },
      {
        "user": "sandor-lisn",
        "created_at": "2024-09-25T04:21:09Z",
        "body": "Hello, \r\nthank you very much for your lightning fast answer! \r\nMy bad, I should have seen this option myself...\r\n\r\nWhen I enable it, I get a python error. The stacktrace is at the botton of this message. \r\n\r\nI followed the instructions on your main project page. My conda environment contains: \r\n- torch 2.4.0.dev20240324+cu121\r\n- nexfort 0.1.dev271\r\n- onediff 1.2.1.dev24\r\n- onediffx 1.2.1.dev24\r\n\r\nDo you have a suggestion? Thank you!\r\n\r\n========\r\nUnable to load nexfort.{extension} module. Is it compatible with your PyTorch installation?\r\n!!! Exception during processing !!! /home/sandor/anaconda3/envs/comfy-flux/lib/python3.10/site-packages/nexfort/_C.cpython-310-x86_64-linux-gnu.so: undefined symbol: _ZNK3c105Error4whatEv\r\nTraceback (most recent call last):\r\n  File \"/home/sandor/workspace/ComfyUI-flux/execution.py\", line 323, in execute\r\n    output_data, output_ui, has_subgraph = get_output_data(obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\r\n  File \"/home/sandor/workspace/ComfyUI-flux/execution.py\", line 198, in get_output_data\r\n    return_values = _map_node_over_list(obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\r\n  File \"/home/sandor/workspace/ComfyUI-flux/execution.py\", line 169, in _map_node_over_list\r\n    process_inputs(input_dict, i)\r\n  File \"/home/sandor/workspace/ComfyUI-flux/execution.py\", line 158, in process_inputs\r\n    results.append(getattr(obj, func)(**inputs))\r\n  File \"/home/sandor/workspace/ComfyUI-flux/custom_nodes/ComfyUI-CogVideoXWrapper/nodes.py\", line 176, in loadmodel\r\n    pipe = compile_pipe(\r\n  File \"/home/sandor/anaconda3/envs/comfy-flux/lib/python3.10/site-packages/onediffx/compilers/diffusion_pipeline_compiler.py\", line 75, in compile_pipe\r\n    pipe = convert_pipe_to_memory_format(\r\n  File \"/home/sandor/anaconda3/envs/comfy-flux/lib/python3.10/site-packages/onediffx/compilers/diffusion_pipeline_compiler.py\", line 120, in convert_pipe_to_memory_format\r\n    from nexfort.utils.attributes import multi_recursive_apply\r\n  File \"/home/sandor/anaconda3/envs/comfy-flux/lib/python3.10/site-packages/nexfort/__init__.py\", line 22, in <module>\r\n    exec(f\"import nexfort.{extension} as {extension}\")\r\n  File \"<string>\", line 1, in <module>\r\nImportError: /home/sandor/anaconda3/envs/comfy-flux/lib/python3.10/site-packages/nexfort/_C.cpython-310-x86_64-linux-gnu.so: undefined symbol: _ZNK3c105Error4whatEv\r\n"
      },
      {
        "user": "kijai",
        "created_at": "2024-09-25T11:02:20Z",
        "body": "Some issue with nexfort install, not seen that one before. Torch 2.4.1 is on stable release now so I'd suggest installing that, as it works for me using it."
      },
      {
        "user": "sandor-lisn",
        "created_at": "2024-09-26T10:11:16Z",
        "body": "Updating to Torch 2.4.1 did the trick. Thanks so much for your great volunteer efforts! "
      }
    ]
  },
  {
    "number": 90,
    "title": "preview image possible?",
    "created_at": "2024-09-23T13:04:05Z",
    "closed_at": "2024-09-30T22:39:58Z",
    "labels": [],
    "url": "https://github.com/kijai/ComfyUI-CogVideoXWrapper/issues/90",
    "body": "Hello,\r\nI just wanted to ask if there is a possibility to get something like a preview image for the upcoming clip? It takes about 8mins for a clip to render on my 3090 and it would be nice to quit the process if the resulting video has a different look then what i have hoped for.  thanks for your time!",
    "comments_url": "https://api.github.com/repos/kijai/ComfyUI-CogVideoXWrapper/issues/90/comments",
    "author": "zweifuchs",
    "comments": [
      {
        "user": "kijai",
        "created_at": "2024-09-23T13:36:51Z",
        "body": "I don't think that's really feasible with video models, especially this one that uses 3D VAE , even if it was it would further slow it down. Maybe if someone figures a latent2rgb matrix for this or something like the tiny autoencoder(taesd).\r\n\r\nBest you can do is just use less steps, and once you find a seed that gives you the motion you want, run it again with more steps. "
      }
    ]
  },
  {
    "number": 85,
    "title": "Question about decoder",
    "created_at": "2024-09-21T21:39:28Z",
    "closed_at": "2024-09-22T09:47:04Z",
    "labels": [],
    "url": "https://github.com/kijai/ComfyUI-CogVideoXWrapper/issues/85",
    "body": "Apologies if this is a stupid question, I have pretty much zero knowledge about how video models work compared to image models.\r\n\r\nIs the way the sampler and decoder currently work somehow similar to generating images in batches with SA or Flux? If so, would it be theoretically possible to unbatch the latents or specify which frame(s) to send to the decoder by index?\r\n\r\nOr am I totally off the mark and the decoder already handles this already, and doesn't decode all frames at once.\r\n\r\nThe reason I got curious about this is because with Fun-xB models (I assume probably caused by the models themselves, not the wrapper) I noticed that it will output extra/duplicated frames at the beginning of image sequence (ie: it outputs 16 frames when selecting 13 frames as length), so I was wondering if it was possible to remove those before sending to the decoder, thus somehow saving on a bit of resources along the way when decoding.\r\n\r\nI tried a few different nodes to separate latents from batch/select by index but obviously it doesn't work ;)",
    "comments_url": "https://api.github.com/repos/kijai/ComfyUI-CogVideoXWrapper/issues/85/comments",
    "author": "thelemuet",
    "comments": [
      {
        "user": "kijai",
        "created_at": "2024-09-21T21:54:28Z",
        "body": "CogVideoX uses a 3D VAE, meaning it also compresses the images temporally: 4 images into one latent. This causes the disparancies you noticed with the frame counts. The decoding is done 2 \"frames\" at the time by design, it can't be less. If memory for decoding is a concern, the VAE tiling works pretty well with the tile size set to half of the dimensions."
      },
      {
        "user": "thelemuet",
        "created_at": "2024-09-21T22:33:20Z",
        "body": "Ah, makes completes sense, thank you for the explanation.\r\n\r\nFunnily enough, another reason I was messing with the latents is because yesterday I had issues with the VAE tiling resulting in very obvious seams. As an alternative I was splitting the latents with some padding using the core \"crop latent\" node before sending to the decoder, then stitching the images back after that myself. Clearly the latent shape was wrong, cropping the Width was cropping the Height and cropping the Height did nothing, but it did actually work even if not as intended hehe,\r\n\r\nBut looks like there are no more visible seams with VAE tiling after updating today, so thank you, definitely much more convenient ;)"
      },
      {
        "user": "kijai",
        "created_at": "2024-09-21T23:23:00Z",
        "body": "> Ah, makes completes sense, thank you for the explanation.\n> \n> Funnily enough, another reason I was messing with the latents is because yesterday I had issues with the VAE tiling resulting in very obvious seams. As an alternative I was splitting the latents with some padding using the core \"crop latent\" node before sending to the decoder, then stitching the images back after that myself. Clearly the latent shape was wrong, cropping the Width was cropping the Height and cropping the Height did nothing, but it did actually work even if not as intended hehe,\n> \n> But looks like there are no more visible seams with VAE tiling after updating today, so thank you, definitely much more convenient ;)\n\nYes they defaults were just awful before, I got the values from the initial code before these new models and as I never really used it myself, I didn't realise they should be completely different. 96x96 tiles made no sense in pixel space especially, half of the image dimension seems fine now and no seams with 0.2 overlap."
      }
    ]
  },
  {
    "number": 83,
    "title": "Got error when using mask with cogvideox5b_i2v",
    "created_at": "2024-09-21T13:38:41Z",
    "closed_at": "2024-09-21T14:11:32Z",
    "labels": [],
    "url": "https://github.com/kijai/ComfyUI-CogVideoXWrapper/issues/83",
    "body": "want to apply motion mask to keep some regions static, i used the mask node of cogvideo imageencoder, but got following error\r\n\r\n`\r\ngot prompt\r\nfinal latents:  torch.Size([1, 1, 16, 60, 90])\r\nlatents torch.Size([1, 13, 16, 60, 90])\r\nself.original_mask:  torch.Size([1, 480, 720])\r\nlatents:  torch.Size([1, 13, 16, 60, 90])\r\nmask:  torch.Size([1, 13, 16, 60, 90])\r\nTemporal tiling disabled\r\nlatents.shape torch.Size([1, 13, 16, 60, 90])\r\n  0%|                                                                                           | 0/20 [00:15<?, ?it/s]\r\n!!! Exception during processing !!! 'NoneType' object has no attribute 'device'\r\nTraceback (most recent call last):\r\n  File \"D:\\AI\\ComfyUI_windows_portable\\ComfyUI\\execution.py\", line 323, in execute\r\n    output_data, output_ui, has_subgraph = get_output_data(obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\r\n                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\AI\\ComfyUI_windows_portable\\ComfyUI\\execution.py\", line 198, in get_output_data\r\n    return_values = _map_node_over_list(obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\r\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\AI\\ComfyUI_windows_portable\\ComfyUI\\execution.py\", line 169, in _map_node_over_list\r\n    process_inputs(input_dict, i)\r\n  File \"D:\\AI\\ComfyUI_windows_portable\\ComfyUI\\execution.py\", line 158, in process_inputs\r\n    results.append(getattr(obj, func)(**inputs))\r\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\AI\\ComfyUI_windows_portable\\ComfyUI\\custom_nodes\\ComfyUI-CogVideoXWrapper\\nodes.py\", line 598, in process\r\n    latents = pipeline[\"pipe\"](\r\n              ^^^^^^^^^^^^^^^^^\r\n  File \"D:\\AI\\ComfyUI_windows_portable\\python_embeded\\Lib\\site-packages\\torch\\utils\\_contextlib.py\", line 115, in decorate_context\r\n    return func(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\AI\\ComfyUI_windows_portable\\ComfyUI\\custom_nodes\\ComfyUI-CogVideoXWrapper\\pipeline_cogvideox.py\", line 642, in __call__\r\n    image_latent = self.scheduler.add_noise(original_image_latents, noise, torch.tensor([noise_timestep])\r\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\AI\\ComfyUI_windows_portable\\python_embeded\\Lib\\site-packages\\diffusers\\schedulers\\scheduling_dpm_cogvideox.py\", line 451, in add_noise\r\n    self.alphas_cumprod = self.alphas_cumprod.to(device=original_samples.device)\r\n                                                        ^^^^^^^^^^^^^^^^^^^^^^^\r\nAttributeError: 'NoneType' object has no attribute 'device'\r\n\r\nPrompt executed in 16.18 seconds\r\n`\r\n\r\n\r\nBTW, is it possible to apply mask on cogvideox-fun models? didn't find mask on such nodes",
    "comments_url": "https://api.github.com/repos/kijai/ComfyUI-CogVideoXWrapper/issues/83/comments",
    "author": "cheezecrisp",
    "comments": [
      {
        "user": "kijai",
        "created_at": "2024-09-21T13:43:18Z",
        "body": "The masking is very experimental and I haven't tried it with the img2vid models yet, it mostly somewhat worked with the normal text2vid model when doing vid2vid."
      },
      {
        "user": "cheezecrisp",
        "created_at": "2024-09-21T14:11:37Z",
        "body": "> The masking is very experimental and I haven't tried it with the img2vid models yet, it mostly somewhat worked with the normal text2vid model when doing vid2vid.\r\n\r\nok, got it"
      }
    ]
  },
  {
    "number": 77,
    "title": "Error occurred when executing DownloadAndLoadCogVideoModel",
    "created_at": "2024-09-20T16:59:48Z",
    "closed_at": "2024-09-20T17:45:45Z",
    "labels": [],
    "url": "https://github.com/kijai/ComfyUI-CogVideoXWrapper/issues/77",
    "body": "When I tried CogVideoX-5b-I2V, I encountered this problem. Does anyone know how to solve it？\r\n![Uploading PixPin_2024-09-21_00-55-09.jpg…]()\r\n",
    "comments_url": "https://api.github.com/repos/kijai/ComfyUI-CogVideoXWrapper/issues/77/comments",
    "author": "TryingToDoBetter25",
    "comments": [
      {
        "user": "TryingToDoBetter25",
        "created_at": "2024-09-20T17:01:37Z",
        "body": "Traceback (most recent call last):\r\n  File \"F:\\1AI\\1\\ComfyUI_CogVideoX-\\ComfyUI\\execution.py\", line 152, in recursive_execute\r\n    output_data, output_ui = get_output_data(obj, input_data_all)\r\n                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"F:\\1AI\\1\\ComfyUI_CogVideoX-\\ComfyUI\\execution.py\", line 82, in get_output_data\r\n    return_values = map_node_over_list(obj, input_data_all, obj.FUNCTION, allow_interrupt=True)\r\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"F:\\1AI\\1\\ComfyUI_CogVideoX-\\ComfyUI\\execution.py\", line 75, in map_node_over_list\r\n    results.append(getattr(obj, func)(**slice_dict(input_data_all, i)))\r\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"F:\\1AI\\1\\ComfyUI_CogVideoX-\\ComfyUI\\custom_nodes\\ComfyUI-CogVideoXWrapper\\nodes.py\", line 98, in loadmodel\r\n    transformer = CogVideoXTransformer3DModel.from_pretrained(base_path, subfolder=\"transformer\")\r\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"F:\\1AI\\1\\ComfyUI_CogVideoX-\\python_embeded\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py\", line 114, in _inner_fn\r\n    return fn(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^\r\n  File \"F:\\1AI\\1\\ComfyUI_CogVideoX-\\python_embeded\\Lib\\site-packages\\diffusers\\models\\modeling_utils.py\", line 774, in from_pretrained\r\n    accelerate.load_checkpoint_and_dispatch(\r\n  File \"F:\\1AI\\1\\ComfyUI_CogVideoX-\\python_embeded\\Lib\\site-packages\\accelerate\\big_modeling.py\", line 613, in load_checkpoint_and_dispatch\r\n    load_checkpoint_in_model(\r\n  File \"F:\\1AI\\1\\ComfyUI_CogVideoX-\\python_embeded\\Lib\\site-packages\\accelerate\\utils\\modeling.py\", line 1821, in load_checkpoint_in_model\r\n    set_module_tensor_to_device(\r\n  File \"F:\\1AI\\1\\ComfyUI_CogVideoX-\\python_embeded\\Lib\\site-packages\\accelerate\\utils\\modeling.py\", line 341, in set_module_tensor_to_device\r\n    raise ValueError(f\"{module} does not have a parameter or a buffer named {tensor_name}.\")\r\nValueError: CogVideoXPatchEmbed(\r\n  (proj): Conv2d(32, 3072, kernel_size=(2, 2), stride=(2, 2))\r\n  (text_proj): Linear(in_features=4096, out_features=3072, bias=True)\r\n) does not have a parameter or a buffer named pos_embedding.\r\n"
      },
      {
        "user": "kijai",
        "created_at": "2024-09-20T17:25:44Z",
        "body": "Did you update diffusers to 0.30.3?"
      },
      {
        "user": "TryingToDoBetter25",
        "created_at": "2024-09-20T17:45:37Z",
        "body": "> Did you update diffusers to 0.30.3?\r\n\r\nI reinstalled it and it ran successfully. Thank you very much"
      }
    ]
  },
  {
    "number": 74,
    "title": "help me：“TypeError: CogVideoXPipeline.__call__() got an unexpected keyword argument 'video'”",
    "created_at": "2024-09-20T06:39:40Z",
    "closed_at": "2024-09-20T06:57:30Z",
    "labels": [],
    "url": "https://github.com/kijai/ComfyUI-CogVideoXWrapper/issues/74",
    "body": "!!! Exception during processing !!! 'Unfun' models not supported in 'CogVideoXFunSampler', use the 'CogVideoSampler'\r\nTraceback (most recent call last):\r\n  File \"D:\\Comfy_UI\\ComfyUI\\execution.py\", line 323, in execute\r\n    output_data, output_ui, has_subgraph = get_output_data(obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\r\n                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\Comfy_UI\\ComfyUI\\execution.py\", line 198, in get_output_data\r\n    return_values = _map_node_over_list(obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\r\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\Comfy_UI\\ComfyUI\\execution.py\", line 169, in _map_node_over_list\r\n    process_inputs(input_dict, i)\r\n  File \"D:\\Comfy_UI\\ComfyUI\\execution.py\", line 158, in process_inputs\r\n    results.append(getattr(obj, func)(**inputs))\r\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\Comfy_UI\\ComfyUI\\custom_nodes\\ComfyUI-CogVideoXWrapper\\nodes.py\", line 594, in process\r\n    assert \"Fun\" in base_path, \"'Unfun' models not supported in 'CogVideoXFunSampler', use the 'CogVideoSampler'\"\r\n           ^^^^^^^^^^^^^^^^^^\r\nAssertionError: 'Unfun' models not supported in 'CogVideoXFunSampler', use the 'CogVideoSampler'",
    "comments_url": "https://api.github.com/repos/kijai/ComfyUI-CogVideoXWrapper/issues/74/comments",
    "author": "tiandaoyuxi",
    "comments": [
      {
        "user": "MayoPonyo",
        "created_at": "2024-09-20T12:15:57Z",
        "body": "I have had the same issue. Changing model fixed it for me. I got the error with THUDM I2V model. Using Kijai model fixed it."
      }
    ]
  },
  {
    "number": 67,
    "title": "CogVideoX-5b-I2V",
    "created_at": "2024-09-19T10:34:25Z",
    "closed_at": "2024-09-19T10:40:56Z",
    "labels": [],
    "url": "https://github.com/kijai/ComfyUI-CogVideoXWrapper/issues/67",
    "body": null,
    "comments_url": "https://api.github.com/repos/kijai/ComfyUI-CogVideoXWrapper/issues/67/comments",
    "author": "Cal-DCosta",
    "comments": [
      {
        "user": "rhystz",
        "created_at": "2024-09-19T10:42:19Z",
        "body": "I had the same issue with no auto download, but as far as i can tell cloning the hugging face i2v folder into models/CogVideo worked for me"
      }
    ]
  },
  {
    "number": 64,
    "title": "Feature request: saving/loading latents after sampling",
    "created_at": "2024-09-19T00:56:33Z",
    "closed_at": "2024-11-19T17:59:19Z",
    "labels": [],
    "url": "https://github.com/kijai/ComfyUI-CogVideoXWrapper/issues/64",
    "body": "Using the inbuilt save/load latent with vae tiling enabled results in the error:\r\n\r\n`Could not run 'aten::slow_conv3d_forward' with arguments from the 'CUDA' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee `\r\n\r\nAnd with vae tiling off:\r\n\r\n`Sizes of tensors must match except in dimension 2. Expected size 60 but got size 12 for tensor number 1 in the list.`\r\n\r\nWould be super useful to have a smaller GPU sampling videos while 30/4090 does the decoding and interpolation stuff, assuming this isn't a comfy limitation. Or even just saving a couple minutes of sampling because OOM in the final stretch",
    "comments_url": "https://api.github.com/repos/kijai/ComfyUI-CogVideoXWrapper/issues/64/comments",
    "author": "tavyscrolls",
    "comments": [
      {
        "user": "synystersocks",
        "created_at": "2024-09-19T07:54:08Z",
        "body": "after the first generation i get with vae tiling on - Sizes of tensors must match except in dimension 1. Expected size 60 but got size 65 for tensor number 1 in the list.\r\n\r\nif you restart comfyui fully so it unloads out of your ram, and go back in, that seems to fix the issue for that generation \"if both issues are related\". im guessing something is being partially passed into the latent value, possibly from keeping some of the previouly used data from the 1st generation or just that specific latent var that isnt resetting correctly.\r\n\r\nunloading the model alone doesnt seem to work, only a full restart of comfyui.\r\n"
      },
      {
        "user": "kijai",
        "created_at": "2024-11-19T17:59:19Z",
        "body": "These issues should be resolved by now, also it is possible to use the built in Save/Load latent node with this."
      }
    ]
  },
  {
    "number": 62,
    "title": "Error occurred when executing DownloadAndLoadCogVideoModel:  CogVideoXPatchEmbed( (proj): Conv2d(32, 3072, kernel_size=(2, 2), stride=(2, 2)) (text_proj): Linear(in_features=4096, out_features=3072, bias=True) ) does not have a parameter or a buffer named pos_embedding.",
    "created_at": "2024-09-18T21:05:16Z",
    "closed_at": "2024-09-18T21:15:36Z",
    "labels": [],
    "url": "https://github.com/kijai/ComfyUI-CogVideoXWrapper/issues/62",
    "body": "Error occurred when executing DownloadAndLoadCogVideoModel:\r\n\r\nCogVideoXPatchEmbed(\r\n(proj): Conv2d(32, 3072, kernel_size=(2, 2), stride=(2, 2))\r\n(text_proj): Linear(in_features=4096, out_features=3072, bias=True)\r\n) does not have a parameter or a buffer named pos_embedding.\r\n\r\nFile \"C:\\Users\\Gaming\\Desktop\\ComfyUI_windows_portable\\ComfyUI\\execution.py\", line 317, in execute\r\noutput_data, output_ui, has_subgraph = get_output_data(obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\r\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nFile \"C:\\Users\\Gaming\\Desktop\\ComfyUI_windows_portable\\ComfyUI\\execution.py\", line 192, in get_output_data\r\nreturn_values = _map_node_over_list(obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\r\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nFile \"C:\\Users\\Gaming\\Desktop\\ComfyUI_windows_portable\\ComfyUI\\execution.py\", line 169, in _map_node_over_list\r\nprocess_inputs(input_dict, i)\r\nFile \"C:\\Users\\Gaming\\Desktop\\ComfyUI_windows_portable\\ComfyUI\\execution.py\", line 158, in process_inputs\r\nresults.append(getattr(obj, func)(**inputs))\r\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nFile \"C:\\Users\\Gaming\\Desktop\\ComfyUI_windows_portable\\ComfyUI\\custom_nodes\\ComfyUI-CogVideoXWrapper\\nodes.py\", line 92, in loadmodel\r\ntransformer = CogVideoXTransformer3DModel.from_pretrained(base_path, subfolder=\"transformer\")\r\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nFile \"C:\\Users\\Gaming\\Desktop\\ComfyUI_windows_portable\\python_embeded\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py\", line 114, in _inner_fn\r\nreturn fn(*args, **kwargs)\r\n^^^^^^^^^^^^^^^^^^^\r\nFile \"C:\\Users\\Gaming\\Desktop\\ComfyUI_windows_portable\\python_embeded\\Lib\\site-packages\\diffusers\\models\\modeling_utils.py\", line 774, in from_pretrained\r\naccelerate.load_checkpoint_and_dispatch(\r\nFile \"C:\\Users\\Gaming\\Desktop\\ComfyUI_windows_portable\\python_embeded\\Lib\\site-packages\\accelerate\\big_modeling.py\", line 613, in load_checkpoint_and_dispatch\r\nload_checkpoint_in_model(\r\nFile \"C:\\Users\\Gaming\\Desktop\\ComfyUI_windows_portable\\python_embeded\\Lib\\site-packages\\accelerate\\utils\\modeling.py\", line 1821, in load_checkpoint_in_model\r\nset_module_tensor_to_device(\r\nFile \"C:\\Users\\Gaming\\Desktop\\ComfyUI_windows_portable\\python_embeded\\Lib\\site-packages\\accelerate\\utils\\modeling.py\", line 341, in set_module_tensor_to_device\r\nraise ValueError(f\"{module} does not have a parameter or a buffer named {tensor_name}.\")",
    "comments_url": "https://api.github.com/repos/kijai/ComfyUI-CogVideoXWrapper/issues/62/comments",
    "author": "brad12d3",
    "comments": [
      {
        "user": "kijai",
        "created_at": "2024-09-18T21:07:50Z",
        "body": "I2V model requires diffusers version 0.30.3 which came out yesterday."
      },
      {
        "user": "brad12d3",
        "created_at": "2024-09-18T21:15:34Z",
        "body": "Yup that was it, thanks. I guess I missed that.\r\n"
      }
    ]
  },
  {
    "number": 57,
    "title": "No module named nexfort",
    "created_at": "2024-09-18T08:48:33Z",
    "closed_at": "2024-11-19T17:35:21Z",
    "labels": [],
    "url": "https://github.com/kijai/ComfyUI-CogVideoXWrapper/issues/57",
    "body": "Tried to compile with nexfort to speed it up, but it can't find it even if installed.\r\n\r\n```\r\n(venv) (base) D:\\Stablediff\\Comfyuimanual\\ComfyUI>pip install nexfort\r\nRequirement already satisfied: nexfort in d:\\stablediff\\comfyuimanual\\comfyui\\venv\\lib\\site-packages (0.0.1.dev0)\r\nRequirement already satisfied: peppercorn in d:\\stablediff\\comfyuimanual\\comfyui\\venv\\lib\\site-packages (from nexfort) (0.6)\r\n```\r\n\r\n```\r\n2024-09-18 10:44:01,793 - root - INFO - Prompt executed in 11.95 seconds\r\n2024-09-18 10:45:07,168 - root - INFO - got prompt\r\n2024-09-18 10:45:07,534 - root - INFO - Requested to load SD3ClipModel_\r\n2024-09-18 10:45:07,534 - root - INFO - Loading 1 new model\r\n2024-09-18 10:45:07,539 - root - INFO - loaded completely 0.0 4541.693359375 True\r\n2024-09-18 10:45:15,744 - root - ERROR - !!! Exception during processing !!! No module named 'nexfort'\r\n2024-09-18 10:45:15,745 - root - ERROR - Traceback (most recent call last):\r\n  File \"D:\\Stablediff\\Comfyuimanual\\ComfyUI\\execution.py\", line 323, in execute\r\n    output_data, output_ui, has_subgraph = get_output_data(obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\r\n  File \"D:\\Stablediff\\Comfyuimanual\\ComfyUI\\execution.py\", line 198, in get_output_data\r\n    return_values = _map_node_over_list(obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\r\n  File \"D:\\Stablediff\\Comfyuimanual\\ComfyUI\\execution.py\", line 169, in _map_node_over_list\r\n    process_inputs(input_dict, i)\r\n  File \"D:\\Stablediff\\Comfyuimanual\\ComfyUI\\execution.py\", line 158, in process_inputs\r\n    results.append(getattr(obj, func)(**inputs))\r\n  File \"D:\\Stablediff\\Comfyuimanual\\ComfyUI\\custom_nodes\\ComfyUI-CogVideoXWrapper\\nodes.py\", line 98, in loadmodel\r\n    pipe = compile_pipe(\r\n  File \"D:\\Stablediff\\Comfyuimanual\\ComfyUI\\venv\\lib\\site-packages\\onediffx\\compilers\\diffusion_pipeline_compiler.py\", line 75, in compile_pipe\r\n    pipe = convert_pipe_to_memory_format(\r\n  File \"D:\\Stablediff\\Comfyuimanual\\ComfyUI\\venv\\lib\\site-packages\\onediffx\\compilers\\diffusion_pipeline_compiler.py\", line 120, in convert_pipe_to_memory_format\r\n    from nexfort.utils.attributes import multi_recursive_apply\r\nModuleNotFoundError: No module named 'nexfort'\r\n```",
    "comments_url": "https://api.github.com/repos/kijai/ComfyUI-CogVideoXWrapper/issues/57/comments",
    "author": "DuckersMcQuack",
    "comments": [
      {
        "user": "kijai",
        "created_at": "2024-09-18T09:37:33Z",
        "body": "It won't work in Windows anyway."
      },
      {
        "user": "DuckersMcQuack",
        "created_at": "2024-09-18T15:43:42Z",
        "body": "> It won't work in Windows anyway.\r\n\r\nGotcha, thanks for noting that :) it only works for debian, right? Or ubuntu specifically?"
      },
      {
        "user": "kijai",
        "created_at": "2024-09-18T15:53:15Z",
        "body": "> > It won't work in Windows anyway.\r\n> \r\n> Gotcha, thanks for noting that :) it only works for debian, right? Or ubuntu specifically?\r\n\r\nShould work with any Linux distro, I've been using with with Debian and PopOS so far."
      },
      {
        "user": "tavyscrolls",
        "created_at": "2024-09-19T00:24:37Z",
        "body": "It was working for me before xformers made py 3.12 wheels available where I upgraded comfyui/manager/transformers/diffusers/torch/etc and now I'm getting same error. On Debian 13\r\n\r\n```\r\ngot prompt\r\n!!! Exception during processing !!! No module named 'nexfort'\r\nTraceback (most recent call last):\r\n  File \"/home/USER/NAME/ComfyUI/execution.py\", line 323, in execute\r\n    output_data, output_ui, has_subgraph = get_output_data(obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\r\n                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/USER/NAME/ComfyUI/execution.py\", line 198, in get_output_data\r\n    return_values = _map_node_over_list(obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\r\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/USER/NAME/ComfyUI/execution.py\", line 169, in _map_node_over_list\r\n    process_inputs(input_dict, i)\r\n  File \"/home/USER/NAME/ComfyUI/execution.py\", line 158, in process_inputs\r\n    results.append(getattr(obj, func)(**inputs))\r\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/USER/NAME/ComfyUI/custom_nodes/ComfyUI-CogVideoXWrapper/nodes.py\", line 130, in loadmodel\r\n    pipe = compile_pipe(\r\n           ^^^^^^^^^^^^^\r\n  File \"/home/USER/NAME/ComfyUI/venv/lib/python3.12/site-packages/onediffx/compilers/diffusion_pipeline_compiler.py\", line 75, in compile_pipe\r\n    pipe = convert_pipe_to_memory_format(\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/USER/NAME/ComfyUI/venv/lib/python3.12/site-packages/onediffx/compilers/diffusion_pipeline_compiler.py\", line 120, in convert_pipe_to_memory_format\r\n    from nexfort.utils.attributes import multi_recursive_apply\r\nModuleNotFoundError: No module named 'nexfort'\r\n\r\nPrompt executed in 36.34 seconds\r\n^C\r\nStopped server\r\n(venv) (base) USER@NAME:~/Desktop/ComfyUI$ pip install nexfort\r\nRequirement already satisfied: nexfort in ./venv/lib/python3.12/site-packages (0.0.1.dev0)\r\n\r\n```\r\n\r\nThere's an open issue on onediff that may be related."
      }
    ]
  },
  {
    "number": 50,
    "title": "Any plans to support torchao quantization?",
    "created_at": "2024-09-07T16:05:16Z",
    "closed_at": "2024-11-19T17:34:29Z",
    "labels": [],
    "url": "https://github.com/kijai/ComfyUI-CogVideoXWrapper/issues/50",
    "body": "The cogvideox model uses torchao as its official quantization method which can achieve a great balance between inference speed and output video quality. The current fp8 quantization seems to incur significant quality loss especially when contrasted with torchao method. I tried to modify the custom node to support torchao but somehow the program always run into an exception which really makes me frustrated.",
    "comments_url": "https://api.github.com/repos/kijai/ComfyUI-CogVideoXWrapper/issues/50/comments",
    "author": "caojiachen1",
    "comments": [
      {
        "user": "kijai",
        "created_at": "2024-09-07T17:45:13Z",
        "body": "I actually tested it today, the bigger issue is that torchao latest versions has to be compiled to install in Windows, which isn't all that simple. Similarly torch.compile requires Triton (Linux only), and on Linux I find onediff to be much faster anyway.\n\nI had int4 torchao running on windows after some trouble, it used around 12GB VRAM and speed was very slow 9s/it."
      },
      {
        "user": "kijai",
        "created_at": "2024-11-19T17:34:29Z",
        "body": "Included now."
      },
      {
        "user": "caojiachen1",
        "created_at": "2024-11-25T09:45:38Z",
        "body": "Thanks a lot!"
      }
    ]
  },
  {
    "number": 49,
    "title": "Update nodes.py",
    "created_at": "2024-09-07T05:34:42Z",
    "closed_at": "2024-09-07T15:39:49Z",
    "labels": [],
    "url": "https://github.com/kijai/ComfyUI-CogVideoXWrapper/pull/49",
    "body": "Add enable_model_cpu_offload support which can speed up the inference.\r\nChange the cogvideox-2b model folder to \"CogVideoX-2b\"",
    "comments_url": "https://api.github.com/repos/kijai/ComfyUI-CogVideoXWrapper/issues/49/comments",
    "author": "caojiachen1",
    "comments": [
      {
        "user": "kijai",
        "created_at": "2024-09-07T14:24:30Z",
        "body": "Thanks for the input, but enable_model_cpu_offload shouldn't do anything as we are already doing it manually in the nodes instead of the pipeline, since we aren't using the pipeline T5.\r\n\r\nAlso I don't really want to change the path just like that since it would force re-download for the users unless they rename the old one. We could make it backwards compatible so that only new downloads go to properly named path though."
      },
      {
        "user": "caojiachen1",
        "created_at": "2024-09-07T15:39:43Z",
        "body": "okay,that's fine,i will close it"
      }
    ]
  },
  {
    "number": 46,
    "title": "CogVideoXPipeline.__call__() got an unexpected keyword argument 'scheduler_name'",
    "created_at": "2024-09-05T04:19:21Z",
    "closed_at": "2024-09-19T13:10:12Z",
    "labels": [],
    "url": "https://github.com/kijai/ComfyUI-CogVideoXWrapper/issues/46",
    "body": "use ComfyUI-CogVideoXWrapper and this repo in comfyui.\r\n\r\nThe code shows that there is 'scheduler_name' in the __call__ method actually, very confusing.",
    "comments_url": "https://api.github.com/repos/kijai/ComfyUI-CogVideoXWrapper/issues/46/comments",
    "author": "sipie800",
    "comments": [
      {
        "user": "kijai",
        "created_at": "2024-09-05T11:11:21Z",
        "body": "Yeah that doesn't make sense, what's the full error?"
      },
      {
        "user": "sipie800",
        "created_at": "2024-09-05T13:09:23Z",
        "body": "the problem is fixed by updating **accelerate** to newest."
      }
    ]
  },
  {
    "number": 45,
    "title": "wrong filename",
    "created_at": "2024-09-03T18:07:27Z",
    "closed_at": "2024-09-04T11:02:31Z",
    "labels": [],
    "url": "https://github.com/kijai/ComfyUI-CogVideoXWrapper/issues/45",
    "body": "I downloaded THUDM/CogVideoX-5b from huggingface but the program stopped with error Error no file named diffusion_pytorch_model.bin found in directory D:\\ComfyUI-aki-v1.3\\models\\CogVideo\\CogVideoX-5b. .However,the model I downloaded was named diffusion_pytorch_model-00001-of-00002.safetensors and diffusion_pytorch_model-00002-of-00002.safetensors .",
    "comments_url": "https://api.github.com/repos/kijai/ComfyUI-CogVideoXWrapper/issues/45/comments",
    "author": "Willian7004",
    "comments": [
      {
        "user": "kijai",
        "created_at": "2024-09-03T18:32:12Z",
        "body": "Yes those what you downloaded are right, the error about `diffusion_pytorch_model.bin` is a generic one diffusers seems to always give when it can't find the model. Check that the folder structure matches what's on huggingface, and check that all the .json files are there and with same names, as they are also required."
      },
      {
        "user": "Willian7004",
        "created_at": "2024-09-04T03:09:53Z",
        "body": "I checked the filenamed again and found that I downloaded the files from browser and all files names was added the folder name as a perfix to avoid duplicate file names.I changed the filenames and it works."
      },
      {
        "user": "kijai",
        "created_at": "2024-09-04T11:02:31Z",
        "body": "Yeah and huggingface seems to always add the subfolder to the filename with .json's."
      }
    ]
  },
  {
    "number": 43,
    "title": "Has anyone successfully compile it before inferencing?",
    "created_at": "2024-09-03T06:15:11Z",
    "closed_at": "2024-09-19T13:09:59Z",
    "labels": [],
    "url": "https://github.com/kijai/ComfyUI-CogVideoXWrapper/issues/43",
    "body": null,
    "comments_url": "https://api.github.com/repos/kijai/ComfyUI-CogVideoXWrapper/issues/43/comments",
    "author": "dogecoinvr",
    "comments": [
      {
        "user": "kijai",
        "created_at": "2024-09-03T16:40:32Z",
        "body": "There was a bug in last few commits that broke onediff, it's working again for me now. I know couple of people who have got it working with the instructions on the readme, myself included. I never got torch.compile to work though, which isn't that important as onediff is much better."
      }
    ]
  },
  {
    "number": 42,
    "title": "question: Is there an image to video option?",
    "created_at": "2024-09-02T19:57:41Z",
    "closed_at": "2024-09-03T16:41:44Z",
    "labels": [],
    "url": "https://github.com/kijai/ComfyUI-CogVideoXWrapper/issues/42",
    "body": "Like the video to video option Is there an image to video option or workflow?",
    "comments_url": "https://api.github.com/repos/kijai/ComfyUI-CogVideoXWrapper/issues/42/comments",
    "author": "ShmuelRonen",
    "comments": [
      {
        "user": "kijai",
        "created_at": "2024-09-02T22:08:06Z",
        "body": "There is no image2video version of the model released publicly, only text2video. It's something that needs to be trained in."
      }
    ]
  },
  {
    "number": 41,
    "title": "LCM support",
    "created_at": "2024-09-02T19:41:50Z",
    "closed_at": "2024-09-02T22:17:52Z",
    "labels": [],
    "url": "https://github.com/kijai/ComfyUI-CogVideoXWrapper/issues/41",
    "body": "Hi there sir, is it possible to add the LCM sampler as an alternative sampler for faster convergence, thereby speeding up rendering? And maybe even something like HyperTile. But i think that LCM sampler support would already give a big boost. Thank you for your time.",
    "comments_url": "https://api.github.com/repos/kijai/ComfyUI-CogVideoXWrapper/issues/41/comments",
    "author": "MGTRIDER",
    "comments": [
      {
        "user": "kijai",
        "created_at": "2024-09-02T22:07:19Z",
        "body": "The LCM sampler itself is not faster, it's just the sampling method needed to sample LCM distilled models, and there's nothing like that available for CogVideoX."
      },
      {
        "user": "MGTRIDER",
        "created_at": "2024-09-02T22:11:53Z",
        "body": "> The LCM sampler itself is not faster, it's just the sampling method needed to sample LCM distilled models, and there's nothing like that available for CogVideoX.\r\n\r\nI see, thanks for the explanation. Can you help me with the following issue ? Whenever i try to use the fp8 transformer on the CogVideo 2b model, i get the following error: Promotion for Float8 Types is not supported, attempted to promote Half and Float8_e4m3fn"
      },
      {
        "user": "kijai",
        "created_at": "2024-09-02T22:15:29Z",
        "body": "> > The LCM sampler itself is not faster, it's just the sampling method needed to sample LCM distilled models, and there's nothing like that available for CogVideoX.\n> \n> I see, thanks for the explanation. Can you help me with the following issue ? Whenever i try to use the fp8 transformer on the CogVideo 2b model, i get the following error: Promotion for Float8 Types is not supported, attempted to promote Half and Float8_e4m3fn\n\nIt's not currently supported on the 2b model, there's a workaround but I haven't applied it yet."
      },
      {
        "user": "MGTRIDER",
        "created_at": "2024-09-02T22:17:10Z",
        "body": "> > > The LCM sampler itself is not faster, it's just the sampling method needed to sample LCM distilled models, and there's nothing like that available for CogVideoX.\r\n> > \r\n> > \r\n> > I see, thanks for the explanation. Can you help me with the following issue ? Whenever i try to use the fp8 transformer on the CogVideo 2b model, i get the following error: Promotion for Float8 Types is not supported, attempted to promote Half and Float8_e4m3fn\r\n> \r\n> It's not currently supported on the 2b model, there's a workaround but I haven't applied it yet.\r\n\r\nAlright, thank you very much, then i will close the issue."
      },
      {
        "user": "kijai",
        "created_at": "2024-09-03T17:53:52Z",
        "body": "> > The LCM sampler itself is not faster, it's just the sampling method needed to sample LCM distilled models, and there's nothing like that available for CogVideoX.\r\n> \r\n> I see, thanks for the explanation. Can you help me with the following issue ? Whenever i try to use the fp8 transformer on the CogVideo 2b model, i get the following error: Promotion for Float8 Types is not supported, attempted to promote Half and Float8_e4m3fn\r\n\r\nUsing fp8 with the 2b model should now be working."
      }
    ]
  },
  {
    "number": 40,
    "title": "RuntimeError: torch._scaled_mm is only supported on CUDA devices with compute capability >= 9.0 or 8.9, or ROCm MI300+",
    "created_at": "2024-09-02T15:14:33Z",
    "closed_at": "2024-09-02T19:23:16Z",
    "labels": [],
    "url": "https://github.com/kijai/ComfyUI-CogVideoXWrapper/issues/40",
    "body": "Hi here, i tryed to test CogVideoX with an RTX 3090. But when i launch i got this error message :\r\n\r\n`RuntimeError: torch._scaled_mm is only supported on CUDA devices with compute capability >= 9.0 or 8.9, or ROCm MI300+`",
    "comments_url": "https://api.github.com/repos/kijai/ComfyUI-CogVideoXWrapper/issues/40/comments",
    "author": "Fictiverse",
    "comments": [
      {
        "user": "ywaby",
        "created_at": "2024-10-14T05:32:11Z",
        "body": "fp8 fast mode will cause this problem"
      }
    ]
  },
  {
    "number": 39,
    "title": "IMPORT FAILED",
    "created_at": "2024-09-02T14:43:45Z",
    "closed_at": "2024-09-03T16:41:36Z",
    "labels": [],
    "url": "https://github.com/kijai/ComfyUI-CogVideoXWrapper/issues/39",
    "body": "`(IMPORT FAILED): D:\\softwares\\ComfyUI-aki-v1.3\\custom_nodes\\ComfyUI-CogVideoXWrapper`\r\n\r\nWhy did I still fail to import node despite installing the required libraries\r\n`Package                   Version\r\n------------------------- ------------------\r\naccelerate                0.33.0\r\naiofiles                  23.2.1\r\naiohappyeyeballs          2.3.4\r\naiohttp                   3.10.0\r\naiosignal                 1.3.1\r\nalbucore                  0.0.13\r\nalbumentations            1.4.12\r\naltair                    5.4.1\r\nannotated-types           0.7.0\r\nantlr4-python3-runtime    4.9.3\r\nanyio                     4.4.0\r\nasync-timeout             4.0.3\r\nattrs                     23.2.0\r\nav                        12.3.0\r\nbitsandbytes              0.43.3\r\nblinker                   1.8.2\r\nboto3                     1.34.86\r\nbotocore                  1.34.162\r\ncachetools                5.5.0\r\ncertifi                   2024.7.4\r\ncffi                      1.16.0\r\ncfgv                      3.4.0\r\nchardet                   5.2.0\r\ncharset-normalizer        3.3.2\r\ncheroot                   10.0.1\r\nclick                     8.1.7\r\ncloudpickle               3.0.0\r\ncolorama                  0.4.6\r\ncontourpy                 1.2.1\r\ncycler                    0.12.1\r\nCython                    3.0.10\r\ndecorator                 4.4.2\r\ndeepdiff                  8.0.0\r\ndiffusers                 0.30.1\r\ndistlib                   0.3.8\r\ndistro                    1.9.0\r\ndynamicprompts            0.31.0\r\neasydict                  1.13\r\neinops                    0.8.0\r\neval_type_backport        0.2.0\r\nexceptiongroup            1.2.2\r\nfacexlib                  0.3.0\r\nfastapi                   0.112.1\r\nffmpy                     0.4.0\r\nfilelock                  3.15.4\r\nfilterpy                  0.0.15\r\nfonttools                 4.53.1\r\nfrozenlist                1.4.1\r\nfsspec                    2024.6.1\r\nfvcore                    0.1.5.post20221221\r\ngevent                    24.2.1\r\ngitdb                     4.0.11\r\nGitPython                 3.1.43\r\ngradio                    4.42.0\r\ngradio_client             1.3.0\r\ngreenlet                  3.0.3\r\nh11                       0.14.0\r\nHTMLParser                0.0.2\r\nhttpcore                  1.0.5\r\nhttpx                     0.27.0\r\nhuggingface-hub           0.24.6\r\nidentify                  2.6.0\r\nidna                      3.7\r\nimageio                   2.34.2\r\nimageio-ffmpeg            0.5.1\r\nimportlib_metadata        8.2.0\r\nimportlib_resources       6.4.0\r\ninsightface               0.7.3\r\niopath                    0.1.9\r\njaraco.functools          4.0.1\r\nJinja2                    3.1.4\r\njiter                     0.5.0\r\njmespath                  1.0.1\r\njoblib                    1.4.2\r\njsonschema                4.23.0\r\njsonschema-specifications 2023.12.1\r\nkiwisolver                1.4.5\r\nlazy_loader               0.4\r\nlinkai                    0.0.6.0\r\nllvmlite                  0.43.0\r\nmarkdown-it-py            3.0.0\r\nMarkupSafe                2.1.5\r\nmatplotlib                3.9.1\r\nmdurl                     0.1.2\r\nmore-itertools            10.3.0\r\nmoviepy                   1.0.3\r\nmpmath                    1.3.0\r\nmultidict                 6.0.5\r\nnarwhals                  1.5.5\r\nnetworkx                  3.2.1\r\nnodeenv                   1.9.1\r\nnumba                     0.60.0\r\nnumpy                     1.26.4\r\nonnx                      1.16.2\r\nopenai                    1.42.0\r\nopencv-python             4.10.0.84\r\nopencv-python-headless    4.10.0.84\r\norderly-set               5.2.1\r\norjson                    3.10.7\r\npackaging                 24.1\r\npandas                    2.2.2\r\npillow                    10.4.0\r\npip                       22.0.4\r\nplatformdirs              4.2.2\r\nportalocker               2.10.1\r\npre-commit                3.8.0\r\nprettytable               3.10.2\r\nproglog                   0.1.10\r\nprotobuf                  5.27.3\r\npsutil                    6.0.0\r\npy-cpuinfo                9.0.0\r\npyarrow                   17.0.0\r\npycparser                 2.22\r\npydantic                  2.8.2\r\npydantic_core             2.20.1\r\npydeck                    0.9.1\r\npydub                     0.25.1\r\nPygments                  2.18.0\r\npynvml                    11.5.3\r\npyparsing                 3.1.2\r\npypng                     0.20220715.0\r\nPyQRCode                  1.2.1\r\npython-dateutil           2.9.0.post0\r\npython-multipart          0.0.9\r\npytz                      2024.1\r\npywin32                   306\r\nPyYAML                    6.0.1\r\nqrcode                    7.4.2\r\nreferencing               0.35.1\r\nregex                     2024.7.24\r\nrequests                  2.32.3\r\nrequests-toolbelt         1.0.0\r\nrich                      13.7.1\r\nrpds-py                   0.20.0\r\nruff                      0.6.1\r\ns3transfer                0.10.2\r\nsafetensors               0.4.4\r\nscikit-image              0.24.0\r\nscikit-learn              1.5.1\r\nscipy                     1.13.1\r\nsemantic-version          2.10.0\r\nsentencepiece             0.2.0\r\nsetuptools                58.1.0\r\nshellingham               1.5.4\r\nsix                       1.16.0\r\nsmmap                     5.0.1\r\nsniffio                   1.3.1\r\nstarlette                 0.38.2\r\nstreamlit                 1.38.0\r\nsurrealist                0.5.3\r\nSwissArmyTransformer      0.4.12\r\nsympy                     1.13.1\r\ntabulate                  0.9.0\r\ntenacity                  8.5.0\r\ntermcolor                 2.4.0\r\nthreadpoolctl             3.5.0\r\ntifffile                  2024.7.24\r\ntiktoken                  0.7.0\r\ntimm                      0.6.13\r\ntokenizers                0.19.1\r\ntoml                      0.10.2\r\ntomli                     2.0.1\r\ntomlkit                   0.12.0\r\ntorch                     2.4.0+cu124\r\ntorchvision               0.19.0+cu124\r\ntornado                   6.4.1\r\ntqdm                      4.66.4\r\ntransformers              4.44.0\r\ntyper                     0.12.4\r\ntyping_extensions         4.12.2\r\ntzdata                    2024.1\r\nurllib3                   2.2.2\r\nuvicorn                   0.30.6\r\nvirtualenv                20.26.3\r\nwatchdog                  4.0.2\r\nwcwidth                   0.2.13\r\nweb.py                    0.62\r\nwebsocket-client          1.8.0\r\nwebsockets                12.0\r\nyacs                      0.1.8\r\nyarl                      1.9.4\r\nzipp                      3.19.2\r\nzope.event                5.0\r\nzope.interface            6.4.post2`",
    "comments_url": "https://api.github.com/repos/kijai/ComfyUI-CogVideoXWrapper/issues/39/comments",
    "author": "gghuanhuan",
    "comments": [
      {
        "user": "kijai",
        "created_at": "2024-09-02T18:38:31Z",
        "body": "The startup logging in comfy should report it somewhere there, usually something like \"module not found\" ."
      },
      {
        "user": "KewkLW",
        "created_at": "2024-09-02T18:56:44Z",
        "body": "It could be so many things, should prolly post your comfyui.log. Tho, I was having an issue and reinstalled xformers to fix it >__<"
      },
      {
        "user": "gghuanhuan",
        "created_at": "2024-09-03T13:41:48Z",
        "body": "> The startup logging in comfy should report it somewhere there, usually something like \"module not found\" .\r\n\r\nI have reinstalled the Torch and xformers libraries and can now import nodes normally. Thank you\r\n\r\n`[2024-09-02 22:46] Traceback (most recent call last):\r\n  File \"D:\\softwares\\ComfyUI-aki-v1.3\\python\\lib\\site-packages\\xformers\\checkpoint.py\", line 53, in <module>\r\n    from torch.utils.checkpoint import SAC_IGNORED_OPS as _ignored_ops  # type: ignore\r\nImportError: cannot import name 'SAC_IGNORED_OPS' from 'torch.utils.checkpoint' (D:\\softwares\\ComfyUI-aki-v1.3\\python\\lib\\site-packages\\torch\\utils\\checkpoint.py)\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"D:\\softwares\\ComfyUI-aki-v1.3\\python\\lib\\site-packages\\diffusers\\utils\\import_utils.py\", line 830, in _get_module\r\n    return importlib.import_module(\".\" + module_name, self.__name__)\r\n  File \"D:\\softwares\\ComfyUI-aki-v1.3\\python\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 992, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\r\n  File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\r\n  File \"D:\\softwares\\ComfyUI-aki-v1.3\\python\\lib\\site-packages\\diffusers\\models\\autoencoders\\__init__.py\", line 1, in <module>\r\n    from .autoencoder_asym_kl import AsymmetricAutoencoderKL\r\n  File \"D:\\softwares\\ComfyUI-aki-v1.3\\python\\lib\\site-packages\\diffusers\\models\\autoencoders\\autoencoder_asym_kl.py\", line 23, in <module>\r\n    from .vae import DecoderOutput, DiagonalGaussianDistribution, Encoder, MaskConditionDecoder\r\n  File \"D:\\softwares\\ComfyUI-aki-v1.3\\python\\lib\\site-packages\\diffusers\\models\\autoencoders\\vae.py\", line 24, in <module>\r\n    from ..attention_processor import SpatialNorm\r\n  File \"D:\\softwares\\ComfyUI-aki-v1.3\\python\\lib\\site-packages\\diffusers\\models\\attention_processor.py\", line 34, in <module>\r\n    import xformers\r\n  File \"D:\\softwares\\ComfyUI-aki-v1.3\\python\\lib\\site-packages\\xformers\\__init__.py\", line 12, in <module>\r\n    from .checkpoint import (  # noqa: E402, F401\r\n  File \"D:\\softwares\\ComfyUI-aki-v1.3\\python\\lib\\site-packages\\xformers\\checkpoint.py\", line 57, in <module>\r\n    from torch.utils.checkpoint import _ignored_ops  # type: ignore\r\nImportError: cannot import name '_ignored_ops' from 'torch.utils.checkpoint' (D:\\softwares\\ComfyUI-aki-v1.3\\python\\lib\\site-packages\\torch\\utils\\checkpoint.py)\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"D:\\softwares\\ComfyUI-aki-v1.3\\nodes.py\", line 1993, in load_custom_node\r\n    module_spec.loader.exec_module(module)\r\n  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\r\n  File \"D:\\softwares\\ComfyUI-aki-v1.3\\custom_nodes\\ComfyUI-CogVideoXWrapper\\__init__.py\", line 1, in <module>\r\n    from .nodes import NODE_CLASS_MAPPINGS, NODE_DISPLAY_NAME_MAPPINGS\r\n  File \"D:\\softwares\\ComfyUI-aki-v1.3\\custom_nodes\\ComfyUI-CogVideoXWrapper\\nodes.py\", line 7, in <module>\r\n    from diffusers.models import AutoencoderKLCogVideoX, CogVideoXTransformer3DModel\r\n  File \"<frozen importlib._bootstrap>\", line 1075, in _handle_fromlist\r\n  File \"D:\\softwares\\ComfyUI-aki-v1.3\\python\\lib\\site-packages\\diffusers\\utils\\import_utils.py\", line 820, in __getattr__\r\n    module = self._get_module(self._class_to_module[name])\r\n  File \"D:\\softwares\\ComfyUI-aki-v1.3\\python\\lib\\site-packages\\diffusers\\utils\\import_utils.py\", line 832, in _get_module\r\n    raise RuntimeError(\r\nRuntimeError: Failed to import diffusers.models.autoencoders.autoencoder_kl_cogvideox because of the following error (look up to see its traceback):\r\ncannot import name '_ignored_ops' from 'torch.utils.checkpoint' (D:\\softwares\\ComfyUI-aki-v1.3\\python\\lib\\site-packages\\torch\\utils\\checkpoint.py)\r\n\r\n[2024-09-02 22:46] Cannot import D:\\softwares\\ComfyUI-aki-v1.3\\custom_nodes\\ComfyUI-CogVideoXWrapper module for custom nodes: Failed to import diffusers.models.autoencoders.autoencoder_kl_cogvideox because of the following error (look up to see its traceback):\r\ncannot import name '_ignored_ops' from 'torch.utils.checkpoint' (D:\\softwares\\ComfyUI-aki-v1.3\\python\\lib\\site-packages\\torch\\utils\\checkpoint.py)\r\n`"
      },
      {
        "user": "gghuanhuan",
        "created_at": "2024-09-03T13:43:10Z",
        "body": "> It could be so many things, should prolly post your comfyui.log. Tho, I was having an issue and reinstalled xformers to fix it >__<\r\n\r\nYou're right, thank you for your help"
      }
    ]
  },
  {
    "number": 35,
    "title": "Can this tool make use of the ability to fine tune the model? ",
    "created_at": "2024-08-31T14:16:27Z",
    "closed_at": "2024-09-04T11:03:32Z",
    "labels": [],
    "url": "https://github.com/kijai/ComfyUI-CogVideoXWrapper/issues/35",
    "body": "Is it possible to add a node to make use of the fine tuning? ",
    "comments_url": "https://api.github.com/repos/kijai/ComfyUI-CogVideoXWrapper/issues/35/comments",
    "author": "nonlin",
    "comments": [
      {
        "user": "kijai",
        "created_at": "2024-09-04T11:03:27Z",
        "body": "Technically it would be, but the resource requirements are so intense (60GB+ VRAM) I don't think it's feasible at this time."
      }
    ]
  },
  {
    "number": 33,
    "title": "Can I run it on m1 Apple Chip",
    "created_at": "2024-08-30T10:34:20Z",
    "closed_at": "2024-11-19T17:32:44Z",
    "labels": [],
    "url": "https://github.com/kijai/ComfyUI-CogVideoXWrapper/issues/33",
    "body": "Excuse - I am not the most knowledge person and will probably find out the answer anyway haha in minute.\r\n\r\nI can use regular comfyui just fine. ",
    "comments_url": "https://api.github.com/repos/kijai/ComfyUI-CogVideoXWrapper/issues/33/comments",
    "author": "ironcarrier",
    "comments": [
      {
        "user": "kijai",
        "created_at": "2024-08-30T10:40:23Z",
        "body": "I have no idea, haven't heard reports one way or the other yet."
      }
    ]
  },
  {
    "number": 32,
    "title": "`prompt_embeds` and `negative_prompt_embeds` must have the same shape when passed directly, but got: `prompt_embeds` torch.Size([1, 452, 4096]) != `negative_prompt_embeds` torch.Size([1, 226, 4096]).",
    "created_at": "2024-08-30T09:52:27Z",
    "closed_at": "2024-08-30T15:28:32Z",
    "labels": [],
    "url": "https://github.com/kijai/ComfyUI-CogVideoXWrapper/issues/32",
    "body": "Error occurred when executing CogVideoSampler:\r\n\r\n`prompt_embeds` and `negative_prompt_embeds` must have the same shape when passed directly, but got: `prompt_embeds` torch.Size([1, 452, 4096]) != `negative_prompt_embeds` torch.Size([1, 226, 4096]).\r\n\r\nFile \"/data/ComfyUI/execution.py\", line 317, in execute\r\noutput_data, output_ui, has_subgraph = get_output_data(obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\r\nFile \"/data/ComfyUI/execution.py\", line 192, in get_output_data\r\nreturn_values = _map_node_over_list(obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\r\nFile \"/data/ComfyUI/execution.py\", line 169, in _map_node_over_list\r\nprocess_inputs(input_dict, i)\r\nFile \"/data/ComfyUI/execution.py\", line 158, in process_inputs\r\nresults.append(getattr(obj, func)(**inputs))\r\nFile \"/data/ComfyUI/custom_nodes/ComfyUI-CogVideoXWrapper/nodes.py\", line 289, in process\r\nlatents = pipeline[\"pipe\"](\r\nFile \"/etc/anaconda3/envs/comfyui/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\r\nreturn func(*args, **kwargs)\r\nFile \"/data/ComfyUI/custom_nodes/ComfyUI-CogVideoXWrapper/pipeline_cogvideox.py\", line 391, in __call__\r\nself.check_inputs(\r\nFile \"/data/ComfyUI/custom_nodes/ComfyUI-CogVideoXWrapper/pipeline_cogvideox.py\", line 225, in check_inputs",
    "comments_url": "https://api.github.com/repos/kijai/ComfyUI-CogVideoXWrapper/issues/32/comments",
    "author": "vanche1212",
    "comments": [
      {
        "user": "vanche1212",
        "created_at": "2024-08-30T09:52:47Z",
        "body": " diffusers==0.30.1"
      },
      {
        "user": "kijai",
        "created_at": "2024-08-30T09:54:13Z",
        "body": "The prompt is probably just too long."
      },
      {
        "user": "vanche1212",
        "created_at": "2024-08-30T09:57:13Z",
        "body": "> The prompt is probably just too long.\r\n\r\ntks, It is really too long. Is there any way to use long prompt words?"
      },
      {
        "user": "vanche1212",
        "created_at": "2024-08-30T09:59:39Z",
        "body": "Here are my hint words，1047 characters only\r\n\r\nIn the blue underwater world, an elegant turtle leisurely shuttles between coral reefs. The turtle's shell is covered with exquisite textures, and the sun shines through the water with mottled light and shadow, making its shell shine with a mysterious luster. The turtle swings its flippers slowly, light and graceful, as if soaring through the water. The underwater world around is colorful, and corals of different shapes are like sculptures of nature, decorating this peaceful ocean paradise. Colorful tropical fish swam in groups among the corals. Some fish stopped beside the turtle as if to say hello to it. The whole scene was full of vigor and vitality. In the distance, the dark blue water gradually became dark and mysterious, as if hiding countless undiscovered secrets. And the turtle is so calm and comfortable in this vast underwater world, as if it is the guardian of this ocean. The whole picture shows a quiet and harmonious natural beauty with soft colors and smooth lines, showing the fantastic world in the depths of the ocean."
      },
      {
        "user": "vanche1212",
        "created_at": "2024-08-30T10:14:34Z",
        "body": "226 tokens ，I found"
      },
      {
        "user": "kijai",
        "created_at": "2024-08-30T10:22:09Z",
        "body": "> 226 tokens ，I found\r\n\r\nYes, I think it's best to stay within that limit. I did modify the code a bit to allow it to run with the longer prompt too, but the results seem worse, if you update you can test it yourself."
      },
      {
        "user": "vanche1212",
        "created_at": "2024-08-30T15:28:29Z",
        "body": "> > 226 tokens ，I found\r\n> \r\n> Yes, I think it's best to stay within that limit. I did modify the code a bit to allow it to run with the longer prompt too, but the results seem worse, if you update you can test it yourself.\r\n\r\ntks，bro"
      }
    ]
  },
  {
    "number": 26,
    "title": "ERROR: Allocation issue",
    "created_at": "2024-08-28T14:52:17Z",
    "closed_at": "2024-09-04T11:06:16Z",
    "labels": [],
    "url": "https://github.com/kijai/ComfyUI-CogVideoXWrapper/issues/26",
    "body": "Probably not much to be done about this but getting more memory but posting this in case someone has an idea beyond that.\r\n\r\n\r\nError occurred when executing CogVideoDecode:\r\n\r\nAllocation on device\r\n\r\nFile \"E:\\ComfyUI_windows_portable\\ComfyUI\\execution.py\", line 317, in execute\r\noutput_data, output_ui, has_subgraph = get_output_data(obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\r\nFile \"E:\\ComfyUI_windows_portable\\ComfyUI\\execution.py\", line 192, in get_output_data\r\nreturn_values = _map_node_over_list(obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\r\nFile \"E:\\ComfyUI_windows_portable\\ComfyUI\\execution.py\", line 169, in _map_node_over_list\r\nprocess_inputs(input_dict, i)\r\nFile \"E:\\ComfyUI_windows_portable\\ComfyUI\\execution.py\", line 158, in process_inputs\r\nresults.append(getattr(obj, func)(**inputs))\r\nFile \"E:\\ComfyUI_windows_portable\\ComfyUI\\custom_nodes\\ComfyUI-CogVideoXWrapper\\nodes.py\", line 336, in decode\r\nframes = vae.decode(latents).sample\r\nFile \"D:\\Python\\Python310\\lib\\site-packages\\diffusers\\utils\\accelerate_utils.py\", line 46, in wrapper\r\nreturn method(self, *args, **kwargs)\r\nFile \"D:\\Python\\Python310\\lib\\site-packages\\diffusers\\models\\autoencoders\\autoencoder_kl_cogvideox.py\", line 1153, in decode\r\ndecoded = self._decode(z).sample\r\nFile \"D:\\Python\\Python310\\lib\\site-packages\\diffusers\\models\\autoencoders\\autoencoder_kl_cogvideox.py\", line 1123, in _decode\r\nz_intermediate = self.decoder(z_intermediate)\r\nFile \"D:\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1532, in _wrapped_call_impl\r\nreturn self._call_impl(*args, **kwargs)\r\nFile \"D:\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1541, in _call_impl\r\nreturn forward_call(*args, **kwargs)\r\nFile \"D:\\Python\\Python310\\lib\\site-packages\\diffusers\\models\\autoencoders\\autoencoder_kl_cogvideox.py\", line 877, in forward\r\nhidden_states = up_block(hidden_states, temb, sample)\r\nFile \"D:\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1532, in _wrapped_call_impl\r\nreturn self._call_impl(*args, **kwargs)\r\nFile \"D:\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1541, in _call_impl\r\nreturn forward_call(*args, **kwargs)\r\nFile \"D:\\Python\\Python310\\lib\\site-packages\\diffusers\\models\\autoencoders\\autoencoder_kl_cogvideox.py\", line 602, in forward\r\nhidden_states = resnet(hidden_states, temb, zq)\r\nFile \"D:\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1532, in _wrapped_call_impl\r\nreturn self._call_impl(*args, **kwargs)\r\nFile \"D:\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1541, in _call_impl\r\nreturn forward_call(*args, **kwargs)\r\nFile \"D:\\Python\\Python310\\lib\\site-packages\\diffusers\\models\\autoencoders\\autoencoder_kl_cogvideox.py\", line 286, in forward\r\nhidden_states = self.norm1(hidden_states, zq)\r\nFile \"D:\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1532, in _wrapped_call_impl\r\nreturn self._call_impl(*args, **kwargs)\r\nFile \"D:\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1541, in _call_impl\r\nreturn forward_call(*args, **kwargs)\r\nFile \"D:\\Python\\Python310\\lib\\site-packages\\diffusers\\models\\autoencoders\\autoencoder_kl_cogvideox.py\", line 187, in forward\r\nnew_f = norm_f * self.conv_y(zq) + self.conv_b(zq)",
    "comments_url": "https://api.github.com/repos/kijai/ComfyUI-CogVideoXWrapper/issues/26/comments",
    "author": "Duemellon",
    "comments": [
      {
        "user": "al3dv2",
        "created_at": "2024-08-28T14:55:28Z",
        "body": "I have the same error and when I put \"enable vae tiling\" to true the error disappear"
      },
      {
        "user": "kijai",
        "created_at": "2024-08-28T16:20:38Z",
        "body": "The decoding is the most memory intensive part, using the tiled option in the decode node reduces the memory use considerably, but also can introduce some seams in the result."
      },
      {
        "user": "Duemellon",
        "created_at": "2024-08-29T14:46:49Z",
        "body": "give me the bare min settings to use to take up the least memory. Even the smallest dimension of images would help. I have a 12gb 3060 rtx\r\n"
      },
      {
        "user": "kijai",
        "created_at": "2024-08-29T14:52:43Z",
        "body": "> give me the bare min settings to use to take up the least memory. Even the smallest dimension of images would help. I have a 12gb 3060 rtx\r\n\r\nIt could fit with the fp8 transformer enabled, and VAE tiling enabled on the VAE decode node. Absolute last resort is the newly added sequential_cpu_offload, it will be slow though. Also doing less frames uses less memory of course."
      }
    ]
  },
  {
    "number": 21,
    "title": "\"Prompt outputs failed validation: Value not in list\"",
    "created_at": "2024-08-28T07:19:18Z",
    "closed_at": "2024-08-28T15:51:50Z",
    "labels": [],
    "url": "https://github.com/kijai/ComfyUI-CogVideoXWrapper/issues/21",
    "body": "I've updated ComfyUI, and I installed the latest CogVideoXWrapper through ComfyUI manager via this Git's URL. I've loaded the \"cogvideox_5b_example_01.json\" workflow, and pointed the Load Clip node to my existing model (t5xxl_fp8_e4m3fn.safetensors).\r\n\r\nAfter hitting queue prompt, I get this error:\r\n\r\nPrompt outputs failed validation: Value not in list: format: 'video/nvenc_h264-mp4' not in ['image/gif', 'image/webp', 'video/ProRes', 'video/av1-webm', 'video/h264-mp4', 'video/h265-mp4', 'video/webm']\r\nVHS_VideoCombine:\r\n    - Value not in list: format: 'video/nvenc_h264-mp4' not in ['image/gif', 'image/webp', 'video/ProRes', 'video/av1-webm', 'video/h264-mp4', 'video/h265-mp4', 'video/webm']",
    "comments_url": "https://api.github.com/repos/kijai/ComfyUI-CogVideoXWrapper/issues/21/comments",
    "author": "Gyramuur",
    "comments": [
      {
        "user": "kijai",
        "created_at": "2024-08-28T12:49:51Z",
        "body": "This is because I forgot the nvenc format selected on the video combine node, it's not supported by all platforms. Just change to some other encode format or recreate the video combine node to get past that."
      },
      {
        "user": "Gyramuur",
        "created_at": "2024-08-28T15:51:50Z",
        "body": "That fixed it, thanks. :) Now getting a separate error but I'll open a different issue."
      }
    ]
  },
  {
    "number": 20,
    "title": "Just logging a solved error: h264_nvenc codec failed to work",
    "created_at": "2024-08-28T03:55:46Z",
    "closed_at": "2024-09-04T11:04:29Z",
    "labels": [],
    "url": "https://github.com/kijai/ComfyUI-CogVideoXWrapper/issues/20",
    "body": "Hi, just logging my issue and solution in case it can help someone else who is searching for a solution on the internet.\r\n\r\nI ran the default workflow after changing the t5 model path name. Everything went well until I got to the video combine node. It appears that the default video codec setting of h264_nvenc-mp4 didn't work for me. I swapped it to video/h264-mp4 and it worked just fine.\r\n\r\nThis is on an ubuntu machine with a A100 attached. Potentially worth noting I have some misconfigured Nvidia drivers somewhere.\r\n\r\nThe full error message:\r\n```\r\n!!! Exception during processing !!! An error occurred in the ffmpeg subprocess:\r\n[h264_nvenc @ 0x55d754c3ce80] OpenEncodeSessionEx failed: unsupported device (2): (no details)\r\n[h264_nvenc @ 0x55d754c3ce80] No capable devices found\r\nError initializing output stream 0:0 -- Error while opening encoder for output stream #0:0 - maybe incorrect parameters such as bit_rate, rate, width or height\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/azureuser/code/ComfyUI/custom_nodes/ComfyUI-VideoHelperSuite/videohelpersuite/nodes.py\", line 128, in ffmpeg_process\r\n    proc.stdin.write(frame_data)\r\nBrokenPipeError: [Errno 32] Broken pipe\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/azureuser/code/ComfyUI/execution.py\", line 317, in execute\r\n    output_data, output_ui, has_subgraph = get_output_data(obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\r\n                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/azureuser/code/ComfyUI/execution.py\", line 192, in get_output_data\r\n    return_values = _map_node_over_list(obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\r\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/azureuser/code/ComfyUI/execution.py\", line 169, in _map_node_over_list\r\n    process_inputs(input_dict, i)\r\n  File \"/home/azureuser/code/ComfyUI/execution.py\", line 158, in process_inputs\r\n    results.append(getattr(obj, func)(**inputs))\r\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/azureuser/code/ComfyUI/custom_nodes/ComfyUI-VideoHelperSuite/videohelpersuite/nodes.py\", line 490, in combine_video\r\n    output_process.send(image)\r\n  File \"/home/azureuser/code/ComfyUI/custom_nodes/ComfyUI-VideoHelperSuite/videohelpersuite/nodes.py\", line 141, in ffmpeg_process\r\n    raise Exception(\"An error occurred in the ffmpeg subprocess:\\n\" \\\r\nException: An error occurred in the ffmpeg subprocess:\r\n[h264_nvenc @ 0x55d754c3ce80] OpenEncodeSessionEx failed: unsupported device (2): (no details)\r\n[h264_nvenc @ 0x55d754c3ce80] No capable devices found\r\nError initializing output stream 0:0 -- Error while opening encoder for output stream #0:0 - maybe incorrect parameters such as bit_rate, rate, width or height\r\n```",
    "comments_url": "https://api.github.com/repos/kijai/ComfyUI-CogVideoXWrapper/issues/20/comments",
    "author": "Grant-CP",
    "comments": [
      {
        "user": "kijai",
        "created_at": "2024-08-28T08:06:48Z",
        "body": "Hmm yeah nvenc shouldn't be the default, noted, thanks."
      }
    ]
  },
  {
    "number": 14,
    "title": "torch.cat(): expected a non-empty list of Tensors",
    "created_at": "2024-08-26T10:29:11Z",
    "closed_at": "2024-09-30T22:41:31Z",
    "labels": [],
    "url": "https://github.com/kijai/ComfyUI-CogVideoXWrapper/issues/14",
    "body": "Repeatedly getting this error after using all example workflows and installation instructions.  Any ideas?",
    "comments_url": "https://api.github.com/repos/kijai/ComfyUI-CogVideoXWrapper/issues/14/comments",
    "author": "darthjawn",
    "comments": [
      {
        "user": "adamjen",
        "created_at": "2024-08-28T00:03:01Z",
        "body": "I have the same error too"
      },
      {
        "user": "kijai",
        "created_at": "2024-09-04T11:05:54Z",
        "body": "Is this still an issue?"
      }
    ]
  },
  {
    "number": 10,
    "title": "Add to CogVideoX page",
    "created_at": "2024-08-10T15:29:10Z",
    "closed_at": "2024-09-04T11:04:53Z",
    "labels": [],
    "url": "https://github.com/kijai/ComfyUI-CogVideoXWrapper/issues/10",
    "body": "I hope this message finds you well.\r\n\r\n We are truly delighted to see your valuable contributions to CogVideoX. I am one of the maintainers of the official CogVideoX repository, and I would like to inquire if you would be willing to be added to our official contributor list. We would also love to feature and promote your work in our community.",
    "comments_url": "https://api.github.com/repos/kijai/ComfyUI-CogVideoXWrapper/issues/10/comments",
    "author": "zRzRzRzRzRzRzR",
    "comments": [
      {
        "user": "kijai",
        "created_at": "2024-09-03T16:44:37Z",
        "body": "I'm sorry I completely missed this question, of course you can add (if you didn't already)!"
      },
      {
        "user": "zRzRzRzRzRzRzR",
        "created_at": "2024-09-10T13:19:15Z",
        "body": "I will add it quickly, sorry about missing "
      }
    ]
  },
  {
    "number": 9,
    "title": "Results from this are different to official CogVideoX demo and I can't figure out how to match it.",
    "created_at": "2024-08-10T07:37:18Z",
    "closed_at": "2024-08-11T06:55:11Z",
    "labels": [],
    "url": "https://github.com/kijai/ComfyUI-CogVideoXWrapper/issues/9",
    "body": "Using the default settings provided with the example workflow, with 16 frames at 8 fps, it only renders a two second video (as expected). But by default, CogVideoX does 6 second clips. However, upping the amount of frames to 48 does not have the intended effect and instead generates three disjointed clips, like three 2 second clips stuck together. \r\n\r\nHow do I get a single 6 second video like it's supposed to do?",
    "comments_url": "https://api.github.com/repos/kijai/ComfyUI-CogVideoXWrapper/issues/9/comments",
    "author": "Gyramuur",
    "comments": [
      {
        "user": "kijai",
        "created_at": "2024-08-10T14:12:41Z",
        "body": "Which workflow exactly? I added the feature to use temporal tiling (t_tile) as context windows, if the value is lower than your frame count it creates the video in what you call \"disjointed clips\", so you'd want to put that to 48 to get the max clips. The point of the t_tile is that you can also go above the 48, though the clips are usually not joined too well together, sometimes it works nicely."
      },
      {
        "user": "Gyramuur",
        "created_at": "2024-08-11T06:55:11Z",
        "body": "> Which workflow exactly? I added the feature to use temporal tiling (t_tile) as context windows, if the value is lower than your frame count it creates the video in what you call \"disjointed clips\", so you'd want to put that to 48 to get the max clips. The point of the t_tile is that you can also go above the 48, though the clips are usually not joined too well together, sometimes it works nicely.\r\n\r\nI'm using the default example_01.json provided in the examples folder. Also increasing t_tile_length along with num_frames fixes it, thank you. :) I wasn't sure what the t_tile_length parameter did.\r\n\r\nAlso it's unrelated to this issue, so I'll close it out anyway, but when you load the aforementioned workflow, it throws an error saying the t_tile_overlap of 2 is less than the minimum of 8."
      }
    ]
  },
  {
    "number": 6,
    "title": "Image to video",
    "created_at": "2024-08-08T18:36:39Z",
    "closed_at": "2024-08-23T22:53:58Z",
    "labels": [],
    "url": "https://github.com/kijai/ComfyUI-CogVideoXWrapper/issues/6",
    "body": "Hello , I saw that you have integrated a video to video workflow, as for the image to video generation, I would be interested for some indications on how to do the workflow",
    "comments_url": "https://api.github.com/repos/kijai/ComfyUI-CogVideoXWrapper/issues/6/comments",
    "author": "SanicsP",
    "comments": [
      {
        "user": "espressotechie",
        "created_at": "2024-08-23T14:55:25Z",
        "body": "I too am interested in Image to video so that we can give it a starting frame just like kling and the results would be cool! "
      },
      {
        "user": "kijai",
        "created_at": "2024-08-23T22:53:58Z",
        "body": "The model itself does not support image2video, nothing to be done unless they release different model."
      }
    ]
  },
  {
    "number": 3,
    "title": "How much VRAM need for this?",
    "created_at": "2024-08-06T11:20:28Z",
    "closed_at": "2024-08-06T13:09:13Z",
    "labels": [],
    "url": "https://github.com/kijai/ComfyUI-CogVideoXWrapper/issues/3",
    "body": "Did 16gb is enough?",
    "comments_url": "https://api.github.com/repos/kijai/ComfyUI-CogVideoXWrapper/issues/3/comments",
    "author": "pondloso",
    "comments": [
      {
        "user": "kijai",
        "created_at": "2024-08-06T11:24:33Z",
        "body": "It should be, haven't tested the absolute minimum yet, sampling itself doesn't take much at all, decoding is probably heaviest part."
      },
      {
        "user": "pondloso",
        "created_at": "2024-08-06T13:09:00Z",
        "body": "Thank you for you answer.\r\nYour work is the best by the way.\r\nI use all of your node for my game is really a great help for me."
      }
    ]
  }
]