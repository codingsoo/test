[
  {
    "number": 18,
    "title": "Number of conditioning frames for RefVOS",
    "created_at": "2025-02-09T16:42:02Z",
    "closed_at": "2025-02-10T08:07:05Z",
    "labels": [],
    "url": "https://github.com/magic-research/Sa2VA/issues/18",
    "body": "Hi,\n\nGreat work!\n\nI'm curious about how you determined that five is the optimal number of keyframes (corresponding to the number of conditioning frames in SAM2) for the RefVOS task. Have you experimented with using fewer conditioning frames in SAM2?\n\nThanks!",
    "comments_url": "https://api.github.com/repos/magic-research/Sa2VA/issues/18/comments",
    "author": "jovanavidenovic",
    "comments": [
      {
        "user": "HarborYuan",
        "created_at": "2025-02-10T06:35:21Z",
        "body": "Hi @jovanavidenovic ,\n\nThanks for your interest in our work.\n\nFor RefVOS, we used the first five frames as key frames instead of processing the entire video. For the key frame extraction, we did not perform a detailed ablation and kept it as simple as possible."
      }
    ]
  },
  {
    "number": 16,
    "title": "[SEG] Hidden State usage",
    "created_at": "2025-02-07T17:01:36Z",
    "closed_at": "2025-02-10T07:08:58Z",
    "labels": [],
    "url": "https://github.com/magic-research/Sa2VA/issues/16",
    "body": "Thank you for the great work. As I read the code, if I understand correctly, it seems that If the model predicts the next token is [SEG], it will take the final layer hidden state and feed through an MLP connector and feed it to SAM2 for decoding.\n\nHowever, if the language model predicts [SEG] as the next token, it means the embedding has the highest (or very high if sampling is used) similarity with [SEG] embedding. Doesn't that mean this embedding fed to SAM2 is always very close to [SEG] no matter what the rest of the sentence/context is? How does the model utilize the context with very similar embeddings for segmenting different objects?\n\nPlease let me know if I misunderstood. Thank you!",
    "comments_url": "https://api.github.com/repos/magic-research/Sa2VA/issues/16/comments",
    "author": "seermer",
    "comments": [
      {
        "user": "HarborYuan",
        "created_at": "2025-02-10T06:31:53Z",
        "body": "Your understanding is correct. But I would like to point out that [SEG]'s embedding has two different MLP/projection layers, outputing to the classifier or visual prompt respectively. When considering an embedding, for text classifiers, they may be similar, but for prompt encoder, these differences are used to segment different objects."
      },
      {
        "user": "seermer",
        "created_at": "2025-02-10T07:08:58Z",
        "body": "Thank you so much for your help! "
      }
    ]
  },
  {
    "number": 13,
    "title": "SAV dataset inquiry",
    "created_at": "2025-02-05T23:47:42Z",
    "closed_at": "2025-02-06T19:31:17Z",
    "labels": [],
    "url": "https://github.com/magic-research/Sa2VA/issues/13",
    "body": "Congrats on your excellent work! I would like to clarify the SAV dataset details:\n\nYou mentioned about sam_v_full should be downloaded from meta/SA-V dataset page, which provides the link of downloading sav_000.tar - sav_055.tar; should we unzip them and put these files under sam_v_full directory as sub directories?\n\nThanks for your clarification!",
    "comments_url": "https://api.github.com/repos/magic-research/Sa2VA/issues/13/comments",
    "author": "Ruining0916",
    "comments": [
      {
        "user": "HarborYuan",
        "created_at": "2025-02-05T23:48:58Z",
        "body": "Hi @Ruining0916 ,\n\nExactly."
      },
      {
        "user": "Ruining0916",
        "created_at": "2025-02-05T23:49:44Z",
        "body": "Thanks for your swift response!\n\n"
      }
    ]
  },
  {
    "number": 11,
    "title": "Roadmap MPS support",
    "created_at": "2025-01-27T19:26:07Z",
    "closed_at": "2025-02-04T22:24:14Z",
    "labels": [],
    "url": "https://github.com/magic-research/Sa2VA/issues/11",
    "body": "Hey there! Are you guys planning to support Apple Silicon / MPS?",
    "comments_url": "https://api.github.com/repos/magic-research/Sa2VA/issues/11/comments",
    "author": "jscastanoc",
    "comments": [
      {
        "user": "lxtGH",
        "created_at": "2025-02-04T06:47:26Z",
        "body": "Hi, we currently do not have this plan"
      }
    ]
  },
  {
    "number": 8,
    "title": "Running demo code on V100",
    "created_at": "2025-01-16T23:38:32Z",
    "closed_at": "2025-02-15T05:49:47Z",
    "labels": [],
    "url": "https://github.com/magic-research/Sa2VA/issues/8",
    "body": "Hi,\n\nCongrats on the great work!\n\nI only have V100 GPUs available to me.\n\nIs there a way to run your inference/demo code and how (e.g. with no flash attention)?\n\nMany thanks in advance!",
    "comments_url": "https://api.github.com/repos/magic-research/Sa2VA/issues/8/comments",
    "author": "mikeleatila",
    "comments": [
      {
        "user": "lxtGH",
        "created_at": "2025-01-17T05:35:29Z",
        "body": "@zhang-tao-whu Check the issues. It seems like you need to modify the code to remove the flash attention."
      },
      {
        "user": "mikeleatila",
        "created_at": "2025-01-17T08:35:28Z",
        "body": "@lxtGH @zhang-tao-whu Thanks a lot. Do you have some hints how to remove flash attention? Can it be done by \"passing-a-parameter-kind-of-thing\"? Been looking around and trying out but it still does not work."
      },
      {
        "user": "HarborYuan",
        "created_at": "2025-01-30T02:32:29Z",
        "body": "@mikeleatila \n\nMaybe you can try:\n> use_flash_attn=False\nto disable the flash attention? \n\nPlease let me know whether it works well on V100."
      },
      {
        "user": "Ruining0916",
        "created_at": "2025-02-06T18:47:46Z",
        "body": "Hi I have also tried to set use_flash_attn=False; but it seems not working for V100? as there is still error message saying the modeling file is requiring flash_attn\n"
      },
      {
        "user": "HarborYuan",
        "created_at": "2025-02-06T19:27:29Z",
        "body": "I see. Let me check it."
      },
      {
        "user": "mikeleatila",
        "created_at": "2025-02-06T21:26:36Z",
        "body": "Yes, I did the same as per @HarborYuan comment and got the same error as @Ruining0916 described above. "
      },
      {
        "user": "Ruining0916",
        "created_at": "2025-02-11T13:08:44Z",
        "body": "I wonder if there is any update on this question? And also the same issue applies to training."
      },
      {
        "user": "lxtGH",
        "created_at": "2025-02-15T05:49:47Z",
        "body": "Dear all:\n\nWe could not answer your questions since nearly all LLM works use A100 or above. \n\nSo I decide to close this issue.\n\nBest!\n\nSa2VA team\n\n\n"
      }
    ]
  },
  {
    "number": 2,
    "title": "How to get a description and not a seg?",
    "created_at": "2025-01-12T11:36:47Z",
    "closed_at": "2025-02-04T22:32:03Z",
    "labels": [
      "documentation"
    ],
    "url": "https://github.com/magic-research/Sa2VA/issues/2",
    "body": "How do we force this to give a description? When asking for descriptions, more than half the time it is returning segs.",
    "comments_url": "https://api.github.com/repos/magic-research/Sa2VA/issues/2/comments",
    "author": "Lumoria",
    "comments": [
      {
        "user": "HarborYuan",
        "created_at": "2025-01-13T04:31:40Z",
        "body": "Hi @Lumoria ,\r\n\r\nThanks for your interest in our work. Could you please show me some cases that you met when you instructed to give descriptions and the model returns seg?\r\n\r\nBest,\r\nHaobo"
      },
      {
        "user": "lxtGH",
        "created_at": "2025-01-13T04:40:05Z",
        "body": "@Lumoria You can test our 4B model. The 1B model has several bugs and we will release a new version of 1B model."
      },
      {
        "user": "shamBITS2024",
        "created_at": "2025-01-16T17:25:30Z",
        "body": "@lxtGH hi.. i am trying to make a product.. it requires grounding but in just x,y co-ordinate format.. i have tried to train it on such data.. will it work?"
      },
      {
        "user": "HarborYuan",
        "created_at": "2025-02-04T22:32:03Z",
        "body": "Hi @shamBITS2024 ,\n\nI think some papers may work on the bounding box grounding, e.g., Ferret. I think finetuning our work with a similar approach could also yield good results. If you have some interesting results, please update them here."
      }
    ]
  }
]