[
  {
    "number": 67,
    "title": "Where is installition folder",
    "created_at": "2025-01-28T17:03:31Z",
    "closed_at": "2025-01-29T08:45:45Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/Janus/issues/67",
    "body": "I cannot find model folders, it isnt in env",
    "comments_url": "https://api.github.com/repos/deepseek-ai/Janus/issues/67/comments",
    "author": "Karag0",
    "comments": [
      {
        "user": "Karag0",
        "created_at": "2025-01-28T17:03:55Z",
        "body": "And its isnt work demo on hugging face too"
      },
      {
        "user": "flobeier",
        "created_at": "2025-01-28T17:25:44Z",
        "body": "The model files will be downloaded when you run the demo. On my system (Ubuntu 24.10) they are saved in `~/.cache/huggingface/hub`."
      },
      {
        "user": "BluEagle",
        "created_at": "2025-01-28T22:36:41Z",
        "body": "Will we create a Janus on Apple play store?"
      },
      {
        "user": "Karag0",
        "created_at": "2025-01-29T08:45:43Z",
        "body": "@flobeier Hi i found it in appdata local pip"
      }
    ]
  },
  {
    "number": 23,
    "title": "About image to image.",
    "created_at": "2024-10-28T10:52:40Z",
    "closed_at": "2024-10-30T19:02:45Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/Janus/issues/23",
    "body": "First of all thank you for releasing the weights and the inference code of Janus alongside the paper.\r\n\r\nThe model design seems to easily allow for img2img generation, where the user gives Janus a text prompt and one (or more) images and Janus generate an image in return.\r\n\r\nCould you please add a small example of how to do that in the readme if Janus supports it? I've tried merging the visual understanding and image generation codes with no success but I'm probably missing something.\r\n\r\nDocumenting the `janus` library could help future users too.",
    "comments_url": "https://api.github.com/repos/deepseek-ai/Janus/issues/23/comments",
    "author": "brayevalerien",
    "comments": [
      {
        "user": "charlesCXK",
        "created_at": "2024-10-30T16:24:59Z",
        "body": "Thank you for your attention! \r\nIn this version, Janus does not utilize image-to-image generation data and is focused solely on the basic text-to-image ability. If you want to implement this feature, you need to include the relevant data and train a new model. When training the model for image-to-image generation, we think it might be better to use the Generation Encoder to encode the reference image as well."
      },
      {
        "user": "brayevalerien",
        "created_at": "2024-10-30T19:02:45Z",
        "body": "Thanks a lot @charlesCXK for your answer.\r\n\r\nAfter reading the paper I thought end-to-end training for txt+img to txt+img had been done, enabling any combination of these two modalities for both understanding and generation, my bad.\r\n\r\nFine-tuning could be possible to do for us but full training is not really an option unfortunatly.\r\n\r\nCan't wait to see where we will be two papers down the line! "
      }
    ]
  },
  {
    "number": 21,
    "title": "from janus.models import MultiModalityCausalLM, VLChatProcessor ModuleNotFoundError: No module named 'janus'",
    "created_at": "2024-10-25T21:15:40Z",
    "closed_at": "2024-11-15T06:59:18Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/Janus/issues/21",
    "body": "` Traceback (most recent call last):\r\n  File \"/content/Janus/demo/app.py\", line 4, in <module>\r\n    from janus.models import MultiModalityCausalLM, VLChatProcessor\r\nModuleNotFoundError: No module named 'janus' `\r\n\r\nwhile running in google colab\r\n",
    "comments_url": "https://api.github.com/repos/deepseek-ai/Janus/issues/21/comments",
    "author": "Indra7pro",
    "comments": [
      {
        "user": "soloice",
        "created_at": "2024-11-15T06:59:18Z",
        "body": "I guess you are running it from the wrong directory. Try to run it at the project root, or include project root in PYTHONPATH"
      }
    ]
  },
  {
    "number": 20,
    "title": "Config.json Error",
    "created_at": "2024-10-22T21:05:28Z",
    "closed_at": "2024-11-15T06:57:03Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/Janus/issues/20",
    "body": "Hello, \r\n\r\nI am currently facing an issue where I cannot use the model, as the model_type field in the config.json is \"multi_modality\". Transformers then throws a ValueError, stating that Transformers does not recognize that architecture. I have tried uninstalling and reinstalling Transformers again before running as well as installing from source rather than pip, but nothing has seemed to work. I was wondering if there is a change or different model_type that should be used here?",
    "comments_url": "https://api.github.com/repos/deepseek-ai/Janus/issues/20/comments",
    "author": "AKjhu",
    "comments": [
      {
        "user": "charlesCXK",
        "created_at": "2024-11-14T18:48:24Z",
        "body": "Sorry for the late reply. It sounds like an issue with the runtime environment. You can set up the environment using the commands provided in the README."
      }
    ]
  },
  {
    "number": 17,
    "title": "Just wondering: why do you choose LLamaGen as image tokenizer, instead of OpenMagViT2?",
    "created_at": "2024-10-22T03:27:32Z",
    "closed_at": "2024-10-22T10:30:30Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/Janus/issues/17",
    "body": "Hello @hills-code @TheOneTrueGuy @eltociear,\r\n\r\nIt's definately a nice work! I am just wondering: why do you choose LLamaGen as image tokenizer, instead of OpenMagViT2? It seems that OpenMagViT2 has better performance and I am using it...If you do the ablation which shows LLamaGen looks better, please let me know and I will also switch my image tokenizer...\r\n\r\nGreat thanks!",
    "comments_url": "https://api.github.com/repos/deepseek-ai/Janus/issues/17/comments",
    "author": "StarCycle",
    "comments": [
      {
        "user": "TheOneTrueGuy",
        "created_at": "2024-10-22T03:36:06Z",
        "body": "Why am I linked in this? I have almost nothing to do with this except contributing a single trivial file."
      },
      {
        "user": "StarCycle",
        "created_at": "2024-10-22T03:44:05Z",
        "body": "@TheOneTrueGuy Oh sorry I just saw you in the contributors"
      },
      {
        "user": "TheOneTrueGuy",
        "created_at": "2024-10-22T04:15:16Z",
        "body": "de nada, sorry I can't answer your question. I'm still just getting started\nlearning about Janus. Good luck.\n"
      },
      {
        "user": "charlesCXK",
        "created_at": "2024-10-22T08:32:59Z",
        "body": "@StarCycle \r\nHi, we directly used the LlamaGen Tokenizer and haven't tried OpenMagViT2. When we started the project, OpenMagViT2 wasn't available yet. We believe that using a better tokenizer can result in better generation results.\r\n\r\n"
      },
      {
        "user": "StarCycle",
        "created_at": "2024-10-22T10:30:27Z",
        "body": "@charlesCXK \r\n\r\nThanks! I see!"
      }
    ]
  },
  {
    "number": 13,
    "title": "Multiple Images per a message?",
    "created_at": "2024-10-20T00:02:12Z",
    "closed_at": "2024-11-15T06:56:44Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/Janus/issues/13",
    "body": "Hello, and thank you for sharing such a novel model.\r\n\r\nI have checked the inference code, and it looks like it's working only with a single image per message. Attaching more causes a Tensor mismatch.\r\n\r\nDoes the model not support multiple images per user message?",
    "comments_url": "https://api.github.com/repos/deepseek-ai/Janus/issues/13/comments",
    "author": "DenisSergeevitch",
    "comments": [
      {
        "user": "charlesCXK",
        "created_at": "2024-11-14T18:45:47Z",
        "body": "Sorry for the late reply. Our model has been trained on multi-image QA data, but we only provided a single-image version when writing the demo code."
      }
    ]
  },
  {
    "number": 8,
    "title": "chore: update siglip_vit.py",
    "created_at": "2024-10-18T22:16:59Z",
    "closed_at": "2024-10-19T09:45:00Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/Janus/pull/8",
    "body": "orignal -> original",
    "comments_url": "https://api.github.com/repos/deepseek-ai/Janus/issues/8/comments",
    "author": "eltociear",
    "comments": [
      {
        "user": "hills-code",
        "created_at": "2024-10-19T09:44:58Z",
        "body": "Thanks for your contribution!"
      }
    ]
  },
  {
    "number": 7,
    "title": "A very basic notebook for using Janus with Google colab. ",
    "created_at": "2024-10-18T20:57:44Z",
    "closed_at": "2024-10-19T09:44:41Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/Janus/pull/7",
    "body": "Basic notebook for Janus on Google colab. Requires the use of A100 or better GPUs, won't work with T4.",
    "comments_url": "https://api.github.com/repos/deepseek-ai/Janus/issues/7/comments",
    "author": "TheOneTrueGuy",
    "comments": [
      {
        "user": "hills-code",
        "created_at": "2024-10-19T09:44:36Z",
        "body": "Thanks for your contribution!"
      }
    ]
  },
  {
    "number": 3,
    "title": "this model can do audio-to-any too?",
    "created_at": "2024-10-18T11:51:30Z",
    "closed_at": "2024-10-22T05:30:28Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/Janus/issues/3",
    "body": "im looking to readme and only viewing messages about image generation and view. it can do something with the audio input?",
    "comments_url": "https://api.github.com/repos/deepseek-ai/Janus/issues/3/comments",
    "author": "eletroswing",
    "comments": [
      {
        "user": "charlesCXK",
        "created_at": "2024-10-19T10:11:58Z",
        "body": "Thank you for your attention to our work! The current Janus model validates the feasibility of using different encoding methods for various tasks (pure text understanding, multimodal understanding, visual generation), and then processing them with a single transformer. However, this version of Janus has not been trained on audio data.\r\n\r\n"
      }
    ]
  }
]