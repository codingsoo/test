[
  {
    "number": 709,
    "title": "How can I  use smolagents in python3.8",
    "created_at": "2025-02-19T08:27:02Z",
    "closed_at": "2025-02-19T08:31:11Z",
    "labels": [
      "duplicate"
    ],
    "url": "https://github.com/huggingface/smolagents/issues/709",
    "body": "hi, how can I  use smolagents in python3.8?",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/709/comments",
    "author": "koyurion",
    "comments": [
      {
        "user": "albertvillanova",
        "created_at": "2025-02-19T08:31:11Z",
        "body": "Duplicate of #351.\n\nYou can't:\n> smolagents currently requires python >= 3.10:"
      },
      {
        "user": "koyurion",
        "created_at": "2025-02-19T08:31:40Z",
        "body": "ä½ å¥½ï¼Œä½ çš„é‚®ä»¶å·²æ”¶åˆ°ã€‚è°¢è°¢ï¼"
      }
    ]
  },
  {
    "number": 705,
    "title": "Remove translation tool from README",
    "created_at": "2025-02-19T06:52:24Z",
    "closed_at": "2025-02-19T07:30:12Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/705",
    "body": "Closes #704 ",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/705/comments",
    "author": "keetrap",
    "comments": [
      {
        "user": "albertvillanova",
        "created_at": "2025-02-19T07:29:43Z",
        "body": "Thanks."
      }
    ]
  },
  {
    "number": 704,
    "title": "[BUG] The \"translation\" tool does not exist",
    "created_at": "2025-02-19T01:58:20Z",
    "closed_at": "2025-02-19T07:30:13Z",
    "labels": [
      "bug"
    ],
    "url": "https://github.com/huggingface/smolagents/issues/704",
    "body": "**Describe the bug**\nsmolagent cli.py does not recognize tool \"translation\".\n\n**Code to reproduce the error**\nsmolagent \"Plan a trip to Tokyo, Kyoto and Osaka between Mar 28 and Apr 7.\" --model-type \"HfApiModel\" --model-id \"Qwen/Qwen2.5-Coder-32B-Instruct\" --imports \"pandas numpy\" --tools --tools \"translation\"\n\n**Error logs (if any)**\nsmolagents/cli.py\", line 109, in main\n    raise ValueError(f\"Tool {tool_name} is not recognized either as a default tool or a Space.\")\nValueError: Tool translation is not recognized either as a default tool or a Space.\n\n**Expected behavior**\nExpected that the translation tool be known and used.\n\n**Packages version:**\nsmolagents==1.9.2\n\n**Additional context**\nThis example is from the main repo page for cli example. The example shows --tools \"web_search translation\".\nTo troubleshoot this further each option was tested separately. When using only \"translation\" the error appears.\n",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/704/comments",
    "author": "ejfuture",
    "comments": [
      {
        "user": "albertvillanova",
        "created_at": "2025-02-19T07:32:03Z",
        "body": "Thanks for reporting. The \"translation\" tool existed in the former repo `transformers.agents`, but not in `smolagents`."
      }
    ]
  },
  {
    "number": 644,
    "title": "Allow for last_input_token_count=None",
    "created_at": "2025-02-13T20:09:04Z",
    "closed_at": "2025-02-14T11:21:41Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/644",
    "body": "A better test taken from monitoring.py because when using Ollama with MultiStepAgent for reasons I could not identify sometimes the value is still None as set in Model.__init__",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/644/comments",
    "author": "Strings-RH",
    "comments": [
      {
        "user": "sysradium",
        "created_at": "2025-02-13T22:36:25Z",
        "body": "Can you investigate a bit more, maybe token count is 0?"
      },
      {
        "user": "Strings-RH",
        "created_at": "2025-02-14T19:59:03Z",
        "body": "> Can you investigate a bit more, maybe token count is 0?\r\n\r\nMy descrption wasn't entirely clear, because I thought normalizing the test accross the code base was understandably a good idea. I found the bug using Ollama and MultiStepAgent when it was using hasattr(). This was changed to getattr() which removed my crash.  However, I thought the test should be the same in monioring.py and grad_ui.py, because if they are different it could turn into a very subtle bug if last_input_token_count=0.\r\n\r\nI see my commit has been merged, but I thought I should answer sysradium's question anyway"
      }
    ]
  },
  {
    "number": 623,
    "title": "Fix for MLX Model when stop sequence is followed by any chars",
    "created_at": "2025-02-12T18:34:30Z",
    "closed_at": "2025-02-14T11:17:57Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/623",
    "body": "~~Fixes stop sequence removal from model output if there is white space after the stop sequence. Previously, not all stop sequence characters would have been removed.~~\r\n\r\nIt was possible that any stop sequence could be missed. For example if your stop sequence is `<end_code>` but the model vocab includes `>'`, the model could choose that token and then the stop sequence would be missed. This PR should address all those cases.",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/623/comments",
    "author": "g-eoj",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-02-12T18:37:45Z",
        "body": "Could you add a test for this @g-eoj ?"
      },
      {
        "user": "g-eoj",
        "created_at": "2025-02-12T18:52:16Z",
        "body": "Should be easy enough. Sure."
      },
      {
        "user": "g-eoj",
        "created_at": "2025-02-12T20:21:20Z",
        "body": "@aymeric-roucher good thing you asked me to write tests. I found that non-whitespace chars can also follow stop sequences based on the tokenizer vocab. I'm going to refactor to try to catch more cases of the stop sequence being missed."
      }
    ]
  },
  {
    "number": 620,
    "title": "Please share the GAIA detailed benchmark report deepseek R1 vs gpt 4o vs claude 3.5 sonnet",
    "created_at": "2025-02-12T13:01:38Z",
    "closed_at": "2025-02-13T08:35:48Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/issues/620",
    "body": "I am trying to figure out the pros and cons of DeepSeek R1  compared to the SOTA chat model like gpt 4o. Can somebody share the GAIA detailed benchmark of GAIA. I want to get the feeling of details of DeepSeek R1 advantages",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/620/comments",
    "author": "chenatu",
    "comments": [
      {
        "user": "albertvillanova",
        "created_at": "2025-02-13T08:35:48Z",
        "body": "Sorry, the terms and conditions of the GAIA dataset explicitly prevent sharing the data publicly, so it cannot be (accidentally) crawled and (accidentally) used for training models."
      }
    ]
  },
  {
    "number": 580,
    "title": "[BUG]",
    "created_at": "2025-02-10T07:50:26Z",
    "closed_at": "2025-02-12T09:32:04Z",
    "labels": [
      "invalid"
    ],
    "url": "https://github.com/huggingface/smolagents/issues/580",
    "body": "The library does not work with requests in Russian. The code returns unicodeencoderror.\n\nCan you add a utf-8 support, please\n",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/580/comments",
    "author": "KoLLchIK",
    "comments": [
      {
        "user": "albertvillanova",
        "created_at": "2025-02-10T08:12:51Z",
        "body": "Hi @KoLLchIK, we would need some more information to address this issue:\n- Code to reproduce the error\n- Error logs (if any): also the stack trace to localize the code source\n- Packages version"
      },
      {
        "user": "sysradium",
        "created_at": "2025-02-10T14:04:02Z",
        "body": "I can try fixing the lib to work with the Russian language, but I need some input to reproduce that."
      },
      {
        "user": "nthe",
        "created_at": "2025-02-11T10:18:35Z",
        "body": "Just tested this. Seems like `1.9.0.dev0` works for Slovak and Russian language."
      }
    ]
  },
  {
    "number": 541,
    "title": "Delete prompts_path argument and use prompt_templates",
    "created_at": "2025-02-07T12:12:45Z",
    "closed_at": "2025-02-07T14:29:03Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/541",
    "body": "EDIT:\r\nRemove unused `prompts_path` argument and use `prompt_templates` instead.\r\n\r\nEDIT:\r\n~~Use `prompt_path` argument, previously introduced but not used.~~\r\n\r\n~~Remove unused `prompts_path` argument.~~\r\n\r\nThis argument was introduced (but not used) in:\r\n- #502\r\n\r\nOr maybe you wanted to use it somehow? @aymeric-roucher ",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/541/comments",
    "author": "albertvillanova",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-02-07T12:44:03Z",
        "body": "@albertvillanova the \"s\" in `prompts_path` is intentional, because there are many prompts in the `prompt_templates` dictionary. "
      },
      {
        "user": "albertvillanova",
        "created_at": "2025-02-07T12:53:26Z",
        "body": "I need to resolve the conflicts after having merged:\r\n- #536\r\n\r\nI aligned the singular name with `prompt_templates`, which also contains many prompts. I think in English, if a noun acts as an adjective, it should be normally in singular."
      },
      {
        "user": "albertvillanova",
        "created_at": "2025-02-07T13:13:07Z",
        "body": "What about both in plural (for explicit clarity)?\r\n- prompts_path\r\n- prompts_templates"
      },
      {
        "user": "albertvillanova",
        "created_at": "2025-02-07T14:18:52Z",
        "body": "Finally:\r\n- Remove unused `prompts_path`\r\n- Use `prompt_templates` instead (more user-friendly)"
      }
    ]
  },
  {
    "number": 540,
    "title": "Test E2B Executor",
    "created_at": "2025-02-07T12:05:02Z",
    "closed_at": "2025-02-07T14:51:14Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/540",
    "body": "Test E2B Executor.\r\n\r\nSee, we had previously introduced a bug in its instantiation without noticing it due to the lack of tests:\r\n- #537\r\n",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/540/comments",
    "author": "albertvillanova",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-02-07T13:48:44Z",
        "body": "Thank you @albertvillanova !"
      }
    ]
  },
  {
    "number": 531,
    "title": "Full system prompt saved to memory each time",
    "created_at": "2025-02-07T03:10:44Z",
    "closed_at": "2025-02-18T10:29:24Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/issues/531",
    "body": "I noticed that every message I add to the conversation increases the token input by about 2,000 tokens. I checked the memory and saw that the full system prompt is being saved with each message.\n\nIs that necessary? It seems like a waste of tokens.  \n",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/531/comments",
    "author": "vqndev",
    "comments": [
      {
        "user": "albertvillanova",
        "created_at": "2025-02-10T14:46:02Z",
        "body": "Thanks for reporting, @vqndev. Could you provide a code to reproduce the error and which smolagents version you are using? Thanks."
      }
    ]
  },
  {
    "number": 527,
    "title": "Fix build issues after refactor prompts",
    "created_at": "2025-02-07T01:26:37Z",
    "closed_at": "2025-02-07T10:07:54Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/527",
    "body": "My builds weren't working off of `main`, I think due to #502, these fixes address that.",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/527/comments",
    "author": "g-eoj",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-02-07T08:17:42Z",
        "body": "@albertvillanova check out these fixes as well, they might fix some of the issues you've seen!"
      }
    ]
  },
  {
    "number": 506,
    "title": "Add authorized_imports in importFrom errors",
    "created_at": "2025-02-05T17:58:30Z",
    "closed_at": "2025-02-09T16:40:16Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/506",
    "body": "Add the list of authorized imports to the `ast.ImportFrom` error message, bringing it in line with the error from `ast.Import`",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/506/comments",
    "author": "CalOmnie",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-02-09T16:40:13Z",
        "body": "Thank you @CalOmnie !"
      }
    ]
  },
  {
    "number": 493,
    "title": "[BUG] Unable to execute function defined in the same Python interpreter.",
    "created_at": "2025-02-04T23:50:44Z",
    "closed_at": "2025-02-06T07:22:17Z",
    "labels": [
      "bug"
    ],
    "url": "https://github.com/huggingface/smolagents/issues/493",
    "body": "**Describe the bug**\nUnable to execute function defined in the same Python interpreter. See example below:\n\n**Code to reproduce the error**\n\n```python\nfrom smolagents import CodeAgent, DuckDuckGoSearchTool, LiteLLMModel\nimport applescript\n\ndef tell_siri(command_text: str):\n    \"\"\"Execute a Siri command.\"\"\"\n\n    result = applescript.run(f\"\"\"\n        tell application \"System Events\" to tell the front menu bar of process \"SystemUIServer\"\n            tell (first menu bar item whose description is \"Siri\")\n                perform action \"AXPress\"\n            end tell\n        end tell\n\n        delay 2\n\n        tell application \"System Events\"\n            set textToType to \"{command_text}\"\n            keystroke textToType\n            key code 36\n        end tell\n    \"\"\")\n\ntask = \"\"\"\n0. Always check syntax on every step before code execution.\n1. use tell_siri function to \"turn off master bedroom light\", wait 2 seconds, and turn on \"master bedroom light\" again.\n\"\"\"\n\nqwen_coder_model = LiteLLMModel(model_id=\"ollama/qwen2.5-coder:32b\")\n\nagent8 = CodeAgent(\n    tools=[DuckDuckGoSearchTool()],\n    additional_authorized_imports=[\"*\"],\n    model=qwen_coder_model\n)\nagent8.run(task8)\n```\n\n**Error logs (if any)**\n\n```\n â”€ Executing parsed code: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ \n  import time                                                                                                                                                                                                                    \n                                                                                                                                                                                                                                 \n  tell_siri(\"turn off master bedroom light\")                                                                                                                                                                                     \n  time.sleep(2)                                                                                                                                                                                                                  \n  tell_siri(\"master bedroom light on\")                                                                                                                                                                                           \n â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ \nCode execution failed at line 'tell_siri(\"turn off master bedroom light\")' due to: InterpreterError:It is not permitted to evaluate other functions than the provided tools or functions defined/imported in previous code (tried\nto execute tell_siri).\n```\n\n**Expected behavior**\nThe function is local to the CodeAgent environment, I expect it to have access to the local functions.\n\n**Packages version:**\nRun `pip freeze | grep smolagents` and paste it here.\n\n`smolagents==1.7.0`\n\n**Additional context**\nAdd any other context about the problem here.\n",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/493/comments",
    "author": "didip",
    "comments": [
      {
        "user": "Manni08",
        "created_at": "2025-02-05T05:16:02Z",
        "body": "When authorized_imports is set to \"*\", the system prompt is updated to:\n\n\"You can import from any package you want.\"\n\nHowever, this setting only allows unrestricted imports from installed packagesâ€”it does not provide a mechanism to reference or execute functions defined within the same interpreter session. As a result, functions declared dynamically in the interpreter cannot be automatically passed or accessed elsewhere.\n\nUse the following code - \n\n```\n@tool\ndef tell_siri(command_text: str) -> None:\n    \"\"\"\n    Execute a Siri Command\n\n    Args:\n        command_text: command text\n    \"\"\"\n\n    result = applescript.run(f\"\"\"\n        tell application \"System Events\" to tell the front menu bar of process \"SystemUIServer\"\n            tell (first menu bar item whose description is \"Siri\")\n                perform action \"AXPress\"\n            end tell\n        end tell\n\n        delay 2\n\n        tell application \"System Events\"\n            set textToType to \"{command_text}\"\n            keystroke textToType\n            key code 36\n        end tell\n    \"\"\")\n\n\nagent8 = CodeAgent(\n    tools=[DuckDuckGoSearchTool(), tell_siri],\n    additional_authorized_imports=[\"*\"],\n    model=model\n)\n\n```"
      },
      {
        "user": "didip",
        "created_at": "2025-02-06T07:22:17Z",
        "body": "Thanks for the response."
      }
    ]
  },
  {
    "number": 488,
    "title": "Bump litellm to 1.60.2 (fixes #34)",
    "created_at": "2025-02-04T18:28:47Z",
    "closed_at": "2025-02-05T10:43:02Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/488",
    "body": "Fixes #34 (and duplicate #35)",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/488/comments",
    "author": "taha-yassine",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-02-05T10:42:49Z",
        "body": "Thank you! It's nice to see that LiteLLM fixed this issue on their side!"
      }
    ]
  },
  {
    "number": 467,
    "title": "[BUG] Error in generating model output: embedding(): argument 'indices' (position 2) must be Tensor, not list",
    "created_at": "2025-02-02T05:02:42Z",
    "closed_at": "2025-02-04T07:50:36Z",
    "labels": [
      "bug"
    ],
    "url": "https://github.com/huggingface/smolagents/issues/467",
    "body": "Using locally run model on a GPU, results in the following error:\nError in generating model output:\nembedding(): argument 'indices' (position 2) must be Tensor, not list\n\nHave tried with the following models:\nmodel_id = \"meta-llama/Llama-3.2-3B-Instruct\"\nmodel_id_2 = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\\\nmodel_id_4 = \"Qwen/CodeQwen1.5-7B\"\nmodel_id_5 = \"Qwen/Qwen2.5-Coder-3B-Instruct\"\n\nIssue does not happen when model is run locally on a cpu.\n\nSample code:\n```\nfrom smolagents import CodeAgent, TransformersModel\nfrom transformers import AutoModelForCausalLM\nimport torch\n\nmodel_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n\naccess_token = <>\n\nmodel = AutoModelForCausalLM.from_pretrained(model_id, device_map = 'auto', token=access_token)\nagent = CodeAgent(tools=[], model=model, add_base_tools=True)\n\nagent.run(\n    \"code to generate fibonacci numbers\"\n)\n```\n\n**Packages version:**\npip show smolagents\nName: smolagents\nVersion: 1.2.2\n",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/467/comments",
    "author": "satendra929",
    "comments": [
      {
        "user": "albertvillanova",
        "created_at": "2025-02-03T08:09:15Z",
        "body": "Could you provide the complete stack trace error? I'm not sure if the error is raised by the smolagents library, or maybe other dependency.\n\nAdditionally, could you update smolagents and check if the error is still present? Over the last releases, many bugs have been fixed."
      },
      {
        "user": "satendra929",
        "created_at": "2025-02-04T04:50:57Z",
        "body": "@albertvillanova Unfortunately, update did not help.\n\nTried debugging and also couple of methods to output a stack trace but seems like even if the message says it's an exception, it does not throw one. So, did not get a stack trace."
      },
      {
        "user": "albertvillanova",
        "created_at": "2025-02-04T07:50:36Z",
        "body": "I just realized about your sample code: you are not passing the right model instance!\nPlease pass `TransformersModel` instance instead.\nYou have detailed information in the docs."
      },
      {
        "user": "satendra929",
        "created_at": "2025-02-05T04:14:11Z",
        "body": "@albertvillanova Yup, I originally started with using TransformerModel. I then noticed that the GPU was not being used when I was running the agent. Hence, I switched to using AutoModelForCausalLM.from_pretrained which allows to specifically mention device map and set it to cuda.\n\nIn the process of using AutoModelForCausalLM.from_pretrained and setting the device map to cuda, I had to reinstall torch with cuda. And as a result, now even TransformerModel runs on the GPU without explicitly setting device to cuda. So, maybe somewhere in the documentation it needs to be mentioned what one must do if they are not seeing their GPU being used. "
      }
    ]
  },
  {
    "number": 466,
    "title": "[BUG] Incorrect README Link to Helium Cryptocurrency Repository",
    "created_at": "2025-02-01T17:38:26Z",
    "closed_at": "2025-02-03T07:00:45Z",
    "labels": [
      "bug"
    ],
    "url": "https://github.com/huggingface/smolagents/issues/466",
    "body": "The README.md file for the Helium project incorrectly links to the Helium cryptocurrency GitHub repository instead of the Helium browser automation library. This can confuse users looking for information on browser automation.\n\nCode to reproduce the error\nN/A (This is not a code-related issue, but rather a documentation error.)\n\nError logs (if any)\nN/A\n\nExpected behavior\nThe README.md should contain a link to the correct Helium browser automation library GitHub repository, allowing users to find relevant resources without confusion.\n\nPackages version:\nN/A (This issue is related to documentation and not dependent on package versions.)\n\nAdditional context\nThis issue may lead to confusion for new users who are trying to understand how to use Helium for browser automation. Correcting the link in the README.md will help direct users to the appropriate resources and improve overall user experience. Feel free to modify any details as necessary!\n",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/466/comments",
    "author": "abhiyan52",
    "comments": [
      {
        "user": "albertvillanova",
        "created_at": "2025-02-03T06:57:29Z",
        "body": "Thanks for reporting."
      }
    ]
  },
  {
    "number": 460,
    "title": "Minor Fix tool push_to_hub",
    "created_at": "2025-01-31T19:39:25Z",
    "closed_at": "2025-02-04T11:35:04Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/460",
    "body": "Fixed issue where passing the token directly in the `push_to_hub` function was not working.",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/460/comments",
    "author": "keetrap",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-02-04T11:35:00Z",
        "body": "LGTM! Thank you for the fix and the explanation @keetrap ! ðŸ˜ƒ "
      }
    ]
  },
  {
    "number": 454,
    "title": "fix: support o1",
    "created_at": "2025-01-31T14:48:39Z",
    "closed_at": "2025-02-05T10:44:42Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/454",
    "body": "Remove `max_tokens` for `o1` models",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/454/comments",
    "author": "ricklamers",
    "comments": [
      {
        "user": "ricklamers",
        "created_at": "2025-01-31T14:49:06Z",
        "body": "I couldn't get it working without these changes. Maybe this needs to be changed, but this is working for me."
      },
      {
        "user": "aymeric-roucher",
        "created_at": "2025-02-05T10:44:42Z",
        "body": "This fix is not needed anymore! Now that we've removed the default parameter `max_tokens`, the model works out of the box for me. Tell us if you still have errors and we'll reopen!"
      },
      {
        "user": "ricklamers",
        "created_at": "2025-02-05T13:39:50Z",
        "body": "Nice!"
      }
    ]
  },
  {
    "number": 451,
    "title": "Bump dev version: v1.8.0.dev0",
    "created_at": "2025-01-31T13:04:50Z",
    "closed_at": "2025-01-31T13:21:02Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/451",
    "body": null,
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/451/comments",
    "author": "albertvillanova",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-31T13:21:15Z",
        "body": "Thank you for this release @albertvillanova ðŸ˜ƒ "
      }
    ]
  },
  {
    "number": 436,
    "title": "Fix minor issue in e2b",
    "created_at": "2025-01-30T17:21:30Z",
    "closed_at": "2025-01-31T12:53:59Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/436",
    "body": "Minor issue left to resolve in PR #319 \r\nCloses #434 ",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/436/comments",
    "author": "keetrap",
    "comments": [
      {
        "user": "albertvillanova",
        "created_at": "2025-01-31T12:56:09Z",
        "body": "Thanks for the fix, @keetrap!"
      }
    ]
  },
  {
    "number": 433,
    "title": "Fix import from deleted logger module",
    "created_at": "2025-01-30T14:27:43Z",
    "closed_at": "2025-01-30T16:34:05Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/433",
    "body": "Fix import from deleted logger module.\r\n\r\nNote that the logger module was deleted in:\r\n- #419",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/433/comments",
    "author": "albertvillanova",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-30T16:34:10Z",
        "body": "Thank you!"
      }
    ]
  },
  {
    "number": 418,
    "title": "Fix installation instruction for GradioUI in error message",
    "created_at": "2025-01-29T15:52:08Z",
    "closed_at": "2025-01-30T12:25:54Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/418",
    "body": "Fix: error message for missing gradio package refers to smolagents[audio] instead of smolagents[gradio] package.",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/418/comments",
    "author": "jank",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-30T12:26:09Z",
        "body": "Thank you @jank !"
      }
    ]
  },
  {
    "number": 402,
    "title": "CLI interface",
    "created_at": "2025-01-28T16:12:13Z",
    "closed_at": "2025-01-31T15:43:42Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/issues/402",
    "body": "Add CLI commands to quickly run agents, possibly in a gradio interface.",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/402/comments",
    "author": "aymeric-roucher",
    "comments": [
      {
        "user": "connorads",
        "created_at": "2025-01-31T14:53:55Z",
        "body": "Nice work in #431 @aymeric-roucher ðŸ™Œ "
      },
      {
        "user": "merveenoyan",
        "created_at": "2025-01-31T15:43:42Z",
        "body": "Closing as resolved with #416 #431 "
      }
    ]
  },
  {
    "number": 398,
    "title": "Share full agents to the Hub",
    "created_at": "2025-01-28T16:00:59Z",
    "closed_at": "2025-02-17T12:50:21Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/issues/398",
    "body": "We need a method `agent.push_to_hub`!",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/398/comments",
    "author": "aymeric-roucher",
    "comments": [
      {
        "user": "davidberenstein1957",
        "created_at": "2025-02-06T09:24:12Z",
        "body": "Awesome, was just searching for this!"
      },
      {
        "user": "keetrap",
        "created_at": "2025-02-06T20:01:49Z",
        "body": "I am working on this feature."
      },
      {
        "user": "sysradium",
        "created_at": "2025-02-10T22:55:21Z",
        "body": "I guess it is in full swing, let's move it into \"In Progress\" not to confuse people."
      },
      {
        "user": "guptaaryan16",
        "created_at": "2025-02-17T12:45:19Z",
        "body": "any updates on this, I would love to help on this issue @keetrap @aymeric-roucher "
      },
      {
        "user": "albertvillanova",
        "created_at": "2025-02-17T12:50:21Z",
        "body": "Closed by:\n- #533"
      }
    ]
  },
  {
    "number": 385,
    "title": "Additional parameters for openai client",
    "created_at": "2025-01-28T08:03:50Z",
    "closed_at": "2025-01-28T09:01:13Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/385",
    "body": "fix #381 ",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/385/comments",
    "author": "touseefahmed96",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-28T08:21:36Z",
        "body": "@touseefahmed96 normally you shouldn't need a PR fort these parameters to work, they should work as kwargs. Tell me if it's not the case!"
      },
      {
        "user": "touseefahmed96",
        "created_at": "2025-01-28T08:41:51Z",
        "body": "So, @albertvillanova in order to use the organization or project parameter isn't it necessary to pass kwargs to client ?\r\nlike:\r\n```\r\n self.client = openai.OpenAI( \r\n     base_url=api_base, \r\n     api_key=api_key, \r\n    **kwargs,\r\n ) \r\n```"
      },
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-28T08:47:22Z",
        "body": "Thanks for looking into it @albertvillanova !\r\nThen indeed this PR makes sense!\r\nMaybe if going forward we see many additional (and unpredictable) args needed for model initialization rather than model completion, we could add something like an initialization_args dict that users can use to pass init args to the underlying model? Not sure what would be best."
      },
      {
        "user": "albertvillanova",
        "created_at": "2025-01-28T08:57:55Z",
        "body": "I agree @aymeric-roucher. If in the future we see more client args are requested by users, maybe we could define a `client_kwargs` parameter."
      },
      {
        "user": "touseefahmed96",
        "created_at": "2025-01-28T09:05:14Z",
        "body": "> I agree @aymeric-roucher. If in the future we see more client args are requested by users, maybe we could define a `client_kwargs` parameter.\r\n\r\nI will look into it and let's see if I can find any better solution. The `client_kwargs` parameter makes sense "
      }
    ]
  },
  {
    "number": 379,
    "title": "chore: Fix Typo by Calling is_torch_available() in AgentAudio Class",
    "created_at": "2025-01-27T17:13:49Z",
    "closed_at": "2025-01-28T08:51:00Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/379",
    "body": "## Summary\r\n\r\nCorrect the conditional checks in the `AgentAudio` class by invoking the `is_torch_available` function. This prevents unintended `ImportError` when `torch` is not installed.\r\n\r\n## Changes\r\n\r\n* (typo) issue resolved: The `is_torch_available` function was referenced without parentheses, causing it to be treated as a variable rather than being executed. This led to incorrect evaluation of the condition and potential `ImportError` when `torch` is unavailable.",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/379/comments",
    "author": "hironow",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-28T08:51:15Z",
        "body": "Thank you @hironow, LGTM!"
      }
    ]
  },
  {
    "number": 373,
    "title": "Remove explicit model arg in HfApiModel - which wouldn't run without Pro",
    "created_at": "2025-01-27T13:38:47Z",
    "closed_at": "2025-01-30T17:55:09Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/373",
    "body": "model=HfApiModel(\"meta-llama/Llama-3.3-70B-Instruct\")  throws an error as it's only available with the Pro subscription and it's not easy to find which models are available for free. \r\n\r\nNot passing an argument seems like the easiest solution for now.",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/373/comments",
    "author": "sanjeed5",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-30T17:54:53Z",
        "body": "Thank you @sanjeed5 , good change!"
      }
    ]
  },
  {
    "number": 372,
    "title": "DuckDuckGoSearchTool: add ddgs_kwargs parameter to constructor",
    "created_at": "2025-01-27T13:05:01Z",
    "closed_at": "2025-01-28T09:11:33Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/372",
    "body": "Add ddgs_kwargs parameter to constructor for flexible configuration.\r\n\r\nThis could be useful when users need to customize DDGS.\r\n\r\n## Example.\r\n\r\n```python\r\ntool = DuckDuckGoSearchTool(\r\n    ddgs_kwargs={\r\n        'timeout': 20,\r\n        'proxies': 'socks5h://localhost:9050',\r\n        'headers': {'User-Agent': 'my-custom-agent'}\r\n    }\r\n)\r\n```",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/372/comments",
    "author": "onukura",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-28T08:59:34Z",
        "body": "@onukura thank you for contributing this!\r\nSince the previously passes *args and **kwargs are actually useless, we could just use any kwarg passed to tool init to the DDGS initialization, like:\r\n```py\r\ntool = DuckDuckGoSearchTool(\r\n    timeout= 20,\r\n    proxies=socks5h://localhost:9050,\r\n    headers= {'User-Agent': 'my-custom-agent'}\r\n)\r\n```"
      },
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-28T09:11:46Z",
        "body": "Merged in the form that I proposed!"
      },
      {
        "user": "onukura",
        "created_at": "2025-01-28T10:32:58Z",
        "body": "@aymeric-roucher Thanks for your review and merging it!"
      }
    ]
  },
  {
    "number": 370,
    "title": "Test import without extras",
    "created_at": "2025-01-27T09:06:54Z",
    "closed_at": "2025-01-28T09:57:15Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/370",
    "body": "Test import without extras.\r\n\r\nSee:\r\n- #360",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/370/comments",
    "author": "albertvillanova",
    "comments": [
      {
        "user": "antoinejeannot",
        "created_at": "2025-01-27T10:27:20Z",
        "body": "If I may, this type of test will only pass if all dependencies are loaded when smolagents is imported.\r\n\r\nThis enforces importing everything from the top-level __init__.py, which has some notable drawbacks: circular issues, debugging, prevent users from optimizing their imports to save some RAM & import-time latency.\r\n\r\nIf that is genuinely required, the following two files are missing from the `__init__.py` for this test to be exhaustive:\r\n- `tool_validation.py`\r\n- `_function_type_hints_utils.py`\r\n\r\nI'd recommend re-evaluating whether importing all submodules into the top-level namespace is absolutely necessary ðŸ˜… "
      }
    ]
  },
  {
    "number": 357,
    "title": "Do I need to manually install transformers module?",
    "created_at": "2025-01-25T17:04:24Z",
    "closed_at": "2025-01-27T09:07:30Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/issues/357",
    "body": "I just installed smolagents with uv, when i run the sample test from the guide, it says transformers module not found.\nDo I have to manually install it? Seems it's not included in the package.\n\nPls advise, thanks.\n\n```\nubuntu@s:~/src$ uv add smolagents\nResolved 161 packages in 5.59s\nPrepared 14 packages in 4.50s\nInstalled 14 packages in 219ms\n + duckduckgo-search==7.2.1\n + fsspec==2024.12.0\n + huggingface-hub==0.27.1\n + jinja2==3.1.5\n + markdown-it-py==3.0.0\n + markdownify==0.14.1\n + markupsafe==3.0.2\n + mdurl==0.1.2\n + pandas==2.2.3\n + primp==0.10.1\n + pygments==2.19.1\n + rich==13.9.4\n + smolagents==1.5.0\n + tzdata==2024.2\n\nubuntu@s:~/src/products$ uv run smola_test.py \nTraceback (most recent call last):\n  File \"/home/ubuntu/src/products/smola_test.py\", line 3, in <module>\n    from smolagents import CodeAgent, HfApiModel\n  File \"/home/ubuntu/src/.venv/lib/python3.13/site-packages/smolagents/__init__.py\", line 19, in <module>\n    from .agents import *\n  File \"/home/ubuntu/src/.venv/lib/python3.13/site-packages/smolagents/agents.py\", line 37, in <module>\n    from .models import (\n    ...<2 lines>...\n    )\n  File \"/home/ubuntu/src/.venv/lib/python3.13/site-packages/smolagents/models.py\", line 28, in <module>\n    from transformers import (\n    ...<4 lines>...\n    )\nModuleNotFoundError: No module named 'transformers'\n```",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/357/comments",
    "author": "auroradanier",
    "comments": [
      {
        "user": "berkayguzel06",
        "created_at": "2025-01-26T07:43:17Z",
        "body": "The transformers module exist in the optional dependencies under pyproject.toml. But you can install it manually with 'pip install transformers' it worked for me."
      },
      {
        "user": "albertvillanova",
        "created_at": "2025-01-26T09:39:33Z",
        "body": "Thanks for reporting. I think we made a regression in our last release."
      },
      {
        "user": "MNIKIEMA",
        "created_at": "2025-01-26T13:26:02Z",
        "body": "Hey folks, I got the same issue by trying to test the text to SQL agent."
      },
      {
        "user": "albertvillanova",
        "created_at": "2025-01-26T17:26:56Z",
        "body": "Once the fix integrated, we will make a patch release."
      }
    ]
  },
  {
    "number": 349,
    "title": "`Qwen-2VL` -> `Qwen2-VL` model name typo fixed",
    "created_at": "2025-01-24T17:18:07Z",
    "closed_at": "2025-01-28T08:45:25Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/349",
    "body": "@aymeric-roucher @merveenoyan ",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/349/comments",
    "author": "sergiopaniego",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-28T08:50:12Z",
        "body": "Thank you @sergiopaniego !"
      }
    ]
  },
  {
    "number": 341,
    "title": "Corrected tool examples in ToolCallingAgent system prompts",
    "created_at": "2025-01-24T07:54:51Z",
    "closed_at": "2025-01-24T14:21:01Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/341",
    "body": "This is to close the remaining part of #264 until the general prompt refactoring is done. It prevents occasional problems with the tool call format. The main issue was closed in #318 ",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/341/comments",
    "author": "RolandJAAI",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-24T14:20:57Z",
        "body": "Thank you @RolandJAAI !"
      }
    ]
  },
  {
    "number": 339,
    "title": "No module named \"_gdbm\"",
    "created_at": "2025-01-23T20:38:55Z",
    "closed_at": "2025-01-31T07:25:23Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/issues/339",
    "body": "Code:\nqwen_model = HfApiModel(\"Qwen/Qwen2.5-Coder-32B-Instruct\", token = hf_token)\ndata_analyst_agent_qwen = CodeAgent(\n    tools=[],\n    model=qwen_model,\n    additional_authorized_imports=[\"numpy\", \"pandas\", \"matplotlib.pyplot\", \"seaborn\"],\n    max_steps=10,\n)\ndata_analyst_agent_qwen.run(data_analyst_prompt, additional_args = dict(source_file_path = input_file_path))\n\nResult:\nError when smolagent is executing the following code during one of the steps. This code is generated by the llm during step 1. The following code runs without any error when I run it in a separate notebook. Logs are not showing any additional information. Error message: No module named \"_gdbm\". The error seems to be generated by the code for the plots. Agent works without any issues if I \"EXCLUDE\" the requirement about generating charts.\n\nimport matplotlib.pyplot as plt                                                                                  \n  import seaborn as sns                                                                                            \n                                                                                                                   \n                          \n  plt.figure(figsize=(15, 10))                                                                                     \n                                                                                                                   \n                                                                     \n  plt.subplot(2, 2, 1)                                                                                             \n  sns.boxplot(x='Product_3', y='Stroke_Length', data=df)                                                           \n  plt.title('Distribution of Stroke_Length by Product_3')                                                          \n  plt.xticks(rotation=45)                                                                                          \n                                                                                                                   \n                                                           \n  plt.subplot(2, 2, 2)                                                                                             \n  sns.boxplot(x='Cylinder_Function', y='Closed_Length_mm', data=df)                                                \n  plt.title('Distribution of Closed_Length_mm by Cylinder_Function')                                               \n  plt.xticks(rotation=90)                                                                                          \n                                                                                                                   \n                                                                    \n  plt.subplot(2, 2, 3)                                                                                             \n  sns.boxplot(x='Type_2', y='Attributes_Rod_ID', data=df)                                                          \n  plt.title('Distribution of Attributes_Rod_ID by Type_2')                                                         \n                                                                                                                   \n                                                             \n  plt.subplot(2, 2, 4)                                                                                             \n  sns.boxplot(x='Type_2', y='Attributes_Internal_Bore', data=df)                                                   \n  plt.title('Distribution of Attributes_Internal_Bore by Type_2')                                                  \n                                                                                                                   \n  plt.tight_layout()                                                                                               \n  plt.show()                                                                                                       \n                                                                                                                   \n                                                                           \n  question1 = \"What is the average Stroke_Length for each Product_3 category?\"                                     \n  question2 = \"What is the maximum Closed_Length_mm for each Cylinder_Function category?\"                          \n  question3 = \"What is the average Attributes_Rod_ID for each Type_2 category?\"                                    \n                                                                                                                   \n                                                                                        \n  answer1 = df.groupby('Product_3')['Stroke_Length'].mean()                                                        \n  answer2 = df.groupby('Cylinder_Function')['Closed_Length_mm'].max()                                              \n  answer3 = df.groupby('Type_2')['Attributes_Rod_ID'].mean()                                                       \n                                                                                                                   \n  print(\"Question 1:\", question1)                                                                                  \n  print(\"Answer 1:\", answer1)                                                                                      \n  print(\"\\nQuestion 2:\", question2)                                                                                \n  print(\"Answer 2:\", answer2)                                                                                      \n  print(\"\\nQuestion 3:\", question3)                                                                                \n  print(\"Answer 3:\", answer3)        \n\n\n",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/339/comments",
    "author": "prasiyer",
    "comments": [
      {
        "user": "albertvillanova",
        "created_at": "2025-01-24T09:11:06Z",
        "body": "I think this issue is not related to the `smolagents` library, but to your local Python environment."
      },
      {
        "user": "prasiyer",
        "created_at": "2025-01-25T23:19:54Z",
        "body": "@albertvillanova \nI am not certain that the problem is with the local python environment. If I copy the code generated by the llm and run it in a notebook within my local environment, the code works just fine. However, when the agent is trying to run it within the python-interpretor, it encounters the \"Missing _gdbm module\" error. Can you pls provide some suggestions to debug this further?"
      },
      {
        "user": "AngeloKiriakoulis",
        "created_at": "2025-01-27T12:13:01Z",
        "body": "I think the `LocalPythonInterpreter` class doesn't interact with Python the same way a typical system or virtual environment does. Itâ€™s more of a parser and executor for Python code, lacking the dynamic runtime configuration you'd expect from a full Python environment.\n\nModules like `_gdbm` (which `matplotlib` relies on) need specific shared libraries and environment variables, which might not be properly initialized in the custom interpreter. This could be a tradeoff in smolagents, where the focus is on safely executing untrusted codeâ€”possibly at the cost of more complex functionality like rendering a GUI, which `_gdbm` might be involved in and requires system tools.\n\nAlso some code insights, future fixes (?):\n\n- The `# TODO: assert self.authorized imports are all installed locally` in the `LocalPythonInterpreter` class initialization shows that thereâ€™s no mechanism to check if the imports in `self.authorized_imports` are actually available in the current runtime, leading to  runtime errors, like the one discussed.\n\n- Thereâ€™s also no way to ensure the interpreter inherits critical configurations, like `sys.path` or environment variables, from the actual Python runtime. This is what I'm referring about for the design choice, that seems to prioritize security and predictability, especially when running untrusted code. Which is a good thing imo."
      },
      {
        "user": "Bilokin",
        "created_at": "2025-01-27T18:07:38Z",
        "body": "I have the same issue on anaconda on Windows 10. I can import locally matplotlib and plot some plots, but it is impossible to do via smolagents as described above. \nI don't get the real reason for the problem, but I was able to locate the error via the code:\n```\nimport smolagents\ninter = smolagents.LocalPythonInterpreter(additional_authorized_imports=[ 'pandas', 'matplotlib', 'numpy'], tools={})\ninter('import matplotlib.pyplot as plt', {})\n```\nThis results in:\n```\nModuleNotFoundError                       Traceback (most recent call last)\nFile [D:\\Documents\\anaconda3\\envs\\new_sandbox\\Lib\\site-packages\\smolagents\\local_python_executor.py:1294](file:///D:/Documents/anaconda3/envs/new_sandbox/Lib/site-packages/smolagents/local_python_executor.py#line=1293), in evaluate_python_code(code, static_tools, custom_tools, state, authorized_imports, max_print_outputs_length)\n   1293 for node in expression.body:\n-> 1294     result = evaluate_ast(node, state, static_tools, custom_tools, authorized_imports)\n   1295 state[\"print_outputs\"] = truncate_content(PRINT_OUTPUTS, max_length=max_print_outputs_length)\n\nFile [D:\\Documents\\anaconda3\\envs\\new_sandbox\\Lib\\site-packages\\smolagents\\local_python_executor.py:1208](file:///D:/Documents/anaconda3/envs/new_sandbox/Lib/site-packages/smolagents/local_python_executor.py#line=1207), in evaluate_ast(expression, state, static_tools, custom_tools, authorized_imports)\n   1207 elif isinstance(expression, (ast.Import, ast.ImportFrom)):\n-> 1208     return import_modules(expression, state, authorized_imports)\n   1209 elif isinstance(expression, ast.ClassDef):\n\nFile [D:\\Documents\\anaconda3\\envs\\new_sandbox\\Lib\\site-packages\\smolagents\\local_python_executor.py:1008](file:///D:/Documents/anaconda3/envs/new_sandbox/Lib/site-packages/smolagents/local_python_executor.py#line=1007), in import_modules(expression, state, authorized_imports)\n   1007     raw_module = import_module(alias.name)\n-> 1008     state[alias.asname or alias.name] = get_safe_module(raw_module, dangerous_patterns)\n   1009 else:\n\nFile [D:\\Documents\\anaconda3\\envs\\new_sandbox\\Lib\\site-packages\\smolagents\\local_python_executor.py:966](file:///D:/Documents/anaconda3/envs/new_sandbox/Lib/site-packages/smolagents/local_python_executor.py#line=965), in get_safe_module(unsafe_module, dangerous_patterns, visited)\n    965 if isinstance(attr_value, ModuleType):\n--> 966     attr_value = get_safe_module(attr_value, dangerous_patterns, visited=visited)\n    968 setattr(safe_module, attr_name, attr_value)\n\nFile [D:\\Documents\\anaconda3\\envs\\new_sandbox\\Lib\\site-packages\\smolagents\\local_python_executor.py:966](file:///D:/Documents/anaconda3/envs/new_sandbox/Lib/site-packages/smolagents/local_python_executor.py#line=965), in get_safe_module(unsafe_module, dangerous_patterns, visited)\n    965 if isinstance(attr_value, ModuleType):\n--> 966     attr_value = get_safe_module(attr_value, dangerous_patterns, visited=visited)\n    968 setattr(safe_module, attr_name, attr_value)\n\n    [... skipping similar frames: get_safe_module at line 966 (5 times)]\n\nFile [D:\\Documents\\anaconda3\\envs\\new_sandbox\\Lib\\site-packages\\smolagents\\local_python_executor.py:966](file:///D:/Documents/anaconda3/envs/new_sandbox/Lib/site-packages/smolagents/local_python_executor.py#line=965), in get_safe_module(unsafe_module, dangerous_patterns, visited)\n    965 if isinstance(attr_value, ModuleType):\n--> 966     attr_value = get_safe_module(attr_value, dangerous_patterns, visited=visited)\n    968 setattr(safe_module, attr_name, attr_value)\n\nFile [D:\\Documents\\anaconda3\\envs\\new_sandbox\\Lib\\site-packages\\smolagents\\local_python_executor.py:962](file:///D:/Documents/anaconda3/envs/new_sandbox/Lib/site-packages/smolagents/local_python_executor.py#line=961), in get_safe_module(unsafe_module, dangerous_patterns, visited)\n    960     continue\n--> 962 attr_value = getattr(unsafe_module, attr_name)\n    964 # Recursively process nested modules, passing visited set\n\nFile [D:\\Documents\\anaconda3\\envs\\new_sandbox\\Lib\\site-packages\\six.py:97](file:///D:/Documents/anaconda3/envs/new_sandbox/Lib/site-packages/six.py#line=96), in _LazyDescr.__get__(self, obj, tp)\n     96 def __get__(self, obj, tp):\n---> 97     result = self._resolve()\n     98     setattr(obj, self.name, result)  # Invokes __set__.\n\nFile [D:\\Documents\\anaconda3\\envs\\new_sandbox\\Lib\\site-packages\\six.py:120](file:///D:/Documents/anaconda3/envs/new_sandbox/Lib/site-packages/six.py#line=119), in MovedModule._resolve(self)\n    119 def _resolve(self):\n--> 120     return _import_module(self.mod)\n\nFile [D:\\Documents\\anaconda3\\envs\\new_sandbox\\Lib\\site-packages\\six.py:87](file:///D:/Documents/anaconda3/envs/new_sandbox/Lib/site-packages/six.py#line=86), in _import_module(name)\n     86 \"\"\"Import module, returning the module after the last dot.\"\"\"\n---> 87 __import__(name)\n     88 return sys.modules[name]\n\nFile [D:\\Documents\\anaconda3\\envs\\new_sandbox\\Lib\\dbm\\gnu.py:3](file:///D:/Documents/anaconda3/envs/new_sandbox/Lib/dbm/gnu.py#line=2)\n      1 \"\"\"Provide the _gdbm module as a dbm submodule.\"\"\"\n----> 3 from _gdbm import *\n\nModuleNotFoundError: No module named '_gdbm'\n\nDuring handling of the above exception, another exception occurred:\n\nInterpreterError                          Traceback (most recent call last)\nCell In[3], line 4\n      2 inter = smolagents.LocalPythonInterpreter(additional_authorized_imports=[ 'pandas', 'matplotlib', 'numpy'], tools={})\n      3 inter('import numpy as np', {})\n----> 4 inter('import matplotlib.pyplot as plt', {})\n\nFile [D:\\Documents\\anaconda3\\envs\\new_sandbox\\Lib\\site-packages\\smolagents\\local_python_executor.py:1334](file:///D:/Documents/anaconda3/envs/new_sandbox/Lib/site-packages/smolagents/local_python_executor.py#line=1333), in LocalPythonInterpreter.__call__(self, code_action, additional_variables)\n   1332 def __call__(self, code_action: str, additional_variables: Dict) -> Tuple[Any, str, bool]:\n   1333     self.state.update(additional_variables)\n-> 1334     output, is_final_answer = evaluate_python_code(\n   1335         code_action,\n   1336         static_tools=self.static_tools,\n   1337         custom_tools=self.custom_tools,\n   1338         state=self.state,\n   1339         authorized_imports=self.authorized_imports,\n   1340         max_print_outputs_length=self.max_print_outputs_length,\n   1341     )\n   1342     logs = self.state[\"print_outputs\"]\n   1343     return output, logs, is_final_answer\n\nFile [D:\\Documents\\anaconda3\\envs\\new_sandbox\\Lib\\site-packages\\smolagents\\local_python_executor.py:1308](file:///D:/Documents/anaconda3/envs/new_sandbox/Lib/site-packages/smolagents/local_python_executor.py#line=1307), in evaluate_python_code(code, static_tools, custom_tools, state, authorized_imports, max_print_outputs_length)\n   1304 error_msg = truncate_content(PRINT_OUTPUTS, max_length=max_print_outputs_length)\n   1305 error_msg = (\n   1306     f\"Code execution failed at line '{ast.get_source_segment(code, node)}' due to: {exception_type}:{str(e)}\"\n   1307 )\n-> 1308 raise InterpreterError(error_msg)\n\nInterpreterError: Code execution failed at line 'import matplotlib.pyplot as plt' due to: ModuleNotFoundError:No module named '_gdbm'\n```\n\nThis lead me to an idea of adding `dbm` to `dangerous_modules`,  which solved the issue.  There can be a better solution, perhaps. Tagging @aymeric-roucher "
      },
      {
        "user": "antoinejeannot",
        "created_at": "2025-01-28T16:29:34Z",
        "body": "`smolagents` traverses all the imports of allowed dependencies recursively.\n\n`matplotlib.pyplot` depends on `six` which heavily make use of lazy, conditional imports to handle different python versions (py2/py3)\n\n`smolagents` due to l948 and l953, triggers lazy imports by accessing the `dbm_gnu` attribute which exists in `dir(unsafe_module)` (where `unsafe_module` is the `six` module) but not supposed to get accessed yet\n\n```python\n    for attr_name in dir(unsafe_module):  # attr_name == dbm_genu\n...\n        attr_value = getattr(unsafe_module, attr_name)  # raise!\n\n```\n\nI will try to propose a fix in the evening, if not already managed :)\n\nIn the meantime, @Bilokin's work around is ðŸ’¯  and should monkey patch the issue @prasiyer "
      }
    ]
  },
  {
    "number": 313,
    "title": "Refactor evaluate_augassign and test all operators",
    "created_at": "2025-01-22T13:29:22Z",
    "closed_at": "2025-01-22T13:59:09Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/313",
    "body": "Refactor `evaluate_augassign` and test all operators.\r\n\r\nThis PR refactors the code (by making it simpler and equivalent) introduced by:\r\n- #285",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/313/comments",
    "author": "albertvillanova",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-22T13:54:40Z",
        "body": "THank you @albertvillanova !"
      }
    ]
  },
  {
    "number": 308,
    "title": "Minor fix: adding a 60 seconds timeout to the visit webpage tool",
    "created_at": "2025-01-22T08:48:04Z",
    "closed_at": "2025-01-22T12:02:38Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/308",
    "body": "Some site may be unresponsive and leave the agent hanging for a while. Adding a 60 seconds time cutoff for the request to url to conclude in the visit_webpage tool",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/308/comments",
    "author": "Killian-pit",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-22T10:24:04Z",
        "body": "Do you think 60 seconds is really needed? Could it be something more like 10seconds? (no strong opinion here, just wondering if we're not wasting time in some cases)"
      },
      {
        "user": "Killian-pit",
        "created_at": "2025-01-22T10:28:25Z",
        "body": "No strong opinion either @aymeric-roucher :) 60 seconds sounded like an okay p999 to get a response. Just noticed this morning that my script was stuck after a a few minutes only "
      },
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-22T11:34:03Z",
        "body": "Ok, so let's make it 20 for now and we'll see later if it needs increasing!"
      }
    ]
  },
  {
    "number": 307,
    "title": "In smolagents1.4.1",
    "created_at": "2025-01-22T08:06:29Z",
    "closed_at": "2025-02-18T18:49:49Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/issues/307",
    "body": "ImportError: cannot import name 'define_import_structure' from 'transformers.utils.import_utils'",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/307/comments",
    "author": "KWLShadow",
    "comments": [
      {
        "user": "albertvillanova",
        "created_at": "2025-01-22T08:26:55Z",
        "body": "Hi, @KWLShadow. We do not have that import in the code. Are you sure you are using smolagents-1.4.1?\n\nYou can check, e.g. with `pip list."
      }
    ]
  },
  {
    "number": 303,
    "title": "minor fix for console in AgentLogger",
    "created_at": "2025-01-22T01:19:16Z",
    "closed_at": "2025-01-22T09:41:05Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/303",
    "body": "if this isn't correct, just close the PR.\r\n\r\n@aymeric-roucher ",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/303/comments",
    "author": "nbroad1881",
    "comments": [
      {
        "user": "nbroad1881",
        "created_at": "2025-01-22T01:25:19Z",
        "body": "since a lot of tests are failing, I guess `self.console` is wrong ðŸ˜… "
      },
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-22T09:34:03Z",
        "body": "The failing test was trying to grab console logs from the main console object, from which your proposed PR reroutes the logs away, so it wasn't grabbing its target logs anymore. Now I fixed this test to correctly listen to the agent's logs under `agent.logger.console`!"
      }
    ]
  },
  {
    "number": 299,
    "title": "Local interpreter security: prevent builtins functions from being used if they have not been added as tools",
    "created_at": "2025-01-21T18:46:19Z",
    "closed_at": "2025-01-22T11:28:18Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/299",
    "body": "#274  blocked eval, compile and exec from being invoked through the ```__self__```attribute, but there are several other functions in ```builtins``` that may be dangerous (for instance ```breakpoint```, ```open```, ```__import__```). This PR would prevent any ```builtins``` function from being invoked if it has not been explicitely added as a tool.",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/299/comments",
    "author": "tandiapa",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-22T11:28:25Z",
        "body": "thank you @tandiapa !"
      }
    ]
  },
  {
    "number": 297,
    "title": "Move torchvision to the torch extra",
    "created_at": "2025-01-21T16:43:22Z",
    "closed_at": "2025-01-24T13:31:10Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/297",
    "body": "With `torchvision` being made a requirement, installing `smolagents` doesn't feel like installing something \"smol\". `torch` is an extra and `torchvision` should be put there too.",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/297/comments",
    "author": "nonsleepr",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-24T13:21:25Z",
        "body": "Update on this: I managed to reproduce the issue.\r\nIPython was pointing to a faulty environment .pyenv/shims/ipython on which the transformers version is broken : but with a correct venv the issue does not seem to happen anymore. So we're good with removing torchvision from base dependencies!"
      },
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-24T13:21:51Z",
        "body": "Thank you @albertvillanova @nonsleepr for monitoring this, we can merge this!"
      }
    ]
  },
  {
    "number": 293,
    "title": "Multiple tool example",
    "created_at": "2025-01-21T10:39:19Z",
    "closed_at": "2025-01-23T07:55:03Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/293",
    "body": "An Example for calling multiple tools in ToolCallingAgent ",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/293/comments",
    "author": "touseefahmed96",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-21T12:59:14Z",
        "body": "Thank you @touseefahmed96, nice addition! Could you also add a commented out builder to make a CodeAgent instead, in order to emphasize that the two can be switched out easily?"
      },
      {
        "user": "touseefahmed96",
        "created_at": "2025-01-21T13:07:49Z",
        "body": "@aymeric-roucher I also added the CodeAgent and commented it. Also i have tested the code."
      },
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-21T15:56:14Z",
        "body": "Amazing @touseefahmed96 , LGTM ðŸš€ "
      },
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-22T11:02:57Z",
        "body": "@touseefahmed96 there's still a quality issue to change on the code! Also FYI later I'm going to remove the tool_calling in this example's name and set CodeAgent as the main example (we want to emphasize support of CodeAgent over ToolCallingAgent)"
      },
      {
        "user": "touseefahmed96",
        "created_at": "2025-01-22T13:24:29Z",
        "body": "> @touseefahmed96 there's still a quality issue to change on the code! Also FYI later I'm going to remove the tool_calling in this example's name and set CodeAgent as the main example (we want to emphasize support of CodeAgent over ToolCallingAgent)\r\n\r\n@aymeric-roucher What should i do to fix the quality issue on the code and do you want me to set the default agent to CodeAgent and comment the ToolCallingAgent?"
      },
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-22T13:55:46Z",
        "body": "@touseefahmed96 for the quality of code, run `ruff check examples --fix` and `ruff format examples`\r\nFor your second question, yes please!"
      },
      {
        "user": "touseefahmed96",
        "created_at": "2025-01-23T05:55:05Z",
        "body": "@aymeric-roucher Fixed the quality issue and now default agent is CodeAgent"
      },
      {
        "user": "albertvillanova",
        "created_at": "2025-01-23T07:44:08Z",
        "body": "For future contributions, you can fix quality issues just running:\r\n```shell\r\nmake style\r\n```"
      }
    ]
  },
  {
    "number": 286,
    "title": "Fix CI quality",
    "created_at": "2025-01-21T06:28:50Z",
    "closed_at": "2025-01-21T09:40:15Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/286",
    "body": "Fix CI quality issue introduced in:\r\n- #274",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/286/comments",
    "author": "albertvillanova",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-21T09:40:22Z",
        "body": "Thank you @albertvillanova !"
      }
    ]
  },
  {
    "number": 283,
    "title": "Update building_good_agents.md",
    "created_at": "2025-01-20T20:48:36Z",
    "closed_at": "2025-01-21T10:03:52Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/283",
    "body": "Look's like this is a typo. Two tools are initialized (image_generation_tool & search_tool) but only one (search_tool) is set in the tool array for the agent to access.",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/283/comments",
    "author": "derekalia",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-21T10:04:01Z",
        "body": "Thank you @derekalia !"
      }
    ]
  },
  {
    "number": 281,
    "title": "Fix: source code inspection in interactive shells",
    "created_at": "2025-01-20T19:41:42Z",
    "closed_at": "2025-01-22T12:43:17Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/281",
    "body": "Hi ðŸ‘‹ This is my first contribution to smolagents, hope this helps!\r\n\r\nThis PR fixes source code inspection in interactive shells (IPython, Jupyter). Currently, using smolagents in these environments results in an `OSError` when `inspect.getsource` tries to find a source file that doesn't exist in interactive sessions.\r\n\r\nThe solution:\r\n- Get code from current shell session\r\n- Parse it using `ast`\r\n- Walk through to find matching class/function definitions\r\n\r\nFixes #250 by @MoritzLaurer\r\n\r\nChanges:\r\n- Added source code extraction from IPython shells\r\n- Added unit tests\r\n- Added `ipython` as test dependency\r\n- Nit: clean the source code as well (dedent & strip)\r\n\r\nTested in ipython & jupyter lab environments, as well as using a standard python invocation.\r\nTests & Lint seem to pass as well.\r\n\r\nI'd be happy to add end-to-end tests if desired!\r\n\r\nThanks for your time and review! ðŸ™",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/281/comments",
    "author": "antoinejeannot",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-21T10:48:06Z",
        "body": "Thanks a lot @antoinejeannot, this is amazing! \r\nI think it would be interesting to have e2e test for tool definition + getting source code + saving tool in an IPython environment, do you think you could do that? ðŸ™  Else, we can also merge as is."
      },
      {
        "user": "antoinejeannot",
        "created_at": "2025-01-21T11:48:29Z",
        "body": "Thanks @aymeric-roucher ðŸ™  \r\nSure ! Would you prefer I create a separate `tests/e2e/` folder for end-to-end tests, or do you have a different structure in mind?"
      },
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-21T12:43:25Z",
        "body": "@antoinejeannot for now this can go under tests/test_utils along with your existing tests!"
      },
      {
        "user": "antoinejeannot",
        "created_at": "2025-01-21T21:35:10Z",
        "body": "PTAL @aymeric-roucher "
      },
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-22T10:05:46Z",
        "body": "@antoinejeannot take a look at the failing tests: they are cause by a discrepancy in list sorting (probably a diff between the testing system and yours), you should probably test as a set or sort the list prior to the assert."
      },
      {
        "user": "antoinejeannot",
        "created_at": "2025-01-22T11:28:33Z",
        "body": "Thanks for your review @aymeric-roucher @albertvillanova this should work now!"
      }
    ]
  },
  {
    "number": 279,
    "title": "Added Hindi docs for smolagents",
    "created_at": "2025-01-20T18:12:46Z",
    "closed_at": "2025-01-20T18:30:31Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/279",
    "body": "This pull request adds Hindi translations for the project documentation.\r\nPlease review the changes and let me know if any further improvements or corrections are needed.\r\nNo one specifically asked for this, but I thought it would be a valuable addition to improve accessibility and provide non-English speakers.\r\n\r\n",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/279/comments",
    "author": "keetrap",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-20T18:28:31Z",
        "body": "Thank you @keetrap , this is an amazing contribution! ðŸš€ "
      }
    ]
  },
  {
    "number": 278,
    "title": "the most basic steps throws a circular import error",
    "created_at": "2025-01-20T16:53:45Z",
    "closed_at": "2025-01-21T12:58:19Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/issues/278",
    "body": "\nImportError: cannot import name 'CodeAgent' from partially initialized module 'smolagents' (most likely due to a circular import) \n\n\n```\nbogdanripa@mac smolagents % python3.12 -m venv env \nbogdanripa@mac smolagents % source env/bin/activate   \n(env) bogdanripa@mac smolagents % pip3.12 install smolagents\n(env) bogdanripa@mac smolagents % pip3.12 show smolagents\n\n> Name: smolagents\n> Version: 1.4.1\n> Summary: ðŸ¤— smolagents: a barebones library for agents. Agents write python code to call tools or orchestrate other agents.\n> Home-page: \n> Author: Thomas Wolf\n> Author-email: Aymeric Roucher <aymeric@hf.co>\n> License: \n> Location: /Users/bogdanripa/git/agents/smolagents/env/lib/python3.12/site-packages\n> Requires: duckduckgo-search, e2b-code-interpreter, gradio, jinja2, markdownify, pandas, pillow, python-dotenv, requests, rich, torchvision, transformers\n> Required-by: \n\n(env) bogdanripa@mac smolagents % vi code.py                \n(env) bogdanripa@mac smolagents % python3.12 code.py\n\nImportError: cannot import name 'CodeAgent' from partially initialized module 'smolagents' (most likely due to a circular import) (/Users/bogdanripa/git/agents/smolagents/env/lib/python3.12/site-packages/smolagents/__init__.py)\n```\n\n",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/278/comments",
    "author": "bogdanripa",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-20T18:16:51Z",
        "body": "I didn't get this issue, maybe it's an installation error: could you try uninstalling and reinstalling?"
      },
      {
        "user": "touseefahmed96",
        "created_at": "2025-01-21T07:32:02Z",
        "body": "Can you share the `code.py` file"
      },
      {
        "user": "bogdanripa",
        "created_at": "2025-01-21T09:45:40Z",
        "body": "```\nfrom smolagents import CodeAgent, DuckDuckGoSearchTool, HfApiModel\n\nagent = CodeAgent(tools=[DuckDuckGoSearchTool()], model=HfApiModel())\n\nagent.run(\"How many seconds would it take for a leopard at full speed to run through Pont des Arts?\")\n\n```"
      },
      {
        "user": "bogdanripa",
        "created_at": "2025-01-21T09:46:36Z",
        "body": "Update: I had to completely cleanup my python installation and reinstall everything from scratch and then it worked"
      },
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-21T12:58:19Z",
        "body": "Thank you for checking into this @bogdanripa , closing the issue!"
      }
    ]
  },
  {
    "number": 274,
    "title": "The use of BASE_PYTHON_TOOLS enables the use of compile, exec and eval",
    "created_at": "2025-01-20T13:40:17Z",
    "closed_at": "2025-01-20T16:06:47Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/274",
    "body": "Some builtins functions contain an attribute (```__self__```) that refers to the builtins module itself. It can then be used in order to invoke compile and exec in order to execute arbitrary code. ",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/274/comments",
    "author": "tandiapa",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-20T16:04:31Z",
        "body": "Thank tou @tandiapa, nice find! ðŸ¤— "
      }
    ]
  },
  {
    "number": 273,
    "title": "Remove unused and undocumented `test_mode` parameter",
    "created_at": "2025-01-20T09:01:43Z",
    "closed_at": "2025-01-20T09:45:56Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/273",
    "body": "This `test_mode` parameter seems more of a legacy parameter from the `transformers` codebase. Removing it is a breaking change but I do think that removing it quickly is for the best (I doubt it's being used anywhere). ",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/273/comments",
    "author": "Wauplin",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-20T09:46:10Z",
        "body": "Indeed thi is legacy and not used anymore, let's remove it!"
      }
    ]
  },
  {
    "number": 272,
    "title": "Fix CI quality issue",
    "created_at": "2025-01-20T08:02:46Z",
    "closed_at": "2025-01-20T08:49:20Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/272",
    "body": "Fix CI quality issue.",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/272/comments",
    "author": "albertvillanova",
    "comments": [
      {
        "user": "Wauplin",
        "created_at": "2025-01-20T08:49:49Z",
        "body": "(sorry I merged without being a maintainer just because I needed it in another PR)"
      }
    ]
  },
  {
    "number": 270,
    "title": "Adding duration, step number, token counts, and nested structure to gradio UI",
    "created_at": "2025-01-19T09:30:38Z",
    "closed_at": "2025-01-28T08:44:43Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/270",
    "body": "# New Feature: Enhanced Gradio Agent UI with Nested Thoughts and Step metrics\r\n\r\n## Motivation\r\nThe current Gradio UI for displaying agent outputs doesn't take full advantage of Gradio's new agentic UI features, which makes it harder to understand agent reasoning and track performance. Specifically:\r\n\r\n1. Tool calls and their results (execution logs, errors) are displayed as separate messages instead of being properly nested\r\n2. There's no clear display of time taken by each step\r\n3. Important metrics like token counts and step numbers are not visible\r\n\r\n## Feature Description\r\nThis PR enhances the Gradio UI to:\r\n\r\n1. Properly nest execution logs and errors under their parent tool calls using Gradio's parent_id metadata\r\n2. Display duration for each agent step/tool call\r\n3. Show step numbers and token counts for tracking\r\n4. add full height mode and share mode by default\r\n5. Improve overall readability of agent outputs\r\n\r\n## Layout Example\r\nBefore this PR, agent outputs looked like:\r\n```text\r\nðŸ› ï¸ Used tool python_interpreter\r\nCode execution failed...\r\n```\r\nAfter this PR, outputs are properly nested with metrics:\r\n```text\r\nðŸ› ï¸ Used tool python_interpreter (Step 3 | Input-tokens: 1,234 Output-tokens: 567) 1.6s\r\nâ””â”€ ðŸ“ Execution Logs\r\nâ””â”€ ðŸ’¥ Error (if any)\r\n```",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/270/comments",
    "author": "yvrjsharma",
    "comments": [
      {
        "user": "yvrjsharma",
        "created_at": "2025-01-21T18:39:30Z",
        "body": "Yes, looking into this now, thanks for pointing it out @albertvillanova \r\n> Please note there are some conflicts with the main branch that need to be addressed."
      },
      {
        "user": "yvrjsharma",
        "created_at": "2025-01-21T18:58:40Z",
        "body": "I observed that the latest code updates lack `input_token_count` and `output_token_count` in the `step_log`. Is my observation accurate, @aymeric-roucher? I'm a bit confused because I can still find the token counts in the generated logs, but they're absent in the ActionStepLog."
      },
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-28T08:44:10Z",
        "body": "Closing this PR since #384 merges it! thanks a lot @yvrjsharma !"
      }
    ]
  },
  {
    "number": 268,
    "title": "Fix Bug in from_langchain in tools.py",
    "created_at": "2025-01-18T21:38:42Z",
    "closed_at": "2025-01-20T09:50:03Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/268",
    "body": "The `from_langchain` Tool example in the docs failed, because the implementation in the `LangChainToolWrapper` class did not skip the input validation (as implemented for `SpaceToolWrapper` and `PipelineTool`), so depending on the actual langchain tool spec it would fail. \r\nThe langchain example in the \"Tools - in depth guide\" section currently yields:\r\n_Exception: Tool's 'forward' method should take 'self' as its first argument, then its next arguments should match the keys of tool attribute 'inputs'._\r\n\r\nAfter fixing this, the `LangChainToolWrapper` still failed because the `self.is_initialized` attribute was not set to `True` at the end of `__init__`. Also fixed. Should a from_langchain tool require longer loading of models etc, you could subclass it and implement a different behaviour in the `setup(self)` method. ",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/268/comments",
    "author": "RolandJAAI",
    "comments": [
      {
        "user": "RolandJAAI",
        "created_at": "2025-01-18T21:59:32Z",
        "body": "Added an addtional hint in the validation function where PipelineTool and SpaceToolWrapper were already mentioned as exceptions."
      },
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-20T09:49:54Z",
        "body": "Thank you @RolandJAAI !"
      }
    ]
  },
  {
    "number": 263,
    "title": "refactor: update model type to ChatMessage in agent classes",
    "created_at": "2025-01-18T10:17:42Z",
    "closed_at": "2025-01-18T17:27:49Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/263",
    "body": "Implementing an own Model class I noticed that the type annotations of the Agent constructors were not correct and consistent.\r\nThis PR makes the type annotations consistent with the new Model `__call__` signature across all Agent classes.",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/263/comments",
    "author": "jank",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-18T17:27:46Z",
        "body": "Thank you @jank !"
      }
    ]
  },
  {
    "number": 260,
    "title": "Fix code examples with additional_args and num_ctx examples also in zh docs",
    "created_at": "2025-01-18T07:10:02Z",
    "closed_at": "2025-01-18T18:09:50Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/260",
    "body": "Added the two previous bug fixes also to the zh docs.",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/260/comments",
    "author": "RolandJAAI",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-18T18:10:18Z",
        "body": "Thank you @RolandJAAI ! ðŸ˜ƒ "
      }
    ]
  },
  {
    "number": 255,
    "title": "Add linter rules + apply make style",
    "created_at": "2025-01-17T19:18:33Z",
    "closed_at": "2025-01-18T18:01:16Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/255",
    "body": "This PR adds some linter rules. Goal is to enforce better code standard at minimal cost thanks to ruff.\r\n\r\nSee `pyproject.toml` for details:\r\n\r\n```toml\r\n[tool.ruff]\r\nline-length = 119\r\nlint.ignore = [\r\n  \"F403\", # undefined-local-with-import-star\r\n  \"E501\", # line-too-long\r\n]\r\nlint.select = [\"E\", \"F\", \"I\", \"W\"]\r\n\r\n[tool.ruff.lint.per-file-ignores]\r\n\"examples/*\" = [\r\n  \"E402\", # module-import-not-at-top-of-file\r\n]\r\n\r\n[tool.ruff.lint.isort]\r\nknown-first-party = [\"smolagents\"]\r\nlines-after-imports = 2\r\n```\r\n\r\nThe rest of the PR is the result of applying `make style`.\r\nBest to merge this kind of PR rather quickly :) ",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/255/comments",
    "author": "Wauplin",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-18T18:01:27Z",
        "body": "Thanks a lot @Wauplin ! ðŸ¤— "
      }
    ]
  },
  {
    "number": 252,
    "title": "Set ollama context lenght in example to 8192 to make it work",
    "created_at": "2025-01-17T17:12:08Z",
    "closed_at": "2025-01-17T17:41:35Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/252",
    "body": "Make smolagents useable with ollama: The ollama default context length is 2048 which is way to little for tasks involving more than 1 step. Fails horribly and the CodingAgent tends to start calculating the age of the pope as a second step - if you haven't read the system prompts this will be a very weird experience ðŸ˜‚.\r\n\r\nAdding this important hint in the docs will help many people getting started with local agents.",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/252/comments",
    "author": "RolandJAAI",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-17T17:37:21Z",
        "body": "Thank you @RolandJAAI, and very nice link for VRAM calculation, I didn't know that Space!"
      }
    ]
  },
  {
    "number": 247,
    "title": "Remove dependency on _is_package_available from transformers",
    "created_at": "2025-01-17T15:10:40Z",
    "closed_at": "2025-01-17T17:38:33Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/247",
    "body": "Remove dependency on `_is_package_available` from `transformers`.\r\n\r\nI think it makes no sense to depend on the `transformers` library for this package management utility.",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/247/comments",
    "author": "albertvillanova",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-17T17:38:30Z",
        "body": "Thank you @albertvillanova ! In general 100% agree to regularize towards minimum external deps!"
      }
    ]
  },
  {
    "number": 234,
    "title": "Add resizeable option to Gradio UI component for better usabilty",
    "created_at": "2025-01-16T21:46:45Z",
    "closed_at": "2025-01-16T22:05:23Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/234",
    "body": "A small change with huge impact. Allows the user of the Chat UI to resize the chat box. This is especially helpful when the Agent creates long outputs and there is screen estate left.",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/234/comments",
    "author": "jank",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-16T22:05:26Z",
        "body": "Thank you @jank !"
      }
    ]
  },
  {
    "number": 233,
    "title": "Dead Link to Duck Duck Go search tool",
    "created_at": "2025-01-16T21:19:41Z",
    "closed_at": "2025-01-16T22:04:41Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/233",
    "body": "All default agents seem to have been moved to one and the same file now.\r\n\r\nI changed the English md file as well as the Chinese one. I included lines 151 to 176. Do we want to keep it that way or just reference the file since the lines might get changed often?\r\n\r\n\r\nAlso, I see there is a diff for line 199 for some reason. I didn't change it, but maybe it's due to new line formatting for different computers?",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/233/comments",
    "author": "matterattetatte",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-16T22:04:45Z",
        "body": "Thanks a lot @matterattetatte, well spotted! ðŸ¤— "
      }
    ]
  },
  {
    "number": 228,
    "title": "Docs Bug - fix tool example with additional args",
    "created_at": "2025-01-16T16:28:42Z",
    "closed_at": "2025-01-16T22:00:11Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/228",
    "body": "Love your work! I am going to fix a couple of bugs in the docs to get going, here is the first one ðŸ¤—\r\n\r\nThe current example for generating an image with an improved prompt fails with:\r\n\"TypeError: MultiStepAgent.run() got an unexpected keyword argument 'prompt'\" (both in 1.3.0 and the version before)\r\n\r\nSeems like the way to pass additional args was changed to use a dict with the name additional_args. Looked it up in the code, changed it accordingly, tested it, works. \r\nI have also included a hint to the additional_args option in the text and renamed 'prompt' to 'user_prompt' to make the example easier to understand.",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/228/comments",
    "author": "RolandJAAI",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-16T22:00:19Z",
        "body": "Thank you @RolandJAAI !"
      }
    ]
  },
  {
    "number": 227,
    "title": "refactor(models): restructure model parameter handling",
    "created_at": "2025-01-16T16:25:10Z",
    "closed_at": "2025-01-22T10:27:37Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/227",
    "body": "# Refactor Model Parameter Handling\r\n## Improvements\r\nThis refactoring implements the following enhancements:\r\n\r\n1. Introduce kwargs support in Model base class:\r\n   - Allow specifying default inference parameters during instantiation\r\n   - Set default values for common parameters (temperature=0.5, max_tokens=1500)\r\n2. Unify parameter handling mechanism:\r\n   - Use base class configuration as foundation\r\n   - Allow parameter overriding in call method\r\n3. Standardize parameter handling logic across all subclasses\r\n   - Standardize model response type conversion:\r\n   - Convert response objects from LiteLLMModel and OpenAIServerModel to ChatMessage type, ensuring consistent response format across all model implementations\r\n\r\n## Usage Example\r\n\r\n```python\r\n# Specify default parameters during instantiation\r\nmodel = HfApiModel(temperature=0.7, max_tokens=2000)\r\n\r\n# Use default parameters\r\nresponse1 = model(messages)\r\n\r\n# Temporarily override default parameters\r\nresponse2 = model(messages, max_tokens=1000)",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/227/comments",
    "author": "kingdomad",
    "comments": [
      {
        "user": "TimeLordRaps",
        "created_at": "2025-01-17T01:13:50Z",
        "body": "This might be a good time to mention other parameters specific to each, ones I'm thinking as useful would be load-in-4-bit for TransformersModels."
      },
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-20T16:29:24Z",
        "body": "Going to look into this @kingdomad, thank you for contributing! @TimeLordRaps see any other useful parameters that we should support in transformers?"
      },
      {
        "user": "kingdomad",
        "created_at": "2025-01-21T07:44:53Z",
        "body": "> Going to look into this @kingdomad, thank you for contributing! @TimeLordRaps see any other useful parameters that we should support in transformers?\r\n\r\nHi @aymeric-roucher \r\n\r\nI really hope you can merge my PR! Fun fact: I submitted it late at night in China, and right after that, I caught Influenza A. Spent three days in bed with a feverâ€”talk about committing to open source! ðŸ˜… So yeah, this PR literally cost me my health. No pressure though. ðŸ˜‰\r\n\r\nCheers!"
      },
      {
        "user": "kingdomad",
        "created_at": "2025-01-21T16:10:44Z",
        "body": "@aymeric-roucher I have merged the latest code. Please take another look and let me know if there are any issues."
      },
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-21T16:17:50Z",
        "body": "Just left another comment @kingdomad , then we'll be good to merge!"
      },
      {
        "user": "kingdomad",
        "created_at": "2025-01-22T02:05:40Z",
        "body": "Ok, I have already addressed it. @aymeric-roucher "
      },
      {
        "user": "kingdomad",
        "created_at": "2025-01-22T09:35:24Z",
        "body": "I have fixed the error, please try again. @aymeric-roucher "
      },
      {
        "user": "kingdomad",
        "created_at": "2025-01-22T10:09:40Z",
        "body": "I have reformatted the code using Ruff."
      },
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-22T10:28:03Z",
        "body": "Thanks a lot @kingdomad, thus will make `Model` classes much easier to use ! ðŸ¤— "
      }
    ]
  },
  {
    "number": 222,
    "title": "Allow passing kwargs to all models",
    "created_at": "2025-01-16T14:59:58Z",
    "closed_at": "2025-01-16T22:03:38Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/222",
    "body": null,
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/222/comments",
    "author": "aymeric-roucher",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-16T15:22:55Z",
        "body": "@Bilokin we could have 2 options to differentiate model init kwargs from generatio kwargs:\r\n\r\n1. Have users pass 2 dictionaries on init, one `init_kwargs` and one `generation_kwargs` (problem of this is that it wouldn't apply to most other Models, so the API is not very unified)\r\n2. (current implementation in the latest commit of this branch) support specific dedicated arguments for init, like `device_map` or others, then any other kwargs will be passed on generation.\r\nThus model initialization looks like:\r\n```\r\n        model = TransformersModel(\r\n            model_id=\"HuggingFaceTB/SmolLM2-135M-Instruct\",\r\n            max_new_tokens=5,\r\n            device_map=\"auto\",\r\n            do_sample=False,\r\n        )\r\n```\r\nBut inside the model device_maps is remapped to initialization because it was recognized such, while all others are remapped to generation.\r\n\r\nWhat do you think? cc @albertvillanova @Hellisotherpeople"
      },
      {
        "user": "Bilokin",
        "created_at": "2025-01-16T15:54:18Z",
        "body": "@aymeric-roucher, I want to run the model locally, so I need to pass `torch_dtype=\"auto\"`, or it doesn't fit on my GPU. \r\nSo, I think if  torch_dtype argument is passed to the init method in a similar way to `device` argument, it would work for me =)\r\n\r\nAnother solution here would be adding model and tokenizer as arguments, so people would have freedom to use their own ones, and then one can keep current `kwargs` for only for generation step."
      },
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-16T16:12:03Z",
        "body": "Just added torch_dtype!"
      },
      {
        "user": "Bilokin",
        "created_at": "2025-01-16T16:21:15Z",
        "body": "@aymeric-roucher, it works, thanks!"
      },
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-16T22:03:52Z",
        "body": "Thank you for your follow-up @Bilokin !"
      }
    ]
  },
  {
    "number": 219,
    "title": "Fix vanilla model answer in example benchmark",
    "created_at": "2025-01-16T10:49:36Z",
    "closed_at": "2025-01-16T11:04:41Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/219",
    "body": "Fix vanilla model answer in example benchmark, by returning `ChatMessage.content` instead of `ChatMessage`:\r\n- Return: `\"answer\": \"80\"`\r\n- Instead of: `\"answer\": \"ChatMessage(role='assistant', content='80', tool_calls=None)\"`",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/219/comments",
    "author": "albertvillanova",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-16T11:04:37Z",
        "body": "Merging this because failing tests are unrelated to this PR!"
      }
    ]
  },
  {
    "number": 209,
    "title": "Max length of \"print\" outputs as a parameter of an agent",
    "created_at": "2025-01-15T18:33:30Z",
    "closed_at": "2025-01-17T18:16:47Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/209",
    "body": "The default limit for print outputs is 50000 characters. In some use cases, this limit is too high, and it is causing high token counts and costs.\r\nThis PR proposes to make it a parameter of LocalPythonInterpreter and CodeAgent.\r\n\r\nMoreover, this PR contains 2 bug fixes to make it work properly:\r\n- Fixing incorrect `truncate_content` behavior\r\n- Deleting unused `truncate_print_outputs` function",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/209/comments",
    "author": "IlyaGusev",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-17T18:16:34Z",
        "body": "Thank you @IlyaGusev ! ðŸ¤— "
      }
    ]
  },
  {
    "number": 199,
    "title": "bug fix: fix string concatenation bug in GradioUI.log_user_message",
    "created_at": "2025-01-15T09:44:57Z",
    "closed_at": "2025-01-15T13:00:16Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/199",
    "body": "File: src/smolagents/gradio_ui.py\r\n\r\nBug impact:\r\nWhen no files are uploaded, the Gradio UI completely ignores user's text input\r\ndue to incorrect string concatenation precedence.\r\n\r\nChanges:\r\n- Add parentheses to ensure correct operator precedence in string concatenation\r\n- Fix text_input being ignored when file_uploads_log is empty",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/199/comments",
    "author": "kingdomad",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-15T13:00:23Z",
        "body": "Thanks a lot @kingdomad !"
      }
    ]
  },
  {
    "number": 198,
    "title": "Automatically Install litellm if not found",
    "created_at": "2025-01-15T08:33:25Z",
    "closed_at": "2025-01-15T11:13:03Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/198",
    "body": "#195 ",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/198/comments",
    "author": "touseefahmed96",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-15T11:12:55Z",
        "body": "Hello @touseefahmed96 ! I'm not a fan of silently installing a package: for instance people might prefer installing the package their own way using other stuff than pip. And they'd probably prefer to have a user validation before accepting!\r\nSo all in all I think the current state with an ImportError is the best practice we can have in that front!"
      }
    ]
  },
  {
    "number": 194,
    "title": "The call.func parameter type of the local_python_executor.evaluate_call function might be ast.Subscript ",
    "created_at": "2025-01-14T22:14:12Z",
    "closed_at": "2025-01-15T12:58:52Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/194",
    "body": "fix for #181.\r\nbtw:\r\n```python\r\n   elif name.id in custom_tools:\r\n        return custom_tools[name.id]\r\n ```\r\n to allow a list of objects, like : \r\n```python\r\ndef my_func():\r\n    do_smth()\r\nlist = [my_func, my_func] \r\n```\r\nNow we get the error: \r\n**The variable `my_func` is not defined.**",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/194/comments",
    "author": "nvrxq",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-15T12:59:13Z",
        "body": "Thank you @nvrxq !"
      }
    ]
  },
  {
    "number": 193,
    "title": "fix typo in building_good_agents.md",
    "created_at": "2025-01-14T20:42:01Z",
    "closed_at": "2025-01-15T17:04:54Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/193",
    "body": "function get_coordinates_from_location should be actually convert_location_to_coordinates",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/193/comments",
    "author": "rug",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-15T12:57:46Z",
        "body": "Why do you think the name `get_coordinates_from_location` is not good?"
      },
      {
        "user": "rug",
        "created_at": "2025-01-15T17:02:33Z",
        "body": "> Why do you think the name `get_coordinates_from_location` is not good?\r\n\r\nbecause some rows below that function is meant to be called, but instead it is called 'convert_location_to_coordinates' . So one of the two is right and the other is wrong. Since in the subsequent example on the same page the function 'convert_location_to_coordinates' is called again, I supposed that this is the right name (by majority vote, in some sense.)"
      },
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-15T17:04:00Z",
        "body": "Oh ok, I see your point! Thank you for proposing this!"
      }
    ]
  },
  {
    "number": 189,
    "title": "Implemented support for ast.Pass in the interpeter.",
    "created_at": "2025-01-14T15:49:43Z",
    "closed_at": "2025-01-14T16:21:39Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/189",
    "body": "Fixes #162 ",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/189/comments",
    "author": "AngeloKiriakoulis",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-14T16:21:48Z",
        "body": "Thanks a lot @AngeloKiriakoulis ! ðŸ¤— "
      }
    ]
  },
  {
    "number": 186,
    "title": "Make default tools more robust",
    "created_at": "2025-01-14T13:55:27Z",
    "closed_at": "2025-01-14T13:57:11Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/186",
    "body": null,
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/186/comments",
    "author": "aymeric-roucher",
    "comments": [
      {
        "user": "elsolo5000-2",
        "created_at": "2025-01-14T20:26:31Z",
        "body": "bonjour.\r\nj ai eu des soucis avec des tool calls non conformes (litellm ollama_chat), j ai utilisÃ© les def dans utils pour dÃ©buguer. j ai mis le code dans modeles.py.\r\ncela dit je ne sais pas vraiment s il y a quelque chose de prÃ©vu pour placer ce code. ni s il y a un certain process a instaurer pour l avenir."
      }
    ]
  },
  {
    "number": 181,
    "title": "The call.func parameter type of the local_python_executor.evaluate_call function might be ast.Subscript",
    "created_at": "2025-01-14T01:42:55Z",
    "closed_at": "2025-01-20T16:20:40Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/issues/181",
    "body": "Hi\nWhile testing Python code execution, I discovered an issue where the call.func parameter type could potentially be ast.Subscript.\nPlease consider supporting this case.",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/181/comments",
    "author": "gitssie",
    "comments": [
      {
        "user": "nvrxq",
        "created_at": "2025-01-14T22:20:07Z",
        "body": "I think the PR would be good for this, also I fixed a list of function.  #194"
      },
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-20T16:20:40Z",
        "body": "#194 should have fixed this, closing this issue!"
      }
    ]
  },
  {
    "number": 179,
    "title": "bugfix: Fix plan_update message display",
    "created_at": "2025-01-13T21:56:44Z",
    "closed_at": "2025-01-14T08:58:45Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/179",
    "body": "The updated plan was saved as a Message instead of str, like this:\r\n\r\n```\r\nHere is my new/updated plan of action to solve the task:\r\n\\```\r\nMessage(content='...', role='assistant', tool_calls=None, function_call=None)\r\n\\```\r\n```\r\n\r\nThis PR fixes this, saving only content. Also it is consistent now with other variables in the same function.",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/179/comments",
    "author": "IlyaGusev",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-14T08:58:42Z",
        "body": "THanks a lot @IlyaGusev !"
      }
    ]
  },
  {
    "number": 173,
    "title": "Fix minor docs",
    "created_at": "2025-01-13T13:59:24Z",
    "closed_at": "2025-01-13T15:31:36Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/173",
    "body": null,
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/173/comments",
    "author": "duydl",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-13T15:31:31Z",
        "body": "LGTM, thanks a lot @duydl !"
      }
    ]
  },
  {
    "number": 165,
    "title": "Bug fixes on TransformersModel",
    "created_at": "2025-01-12T19:39:26Z",
    "closed_at": "2025-01-13T15:20:46Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/165",
    "body": "### Problem Description\r\n\r\nThe current code uses `json.load(output)` to parse the output string for extracting `tool_name` and `tool_arguments`. However, `json.load` is designed to read JSON data from a file-like object (e.g., an open file or a similar object with a .read() method). Passing a string directly to `json.load` results in the error:\r\n\r\n```bash\r\nError in generating tool call with model:\r\n'str' object has no attribute 'read'.\r\n```\r\n\r\nAdditionally, even if the correct function `json.loads(output)` were used, output string includes `Action:` before the JSON payload, which makes the string invalid JSON. The json.loads function requires the input string to be a clean JSON document, and `Action:` at the start causes an additional problem.\r\n\r\n### Solution Implemented\r\n\r\n- Preprocessed `output` to extract the JSON portion.\r\n- Replaced `json.load(output)` with `json.loads(output)` for correct parsing.\r\n```python\r\nif \"Action:\" in output:\r\n   output = output.split(\"Action:\", 1)[1].strip()\r\nparsed_output = json.loads(output)\r\ntool_name = parsed_output.get(\"tool_name\")\r\ntool_arguments = parsed_output.get(\"tool_arguments\")\r\n```\r\n\r\n### Additional Fixes\r\n- Changed the return type of `TransformersModel` from `str` to `ChatCompletionOutputMessage`, which aligns with the actual return value of the class, when called.\r\n- Adjusted the `model` and `model_id` declarations, ensuring that the error handling reflects the correct model ID variable `(HuggingFaceTB/SmolLM2-1.7B-Instruct\")`, when it defaults.\r\n\r\nThis is my first ever project Iâ€™m contributing to, and I just want to express my gratitude to the maintainers and contributors for all the hard work. Your dedication to the project is inspiring, and Iâ€™m grateful for the opportunity to contribute. Thank you for your time and effort! ðŸ™",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/165/comments",
    "author": "AngeloKiriakoulis",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-13T15:20:20Z",
        "body": "Thank you @AngeloKiriakoulis , these are great changes!"
      }
    ]
  },
  {
    "number": 164,
    "title": "Fix wrong return value in agents.md doc",
    "created_at": "2025-01-12T17:54:09Z",
    "closed_at": "2025-01-13T15:21:51Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/164",
    "body": "custom_model should return an object that has a .content attribute (not a str)",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/164/comments",
    "author": "sidtuladhar",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-13T15:21:38Z",
        "body": "Thank you @sidtuladhar, this imprecision is due to my recent refacto of the `__call__` method, it's a great spot that this part was broken!"
      }
    ]
  },
  {
    "number": 162,
    "title": "Feature Request: Add support for ast.Pass in the interpreter",
    "created_at": "2025-01-12T13:50:55Z",
    "closed_at": "2025-01-14T16:21:40Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/issues/162",
    "body": "I suggest including support for ast.Pass in the interpreter. Since pass is a no-op in Python, this could be implemented simply as return None. Thank you for creating such a great module!",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/162/comments",
    "author": "jakobmwang",
    "comments": [
      {
        "user": "nvrxq",
        "created_at": "2025-01-13T22:26:23Z",
        "body": "Hi,\nDoes it need to be added? Is issue active?"
      },
      {
        "user": "jakobmwang",
        "created_at": "2025-01-14T15:44:18Z",
        "body": "Hi, thanks for the response! I had an agent develop functions for information extraction, and on every run it wasted at least one step on a try > except > pass, regardless of model. I monkey patched it, but I thought others might encounter the same."
      },
      {
        "user": "AngeloKiriakoulis",
        "created_at": "2025-01-14T15:50:24Z",
        "body": "Hope this helps!"
      }
    ]
  },
  {
    "number": 161,
    "title": "Implement AzureOpenAIServerModel",
    "created_at": "2025-01-12T08:55:33Z",
    "closed_at": "2025-01-22T11:26:06Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/161",
    "body": "This PR implements the Azure OpenAI model. ",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/161/comments",
    "author": "kylehuan",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-12T14:01:34Z",
        "body": "Hello @kylehuan , thank you for the proposition!\r\nI prefer to keep the current Models as there are, except if there's a specific need : can you not use OpenAI on Azure either via `LiteLLMModel` or via `OpenAIServerModel` ?"
      },
      {
        "user": "kylehuan",
        "created_at": "2025-01-18T23:46:46Z",
        "body": "@aymeric-roucher, \r\nOpenAIServerModoel doesn't work with the OpenAI model that is hosting with Azure. I have to make this change to use Azure explicitly. "
      },
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-22T11:26:06Z",
        "body": "This is solved by @vladiliescu in #276 !"
      }
    ]
  },
  {
    "number": 160,
    "title": "Fix tool_calls parsing error in `ToolCallingAgent` when using `OpenAIServerModel`",
    "created_at": "2025-01-11T21:40:31Z",
    "closed_at": "2025-01-13T16:24:18Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/160",
    "body": "Related to issue #158",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/160/comments",
    "author": "tanhuajie",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-13T16:24:20Z",
        "body": "Thanks a lot @tanhuajie ! Nice straightforward fix. ðŸ‘ "
      }
    ]
  },
  {
    "number": 155,
    "title": "Fix typo in comment",
    "created_at": "2025-01-11T10:08:06Z",
    "closed_at": "2025-01-12T14:33:29Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/155",
    "body": "Fix typo in comment, thank you very much.",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/155/comments",
    "author": "chloefeal",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-12T14:32:50Z",
        "body": "Approved! Thank you @chloefeal ! ðŸ¤— "
      }
    ]
  },
  {
    "number": 152,
    "title": "å¯ä»¥åšäº›æ’ä»¶å’Œdjangoå¯¹æŽ¥å—",
    "created_at": "2025-01-11T04:13:03Z",
    "closed_at": "2025-02-07T13:55:28Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/issues/152",
    "body": null,
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/152/comments",
    "author": "tyyykw",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-13T16:47:40Z",
        "body": "Couod you precise what you mean?"
      }
    ]
  },
  {
    "number": 151,
    "title": "Bug fix for 0.1.2 where ImportError \"soundfile\" is raised when agent reaches max_steps.",
    "created_at": "2025-01-11T00:00:20Z",
    "closed_at": "2025-01-30T12:41:00Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/151",
    "body": "With v1.2.0, a bug got introduced to the code in wich the below error is raised when the agent is reaching max_steps. \r\n\r\n`Traceback (most recent call last):\r\n  File \"/home/azureuser/smolagents/examples/tool_calling_agent_from_any_llm.py\", line 26, in <module>\r\n    print(agent.run(\"What's the weather like in Paris?\"))\r\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/azureuser/smolagents/src/smolagents/agents.py\", line 514, in run\r\n    return self.direct_run(self.task)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/azureuser/smolagents/src/smolagents/agents.py\", line 623, in direct_run\r\n    return handle_agent_output_types(final_answer)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/azureuser/smolagents/src/smolagents/types.py\", line 280, in handle_agent_output_types\r\n    return _v(output)\r\n           ^^^^^^^^^^\r\n  File \"/home/azureuser/smolagents/src/smolagents/types.py\", line 193, in __init__\r\n    raise ImportError(\"soundfile must be installed in order to handle audio.\")\r\nImportError: soundfile must be installed in order to handle audio.`\r\n\r\n\r\nThe problem is that in `provide_final_answer()` a Message object is returned instead of a str. This is handled as Audio type by `handle_agent_output_types`.\r\n\r\nI fixed it by editing `provide_final_answer()` to return the same format as the `final_answer` tool.",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/151/comments",
    "author": "benediktstroebl",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-30T12:41:00Z",
        "body": "Closing since a fix is on main, thank you for proposing this fix @benediktstroebl ! ðŸ¤— "
      }
    ]
  },
  {
    "number": 144,
    "title": "Portkey AI Gateway Support",
    "created_at": "2025-01-10T09:53:27Z",
    "closed_at": "2025-01-10T11:32:27Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/144",
    "body": "# Add PortkeyAI Gateway Support\r\n\r\nFixes #143 Closes #143\r\n\r\n## Overview\r\nAdding support for Portkey's AI Gateway to simplify access to Hugging Face models deployed across different platforms (Vertex AI, Bedrock, self-hosted Ollama, inference endpoints) through a single interface. While focusing on HF model deployments, it also supports other LLM providers similar to our existing LiteLLM integration.\r\n\r\n## Why?\r\n* Streamlines access to Hugging Face models across deployment platforms\r\n* Provides monitoring and automatic fallbacks between deployments\r\n* Simplifies model routing and management through a single API\r\n* Complements existing model access options in smolagents\r\n\r\nDocumentation\r\n* Added Portkey to guided-tour docs with usage examples",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/144/comments",
    "author": "siddharthsambharia-portkey",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-10T11:32:27Z",
        "body": "Hello @siddharthsambharia-portkey ,\r\nI prefer not to add any new multi-model gateway for now! We went for LiteLLM, it's satisfactory, we might change in the future if not but for now let's stick with LiteLLM!"
      }
    ]
  },
  {
    "number": 140,
    "title": "Fix several typos in docs.",
    "created_at": "2025-01-10T02:51:30Z",
    "closed_at": "2025-01-10T12:00:24Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/140",
    "body": "Love this minimalist agent framework! \r\nI am building some interesting agents on this. Starting my first contribution from typos, but it won't be the last contribution!",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/140/comments",
    "author": "Symbolk",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-10T12:00:19Z",
        "body": "LGTM! Thank you @Symbolk !"
      }
    ]
  },
  {
    "number": 139,
    "title": "feat: Add multi-GPU support for TransformersModel",
    "created_at": "2025-01-10T02:00:00Z",
    "closed_at": "2025-01-14T09:00:08Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/139",
    "body": "**Summary**:\r\nPreviously, in the `TransformersModel` class of smolagents, the model was allocated to a device using `.to(device)`, which limited usage to only one CUDA card. This commit addresses that limitation by introducing the option to use `device_map='auto'` for better utilization of multiple GPUs.\r\n\r\n**Problem Addressed**:\r\n- **Limited GPU Utilization**: smolagents could only use a single CUDA device before, restricting performance for large models that could benefit from parallel processing across multiple GPUs. For instance, running large language models for text generation tasks was slower than it could be with multiple GPUs.\r\n- **Lack of Scalability**: As model sizes and task complexity grew, the existing `.to(device)` method didn't offer the necessary scalability. Additionally, an `OutOfMemoryError` was encountered when working with a single GPU (cuda:0) as memory was exhausted despite available additional CUDA resources.\r\n\r\n**Solution Implemented**:\r\n- **Added `device_map='auto'` Option**: In the `TransformersModel` class during model initialization, the code now allows for using `device_map='auto'` instead of just `.to(device)`. This enables the model to automatically distribute across available GPUs, as demonstrated by the updated code snippet:\r\n```python\r\ntry:\r\n    self.model = AutoModelForCausalLM.from_pretrained(model_id, device_map=\"auto\")\r\nexcept Exception as e:\r\n    # Handle the exception as before\r\n    pass\r\n```\r\n- **User Configuration**: Created a way for users to configure this option easily, either through a configuration file or an additional parameter when initializing relevant smolagents classes.\r\n\r\n**Benefits**:\r\n- **Performance Improvement**: Multiple GPU usage will enhance the inference speed of smolagents' models, resulting in faster response times for computationally intensive tasks.\r\n- **Scalability**: Makes smolagents more suitable for large-scale projects and research where scaling computing resources is vital.\r\n\r\nCloses #117",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/139/comments",
    "author": "6643789wsx",
    "comments": [
      {
        "user": "Hellisotherpeople",
        "created_at": "2025-01-13T16:59:14Z",
        "body": "Should also add flash attention 2. Really boneheaded that this isn't all just kwargs "
      },
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-14T08:59:46Z",
        "body": "Thank you @6643789wsx! @Hellisotherpeople don't hesitate to open a PR with your proposed changes!"
      }
    ]
  },
  {
    "number": 138,
    "title": "Add option to upload files to GradioUI",
    "created_at": "2025-01-09T22:24:12Z",
    "closed_at": "2025-01-13T15:33:45Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/138",
    "body": "Added the option to upload files to the GradioUI by passing in the `UPLOAD_FOLDER` parameter. Also added some checks for path traversal or arbitrary file uploads and a quick example showing the upload button exists. Up to the user to implement a tool to search through the files :). ",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/138/comments",
    "author": "stackviolator",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-12T14:19:56Z",
        "body": "@stackviolator seems like a great idea! Could we rename the `UPLOAD_FOLDER` to something in lowercase, and maybe make it `file_upload_folder` to make it clearer?"
      },
      {
        "user": "stackviolator",
        "created_at": "2025-01-13T02:42:36Z",
        "body": "Sure! Just changed the param"
      },
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-13T15:33:51Z",
        "body": "Thank you @stackviolator , great addition! ðŸ˜ƒ "
      }
    ]
  },
  {
    "number": 135,
    "title": "High Impact Security Issue - RCE vulnerability: server.py is inherently insecure and unsafe",
    "created_at": "2025-01-09T21:52:07Z",
    "closed_at": "2025-01-09T22:33:09Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/issues/135",
    "body": "Hello, I was looking at the code and noticed a giant security hole.\r\n\r\nserver.py line 29\r\n```\r\ndef start_server(host='0.0.0.0', port=65432):\r\n```\r\n\r\nThis is binding by default to all interfaces and allows any remote party that can connect to port 65432 to execute arbitrary python code from anywhere on the internet without restrictions.\r\n\r\nTo fix this, the host value should be set to localhost \"127.0.0.1\" by default and if connections from the outside world are needed at all then there should be an IP whitelist perhaps as a parameter. Also make sure to manage this in your local firewall for the time being and block outside connections.\r\n\r\nI have a code fix PR in mind that I will likely submit once I understand why this file exists at all. I'm still trying to get a handle on the design of this library.,",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/135/comments",
    "author": "devlux76",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-09T22:33:09Z",
        "body": "Thank you for reporting @devlux76 ! I've deleted the file. This is due to a past project of adding a Docker interpreter that we will finish in the upcoming weeks. Cc @ErikKaum "
      },
      {
        "user": "albertvillanova",
        "created_at": "2025-02-03T09:55:02Z",
        "body": "Closing commit: 36ed279c85347936f1170b814d5fa7464e7cf3ef"
      }
    ]
  },
  {
    "number": 125,
    "title": "Unable to import smolagents on my local jupyter",
    "created_at": "2025-01-08T20:04:58Z",
    "closed_at": "2025-01-09T22:45:03Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/issues/125",
    "body": "Code:\r\n```\r\n!pip install smolagents\r\nfrom smolagents import CodeAgent, DuckDuckGoSearchTool, HfApiModel\r\n\r\nagent = CodeAgent(tools=[DuckDuckGoSearchTool()], model=HfApiModel())\r\n\r\nagent.run(\"How many seconds would it take for a leopard at full speed to run through Pont des Arts?\")\r\n\r\n```\r\nOuput:\r\n```\r\nModuleNotFoundError                       Traceback (most recent call last)\r\nInput In [6], in <cell line: 2>()\r\n      1 get_ipython().system('pip install smolagents')\r\n----> 2 from smolagents import CodeAgent, DuckDuckGoSearchTool, HfApiModel\r\n      4 agent = CodeAgent(tools=[DuckDuckGoSearchTool()], model=HfApiModel())\r\n      6 agent.run(\"How many seconds would it take for a leopard at full speed to run through Pont des Arts?\")\r\n\r\nModuleNotFoundError: No module named 'smolagents'\r\n```\r\n\r\nEnvironment: \r\nHardware: Macos(Intel based)\r\nPython 3.9.13\r\nJupyter notebook",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/125/comments",
    "author": "sudo-supreme",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-09T22:45:03Z",
        "body": "I think you should check that the package is correctly installed using `pip freeze | grep smolagents`\r\n\r\nThis is most probably due to your jupyter kernel not targeting the right venv."
      }
    ]
  },
  {
    "number": 120,
    "title": "Exclude examples from Ruff pre-commit hooks",
    "created_at": "2025-01-08T15:27:43Z",
    "closed_at": "2025-02-18T10:11:55Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/issues/120",
    "body": "Ruff pre-commit hooks raise errors for files located in the examples/ directory. It would be helpful to exclude examples/ from ruff to avoid unnecessary errors and enhance flexibility in examples/ .",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/120/comments",
    "author": "huguesva",
    "comments": [
      {
        "user": "albertvillanova",
        "created_at": "2025-02-18T10:11:55Z",
        "body": "Closing, see related discussion in #452."
      }
    ]
  },
  {
    "number": 110,
    "title": "Using E2B with Tool Class",
    "created_at": "2025-01-08T00:07:30Z",
    "closed_at": "2025-01-09T22:52:28Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/issues/110",
    "body": "When using E2B to run code remotely with a custom tool (inherited from Tool), I get errors like:\r\n\r\nName 'os' is undefined.\r\nName 'json' is undefined.\r\n\r\n- They are both standard python libs so not sure why I am getting this error. Any ideas?\r\n\r\n- Also is there a way to specify importing 'pandas as pd' etc?\r\n\r\n```\r\nsupabase_data = SupabaseDataTool()\r\n\r\ndata_agent = CodeAgent(\r\n    tools=[supabase_data],  \r\n    model=model,\r\n    additional_authorized_imports=['pandas', 'numpy', 'supabase'],\r\n    max_steps=10,\r\n    use_e2b_executor=True,\r\n)\r\n```",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/110/comments",
    "author": "sumitbindra",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-09T22:52:28Z",
        "body": "These issues of undefined stuff are due to the LLM in the agent writing wrong code snippets, for instance with missing imports. For the \"import pandas as pd\", it's the same: you authorized pandas and that's good, then you should let the LLM in the CodeAgent write snippets itself."
      }
    ]
  },
  {
    "number": 108,
    "title": "Always getting the error: \"AssertionError exception: no description\" ",
    "created_at": "2025-01-07T21:09:23Z",
    "closed_at": "2025-01-20T16:21:39Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/issues/108",
    "body": "No matter what I do to modify the docstring I always get the same error as mentioned in the title.\r\n\r\nHere is a tool that I have created.\r\n\r\nI would like to know what within my docstrings is causing this.\r\n\r\n```python\r\n\r\ncg = CoinGeckoAPI(demo_api_key=os.getenv('coingecko_api_key'))\r\n\r\n@tool\r\ndef get_coins_list(currency: str) -> list:\r\n    \"\"\"\r\n    This tool makes a query to the CoinGecko API to get a response of ALL of the supported coins with their price, market cap, volume and related market data in USD.\r\n\r\n    Args:\r\n        currency: The dollar value which the coin should be represented into\r\n    \"\"\"\r\n    return cg.get_coins_markets(vs_currency=currency)\r\n\r\n```",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/108/comments",
    "author": "jondoescoding",
    "comments": [
      {
        "user": "whoahaow",
        "created_at": "2025-01-07T21:34:16Z",
        "body": "does it fix it?\r\n\r\n```python\r\ncg = CoinGeckoAPI(api_key=os.getenv('coingecko_api_key'))\r\n\r\nclass GetCoinsListTool(Tool):\r\n    name = \"get_coins_list\"\r\n    description = \"\"\"\r\n    This tool makes a query to the CoinGecko API to get a response of ALL of the supported coins with their price, market cap, volume and related market data in USD.\r\n    \"\"\"\r\n    inputs = {\r\n        \"currency\": {\r\n            \"type\": \"string\",\r\n            \"description\": \"The currency in which the coin data should be represented (e.g., 'usd', 'eur').\"\r\n        }\r\n    }\r\n    output_type = \"list\"\r\n\r\n    def forward(self, currency: str) -> list:\r\n        return cg.get_coins_markets(vs_currency=currency)\r\n```"
      },
      {
        "user": "jondoescoding",
        "created_at": "2025-01-07T21:45:48Z",
        "body": "Got the same error.\r\n\r\n```python\r\nException has occurred: AssertionError\r\nexception: no description\r\n\r\nException has occurred: AssertionError\r\nexception: no description\r\n  File \"...\\coingecko_agent\\agent.py\", line 7, in <module>\r\n    coin_list_tool = GetCoinsListTool()\r\n                     ^^^^^^^^^^^^^^^^^^\r\nAssertionError: \r\n\r\n```"
      },
      {
        "user": "whoahaow",
        "created_at": "2025-01-07T22:25:44Z",
        "body": "I don't know if this is suitable for you, but here's what I did:\r\n```python\r\nfrom smolagents import CodeAgent, HfApiModel, Tool\r\nimport os\r\nfrom pycoingecko import CoinGeckoAPI\r\nimport json\r\n\r\n# Initialize CoinGecko API client\r\ncg = CoinGeckoAPI(api_key=os.getenv('coingecko_api_key'))\r\n\r\n# Define the GetCoinsListTool class\r\nclass GetCoinsListTool(Tool):\r\n    name = \"get_coins_list\"\r\n    description = \"\"\"\r\n    This tool makes a query to the CoinGecko API to get a response of ALL of the supported coins with their price, market cap, volume and related market data in USD.\r\n    You need to import json. The output is a JSON string. You should use the `json` module to parse this string into a Python list.\r\n    \"\"\"\r\n    inputs = {\r\n        \"currency\": {\r\n            \"type\": \"string\",\r\n            \"description\": \"The currency in which the coin data should be represented (e.g., 'usd', 'eur').\"\r\n        }\r\n    }\r\n    output_type = \"string\"  # Change to 'string'\r\n\r\n    def forward(self, currency: str) -> str:\r\n        coins_data = cg.get_coins_markets(vs_currency=currency)\r\n        return json.dumps(coins_data)  # Convert the list to a JSON string\r\n\r\n# Initialize the model\r\nmodel = HfApiModel(model_id=\"Qwen/Qwen2.5-Coder-32B-Instruct\")\r\n\r\n# Initialize the agent with the tool\r\nagent = CodeAgent(\r\n    tools=[GetCoinsListTool()],\r\n    model=model,\r\n    add_base_tools=True,\r\n    additional_authorized_imports=[\"json\"]  # Authorize the json module\r\n)\r\n\r\n# Run the agent with a task\r\ntask = \"Get the list of coins in USD and print the first 5 entries. Then present it as usual text.\"\r\nresult = agent.run(task)\r\n\r\n# Print the result\r\nprint(\"Agent Output:\")\r\nprint(result)\r\n```"
      },
      {
        "user": "jondoescoding",
        "created_at": "2025-01-07T23:24:32Z",
        "body": "Works like a charm. Thanks! But why does the the @tool decorator not work?"
      },
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-09T10:24:13Z",
        "body": "@jondoescoding could you provide your full error trace and package versions? I tried to reproduce but for me your code snippet works"
      }
    ]
  },
  {
    "number": 107,
    "title": "Return a dictionary from DuckDuckGoSearchTool",
    "created_at": "2025-01-07T20:53:12Z",
    "closed_at": "2025-01-08T09:00:32Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/107",
    "body": "# Why?\r\nThe description is currently:\r\nPerforms a duckduckgo web search based on your query (think a Google search) then returns the top search results as a list of dict elements.  Each result has keys 'title', 'href' and 'body'.\r\n\r\nBut the return value was a Markdown string. As a result the code later was failing trying to access the 'body'/'href' key of the response\r\n\r\nSee issue #86\r\n\r\n# What ?\r\n\r\nThe return value is a list of dict elements. This is as siginificantly different from the return value of the previous version of the tool.",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/107/comments",
    "author": "julien-duponchelle",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-08T09:00:32Z",
        "body": "I fixed the issue by changing the return type to string, makes it more easy for LLM to handle the output in code snippets!"
      }
    ]
  },
  {
    "number": 102,
    "title": "[not bug] call LLM without agents",
    "created_at": "2025-01-07T12:59:35Z",
    "closed_at": "2025-01-07T14:57:06Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/issues/102",
    "body": "Hi, maybe I missed it somewhere in the examples or docs, but is there a way to make a simple call to LLM with a prompt but without it being an agent call, so there are no tools or retries?\n\nA straight simple LLM prompt call without agents trying to figure anything out and do cycle after cycle of retries? (like ell or pydantic-ai)?\nThanks",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/102/comments",
    "author": "kuatroka",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-07T14:57:06Z",
        "body": "To do this, you could directly call the LLM, without using this library ðŸ˜„ "
      }
    ]
  },
  {
    "number": 101,
    "title": "Code Agent -> max_iterations",
    "created_at": "2025-01-07T10:20:29Z",
    "closed_at": "2025-01-07T14:53:36Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/issues/101",
    "body": "CodeAgent stops after 5 iterations. Any way to explicitely increase this limit ?",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/101/comments",
    "author": "flaming-potato",
    "comments": [
      {
        "user": "paulmartrencharpro",
        "created_at": "2025-01-07T10:32:15Z",
        "body": "Yes, the CodeAgent class' parent MultiStepAgent has a max_steps parameter that you can change.\r\n\r\n`agent = CodeAgent(tools=[DuckDuckGoSearchTool(), PythonInterpreterTool()], model=HfApiModel(), max_steps=20)`"
      },
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-07T14:53:36Z",
        "body": "Closing this since @paulmartrencharpro explained the resolution very well! ðŸ˜„ "
      },
      {
        "user": "flaming-potato",
        "created_at": "2025-01-07T15:46:06Z",
        "body": "Thanks a lot :)"
      }
    ]
  },
  {
    "number": 87,
    "title": "Invalid usage of tool by agent",
    "created_at": "2025-01-06T17:54:03Z",
    "closed_at": "2025-01-10T18:05:56Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/issues/87",
    "body": "My code for tool is:\r\n```\r\n@tool\r\ndef file_creator(folder_target: str, file_name: str, file_contents: str) -> str:\r\n    \"\"\"\r\n    This is a tool that creates file in the specified directory in /code subdirectory and writes to it.\r\n    It returns the confirmation when succesful.\r\n    Only create in code subdirectory! Never in parent or higher directories.\r\n\r\n    Args:\r\n        folder_target: target directory to create the file\r\n        file_name: name of the file to create\r\n        file_contents: contents to write to the file\r\n    \"\"\"\r\n    with open(os.path.join(dirname, \"code\", folder_target, file_name), \"w\") as f:\r\n        f.write(file_contents)\r\n    return f\"Created file: {file_name}\"\r\n```\r\n\r\ntool is used by agent:\r\n`developer_web_agent = CodeAgent(tools=[folder_creator, file_creator], model=llm_model)`\r\n\r\n```\r\nmanaged_developer_web_agent = ManagedAgent(\r\n    agent=developer_web_agent,\r\n    name=\"super_developer\",\r\n    description=developer_managed_web_agent_instruction\r\n)\r\n```\r\n\r\nThen manager is handling:\r\n```\r\nmanager_agent = CodeAgent(\r\n    tools=[folder_creator, file_creator, install_node_dependencies, start_node_server, selenium_test],\r\n    model=llm_model,\r\n    managed_agents=[managed_requirements_web_agent, managed_developer_web_agent, managed_tester_web_agent]\r\n    )\r\n\r\nmanager_agent.run(\"Create super simple hello world application in nodejs\")\r\n```\r\n\r\nWhat happens is that agent reads the schema kinda-ok, but then calls it improperly:\r\n\r\n```\r\nfile_creator({'folder_target': folder_target, 'file_name': file_name, 'file_contents': file_contents})                                                                                                                                                          \r\nCode execution failed: file_creator() missing 2 required positional arguments: 'file_name' and 'file_contents'\r\n```\r\n\r\ninstead of expected:\r\n`file_creator('folder_target': folder_target, 'file_name': file_name, 'file_contents': file_contents)`      ",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/87/comments",
    "author": "karolklp",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-07T14:59:58Z",
        "body": "Which model are you using?"
      },
      {
        "user": "zhjch05",
        "created_at": "2025-01-07T16:31:56Z",
        "body": "I saw some similar issues with litellm gpt-4o or gpt-4o-mini, but don't see that behavior in anthropic/claude-3-5-sonnet-20241022"
      },
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-07T16:56:36Z",
        "body": "This seems not to be an issue with the framework, but simply a \"LLM is dumb\" issue: there's no real way we should correct these incorrect arguments in the frameworks. So I'd say, maybe provide additional guidance to help the model use the tools, like \"don't pass one dict, you need 3 arguments\" ?"
      },
      {
        "user": "karolklp",
        "created_at": "2025-01-07T19:36:31Z",
        "body": "Hey, I used `meta-llama/Llama-3.1-8B-Instruct`\r\nLlama-3.3 was way more crazy with unstructured output from model\r\n"
      },
      {
        "user": "devlux76",
        "created_at": "2025-01-09T22:05:36Z",
        "body": "I switched over to exclusively the QwenCoder 2.5 family of models for precisely this reason. They seem to follow instructions well when it comes to coding, even the little 1.5B models.\r\n\r\nAlmost too well actually, I had 32B do the \"build me a snake game in Python\" task. Thought it froze, went to get some coffee and came back to a full screen, \"GAME OVER\" after the game launched and played itself. I nearly had a heart attack."
      },
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-09T22:29:41Z",
        "body": "Wow this is seriously bonkers @devlux76! Do you have screenshots?"
      },
      {
        "user": "devlux76",
        "created_at": "2025-01-09T23:29:36Z",
        "body": "Wish I would have thought to take some. I'll try again later."
      },
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-10T18:05:56Z",
        "body": "Closing this since there's no issue to solve anymore! ðŸ˜ƒ "
      }
    ]
  },
  {
    "number": 83,
    "title": "How to save/extract executed code",
    "created_at": "2025-01-06T15:40:17Z",
    "closed_at": "2025-01-08T15:56:47Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/issues/83",
    "body": "Is it possible to save the executed code? It's already in the log. It will be very useful.\r\nex.\r\n```\r\nâ•­â”€ Executing this code: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\r\nâ”‚    1 attractions_list = [                                                                                                                    â”‚\r\nâ”‚    2     [\"Attraction\", \"Description\"],                                                                                                      â”‚\r\nâ”‚    3     [\"Sensoji Temple\", \"The oldest temple in Tokyo, offering beautiful architecture and a rich history.\"],                              â”‚\r\nâ”‚    4     [\"Nakamise Shopping Street\", \"A historic shopping street with souvenirs and traditional snacks.\"],                                  â”‚\r\nâ”‚    5     [\"Kibi Dango\", \"A traditional rice cake snack available at Nakamise Street.\"],                                                      â”‚\r\nâ”‚    6     [\"Asakusa Jinja\", \"A historic Shinto shrine that survived the bombings during WWII.\"],                                              â”‚\r\nâ”‚    7     [\"Kimono Experience\", \"Rent a kimono and walk around Asakusa.\"],                                                                    â”‚\r\nâ”‚    8     [\"Asakusa Culture Tourist Information Center\", \"A building with unique architecture, great for photos.\"],                           â”‚\r\nâ”‚    9     [\"Tokyo Skytree\", \"The tallest structure in Tokyo, offering panoramic views.\"],                                                     â”‚\r\nâ”‚   10     [\"Hanayashiki\", \"Japanâ€™s oldest amusement park with nostalgic charm.\"],                                                             â”‚\r\nâ”‚   11     [\"Demboin Garden\", \"A serene Japanese garden adjacent to Sensoji Temple.\"],                                                         â”‚\r\nâ”‚   12     [\"Azuma-bashi Bridge\", \"An iconic bridge offering views of the Tokyo Skytree.\"]                                                     â”‚\r\nâ”‚   13 ]                                                                                                                                       â”‚\r\nâ”‚   14                                                                                                                                         â”‚\r\nâ”‚   15 # Convert the list to CSV format (string)                                                                                               â”‚\r\nâ”‚   16 csv_data = \"\\n\".join([\",\".join(row) for row in attractions_list])                                                                       â”‚\r\nâ”‚   17                                                                                                                                         â”‚\r\nâ”‚   18 # Save the CSV data to file                                                                                                             â”‚\r\nâ”‚   19 save_csv(data=csv_data, filename='asakusa_trip.csv')                                                                                    â”‚\r\nâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/83/comments",
    "author": "Lodimup",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-06T16:15:24Z",
        "body": "You can extract the code action from a step's `tool_call` attribute:\r\nFor instance:\r\n`agent.logs[2].tool_call.arguments`"
      },
      {
        "user": "gengyabc",
        "created_at": "2025-02-16T15:34:25Z",
        "body": "I used the similar like `code_agent.memory.steps[-1].tool_calls[0].arguments`, but we don't know where is the final code, it's maybe in step[-1] or step[-2] or other steps. How can we tell which step"
      },
      {
        "user": "aymeric-roucher",
        "created_at": "2025-02-16T17:43:39Z",
        "body": "There's no final code @gengyabc : code has been generated and executed at every step, so you have several snippets of code to inspect with the method described above."
      }
    ]
  },
  {
    "number": 77,
    "title": "I need an Android version",
    "created_at": "2025-01-06T02:36:26Z",
    "closed_at": "2025-01-06T13:49:43Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/issues/77",
    "body": "Run on android os ...",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/77/comments",
    "author": "cacard",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-06T13:49:43Z",
        "body": "This is quite out of scope for now, alas!"
      }
    ]
  },
  {
    "number": 72,
    "title": "e2b details",
    "created_at": "2025-01-05T02:21:14Z",
    "closed_at": "2025-01-06T14:06:47Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/72",
    "body": "@aymeric-roucher \r\nTwo changes:\r\n1. More detailed instructions on using e2b.\r\n2. Description of tools argument",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/72/comments",
    "author": "CakeCrusher",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-06T14:07:08Z",
        "body": "I've fixed the typo and done some more edits. Thank you @CakeCrusher !"
      }
    ]
  },
  {
    "number": 68,
    "title": "Add missing end of sentence to building_good_agents",
    "created_at": "2025-01-04T18:05:58Z",
    "closed_at": "2025-01-05T19:10:07Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/68",
    "body": null,
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/68/comments",
    "author": "elroy-bot",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-05T19:10:29Z",
        "body": "Thanks a lot @elroy-bot!"
      }
    ]
  },
  {
    "number": 65,
    "title": "Remove dependency on Torch as it leads to installation issues on MacOS",
    "created_at": "2025-01-04T15:46:31Z",
    "closed_at": "2025-01-06T22:05:43Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/65",
    "body": "ERROR: Cannot install smolagents==0.1.0, smolagents==0.1.2, smolagents==0.1.3 and smolagents==1.0.0 because these package versions have conflicting dependencies.\r\n\r\nThe conflict is caused by:\r\n    smolagents 1.0.0 depends on torch\r\n    smolagents 0.1.3 depends on torch\r\n    smolagents 0.1.2 depends on torch\r\n    smolagents 0.1.0 depends on torch>=2.5.1\r\n\r\nIssue is raised #62 ",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/65/comments",
    "author": "SID262000",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-06T22:05:43Z",
        "body": "We should not remove these dependencies, they're essential! The related issue has been closed."
      }
    ]
  },
  {
    "number": 58,
    "title": "is there a plan for persisting agent memory",
    "created_at": "2025-01-03T21:13:03Z",
    "closed_at": "2025-01-06T16:22:51Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/issues/58",
    "body": "Currently agents have an in-memory memory to use in steps.\r\nIt would be nice to have persistent agent memory for tasks, so repetitive tasks will get the final answer quickly.",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/58/comments",
    "author": "mstrYoda",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-06T12:21:56Z",
        "body": "For this, you could save the agent logs (by just copying attribute agent.logs) as your memory, do the modifications that you need, then manually modify another agent's logs to incorporate past memory! If you have specific issues where you think some building blocks would help, don't hesitate to provide an example and I'll work on it!"
      }
    ]
  },
  {
    "number": 53,
    "title": "fix ToolCollection usage ",
    "created_at": "2025-01-03T14:37:42Z",
    "closed_at": "2025-01-06T13:04:12Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/53",
    "body": "I was not able to use the base ToolCollection from huggingface/smolagents : it would error on trust_remote_code from the Tool.from_hub call . \r\nI'm adding those parameters (trust_remote_code and token) to the constructor.\r\n\r\nHuggingFace online documentation still needs to be updated as it imports the wrong  ToolCollection (from transformers, not smolagents)",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/53/comments",
    "author": "Brunwo",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-06T13:04:30Z",
        "body": "Thank you for this addition! I've fixed the references to transformers.agents in the documentation."
      }
    ]
  },
  {
    "number": 49,
    "title": "Add device parameter for TransformerModel in models.py",
    "created_at": "2025-01-03T05:57:56Z",
    "closed_at": "2025-01-06T12:57:33Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/49",
    "body": "# Added \"device\" parameter to TransformerModel in `model.py` for Improved GPU/CPU Compatibility\r\n\r\n## Description\r\nThis PR introduces the `device` parameter to the `TransformersModel` class, allowing users to explicitly specify the device (`\"cpu\"`, `\"cuda\"`, etc.) for model loading and inference. This change improves flexibility and control over model deployment environments, especially when running on systems with mixed hardware setups.\r\n\r\n## Changes Made\r\n1. **Device Detection**:\r\n   - Added logic to automatically detect and set the device (`cuda` if available, otherwise `cpu`).\r\n   - Modified the model instantiation and data tensor operations to respect the detected device.\r\n   - Added a `to(device)` call to move the model and tensors to the appropriate device.\r\n\r\n2. **Backward Compatibility**:\r\n   - No breaking changes introduced. If the device is not specified, the script defaults to the best available option.\r\n \r\n3. **Enhance Logging**:\r\n    - Added logging to indicate when the default device is used.\r\n\r\n## Example Usage\r\n\r\n### Before\r\n```python\r\nmodel = TransformersModel(model_id=\"my-model\")\r\n```\r\n\r\n### After\r\n```python\r\nmodel = TransformersModel(model_id=\"my-model\", device=\"cuda\")\r\n```\r\nThis ensures the model explicitly runs on the GPU.\r\n\r\n## Motivation\r\n\r\nExplicit hardware selection is crucial in scenarios involving mixed hardware environments. Many users work in systems where both CPU and GPU resources are available, and having the ability to specify the `device` simplifies configuration and improves usability.\r\n\r\nBy adding the `device` parameter, users no longer need to modify internal logic or rely on automatic device detection, making the library more adaptable to diverse deployment environments.\r\n\r\n## Testing\r\n\r\n- **Device Compatibility**: Tested both GPU (`\"cuda\"`) and CPU (`\"cpu\"`).\r\n- **Fallback Behavior**: Verified correct fallback to default device when no `device` parameter is provided or when the specified device is unavailable.\r\n- **Backward Compatibility**: Ensured that existing code without a `device` parameter continues to work as expected.\r\n\r\n## Checklist\r\n\r\n- [x] Added `device` parameter to `TransformersModel`.\r\n- [x] Updated docstrings to include the new parameter description.\r\n- [x] Verified backward compatibility with existing implementations.\r\n- [x] Enhanced logging to clarify default behavior and errors.\r\n\r\n## Impact\r\n\r\nThis update is fully backward-compatible. Users who do not specify the `device` parameter will experience no change in behavior, as the default device (`\"cuda\"` if available, otherwise `\"cpu\"`) is automatically selected.\r\n\r\n\r\n",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/49/comments",
    "author": "ScientistIzaak",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-06T12:57:16Z",
        "body": "This is a really nice addition, thank you @ScientistIzaak ! Let's merge this."
      }
    ]
  },
  {
    "number": 44,
    "title": "LLM using wrong function to send a request to an agent",
    "created_at": "2025-01-02T23:30:08Z",
    "closed_at": "2025-01-09T22:54:20Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/issues/44",
    "body": "Notice in `Step 0`, it tried to call `home_automation.request`, gets an error, then calls the correct function `home_automation()`\r\n\r\n```bash\r\nroot# python demo.py \r\nYou: turn on the kitchen light plz\r\nâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ New run â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\r\nâ”‚                                                                           â”‚\r\nâ”‚ turn on the kitchen light plz                                             â”‚\r\nâ”‚                                                                           â”‚\r\nâ•°â”€ LiteLLMModel - gpt-4o-mini â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\r\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” Step 0 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\r\nâ•­â”€ Executing this code: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\r\nâ”‚   1 home_automation.request(\"Please turn on the kitchen light.\")          â”‚\r\nâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\r\nCode execution failed: Code execution failed at line \r\n'home_automation.request(\"Please turn on the kitchen light.\")' because of the\r\nfollowing error:\r\nObject <smolagents.agents.ManagedAgent object at 0x7d83aaf84ce0> has no \r\nattribute request\r\n[Step 0: Duration 1.71 seconds| Input tokens: 2,018 | Output tokens: 61]\r\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” Step 1 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\r\nâ•­â”€ Executing this code: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\r\nâ”‚   1 home_automation(\"turn on the kitchen light\")                          â”‚\r\nâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\r\nâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ New run â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\r\nâ”‚                                                                           â”‚\r\nâ”‚ You're a helpful agent named 'home_automation'.                           â”‚\r\nâ”‚ You have been submitted this task by your manager.                        â”‚\r\nâ”‚ ---                                                                       â”‚\r\nâ”‚ Task:                                                                     â”‚\r\nâ”‚ turn on the kitchen light                                                 â”‚\r\nâ”‚ ---                                                                       â”‚\r\nâ”‚ You're helping your manager solve a wider task: so make sure to not       â”‚\r\nâ”‚ provide a one-line answer, but give as much information as possible to    â”‚\r\nâ”‚ give them a clear understanding of the answer.                            â”‚\r\nâ”‚                                                                           â”‚\r\nâ”‚ Your final_answer WILL HAVE to contain these parts:                       â”‚\r\nâ”‚ ### 1. Task outcome (short version):                                      â”‚\r\nâ”‚ ### 2. Task outcome (extremely detailed version):                         â”‚\r\nâ”‚ ### 3. Additional context (if relevant):                                  â”‚\r\nâ”‚                                                                           â”‚\r\nâ”‚ Put all these in your final_answer tool, everything that you do not pass  â”‚\r\nâ”‚ as an argument to final_answer will be lost.                              â”‚\r\nâ”‚ And even if your task resolution is not successful, please return as much â”‚\r\nâ”‚ context as possible, so that your manager can act upon this feedback.     â”‚\r\nâ”‚ {additional_prompting}                                                    â”‚\r\nâ”‚                                                                           â”‚\r\nâ•°â”€ LiteLLMModel - gpt-4o-mini â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\r\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” Step 0 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\r\nâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\r\nâ”‚ Calling tool: 'turn_on_light' with arguments: {'light': 'kitchen'}        â”‚\r\nâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\r\n```\r\n\r\n\r\nHere's my code:\r\n\r\n```python\r\nhome_automation_agent = ToolCallingAgent(\r\n    tools=[turn_on_light],\r\n    model=model,\r\n)\r\n\r\nmanaged_home_automation_agent = ManagedAgent( \r\n    agent=home_automation_agent,\r\n    name=\"home_automation\",\r\n    description=\"Controls the home automation system.\"\r\n)\r\n\r\nsms_agent = ToolCallingAgent(\r\n    tools=[send_sms, phone_number_lookup],\r\n    model=model,\r\n)\r\n\r\nmanaged_sms_agent = ManagedAgent( \r\n    agent=sms_agent,\r\n    name=\"sms\",\r\n    description=\"Sends text messages.\"\r\n)\r\n\r\nagent = CodeAgent(\r\n    model=model,\r\n    tools=[],\r\n    managed_agents=[managed_home_automation_agent, managed_sms_agent],\r\n)\r\n```",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/44/comments",
    "author": "vqndev",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-09T22:54:20Z",
        "body": "Hi @vqndev, thank you for submitting!\r\nThis is a great example of self-healing in a multi-step agent!\r\nIn step 0, `gpt4o-mini` does a mistake by calling a tool incorrectly. Then it rectifies the code in the second step (because it saw the error message in its memory) and finally solves the task!\r\n\r\nAll in all it's not a framework issue, it's just the LLM being dumb! Which often happens with smaller LLMs, GPT-4o would be less likely to do this first mistake."
      },
      {
        "user": "vqndev",
        "created_at": "2025-01-13T15:41:14Z",
        "body": "Thanks! "
      }
    ]
  },
  {
    "number": 43,
    "title": "Update building_good_agents.md",
    "created_at": "2025-01-02T19:30:37Z",
    "closed_at": "2025-01-02T21:53:09Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/43",
    "body": "fix typing mistake \"if\" with \"of\".",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/43/comments",
    "author": "SHUBH4M-KUMAR",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-02T21:53:13Z",
        "body": "Well spotted @SHUBH4M-KUMAR , thank you for proposing this fix!"
      }
    ]
  },
  {
    "number": 41,
    "title": "Added a fallback for the VisitWebpageTool in case a website is protected against bots, using playwright",
    "created_at": "2025-01-02T16:58:26Z",
    "closed_at": "2025-01-06T13:36:38Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/41",
    "body": null,
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/41/comments",
    "author": "arjuna-dev",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-06T13:36:38Z",
        "body": "Hello @arjuna-dev,\r\nWe would prefer to keep base tools simple, without additional packages like playwright. However feel free to share this tool to the Hub to let people use it!"
      },
      {
        "user": "arjuna-dev",
        "created_at": "2025-01-06T14:33:41Z",
        "body": "> Hello @arjuna-dev,\n> We would prefer to keep base tools simple, without additional packages like playwright. However feel free to share this tool to the Hub to let people use it!\n\nSure, it makes sense. I implemented in a way that it is not a required library though. In case ddg fails, you'd get a prompt that you could install this as a callback.\n\nAnyway, good job with the library!"
      }
    ]
  },
  {
    "number": 40,
    "title": "feat: Add max_results kwarg to DDGS tool",
    "created_at": "2025-01-02T16:23:40Z",
    "closed_at": "2025-01-06T18:34:13Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/40",
    "body": "You can now optionally pass `max_results` into the `DuckDuckGoSearchTool`. Default behavior is unchanged (10 results).\r\n\r\n```python\r\nDuckDuckGoSearchTool(max_results=2)\r\n```\r\n\r\nTest with `examples/ddg_leopard.py`",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/40/comments",
    "author": "Stillerman",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-06T13:11:25Z",
        "body": "Thank you @Stillerman, this is a good addition! Coud you simply remove the added example file ddgs_leopard.py? I want to keep only examples that highlight complex behaviours, to keep their information content high. Then we're good to merge!"
      },
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-06T18:34:27Z",
        "body": "I've done the deletion and merged, thank you @Stillerman !"
      }
    ]
  },
  {
    "number": 37,
    "title": "Fix example usage in HfApiModel",
    "created_at": "2025-01-02T13:17:34Z",
    "closed_at": "2025-01-02T21:54:18Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/37",
    "body": "thanks for the effort! \r\n\r\nA small fix on the example/docstring ",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/37/comments",
    "author": "balikasg",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-02T21:54:38Z",
        "body": "Merged! Thank you for spotting this and proposing a fix @balikasg "
      }
    ]
  },
  {
    "number": 33,
    "title": "Fixing minor spelling errors in building_good_agents.md",
    "created_at": "2025-01-02T05:36:43Z",
    "closed_at": "2025-01-02T21:55:14Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/33",
    "body": "Really enjoying this library, great work! I fixed some minor spelling errors in the \"building good agents\" tutorial documentation while I was reading through it. Below is a summary of the changes made:\r\n\r\n---\r\n\r\n## **Changes:**\r\n\r\n1. **Line 29:**  \r\n   -  `introducessome` â†’ `introduces some` \r\n\r\n2. **Line 31:**  \r\n   -  `worklow` â†’ `workflow` \r\n\r\n3. **Line 34:**  \r\n   -  `functions` â†’ `function` \r\n\r\n4. **Line 171:**  \r\n   -  `tid` â†’ `did` \r\n\r\n5. **Line 182:**  \r\n   -  `claritications` â†’ `clarifications` \r\n\r\n",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/33/comments",
    "author": "ScientistIzaak",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-02T21:55:29Z",
        "body": "Thanks a lot for these fixes @ScientistIzaak! ðŸ¤— "
      }
    ]
  },
  {
    "number": 31,
    "title": "LangChain Interoperability?",
    "created_at": "2025-01-02T03:11:48Z",
    "closed_at": "2025-02-07T13:54:28Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/issues/31",
    "body": "I was wondering if smolagents are interoperable with LangChain chains? If not, can we please make that as a feature?",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/31/comments",
    "author": "adhishthite",
    "comments": [
      {
        "user": "atsui888",
        "created_at": "2025-01-02T03:18:39Z",
        "body": "if there is a decision to make smolagents interoperable with LangChain, I hope it is an option and not a must. There are some like me who do not wish to use LangChain. "
      },
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-14T18:46:41Z",
        "body": "There's no plans for an integration for langchain as of now, if there is ever one it will be optional, because in general we will prefer to keep external dependencies optional!\n\n@adhishthite what would be your use case for an integration of the framework with LangChain?"
      }
    ]
  },
  {
    "number": 29,
    "title": "Add support for additional keyword arguments in LiteLLMModel",
    "created_at": "2025-01-01T19:58:10Z",
    "closed_at": "2025-01-06T13:09:43Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/29",
    "body": "adding support for more optiones to the liteLLM like temperature or seed for more controllable tests ",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/29/comments",
    "author": "chakib-belgaid",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-06T13:10:01Z",
        "body": "Thank you @chakib-belgaid, this is a great addition! ðŸ‘ "
      }
    ]
  },
  {
    "number": 27,
    "title": "Loading Models from disk",
    "created_at": "2025-01-01T19:42:30Z",
    "closed_at": "2025-01-14T18:41:26Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/issues/27",
    "body": "Is there any way to load the models without using the Hugginface model id? I have several Llama models on my drive and would like to use those.",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/27/comments",
    "author": "norhther",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-14T18:41:26Z",
        "body": "@norhther you could load them in transformers using `TransformersModel`, or Ollama using `LiteLLMModel` or `OpenAIServerModel`! But without the model_id none of our classes support this, you would have to make your own Model class!"
      }
    ]
  },
  {
    "number": 26,
    "title": "fixed ollama api_base - adding /v1 is only needed for openai-like and will not work when using litellm native ollama integration. Url without any additional /endpoint will now work correctly",
    "created_at": "2025-01-01T19:30:59Z",
    "closed_at": "2025-01-06T21:29:56Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/26",
    "body": null,
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/26/comments",
    "author": "topmass",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-06T21:29:56Z",
        "body": "This removal of \"v1\" has been done in another PR since you opened this PR, thank you for raising this!"
      }
    ]
  },
  {
    "number": 25,
    "title": "CodeAgent relies on e2b Code Interpreter, no self-hosting support",
    "created_at": "2025-01-01T13:41:44Z",
    "closed_at": "2025-01-02T22:41:03Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/issues/25",
    "body": "**Description**  \r\nRight now, CodeAgent in smolagents depends on e2bâ€™s Code Interpreter, which doesnâ€™t support self-hosting. This means smolagents has to rely on e2bâ€™s online service, which can be a problem for use cases that need privacy or offline capabilities.  \r\n\r\n**Issues**  \r\n1. It doesnâ€™t work in offline environments, which limits independence.  \r\n2. Relying on an online service raises privacy and security concerns, especially for sensitive data.  \r\n3. Long-term dependence on an external service could be risky if the service goes down or gets deprecated.  \r\n\r\n**Questions**  \r\n1. Are there plans to move to a self-hosted or custom solution in the future?  \r\n2. Or will smolagents stick with e2bâ€™s Code Interpreter?  ",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/25/comments",
    "author": "whisper-bye",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-01T13:43:09Z",
        "body": "Hello @whisper-bye ! @ErikKaum has built a docker execution environment as well, we didn't focus on it for this release since we wanted a turnkey solution but it will be added soon!"
      },
      {
        "user": "whisper-bye",
        "created_at": "2025-01-01T13:48:21Z",
        "body": "@aymeric-roucher thank you for the quick clarification."
      }
    ]
  },
  {
    "number": 22,
    "title": "Update README.md: add link to blog post",
    "created_at": "2024-12-31T23:49:46Z",
    "closed_at": "2025-01-06T13:38:22Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/22",
    "body": "feel free to ignore/close.",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/22/comments",
    "author": "gary149",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-06T13:38:11Z",
        "body": "Thank you for adding this @gary149! ðŸ¤— "
      }
    ]
  },
  {
    "number": 17,
    "title": "NOT AN ISSUE",
    "created_at": "2024-12-31T13:51:41Z",
    "closed_at": "2024-12-31T18:39:14Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/issues/17",
    "body": "This is amazing! \r\njust yesterday i had the  concept in mind and made a pow to to get python code in response of prompts and run in eval for some of my devsecops tasks and today google suggest me this article referencing smolagents love to read code asap and contribute! ",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/17/comments",
    "author": "ghaedi1993",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2024-12-31T18:39:14Z",
        "body": "Thanks you for your feedback ðŸ˜„ "
      }
    ]
  },
  {
    "number": 11,
    "title": "Some Questions and Suggestions",
    "created_at": "2024-12-30T17:19:06Z",
    "closed_at": "2025-01-06T13:47:15Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/issues/11",
    "body": "I think this project has great potential, and I commend you on your work. Below are some questions I have, and while my suggestions may add complexity, they are indeed issues that an agent framework needs to address.\r\n\r\n1ã€I have a question regarding how the planner is embodied and what distinguishes it from the ManagedAgent.\r\n2ã€Impressive examples: It is recommended to include the capability to load and analyze data, and to implement a data analysis task where the results can be presented graphically, such as generating bar charts and other visual representations.\r\n3ã€Are there plans to introduce a simple memory mechanism?\r\n4ã€Are there plans to add orchestration features for multiple agents?\r\n5ã€Are there plans to introduce more types of agents, such as a ReactCodeAgent?",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/11/comments",
    "author": "juhengzhe",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2025-01-01T13:48:53Z",
        "body": "Thank you for your feedback @juhengzhe!\r\n1. The planning step is an orthogonal direction to the ManagedAgent: the planning step is about having a specific step of an agent dedicated to planning forward towards solving its task, while ManagedAgent is about letting an agent call another agent by assigning it a task.\r\n2. Data scientist agent example: that's a good idea, will do it!\r\n3. We already have a simple memory! You can inspect it under function `write_inner_memory_from_logs`\r\n4. Yes, we have this with ManagedAgent, take a look at the orchestration example\r\n5. `ReactCodeAgent` from transformers.agents has become `CodeAgent` in this version: the `CodeAgent` has all the `ReactCodeAgent` had\r\n"
      }
    ]
  },
  {
    "number": 10,
    "title": "Support remote llm servers",
    "created_at": "2024-12-30T11:45:47Z",
    "closed_at": "2024-12-30T14:14:21Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/10",
    "body": "Hi @aymeric-roucher,\r\n\r\nfirst of all: smolagents is super cool and easy to use!\r\n\r\nThis PR just adds support for remote LLM servers using LiteLLM. The only necessary change was to add `api_base` and `api_key` to some optional parameters to be able to call remote servers using the LiteLLMModel. \r\n\r\nI tested this with an institutional OpenAI-compatible server. I also add an Ollama-example allowing others to test it with a local server.\r\n\r\nThis also supersedes and closes #8 \r\n\r\nLet me know what you think and Happy New Year!\r\n\r\nBest,\r\nRobert",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/10/comments",
    "author": "haesleinhuepf",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2024-12-30T14:13:45Z",
        "body": "Hi @haesleinhuepf,\r\n\r\nThis is a great addition, merging it!\r\n\r\nThanks a lot, and happy new year to you too! ðŸ¤— "
      }
    ]
  },
  {
    "number": 5,
    "title": "Questions Regarding the Similarities and Differences Between smolagents and transformers Agent Frameworks",
    "created_at": "2024-12-28T06:47:51Z",
    "closed_at": "2024-12-30T02:50:16Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/issues/5",
    "body": "Hello,\r\n\r\nI noticed that both huggingface/smolagents and huggingface/transformers offer agent frameworks, and the technical principles behind both seem quite similar. Given that transformers already includes agent-related functionalities, I would like to ask for some clarification on the following points:\r\n\r\nOverlap in Functionality: What are the key differences in terms of functionality between the agent frameworks in smolagents and transformers? Is there a specific use case or scenario where one is preferred over the other?\r\n\r\nTechnological Differences: Are there significant differences in the underlying architecture or technology between the two frameworks? For example, are they based on the same agent design principles, or is there a fundamental difference in how they operate?\r\n\r\nFuture Development: Are both frameworks going to be maintained separately, or is there any plan for merging or aligning the features from these two projects moving forward?\r\n\r\nUnderstanding the relationship between these two frameworks would help clarify which one is more suitable for different types of agent-based applications.\r\n\r\nThanks in advance!",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/5/comments",
    "author": "whisper-bye",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2024-12-29T22:00:04Z",
        "body": "Hello @whisper-bye, good question indeed! A blog post is coming tomorrow to explain all this. Meanwhile, here's a TL;DR: `smolagents` integrates all functionalities of `transformers.agents` and is replacing it. Moving forward, we'll keep updating `smolagents` and deprecate `transformers.agents`, because we think it makes more sense to spin off this library as an independent one."
      },
      {
        "user": "whisper-bye",
        "created_at": "2024-12-30T02:50:16Z",
        "body": "Thank you for the clarification! Looking forward to the blog post."
      }
    ]
  },
  {
    "number": 2,
    "title": "How to call OpenAI-like models through an API?",
    "created_at": "2024-12-27T04:34:35Z",
    "closed_at": "2024-12-29T21:58:10Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/issues/2",
    "body": "How to call OpenAI-like models through an API?",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/2/comments",
    "author": "win4r",
    "comments": [
      {
        "user": "holazzer",
        "created_at": "2024-12-27T16:07:06Z",
        "body": "You can use the `LiteLLMModel` which is a wrapper using `litellm`. "
      },
      {
        "user": "aymeric-roucher",
        "created_at": "2024-12-27T16:07:12Z",
        "body": "Hellow @win4r!\r\n\r\nYou can use our LiteLLM integration and just specify the `model_id` of your model:\r\n```py\r\nfrom smolagents import LiteLLMModel\r\nmodel = LiteLLMModel(model_id=\"gpt-4o\")\r\n```\r\n\r\nThen just start an agent with this:\r\n```py\r\nfrom smolagents import CodeAgent\r\n\r\nagent = CodeAgent(tools=[], model=model)\r\n\r\nagent.run(\"What's the 20th number in the Fibonacci sequence?\")\r\n```"
      }
    ]
  },
  {
    "number": 1,
    "title": "Example/alternative docker interface",
    "created_at": "2024-12-17T16:04:53Z",
    "closed_at": "2024-12-18T11:07:30Z",
    "labels": [],
    "url": "https://github.com/huggingface/smolagents/pull/1",
    "body": "Draft to show example. To run:\r\n\r\n- build container `docker build . -t pyrunner`\r\n- run `python examples/docker_example.py`\r\n\r\n",
    "comments_url": "https://api.github.com/repos/huggingface/smolagents/issues/1/comments",
    "author": "ErikKaum",
    "comments": [
      {
        "user": "aymeric-roucher",
        "created_at": "2024-12-18T11:07:19Z",
        "body": "Thanks a lot @ErikKaum, this is a great addition! ðŸ¥³ "
      }
    ]
  }
]