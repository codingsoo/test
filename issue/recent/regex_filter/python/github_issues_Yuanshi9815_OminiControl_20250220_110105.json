[
  {
    "number": 95,
    "title": "Question on fine-tuning flux-schnell",
    "created_at": "2025-02-11T03:53:51Z",
    "closed_at": "2025-02-12T03:55:27Z",
    "labels": [],
    "url": "https://github.com/Yuanshi9815/OminiControl/issues/95",
    "body": "Hello, thank you for releasing awesome work.\n\nI noticed that the paper claims that fluxâ€schnell outperforms fluxâ€dev in subject-driven generation. However, when I run the training code with Subject200K dataset, the fluxâ€schnell results appear very blurry (with 4, 8 inference steps) while fluxâ€dev looks good.\n\nFluxâ€schnell is a timestep-distilled model using adversarial loss, but it seems that the current code fine-tunes fluxâ€schnell with L2 diffusion loss. \n\nCould you please clarify how fluxâ€schnell was fine-tuned? \n\nIs the L2 loss causing the blurriness, or is there another factor I might be missing?\n\nThank you very much for your help!",
    "comments_url": "https://api.github.com/repos/Yuanshi9815/OminiControl/issues/95/comments",
    "author": "jychoi118",
    "comments": [
      {
        "user": "jychoi118",
        "created_at": "2025-02-11T04:38:59Z",
        "body": "Additionally, I observed that training LoRA on flux-dev and then attaching that LoRA to fluxâ€schnell at inference time produces good results. \n\nWas the LoRA training performed on fluxâ€dev instead of fluxâ€schnell for subject-driven generation?"
      },
      {
        "user": "Yuanshi9815",
        "created_at": "2025-02-11T04:45:57Z",
        "body": "Hi @jychoi118 ,\n\nThanks for your attention!\n\nYes, we did not train our models on fluxâ€schnell. The model was trained on dev, and when we applied it to the FLUX, we found that fluxâ€schnell could generate better results than fluxâ€dev.\n\nBesides, we have tried to train our model base fluxâ€schnell. However, it failed because we did not find the proper loss function yet.\n\n:D"
      },
      {
        "user": "chaehunshin",
        "created_at": "2025-02-15T14:08:18Z",
        "body": " @Yuanshi9815 Does this still apply to the 1024 beta version? While the 1024 beta version can produce good images with flux-schnell, it introduces some artifacts when used with flux-dev."
      }
    ]
  },
  {
    "number": 92,
    "title": "Different Results on Callback and Inference on same image, same ckpt and seed",
    "created_at": "2025-02-06T19:03:43Z",
    "closed_at": "2025-02-11T05:08:07Z",
    "labels": [],
    "url": "https://github.com/Yuanshi9815/OminiControl/issues/92",
    "body": "HI,\n\nI am trying to train on cartoon condition on same dataset as given from scratch, but the results I am getting on callbacks and inference are different and don't match and degree of difference increases as number of steps increases. Can anyone help resolve this ? or point to potential issues causing this ? Also I thought it could be bcoz weights are fused in callback but when I fuse_lora with below code, it gives noisy image as output \n\n```\npipe = FluxPipeline.from_pretrained(\n    \"black-forest-labs/FLUX.1-dev\", torch_dtype=torch.bfloat16\n)\npipe = pipe.to(\"cuda\")\npipe.load_lora_weights(\n    \"OminiControl/runs/20250206-033521/ckpt/10000/\",\n    weight_name=f\"pytorch_lora_weights.safetensors\",\n    adapter_name=\"cartoon\",\n)\npipe.set_adapters(\"cartoon\")\npipe.fuse_lora(adapter_names=[\"cartoon\"],lora_scale=1.0,safe_fusing=True)\npipe.unload_lora_weights()\n# save locally\npipe.save_pretrained(\"save_path\")\n```",
    "comments_url": "https://api.github.com/repos/Yuanshi9815/OminiControl/issues/92/comments",
    "author": "asinghan2603",
    "comments": [
      {
        "user": "Yuanshi9815",
        "created_at": "2025-02-11T05:08:00Z",
        "body": "Hi @asinghan2603 ,\n\nThe LoRA parameter should not be fused with the original parameters. This is because the LoRA process is unique in the OminiControl. The LoRA parameters will only affect certain tokens instead of all tokens.\n\n:D"
      }
    ]
  },
  {
    "number": 91,
    "title": "setting of the lora scale and alpha",
    "created_at": "2025-02-03T04:11:49Z",
    "closed_at": "2025-02-11T09:36:39Z",
    "labels": [],
    "url": "https://github.com/Yuanshi9815/OminiControl/issues/91",
    "body": "Dear authors,\nthanks for your brilliant jobs, \n\nI have a question about why the lora rank is set so low, have you ever tried a higher rank? Is that better?\n\nAlso, the alpha always set to be the 4 times of rank, may I ask why there is the same.\n\n",
    "comments_url": "https://api.github.com/repos/Yuanshi9815/OminiControl/issues/91/comments",
    "author": "CONSTANT1386",
    "comments": [
      {
        "user": "Yuanshi9815",
        "created_at": "2025-02-11T04:29:45Z",
        "body": "Hi @CONSTANT1386 ,\n\n1. From our experiments, a lower LoRA rank requires fewer parameters and yields similar results. So we set `lora_rank=4`.\n2. We have no special design on LoRA alpha.\n\n:D"
      },
      {
        "user": "CONSTANT1386",
        "created_at": "2025-02-11T09:36:36Z",
        "body": "Thanks!"
      }
    ]
  },
  {
    "number": 86,
    "title": "little typos, double colon and dateset",
    "created_at": "2025-01-23T03:05:11Z",
    "closed_at": "2025-01-23T03:12:44Z",
    "labels": [],
    "url": "https://github.com/Yuanshi9815/OminiControl/pull/86",
    "body": "I noticed that there is a syntax error in the code where `::` is used. Specifically, in the line 114 of `train.py`:\r\n\r\n```python\r\nelif training_config[\"dataset\"][\"type\"] == \"cartoon\"::\r\n```\r\nThe double colons (`::`) seem to be a typo, as they result in a syntax error. At least from my understanding, this is not valid Python syntax. Could someone clarify the intended usage here or confirm if this is indeed an error that needs to be fixed?\r\n\r\nAlso, I fixed a minor typo that doesnâ€™t cause an error but should still be corrected (`Subject200KDateset` -> `Subject200KDataset`).",
    "comments_url": "https://api.github.com/repos/Yuanshi9815/OminiControl/issues/86/comments",
    "author": "thwan11",
    "comments": [
      {
        "user": "Yuanshi9815",
        "created_at": "2025-01-23T03:13:17Z",
        "body": "Hi @thwan11 ,\r\n\r\nThanks for your PR!\r\n\r\n;D"
      }
    ]
  },
  {
    "number": 82,
    "title": "your huggingface workspace failed",
    "created_at": "2025-01-17T20:44:55Z",
    "closed_at": "2025-01-17T23:54:44Z",
    "labels": [],
    "url": "https://github.com/Yuanshi9815/OminiControl/issues/82",
    "body": "What is wrong?",
    "comments_url": "https://api.github.com/repos/Yuanshi9815/OminiControl/issues/82/comments",
    "author": "jjiikkkk",
    "comments": [
      {
        "user": "Yuanshi9815",
        "created_at": "2025-01-17T23:54:44Z",
        "body": "Hi @jjiikkkk ,\n\nThe code of space has been updated to support the latest diffusers.\nNow you can use the app.\n\n:D"
      }
    ]
  },
  {
    "number": 77,
    "title": "OOM on 48G gpu",
    "created_at": "2025-01-16T00:16:03Z",
    "closed_at": "2025-01-17T01:27:48Z",
    "labels": [],
    "url": "https://github.com/Yuanshi9815/OminiControl/issues/77",
    "body": "I'm currently trying to train it using the a6000 ada gpus, I set the strategy to FSDP but it still reports OOM\r\nDo we have to use 80gb memory for training?",
    "comments_url": "https://api.github.com/repos/Yuanshi9815/OminiControl/issues/77/comments",
    "author": "PeterYYZhang",
    "comments": [
      {
        "user": "Yuanshi9815",
        "created_at": "2025-01-16T07:05:55Z",
        "body": "Hi @PeterYYZhang,\r\n\r\nJust FYI - you should be able to run the 512x512 config on 48GB GPUs by enabling `gradient_checkpointing: true ` in your config.\r\n\r\n:D"
      },
      {
        "user": "PeterYYZhang",
        "created_at": "2025-01-17T01:27:43Z",
        "body": "Thanks @Yuanshi9815! Now it works!!"
      },
      {
        "user": "rishabh063",
        "created_at": "2025-01-28T15:01:15Z",
        "body": "hey i am getting oom on 48gb vram even when gradient checkpoint is true"
      }
    ]
  },
  {
    "number": 73,
    "title": "Customized generation of multiple subjectsï¼Ÿ",
    "created_at": "2025-01-08T00:20:23Z",
    "closed_at": "2025-01-09T10:40:13Z",
    "labels": [],
    "url": "https://github.com/Yuanshi9815/OminiControl/issues/73",
    "body": null,
    "comments_url": "https://api.github.com/repos/Yuanshi9815/OminiControl/issues/73/comments",
    "author": "JoshonSmith",
    "comments": [
      {
        "user": "Yuanshi9815",
        "created_at": "2025-01-08T07:11:31Z",
        "body": "Hi @JoshonSmith ,\r\n\r\nCould you please provide more details about your issue?\r\n\r\nThank you. :D "
      },
      {
        "user": "JoshonSmith",
        "created_at": "2025-01-08T07:36:29Z",
        "body": "> Hi @JoshonSmith ,\r\n> \r\n> Could you please provide more details about your issue?\r\n> \r\n> Thank you. :D\r\n\r\nsorry, \r\nWhether OminiControl can support the generation of multiple reference subjectï¼Ÿ"
      },
      {
        "user": "Yuanshi9815",
        "created_at": "2025-01-08T08:36:19Z",
        "body": "Hi @JoshonSmith ,\r\n\r\nThe method of OminiControl could be applied to the task you described.\r\nHowever, the currently released OminiControl models may not support it."
      }
    ]
  },
  {
    "number": 63,
    "title": "After getting a loraï¼Œuse generate.py and get a mosaic image",
    "created_at": "2025-01-02T04:44:14Z",
    "closed_at": "2025-01-02T10:02:13Z",
    "labels": [
      "good first issue"
    ],
    "url": "https://github.com/Yuanshi9815/OminiControl/issues/63",
    "body": "**Configuration: The base model is Schnell\r\nWhen the training parameters lorarank=16 and lora_alpha=4, the training can produce images normally. However, after loading the trained lora with load_raraw_weights, the generated images for testing are all mosaic\r\nWhen the training parameters lorarank=4 and lora_alpha=4, there is no such problem**\r\n\r\n\r\npipe = FluxPipeline.from_pretrained(\r\n    \"black-forest-labs/FLUX.1-schnell\", torch_dtype=torch.bfloat16\r\n)\r\npipe = pipe.to(\"cuda\")\r\nlora_path = \"xxxxxx\"\r\npipe.load_lora_weights(\r\n    lora_path,\r\n    adapter_name=\"subject\",\r\n    torch_dtype=torch.bfloat16\r\n)\r\nimage = Image.open(\"xxxxx\").convert(\"RGB\").resize((576, 1024))\r\nmyimage_out = 'xxxxxxx'\r\nprompt = \"A person is sitting on a chair, wearing this pair of brown boots. \"\r\ncondition = Condition(\"subject\", image,position_delta=[0, -32])\r\ngenerator = torch.Generator(device=\"cuda\")\r\ngenerator.manual_seed(42)\r\nresult_img = generate(\r\n    pipe,\r\n    prompt=prompt,\r\n    conditions=[condition],\r\n    model_config = {\"latent_lora\":False,\"add_cond_attn\":False,\"union_cond_attn\":True}, #é»˜è®¤æ˜¯ä¸åŠ è¿™ä¸ª\r\n    num_inference_steps=28,\r\n    height=1024,\r\n    width=576,\r\n    default_lora=False,\r\n    generator = generator\r\n).images[0]\r\n\r\n",
    "comments_url": "https://api.github.com/repos/Yuanshi9815/OminiControl/issues/63/comments",
    "author": "lmnhsp",
    "comments": [
      {
        "user": "Yuanshi9815",
        "created_at": "2025-01-02T10:02:07Z",
        "body": "Hi @lmnhsp,\r\n\r\nYou should keep the same value of lora_alpha and lora_scale. Consider these solutions:\r\n\r\n**Solution1 (Using your trained model):**\r\nSet `lora_scale=4` (16/4) before inference, given your `lora_rank=16` and `lora_alpha=4`.\r\n\r\n**Solution2 (Training new):**\r\nMatch `lora_rank` and `lora_alpha` during training.\r\n\r\nFeel free to let me know if either helps or if you have other questions. \r\n\r\n:D"
      },
      {
        "user": "lmnhsp",
        "created_at": "2025-01-05T05:00:08Z",
        "body": "thank you for your replying, do you mean lora_scale = 4/16 = 0.25 because i found the scaling==0.25 when i was traing"
      }
    ]
  },
  {
    "number": 60,
    "title": "How to load the released subject-driven lora model for continuing training?",
    "created_at": "2024-12-30T11:32:06Z",
    "closed_at": "2025-01-02T09:48:05Z",
    "labels": [],
    "url": "https://github.com/Yuanshi9815/OminiControl/issues/60",
    "body": null,
    "comments_url": "https://api.github.com/repos/Yuanshi9815/OminiControl/issues/60/comments",
    "author": "Viaring",
    "comments": [
      {
        "user": "Viaring",
        "created_at": "2024-12-30T11:36:45Z",
        "body": "I use the training codes for training based on Flux1.schnell, but I found the size of the lora model was different from the released one.\r\nWhat's  the  difference of the setupï¼Ÿ \r\nThanks for reply!\r\n"
      },
      {
        "user": "Yuanshi9815",
        "created_at": "2025-01-02T09:48:05Z",
        "body": "Hi @Viaring ,\r\n\r\nWe have not yet implemented checkpoint loading functionality.\r\n\r\nIn our released models, the `omini/subject` model sizes may be larger because we used a LoRA rank = 16 setting while reducing the number of LoRA modules. \r\n\r\nThe models in `omini/experimental` should match the released training code configuration.\r\n\r\nAdditionally, we recommend not training with the Flux1.schnell model as it may yield unsatisfying results."
      }
    ]
  },
  {
    "number": 58,
    "title": "which version of diffusers?",
    "created_at": "2024-12-28T16:15:27Z",
    "closed_at": "2024-12-29T02:09:20Z",
    "labels": [],
    "url": "https://github.com/Yuanshi9815/OminiControl/issues/58",
    "body": "File \"/Disk1/ComfyUI/custom_nodes/ComfyUI_RH_OminiControl/src/transformer.py\", line 139, in tranformer_forward\r\nimage_rotary_emb = self.pos_embed(ids)\r\n^^^^^^^^^^^^^^^^^^^\r\nFile \"/Disk1/miniforge3/envs/comfyui311/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\r\nreturn self._call_impl(*args, **kwargs)\r\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nFile \"/Disk1/miniforge3/envs/comfyui311/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\r\nreturn forward_call(*args, **kwargs)\r\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nFile \"/Disk1/miniforge3/envs/comfyui311/lib/python3.11/site-packages/diffusers/models/transformers/transformer_flux.py\", line 65, in forward\r\n[rope(ids[..., i], self.axes_dim[i], self.theta) for i in range(n_axes)],\r\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nFile \"/Disk1/miniforge3/envs/comfyui311/lib/python3.11/site-packages/diffusers/models/transformers/transformer_flux.py\", line 65, in\r\n[rope(ids[..., i], self.axes_dim[i], self.theta) for i in range(n_axes)],\r\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nFile \"/Disk1/miniforge3/envs/comfyui311/lib/python3.11/site-packages/diffusers/models/transformers/transformer_flux.py\", line 44, in rope\r\nbatch_size, seq_length = pos.shape\r\n^^^^^^^^^^^^^^^^^^^^^^\r\nValueError: not enough values to unpack (expected 2, got 1)\r\n----\r\nseems like something rong with the diffusers? could you please tell me the version of it ?\r\n\r\n\r\n",
    "comments_url": "https://api.github.com/repos/Yuanshi9815/OminiControl/issues/58/comments",
    "author": "jacksonjack001",
    "comments": [
      {
        "user": "Yuanshi9815",
        "created_at": "2024-12-29T02:09:20Z",
        "body": "Hi @jacksonjack001 ,\r\n\r\nIt looks like you are using a ComfyUI node.\r\nYou may avoid this bug by using diffusers `0.31.0`."
      }
    ]
  },
  {
    "number": 54,
    "title": "Activate Repo? Initialization",
    "created_at": "2024-12-22T08:16:34Z",
    "closed_at": "2024-12-23T06:12:57Z",
    "labels": [],
    "url": "https://github.com/Yuanshi9815/OminiControl/issues/54",
    "body": "Hi @Yuanshi9815 @sleeper @ManishSahu53 et al.,\r\n\r\nmay i ask if the initialization of the lora does not fine-tune the model from zero conv? thx & rgds,",
    "comments_url": "https://api.github.com/repos/Yuanshi9815/OminiControl/issues/54/comments",
    "author": "GloryyrolG",
    "comments": [
      {
        "user": "Yuanshi9815",
        "created_at": "2024-12-23T05:59:28Z",
        "body": "Hi @GloryyrolG ,\r\n\r\nThe LoRA B matrix is initialized to zero values at the start of training."
      }
    ]
  },
  {
    "number": 53,
    "title": "LoRA scale=0.0 for non-Conditional tokens",
    "created_at": "2024-12-21T11:08:16Z",
    "closed_at": "2024-12-27T12:20:03Z",
    "labels": [],
    "url": "https://github.com/Yuanshi9815/OminiControl/issues/53",
    "body": "Hello @Yuanshi9815 !\r\nGreat work!\r\n\r\nI have a question regarding setting lora weight for non-conditional tokens to 0.0\r\nSee #3 \r\nCan you please mention where you do it in the code? In which module?\r\n\r\nKind regards,\r\nIgor ",
    "comments_url": "https://api.github.com/repos/Yuanshi9815/OminiControl/issues/53/comments",
    "author": "reallyigor",
    "comments": [
      {
        "user": "Yuanshi9815",
        "created_at": "2024-12-23T05:54:49Z",
        "body": "Hiii @reallyigor ,\r\n\r\nThanks for your attention. \r\n\r\nYou may find it in the file `src/lora_controller.py`. ðŸ™Œ"
      },
      {
        "user": "reallyigor",
        "created_at": "2024-12-23T10:57:48Z",
        "body": "Thank you for such a swift answer!\r\ncan you please tell me the exact row?\r\n\r\ne.g. `set_lora_scale` function is not used in the code at all"
      },
      {
        "user": "Yuanshi9815",
        "created_at": "2024-12-25T04:06:39Z",
        "body": "Hi @reallyigor ,\r\n\r\nMerry Christmas! ðŸŽ„\r\n\r\nThe LoRA weight control is implemented through the `enable_lora` context manager. For example, in `src/transformer.py ` line 98:\r\n  ```python\r\n  with enable_lora((self.x_embedder,), model_config.get(\"latent_lora\", False)):\r\n      hidden_states = self.x_embedder(hidden_states)\r\n  ```\r\nWhen`latent_lora` is `False`, the LoRA weights are set to 0 for the `x_embedder` module."
      },
      {
        "user": "reallyigor",
        "created_at": "2024-12-25T08:18:28Z",
        "body": "Thank you very much, @Yuanshi9815 !\r\nðŸŽ„ Merry Christmas! ðŸŽ„\r\nHow this `model_config` controls conditional/non-conditional tokens? it enables/disables lora for the whole model, doesnt it? "
      },
      {
        "user": "Yuanshi9815",
        "created_at": "2024-12-27T04:45:38Z",
        "body": "Hi @reallyigor ,\r\n\r\nWe dynamically enable/disable LoRA during model execution. The `model_config` doesn't determine conditional/non-conditional tokens - it only controls whether to use LoRA on non-conditional tokens, which should match the training configuration. \r\n\r\nIn our released models, LoRA is used on conditional tokens but not on non-conditional tokens, hence the default False setting.\r\n\r\nXD"
      },
      {
        "user": "reallyigor",
        "created_at": "2024-12-27T12:20:03Z",
        "body": "Thank you! "
      }
    ]
  },
  {
    "number": 50,
    "title": "great work ï¼ï¼ when are you gonna release the train code ?",
    "created_at": "2024-12-16T07:37:49Z",
    "closed_at": "2024-12-26T07:08:22Z",
    "labels": [],
    "url": "https://github.com/Yuanshi9815/OminiControl/issues/50",
    "body": null,
    "comments_url": "https://api.github.com/repos/Yuanshi9815/OminiControl/issues/50/comments",
    "author": "tnickMoxuan",
    "comments": [
      {
        "user": "Yuanshi9815",
        "created_at": "2024-12-23T06:08:21Z",
        "body": "Hi @tnickMoxuan ,\r\n\r\nWe are in the final stages of optimizing our training code for public release, and we plan to make it available very soon."
      },
      {
        "user": "Yuanshi9815",
        "created_at": "2024-12-26T07:08:22Z",
        "body": "Hi @tnickMoxuan ,\r\n\r\nTraining codes are released. Now you can create your own OminiControl model by customizing any control tasks (3D, multi-view, pose-guided, try-on, etc.) with the FLUX model! "
      }
    ]
  },
  {
    "number": 49,
    "title": "Subject driven inpaint",
    "created_at": "2024-12-13T10:32:31Z",
    "closed_at": "2024-12-26T14:04:52Z",
    "labels": [],
    "url": "https://github.com/Yuanshi9815/OminiControl/issues/49",
    "body": "do you have any plan on releasing an inpaint version for subject driven generation. Ultimately, i want to insert an object into my image where the position and scale provided by the mask. I think, there is no need for a new model as the inpaint pipeline can be inferred from text2image pipeline ",
    "comments_url": "https://api.github.com/repos/Yuanshi9815/OminiControl/issues/49/comments",
    "author": "hamzaakyildiz",
    "comments": [
      {
        "user": "hamzaakyildiz",
        "created_at": "2024-12-26T13:21:27Z",
        "body": "do you have any plan on this ?"
      },
      {
        "user": "Yuanshi9815",
        "created_at": "2024-12-26T14:04:52Z",
        "body": "Hi @hamzaakyildiz ,\r\n\r\nThank you for being so interested! This idea aligns with part of our ongoing work. And we have been working on this for quite some time. We will release our work when it's ready! ðŸ™Œ"
      }
    ]
  },
  {
    "number": 42,
    "title": "License?",
    "created_at": "2024-12-07T19:20:39Z",
    "closed_at": "2024-12-10T10:58:41Z",
    "labels": [],
    "url": "https://github.com/Yuanshi9815/OminiControl/issues/42",
    "body": "Hi devs, can you please clarify licensing?\r\nWe know Schnell has no restrictions, is Omini good for commercial purposes?\r\n\r\nThanks!",
    "comments_url": "https://api.github.com/repos/Yuanshi9815/OminiControl/issues/42/comments",
    "author": "Ema81xsd",
    "comments": [
      {
        "user": "Yuanshi9815",
        "created_at": "2024-12-10T10:58:41Z",
        "body": "Hi @Ema81xsd,\r\n\r\nWe've updated the project to use the Apache License 2.0, which is now clearly documented in our LICENSE file."
      }
    ]
  },
  {
    "number": 41,
    "title": "Question about Attention Mask",
    "created_at": "2024-12-07T02:05:15Z",
    "closed_at": "2024-12-23T12:51:57Z",
    "labels": [],
    "url": "https://github.com/Yuanshi9815/OminiControl/issues/41",
    "body": "Thank you for your wonderful work! \r\n\r\nI have a question regarding the attention mask. In your paper, you mention using BiasedAttention for the interaction between the noisy image and the cond image. However, when I run your code, I've noticed that the attention mask is not being used (by the way, it seems that the attention mask defined in the block/attn_forward function differs slightly from what you mentioned in your paper), and yet it achieves excellent generation results. \r\n\r\nI would like to know if the attention mask is ineffective because I haven't run omini control correctly, or if your current version does not enable the attention mask. Looking forward to your reply, and once again, thank you for providing such an impressive work!",
    "comments_url": "https://api.github.com/repos/Yuanshi9815/OminiControl/issues/41/comments",
    "author": "sd0809",
    "comments": [
      {
        "user": "Yuanshi9815",
        "created_at": "2024-12-10T10:21:07Z",
        "body": "Hi @sd0809 ,\r\n\r\nThe BiasedAttention functionality can be activated during inference by passing the `condition_scale` parameter to the `generate()` function. \r\n\r\nFeel free to let us know if you need any clarification about the implementation details."
      }
    ]
  },
  {
    "number": 38,
    "title": "what is cond_type_embed ?",
    "created_at": "2024-12-06T03:49:29Z",
    "closed_at": "2024-12-07T05:18:39Z",
    "labels": [],
    "url": "https://github.com/Yuanshi9815/OminiControl/issues/38",
    "body": "Excellent Work! I have a question in your code. \r\n`if hasattr(self, \"cond_type_embed\") and condition_type_ids is not None:\r\n        cond_type_proj = self.time_text_embed.time_proj(condition_type_ids[0])\r\n        cond_type_emb = self.cond_type_embed(cond_type_proj.to(dtype=cond_temb.dtype))\r\n        cond_temb = cond_temb + cond_type_emb`\r\nWhat is the function of this code? I suppose it doesn't work in this version of your code, but I wonder why you didn't use it to train your network? And if this part of code is not been executed, the Variable 'condition_type_ids' is redundant in your code. I wonder whether you validate the effect of this type of design?",
    "comments_url": "https://api.github.com/repos/Yuanshi9815/OminiControl/issues/38/comments",
    "author": "Xuan-World",
    "comments": [
      {
        "user": "Yuanshi9815",
        "created_at": "2024-12-07T05:18:39Z",
        "body": "Hi @Xuan-World !\r\n\r\nThis module was designed for an \"all-in-one\" adapter approach, which would allow multiple control types to be handled by a single adapter. While it's a functional design and we've seen promising results with it, we haven't released this version yet."
      }
    ]
  },
  {
    "number": 35,
    "title": "Is there a mistake in your cited paper link about MM-Attentionï¼Ÿ",
    "created_at": "2024-12-05T13:01:20Z",
    "closed_at": "2024-12-05T13:18:53Z",
    "labels": [],
    "url": "https://github.com/Yuanshi9815/OminiControl/issues/35",
    "body": "well, in [30] the cited paper about MM-Diffusion seems unreasonable.",
    "comments_url": "https://api.github.com/repos/Yuanshi9815/OminiControl/issues/35/comments",
    "author": "tyxsspa",
    "comments": [
      {
        "user": "Yuanshi9815",
        "created_at": "2024-12-05T13:16:44Z",
        "body": "Thank you very much for identifying this issue!\r\n\r\nWe sincerely apologize for the incorrect citation regarding MM-Attention. We will update this error and release a corrected version soon. ðŸ™"
      },
      {
        "user": "Yuanshi9815",
        "created_at": "2024-12-05T13:18:53Z",
        "body": "Additionally, we noted that the MM-Attention citation you referenced ([30]) appears from an earlier version. We encourage you to check our latest revision for the most up-to-date references. We are continuously improving the paper!"
      }
    ]
  },
  {
    "number": 33,
    "title": "when will the train codes be available? Looking forward to it!",
    "created_at": "2024-12-03T03:37:22Z",
    "closed_at": "2024-12-26T07:07:30Z",
    "labels": [],
    "url": "https://github.com/Yuanshi9815/OminiControl/issues/33",
    "body": "Hi, current 512 models are really doing a great job, excelling greatly in all kinds of image-editting image-translation tasks. So when will the training code be available? Can't wait to try with our own data for certain specified categories : )",
    "comments_url": "https://api.github.com/repos/Yuanshi9815/OminiControl/issues/33/comments",
    "author": "xdfeng07",
    "comments": [
      {
        "user": "xduzhangjiayu",
        "created_at": "2024-12-06T01:39:08Z",
        "body": "+1"
      },
      {
        "user": "universewill",
        "created_at": "2024-12-06T03:06:47Z",
        "body": "+1"
      },
      {
        "user": "Yuanshi9815",
        "created_at": "2024-12-26T07:07:30Z",
        "body": "Hi @xdfeng07 @xduzhangjiayu @universewill \r\n\r\nTraining codes are released. Now you can create your own OminiControl model by customizing any control tasks (3D, multi-view, pose-guided, try-on, etc.) with the FLUX model! "
      },
      {
        "user": "universewill",
        "created_at": "2024-12-26T07:18:35Z",
        "body": "> Hi @xdfeng07 @xduzhangjiayu @universewill\r\n> \r\n> Training codes are released. Now you can create your own OminiControl model by customizing any control tasks (3D, multi-view, pose-guided, try-on, etc.) with the FLUX model!\r\n\r\nHow much vram needed to train 512x512 and 704x704 with batchsize = 1 ?"
      }
    ]
  },
  {
    "number": 27,
    "title": "what's your training dataset?",
    "created_at": "2024-11-30T06:18:06Z",
    "closed_at": "2024-12-26T07:07:01Z",
    "labels": [],
    "url": "https://github.com/Yuanshi9815/OminiControl/issues/27",
    "body": "Excellent work! I wonder what's your training dataset?\r\nIt seems you use the  SUBJECT200K made by your team to train subject-driven generation.\r\nBut I don't find the description about your training dataset for spacial-control generation.\r\n",
    "comments_url": "https://api.github.com/repos/Yuanshi9815/OminiControl/issues/27/comments",
    "author": "Xuan-World",
    "comments": [
      {
        "user": "mycfhs",
        "created_at": "2024-12-09T08:16:30Z",
        "body": "Same question"
      },
      {
        "user": "Yuanshi9815",
        "created_at": "2024-12-26T07:07:01Z",
        "body": "Training codes are released. Now you can create your own OminiControl model by customizing any control tasks (3D, multi-view, pose-guided, try-on, etc.) with the FLUX model! "
      }
    ]
  },
  {
    "number": 22,
    "title": "is support sd3.5 or sdxl",
    "created_at": "2024-11-27T03:48:58Z",
    "closed_at": "2024-11-28T13:56:38Z",
    "labels": [],
    "url": "https://github.com/Yuanshi9815/OminiControl/issues/22",
    "body": null,
    "comments_url": "https://api.github.com/repos/Yuanshi9815/OminiControl/issues/22/comments",
    "author": "libai-lab",
    "comments": [
      {
        "user": "Yuanshi9815",
        "created_at": "2024-11-28T13:56:38Z",
        "body": "Currently, we do not support StableDiffusion 3.5 or StableDiffusion XL. We also don't have immediate plans to add support for these models. ðŸ˜¬"
      }
    ]
  },
  {
    "number": 18,
    "title": "Can it be used commercially?",
    "created_at": "2024-11-26T15:48:36Z",
    "closed_at": "2024-12-10T11:01:01Z",
    "labels": [],
    "url": "https://github.com/Yuanshi9815/OminiControl/issues/18",
    "body": null,
    "comments_url": "https://api.github.com/repos/Yuanshi9815/OminiControl/issues/18/comments",
    "author": "vic-aace",
    "comments": [
      {
        "user": "Yuanshi9815",
        "created_at": "2024-12-10T11:01:01Z",
        "body": "Hi @vic-aace ,\r\n\r\nWe've updated the project to use the Apache License 2.0, which is now clearly documented in our LICENSE file."
      }
    ]
  },
  {
    "number": 16,
    "title": "How to keep the text correct in the generated images?",
    "created_at": "2024-11-26T08:14:57Z",
    "closed_at": "2024-11-26T09:48:41Z",
    "labels": [],
    "url": "https://github.com/Yuanshi9815/OminiControl/issues/16",
    "body": "I see penguin images with different text in them. I think they are generated by an image + text prompt (viewed as a subject-driven generation task). While previous methods like Stable Diffusion (SD) struggle to keep the text in the image accurate, how does OmniControl achieve this? Does it benefit from a powerful base model like Flux or a specialized training dataset? Thanks!",
    "comments_url": "https://api.github.com/repos/Yuanshi9815/OminiControl/issues/16/comments",
    "author": "YuyangYin",
    "comments": [
      {
        "user": "Yuanshi9815",
        "created_at": "2024-11-26T09:48:41Z",
        "body": "Thanks for your attention! The capability of text generation is inherent in FLUX. It does not benefit from our training."
      }
    ]
  },
  {
    "number": 15,
    "title": "Will the training script be released?",
    "created_at": "2024-11-26T07:58:20Z",
    "closed_at": "2024-12-26T07:07:16Z",
    "labels": [],
    "url": "https://github.com/Yuanshi9815/OminiControl/issues/15",
    "body": "Thanks for this great work, and I am wondering will you release the training script? \r\nAlso looking forward to the Comfyui version which could support adding other loras and tools.\r\nThat would help a lot if it is possible. ",
    "comments_url": "https://api.github.com/repos/Yuanshi9815/OminiControl/issues/15/comments",
    "author": "XueniLuo",
    "comments": [
      {
        "user": "Yuanshi9815",
        "created_at": "2024-11-26T09:40:05Z",
        "body": "Thanks for your kind words. Yes, releasing the training codes is on our TODO list. #7 "
      },
      {
        "user": "XueniLuo",
        "created_at": "2024-11-27T08:27:57Z",
        "body": "> Thanks for your kind words. Yes, releasing the training codes is on our TODO list. #7\r\n\r\nReally excited to hear this! looking forward to your new release : D"
      },
      {
        "user": "Yuanshi9815",
        "created_at": "2024-12-26T07:07:16Z",
        "body": "Training codes are released. Now you can create your own OminiControl model by customizing any control tasks (3D, multi-view, pose-guided, try-on, etc.) with the FLUX model! "
      }
    ]
  },
  {
    "number": 12,
    "title": "Why Positions set to (0,0( in Flux.1",
    "created_at": "2024-11-26T06:46:53Z",
    "closed_at": "2024-11-26T10:36:32Z",
    "labels": [],
    "url": "https://github.com/Yuanshi9815/OminiControl/issues/12",
    "body": "Hi, thanks for clear explanation of DiT architectures at the paper. I want to ask a question about your statement:\r\n\r\n\"the text condition tokens CT have their query and key projections defined in the same way, with all text token positions set to (0, 0) in FLUX.1\". \r\n\r\nDo you know the resason or have an idea for that?",
    "comments_url": "https://api.github.com/repos/Yuanshi9815/OminiControl/issues/12/comments",
    "author": "Oguzhanercan",
    "comments": [
      {
        "user": "Yuanshi9815",
        "created_at": "2024-11-26T10:36:32Z",
        "body": "Hi, this positional indexing design for text tokens was implemented by Black Forest Labs."
      }
    ]
  },
  {
    "number": 11,
    "title": "Can other conditions be used as control signals?",
    "created_at": "2024-11-26T02:11:44Z",
    "closed_at": "2024-11-26T10:12:45Z",
    "labels": [],
    "url": "https://github.com/Yuanshi9815/OminiControl/issues/11",
    "body": "Thank you for such excellent work. I am very interested in your work. \r\nCan other control conditions (semantic segmentation maps, sketches, etc.) be used as control images? \r\n\r\nI am a little confused. Most of the research work claiming to be controllable focuses more on edge/canny maps and depth maps, and few studies focus on semantic segmentation maps and sketches (in the generative models of sdxl and Flux versions). Is it because the result is not good or there is little demand?",
    "comments_url": "https://api.github.com/repos/Yuanshi9815/OminiControl/issues/11/comments",
    "author": "huo852yan",
    "comments": [
      {
        "user": "Yuanshi9815",
        "created_at": "2024-11-26T05:13:46Z",
        "body": "This is a good question. While we haven't trained the model on other control conditions such as segmentation maps and sketches, we believe OmniControl could potentially handle these tasks.\r\n\r\nRegarding why most research works (including our OminiControl) focus on canny edge-to-image tasks -- we think it's primarily because canny edges provide a straightforward way to demonstrate a method's capability for condition controlling. Since it's relatively easy to extract canny edges from target images, this makes it convenient for implementation and experimental validation."
      },
      {
        "user": "huo852yan",
        "created_at": "2024-11-26T09:52:59Z",
        "body": "Thanks for your reply. \r\n\r\nI am currently concentrating on achieving precise alignment in image generation using sparse guidance conditions, such as semantic segmentation maps and sketches. \r\n\r\nYour work has provided me with new inspiration. I look forward to exploring more of your research and hope for the opportunity to engage in further discussions with youðŸ˜Š"
      },
      {
        "user": "Yuanshi9815",
        "created_at": "2024-11-26T10:13:30Z",
        "body": "Thank you for your interest! Feel free to reach out anytime for discussion."
      }
    ]
  },
  {
    "number": 7,
    "title": "Is there any plan to release fine-tune code?",
    "created_at": "2024-11-25T15:47:47Z",
    "closed_at": "2024-11-27T02:23:20Z",
    "labels": [],
    "url": "https://github.com/Yuanshi9815/OminiControl/issues/7",
    "body": "great work !",
    "comments_url": "https://api.github.com/repos/Yuanshi9815/OminiControl/issues/7/comments",
    "author": "JoshonSmith",
    "comments": [
      {
        "user": "Yuanshi9815",
        "created_at": "2024-11-26T04:27:14Z",
        "body": "Thanks for your kind words! Yes, releasing the training codes is on our TODO list."
      },
      {
        "user": "JoshonSmith",
        "created_at": "2024-11-27T02:23:18Z",
        "body": "> Thanks for your kind words! Yes, releasing the training codes is on our TODO list.\r\n\r\nðŸ‘ðŸ»"
      },
      {
        "user": "Oguzhanercan",
        "created_at": "2024-12-09T10:40:16Z",
        "body": "@Yuanshi9815 hi, when are you gonna release the train code ? "
      }
    ]
  },
  {
    "number": 6,
    "title": "How can I use an existing Flux installation with this?",
    "created_at": "2024-11-25T12:35:44Z",
    "closed_at": "2024-11-26T09:43:44Z",
    "labels": [],
    "url": "https://github.com/Yuanshi9815/OminiControl/issues/6",
    "body": "Smoothbrain here, how do I modify the code to make it use an existing Flux installation? I'd rather not download another 30+ gbs of models when I already have them. Thank you.",
    "comments_url": "https://api.github.com/repos/Yuanshi9815/OminiControl/issues/6/comments",
    "author": "EightiesPower",
    "comments": [
      {
        "user": "lior007",
        "created_at": "2024-11-25T17:37:08Z",
        "body": "> Smoothbrain here, how do I modify the code to make it use an existing Flux installation? I'd rather not download another 30+ gbs of models when I already have them. Thank you.\r\n\r\nYou asked an important question - waiting for an answer as well"
      },
      {
        "user": "Yuanshi9815",
        "created_at": "2024-11-26T09:43:44Z",
        "body": "Our implementation is based on the official Flux diffusers model. If you already have Flux installed, you only need to download our additional model weights which are relatively small (30-50MB)."
      }
    ]
  },
  {
    "number": 4,
    "title": "What's the actual name?",
    "created_at": "2024-11-25T09:13:58Z",
    "closed_at": "2024-11-25T09:37:12Z",
    "labels": [],
    "url": "https://github.com/Yuanshi9815/OminiControl/issues/4",
    "body": "Paper says \"Omini\" but the conclusion says \"omni\", twice. The Readme of this repo says \"Omini\", except the \"Features\" part refers to it as \"Omni\".\r\nWas the project called OmniControl originally and then switched to \"OminiControl\"? Does Omini has a meaning (I can't find any)?",
    "comments_url": "https://api.github.com/repos/Yuanshi9815/OminiControl/issues/4/comments",
    "author": "Qu3tzal",
    "comments": [
      {
        "user": "Yuanshi9815",
        "created_at": "2024-11-25T09:22:03Z",
        "body": "Thank you for pointing that out. The name is indeed \"OminiControl,\" not \"OmniControl.\" We will correct it in the paper. \r\n\r\n\"Omini\" combines \"omni\" and \"mini\" to reflect the strengths of our framework. Itâ€™s a unified and versatile image-guided generation framework that achieves great results while requiring only minimal additional parameters and network modifications."
      },
      {
        "user": "Qu3tzal",
        "created_at": "2024-11-25T09:37:12Z",
        "body": "Understood, thank you!"
      }
    ]
  },
  {
    "number": 3,
    "title": "Is Lora scale for non-condition tokens set to 0 during training?",
    "created_at": "2024-11-25T08:21:15Z",
    "closed_at": "2024-11-26T02:21:11Z",
    "labels": [],
    "url": "https://github.com/Yuanshi9815/OminiControl/issues/3",
    "body": "Hi, thanks for sharing your great work. \r\n\r\nIt is mentioned that the LoRA scale is set to 0 when processing non-condition tokens. I wonder if this setting takes effect during training, and how much improvement can it bring by setting non-condition tokens 0 lora scale?\r\n\r\nBy the way, is there any plan to share the training code? \r\n\r\nThank you !",
    "comments_url": "https://api.github.com/repos/Yuanshi9815/OminiControl/issues/3/comments",
    "author": "FlyHighest",
    "comments": [
      {
        "user": "Yuanshi9815",
        "created_at": "2024-11-25T08:38:50Z",
        "body": "Hi, thank you for your interest in our work!\r\n\r\nYes, this is one of our settings, and it is applied during training as well. However, we havenâ€™t conducted ablation experiments specifically to evaluate the impact of setting the LoRA scale to 0 for non-condition tokens. The primary motivation behind this design is to enhance flexibility and prepare for future support of multi-condition scenarios.\r\n\r\nThanks again for reaching out!"
      }
    ]
  }
]