[
  {
    "number": 235,
    "title": "Can the inference mode change into video interpolation generation using the first image and last image as condition?",
    "created_at": "2025-01-21T12:52:41Z",
    "closed_at": "2025-02-08T08:53:38Z",
    "labels": [],
    "url": "https://github.com/jy0205/Pyramid-Flow/issues/235",
    "body": "Hoping for your kindly answer! Thanks!",
    "comments_url": "https://api.github.com/repos/jy0205/Pyramid-Flow/issues/235/comments",
    "author": "0Godness",
    "comments": [
      {
        "user": "feifeiobama",
        "created_at": "2025-01-24T06:53:49Z",
        "body": "It does not currently support this. One of the main limitations of autoregressive video generation is that it does not support bidirectional information flow. So it would be non-trivial to adapt it for video interpolation."
      },
      {
        "user": "0Godness",
        "created_at": "2025-02-08T08:53:30Z",
        "body": "> It does not currently support this. One of the main limitations of autoregressive video generation is that it does not support bidirectional information flow. So it would be non-trivial to adapt it for video interpolation.\n\nThanks！"
      }
    ]
  },
  {
    "number": 225,
    "title": "Change gradio launch to stop being public by default.",
    "created_at": "2024-12-21T17:37:52Z",
    "closed_at": "2024-12-21T19:11:41Z",
    "labels": [],
    "url": "https://github.com/jy0205/Pyramid-Flow/pull/225",
    "body": "I changed the launch argument \"share\" to false to stop creating a public link by default, since it has been requested and is a security risk.\r\n\r\nTemporary fix until a user friendly way is implemented. If that's even needed.",
    "comments_url": "https://api.github.com/repos/jy0205/Pyramid-Flow/issues/225/comments",
    "author": "VyneNave",
    "comments": [
      {
        "user": "feifeiobama",
        "created_at": "2024-12-21T19:11:53Z",
        "body": "Thank you for your contribution!"
      }
    ]
  },
  {
    "number": 212,
    "title": "Suggestion about citing f-DM in the paper",
    "created_at": "2024-12-12T05:48:12Z",
    "closed_at": "2024-12-12T11:15:46Z",
    "labels": [],
    "url": "https://github.com/jy0205/Pyramid-Flow/issues/212",
    "body": "I think paper f-DM: A Multi-stage Diffusion Model via Progressive Signal Transformation shares some similar ideas to this work: dividing the diffusion process into multiple scales, interpolating the denoising target within each scale, and preserving the variance in each jump point. The key difference is that f-DM builds on DDPM, while the work builds on Flow Matching. Considering the similarity of f-DM and this work, I suggest the authors mention f-DM in the final version of the paper to help readers learn more related works.",
    "comments_url": "https://api.github.com/repos/jy0205/Pyramid-Flow/issues/212/comments",
    "author": "SingleZombie",
    "comments": [
      {
        "user": "feifeiobama",
        "created_at": "2024-12-12T07:48:46Z",
        "body": "Thank you for bring our attention to this paper, we will update the draft to provide a more comprehensive background."
      }
    ]
  },
  {
    "number": 206,
    "title": "2. Inference Code 太慢了",
    "created_at": "2024-12-05T02:32:55Z",
    "closed_at": "2024-12-06T03:35:08Z",
    "labels": [],
    "url": "https://github.com/jy0205/Pyramid-Flow/issues/206",
    "body": "使用最新readme里面的Inference Code和flux模型。A800显卡需要1h出结果，怎么回事，很慢。原始模型在哪呢。感谢",
    "comments_url": "https://api.github.com/repos/jy0205/Pyramid-Flow/issues/206/comments",
    "author": "henbucuoshanghai",
    "comments": [
      {
        "user": "feifeiobama",
        "created_at": "2024-12-05T02:54:38Z",
        "body": "There shouldn't be any speed difference between miniflux and sd3 based versions. Could you please check if (sequential) CPU offloading is disabled?"
      },
      {
        "user": "henbucuoshanghai",
        "created_at": "2024-12-05T03:07:15Z",
        "body": "(sequential) CPU offloading is disabled，then others to cuda,it about 1 mins for a video?"
      }
    ]
  },
  {
    "number": 205,
    "title": "\"I'm unable to make any progress.\"",
    "created_at": "2024-12-01T18:25:30Z",
    "closed_at": "2024-12-02T19:14:36Z",
    "labels": [],
    "url": "https://github.com/jy0205/Pyramid-Flow/issues/205",
    "body": null,
    "comments_url": "https://api.github.com/repos/jy0205/Pyramid-Flow/issues/205/comments",
    "author": "bihmet",
    "comments": [
      {
        "user": "nitinmukesh",
        "created_at": "2024-12-02T16:30:18Z",
        "body": "What is the error in command prompt?"
      }
    ]
  },
  {
    "number": 191,
    "title": "Add Quick Start Instructions for Google Colab to README",
    "created_at": "2024-11-17T02:37:55Z",
    "closed_at": "2024-11-17T02:42:22Z",
    "labels": [],
    "url": "https://github.com/jy0205/Pyramid-Flow/pull/191",
    "body": "Hello!\r\n\r\nThis PR introduces a \"Quick Start with Google Colab\" section to the README, providing users with an alternative way to quickly try out Pyramid Flow without setting up a local environment.\r\n\r\n**Motivation:**\r\nMany users may find it challenging to configure the local environment for Pyramid Flow due to dependency management or hardware requirements. By offering a Colab-based solution, users can experience the model with minimal setup, leveraging Colab's compute resources.\r\n\r\n**Changes:**\r\n- Added a \"Quick Start with Google Colab\" section under the `Inference` section.\r\n- Provided step-by-step Colab commands, including environment setup, model download, and starting the Gradio demo.\r\n- Ensured that all necessary packages, including `gradio`, are installed as part of the instructions.\r\n\r\nThis addition aims to enhance accessibility and lower the entry barrier for users who want to experiment with Pyramid Flow quickly.\r\n\r\nI look forward to your feedback and suggestions to improve this addition.\r\nThank you for reviewing!",
    "comments_url": "https://api.github.com/repos/jy0205/Pyramid-Flow/issues/191/comments",
    "author": "shinshin86",
    "comments": [
      {
        "user": "feifeiobama",
        "created_at": "2024-11-17T02:45:47Z",
        "body": "Thank you for the commit!"
      }
    ]
  },
  {
    "number": 170,
    "title": "[WARNING]",
    "created_at": "2024-11-10T21:33:10Z",
    "closed_at": "2024-11-13T15:17:23Z",
    "labels": [],
    "url": "https://github.com/jy0205/Pyramid-Flow/issues/170",
    "body": "[WARNING] Required file 'config.json' missing in 'D:\\Pyramid-Flow-main\\pyramid_flow_model\\diffusion_transformer_768p'.",
    "comments_url": "https://api.github.com/repos/jy0205/Pyramid-Flow/issues/170/comments",
    "author": "wx331406",
    "comments": [
      {
        "user": "feifeiobama",
        "created_at": "2024-11-11T00:33:07Z",
        "body": "The warning of 'config.json' missing is completely normal and does not affect subsequent usage."
      },
      {
        "user": "wx331406",
        "created_at": "2024-11-11T12:12:54Z",
        "body": "谢谢"
      }
    ]
  },
  {
    "number": 164,
    "title": "Questions about the differences between two training scripts.",
    "created_at": "2024-11-06T06:32:13Z",
    "closed_at": "2024-11-16T16:30:39Z",
    "labels": [],
    "url": "https://github.com/jy0205/Pyramid-Flow/issues/164",
    "body": "Hi authors, thanks for the well-written code, cause I'm a novice in video generation, I'm curious about the difference between the two scripts you provided, i.e., scripts/train_pyramid_flow.sh and scripts/train_pyramid_flow_without_ar.sh. It seems like the first one is for t2v and the second one is for t2i? Does that mean I need to fine-tune separately for t2i and t2v?",
    "comments_url": "https://api.github.com/repos/jy0205/Pyramid-Flow/issues/164/comments",
    "author": "wuzy2115",
    "comments": [
      {
        "user": "feifeiobama",
        "created_at": "2024-11-06T07:26:01Z",
        "body": "Both are for t2v. The first is our proposed method (spatial pyramid + temporal pyramid), the second is just the spatial pyramid."
      }
    ]
  },
  {
    "number": 161,
    "title": "Enhancing the straightness of the flow trajectory.",
    "created_at": "2024-11-05T14:32:05Z",
    "closed_at": "2024-11-07T08:38:35Z",
    "labels": [],
    "url": "https://github.com/jy0205/Pyramid-Flow/issues/161",
    "body": "Hi! \r\n\r\nFirst of all, congrats on your great work, and thank you for open-sourcing it!\r\nCan you explain in more detail why equations 9 and 10 from the paper should enhance the straightness of the flow trajectory?\r\n\r\nThanks in advance.",
    "comments_url": "https://api.github.com/repos/jy0205/Pyramid-Flow/issues/161/comments",
    "author": "levon-khachatryan",
    "comments": [
      {
        "user": "feifeiobama",
        "created_at": "2024-11-05T15:04:50Z",
        "body": "The straightness of the flow trajectory is usually compromised when there are intersections. Sampling the endpoints independently (as in vanilla flow matching) creates random directions for each trajectory and leads to intersections. Instead, by coupling the sampling of these endpoints (as in Equations 9 and 10), we can create more organized, possibly parallel trajectories with fewer intersections, thus improving straightness."
      },
      {
        "user": "levon-khachatryan",
        "created_at": "2024-11-07T09:15:20Z",
        "body": "Thanks for the answer."
      }
    ]
  },
  {
    "number": 158,
    "title": "RuntimeError with the new flux models ",
    "created_at": "2024-11-04T10:43:57Z",
    "closed_at": "2024-11-04T14:53:42Z",
    "labels": [],
    "url": "https://github.com/jy0205/Pyramid-Flow/issues/158",
    "body": "Congratulations and thank you on this amazing work. \r\n\r\nUnfortunately when I try to use the flux models, I get the following error. It occurs both with `t2v` and `i2v` tasks with a different sized tensor. \r\n```\r\n  File \"/mnt/efs/users/vsrinivasan/Projects/Pyramid-Flow/pyramid_dit/flux_modules/modeling_flux_block.py\", line 717, in forward                                       \r\n    return self.processor(                                                         \r\n  File \"/mnt/efs/users/vsrinivasan/Projects/Pyramid-Flow/pyramid_dit/flux_modules/modeling_flux_block.py\", line 861, in __call__                                      \r\n    hidden_states, encoder_hidden_states = self.varlen_attn(                                                                                                          \r\n  File \"/mnt/efs/users/vsrinivasan/Projects/Pyramid-Flow/pyramid_dit/flux_modules/modeling_flux_block.py\", line 300, in __call__                                      \r\n    concat_qkv_tokens[:,:,0], concat_qkv_tokens[:,:,1] = apply_rope(concat_qkv_tokens[:,:,0], concat_qkv_tokens[:,:,1], image_rotary_emb[i_p])                        \r\n  File \"/mnt/efs/users/vsrinivasan/Projects/Pyramid-Flow/pyramid_dit/flux_modules/modeling_flux_block.py\", line 37, in apply_rope                                     \r\n    xq_out = freqs_cis[..., 0] * xq_[..., 0] + freqs_cis[..., 1] * xq_[..., 1]                                                                                        \r\nRuntimeError: The size of tensor a (248) must match the size of tensor b (249) at non-singleton dimension 1            \r\n```\r\n\r\nAny ideas on how I can fix this would be much appreciated. \r\n\r\nSide note: I also get this warning despite having all the models downloaded from the huggingface hub.  \r\n```\r\nAn error occurred while trying to fetch ./models_flux/causal_video_vae: Error no file named diffusion_pytorch_model.safetensors found in directory ./models_flux/causal_video_vae.                                                                                                                                                          \r\nDefaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.                                                                              \r\n```\r\n\r\nI hope these two are not related. \r\n\r\nThank you very much in advance. ",
    "comments_url": "https://api.github.com/repos/jy0205/Pyramid-Flow/issues/158/comments",
    "author": "VigneshSrinivasan10",
    "comments": [
      {
        "user": "jy0205",
        "created_at": "2024-11-04T13:19:04Z",
        "body": "Hi, this warning does nit affect the normal running. I guess this bug is because you use the incorrect width or height setting? Can you share your setting?"
      },
      {
        "user": "VigneshSrinivasan10",
        "created_at": "2024-11-04T13:46:27Z",
        "body": "Thank you for the prompt response. \r\n\r\nI am using the default setting for the task `i2v` (and `t2v`). \r\nTrying to run it on 3 GPUs in one node. No changes other than that. "
      },
      {
        "user": "jy0205",
        "created_at": "2024-11-04T14:24:02Z",
        "body": "What do you set the `width` and `height`? And do you use the multi-gpu inference?"
      },
      {
        "user": "VigneshSrinivasan10",
        "created_at": "2024-11-04T14:32:45Z",
        "body": "```      \r\nwidth = 640\r\nheight = 384\r\n``` \r\nI see that the input image is also resized with this. \r\n```\r\nimage_path = 'assets/the_great_wall.jpg'\r\nimage = Image.open(image_path).convert(\"RGB\")\r\nimage = image.resize((width, height))\r\n``` \r\nAnd I am keeping the variant as `diffusion_transformer_384p`. \r\n\r\nYes, I use multi-gpu inference by running it this way:\r\n `CUDA_VISIBLE_DEVICES=0,1,2 sh scripts/inference_multigpu.sh`\r\n\r\n"
      },
      {
        "user": "VigneshSrinivasan10",
        "created_at": "2024-11-04T14:53:42Z",
        "body": "The issue is fixed if I set: \r\n`GPUS=2`\r\n\r\nThe issue can be reproduced by setting \r\n`GPUS=3`\r\n\r\nSetting `GPUS=4` gives another new error \r\n```\r\n  File \"/mnt/efs/users/vsrinivasan/Projects/Pyramid-Flow/pyramid_dit/flux_modules/modeling_flux_block.py\", line 716, in forward                                       \r\n    return self.processor(                                                                                                                                            \r\n  File \"/mnt/efs/users/vsrinivasan/Projects/Pyramid-Flow/pyramid_dit/flux_modules/modeling_flux_block.py\", line 868, in __call__                                      \r\n    hidden_states = attn.to_out[0](hidden_states)                                                                                                                     \r\n  File \"/mnt/efs/users/vsrinivasan/Projects/Pyramid-Flow/pyramid-flow/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl      \r\n    return self._call_impl(*args, **kwargs)\r\n  File \"/mnt/efs/users/vsrinivasan/Projects/Pyramid-Flow/pyramid-flow/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n  File \"/mnt/efs/users/vsrinivasan/Projects/Pyramid-Flow/pyramid-flow/lib/python3.10/site-packages/torch/nn/modules/linear.py\", line 114, in forward\r\n    return F.linear(input, self.weight, self.bias)\r\nRuntimeError: mat1 and mat2 shapes cannot be multiplied (60x2048 and 1920x1920)\r\n```\r\n\r\nFor now, the code is running for me. Its not necessary for me to use >2 GPUS (would be nice though:). \r\nThank you very much. \r\n"
      },
      {
        "user": "QingZhong1996",
        "created_at": "2025-02-06T16:18:38Z",
        "body": "2 for pyramid_flux, 2 or 4 for pyramid_mmdit @VigneshSrinivasan10 "
      }
    ]
  },
  {
    "number": 138,
    "title": "MultiGPU fp16 Availability",
    "created_at": "2024-10-29T16:34:21Z",
    "closed_at": "2024-11-16T16:25:54Z",
    "labels": [],
    "url": "https://github.com/jy0205/Pyramid-Flow/issues/138",
    "body": "Hello,\r\nI know yall said the model isnt compatible with fp16, but then why \r\nIn the file \"app_multi_gpu_engine.py\" line 61, does it give it as an option?  Is this a feature you plan on implementing?\r\n\r\n    if model_dtype == \"bf16\":\r\n        torch_dtype = torch.bfloat16 \r\n    elif model_dtype == \"fp16\":\r\n        torch_dtype = torch.float16\r\n    else:\r\n        torch_dtype = torch.float32",
    "comments_url": "https://api.github.com/repos/jy0205/Pyramid-Flow/issues/138/comments",
    "author": "philbanjo55",
    "comments": [
      {
        "user": "feifeiobama",
        "created_at": "2024-10-29T16:49:48Z",
        "body": "Sorry, this is an oversight. We have no plans to support fp16 in the near future."
      },
      {
        "user": "unsiao",
        "created_at": "2024-11-22T16:54:13Z",
        "body": "意味着 NVIDA RTX系列无法使用？"
      },
      {
        "user": "feifeiobama",
        "created_at": "2024-11-22T20:03:48Z",
        "body": "> 意味着 NVIDA RTX系列无法使用？\r\n\r\nRTX series should be able to run the code with bf16 :)"
      }
    ]
  },
  {
    "number": 136,
    "title": "Question about \"frame_per_unit\"",
    "created_at": "2024-10-26T08:50:30Z",
    "closed_at": "2024-11-16T16:25:43Z",
    "labels": [],
    "url": "https://github.com/jy0205/Pyramid-Flow/issues/136",
    "body": "Thanks for your amazing work!\r\nI wonder how \"frame_per_unit\" is set during training, have you experimented with varying values for it during training, and can we run inference with different \"frame_per_unit\"?",
    "comments_url": "https://api.github.com/repos/jy0205/Pyramid-Flow/issues/136/comments",
    "author": "xujingUSTC",
    "comments": [
      {
        "user": "feifeiobama",
        "created_at": "2024-10-30T03:52:22Z",
        "body": "We implemented `frame_per_unit` in advance just in case the autoregressive model doesn't perform well in predicting the next single frame, so we might want it to predict multiple frames at once. In later experiments, however, we find that this is not necessary.\r\n\r\nSince we just open-sourced the training code, please feel free to use it to test your ideas."
      }
    ]
  },
  {
    "number": 130,
    "title": "请问一下目前是不是只支持英文输入？",
    "created_at": "2024-10-21T06:51:06Z",
    "closed_at": "2024-10-21T07:21:24Z",
    "labels": [],
    "url": "https://github.com/jy0205/Pyramid-Flow/issues/130",
    "body": null,
    "comments_url": "https://api.github.com/repos/jy0205/Pyramid-Flow/issues/130/comments",
    "author": "badarrrr",
    "comments": [
      {
        "user": "feifeiobama",
        "created_at": "2024-10-21T06:54:27Z",
        "body": "Yes, we used the English T5 text encoder and trained the model with English captions only."
      },
      {
        "user": "badarrrr",
        "created_at": "2024-10-21T07:21:13Z",
        "body": "谢谢回复🙇‍"
      }
    ]
  },
  {
    "number": 123,
    "title": "Do you check the number of frames for the video?",
    "created_at": "2024-10-19T11:01:41Z",
    "closed_at": "2024-10-19T11:47:59Z",
    "labels": [],
    "url": "https://github.com/jy0205/Pyramid-Flow/issues/123",
    "body": "hi\r\nJust a tip, pay attention to it.\r\nIn my experience with video models when using internet video dataset, the number of frames is usually different in each video even if the source says so, so it is better to make a filter that checks the number of video frames because the unstable distortion is caused by the different number of frames for each video.",
    "comments_url": "https://api.github.com/repos/jy0205/Pyramid-Flow/issues/123/comments",
    "author": "AA-Developer",
    "comments": [
      {
        "user": "feifeiobama",
        "created_at": "2024-10-19T11:26:56Z",
        "body": "Thank you for sharing this tip, we have carefully handled the different number of frames for each video. Stay tuned for a better model coming soon!"
      }
    ]
  },
  {
    "number": 119,
    "title": "About training detail",
    "created_at": "2024-10-18T08:19:35Z",
    "closed_at": "2024-10-20T16:14:45Z",
    "labels": [],
    "url": "https://github.com/jy0205/Pyramid-Flow/issues/119",
    "body": "Hi, thanks for sharing the great project.\r\n\r\nI have found the mmdit in your method can accept different stages as input, and different stage are concatenated in token dimension. This may require the timestep to be same in different stages but different stages have their respective timestep interval. I wonder if the training sampled for each batch only include one stage, or my understanding is wrong in something. Looking forward for your reply, and thanks again for the excellent project!",
    "comments_url": "https://api.github.com/repos/jy0205/Pyramid-Flow/issues/119/comments",
    "author": "WangFeng18",
    "comments": [
      {
        "user": "feifeiobama",
        "created_at": "2024-10-18T13:58:19Z",
        "body": "> Hi, thanks for sharing the great project.\r\n> \r\n> I have found the mmdit in your method can accept different stages as input, and different stage are concatenated in token dimension. This may require the timestep to be same in different stages but different stages have their respective timestep interval. I wonder if the training sampled for each batch only include one stage, or my understanding is wrong in something. Looking forward for your reply, and thanks again for the excellent project!\r\n\r\nIn the original implementation, we composed the training batch so that it contained different stages uniformly. In the newest version (expected to release soon), we have optimized the procedure so that it contains three stages by 25%/50%/25% which shows certain improvement."
      },
      {
        "user": "WangFeng18",
        "created_at": "2024-10-24T06:58:28Z",
        "body": "Thanks"
      }
    ]
  },
  {
    "number": 117,
    "title": "training / finetune code?",
    "created_at": "2024-10-18T07:17:19Z",
    "closed_at": "2024-11-04T04:06:11Z",
    "labels": [],
    "url": "https://github.com/jy0205/Pyramid-Flow/issues/117",
    "body": "Do you have plans to release the training and fine-tuning code in the future? Thanks.❤️",
    "comments_url": "https://api.github.com/repos/jy0205/Pyramid-Flow/issues/117/comments",
    "author": "hrcheng98",
    "comments": [
      {
        "user": "jy0205",
        "created_at": "2024-10-18T07:32:52Z",
        "body": "The training (fine-tuning) code will be released next week. By the way, we recently switched to flux architecture and retrained the model from scratch to solve the human structure and face distortion problems due to the sd3 weights. We also plan to release the new checkpoint next week (first 384p version and then 768p version after finishing training). Stay tuned!"
      },
      {
        "user": "andrearama",
        "created_at": "2024-10-29T10:32:59Z",
        "body": "Any news on when the training and flux models will be release? \r\n\r\nThanks for the great work!"
      },
      {
        "user": "jy0205",
        "created_at": "2024-10-29T10:35:13Z",
        "body": "Soon, we're almost done"
      },
      {
        "user": "feifeiobama",
        "created_at": "2024-10-30T03:48:27Z",
        "body": "We have open-sourced the training code and flux models, please feel free to use them and report any issues :D"
      }
    ]
  },
  {
    "number": 112,
    "title": "Create movie_editor.py",
    "created_at": "2024-10-16T21:49:16Z",
    "closed_at": "2025-01-31T20:21:20Z",
    "labels": [],
    "url": "https://github.com/jy0205/Pyramid-Flow/pull/112",
    "body": "A simple Gradio interface with an Extend Video tab.\r\nThis defaults to settings that work on 24GB vram and offer a simple workflow to extend videos using the last frame as the input for the generation, then stitching the two videos together. ",
    "comments_url": "https://api.github.com/repos/jy0205/Pyramid-Flow/issues/112/comments",
    "author": "ruapotato",
    "comments": [
      {
        "user": "agronholm",
        "created_at": "2024-10-21T10:41:58Z",
        "body": "By working on 24 GB vram, do you mean 768p too?"
      },
      {
        "user": "ruapotato",
        "created_at": "2024-10-27T14:01:01Z",
        "body": "Nope, but if you have the vram,  you can select the higher resolution."
      },
      {
        "user": "agronholm",
        "created_at": "2024-10-27T14:02:18Z",
        "body": "How much VRAM are we talking about, with the bf16 models?"
      }
    ]
  },
  {
    "number": 111,
    "title": "Rough estimate when training code will release",
    "created_at": "2024-10-16T21:22:39Z",
    "closed_at": "2024-11-16T16:26:09Z",
    "labels": [],
    "url": "https://github.com/jy0205/Pyramid-Flow/issues/111",
    "body": "Hi,\r\nI was wondering if you could give a rough estimate when the training code will be released? also will we be able to adjust the resolution and number of frames  for training? Thank you!",
    "comments_url": "https://api.github.com/repos/jy0205/Pyramid-Flow/issues/111/comments",
    "author": "jcho19",
    "comments": [
      {
        "user": "jy0205",
        "created_at": "2024-10-17T09:59:34Z",
        "body": "We are still working on the new model checkpoint and will share the training code after that.  About one week. Thanks for your attention again."
      },
      {
        "user": "feifeiobama",
        "created_at": "2024-10-30T03:44:05Z",
        "body": "We have open-sourced the training code, please feel free to use them and report any issues."
      }
    ]
  },
  {
    "number": 110,
    "title": "Add portrait mode",
    "created_at": "2024-10-16T17:57:09Z",
    "closed_at": "2024-10-20T16:11:50Z",
    "labels": [],
    "url": "https://github.com/jy0205/Pyramid-Flow/issues/110",
    "body": "Hey guys, please add portrait mode (when detected the image to image-video is in portrait ratio.\r\ni tried to swap resolution on app.py, it \"works\" but the video get scrambled after 2-3 frames!\r\n\r\nThanks.",
    "comments_url": "https://api.github.com/repos/jy0205/Pyramid-Flow/issues/110/comments",
    "author": "RodTDai",
    "comments": [
      {
        "user": "feifeiobama",
        "created_at": "2024-10-16T18:08:10Z",
        "body": "Thank you for your valuable feedback. Our model does not support portrait mode because most open-source video training data is widescreen."
      },
      {
        "user": "RodTDai",
        "created_at": "2024-10-19T19:56:12Z",
        "body": "ah, that is understandable... \r\nneverheless, i'm wondering, if we generate in landscape mode and adjust the crop to match the portrait in a second step?\r\ni mean, this is probably what commercial ones do, right? because in my tests(in comercial ones), the landscape and portrait generations does not differ, so i think it is acting in same training data (landscape) even when producing portrait outputs that matches image. Thanks for the good work!\r\nThe main think i believe need to be addressed is consistency, right now the elements on image morpth too much or too fast."
      },
      {
        "user": "feifeiobama",
        "created_at": "2024-10-20T03:55:33Z",
        "body": "Thank you for the valuable advice. I think the portrait mode can be supported by finetuning the model with the corresponding videos. We are working on the consistency issue and will share a new video generation checkpoint soon."
      }
    ]
  },
  {
    "number": 107,
    "title": "text encoder network details?",
    "created_at": "2024-10-16T07:16:21Z",
    "closed_at": "2024-10-17T08:56:27Z",
    "labels": [],
    "url": "https://github.com/jy0205/Pyramid-Flow/issues/107",
    "body": "I noticed that in your code, for the text encoder part, you used the clip and T5 models. Based on this, I have two questions: 1. Will the clip and T5 models update parameters during training? 2. What is the difference between these two clip models?\r\nLooking forward to your answer, thank you",
    "comments_url": "https://api.github.com/repos/jy0205/Pyramid-Flow/issues/107/comments",
    "author": "xuzukang",
    "comments": [
      {
        "user": "feifeiobama",
        "created_at": "2024-10-16T07:31:15Z",
        "body": "We followed SD3 in the text encoder design, where these models are frozen during training. The two CLIP models are used separately for the text branch of MM-DiT and AdaLN."
      },
      {
        "user": "xuzukang",
        "created_at": "2024-10-16T07:35:53Z",
        "body": "In training process, only the parameters of MM-DiT and VAE will be updated?"
      },
      {
        "user": "feifeiobama",
        "created_at": "2024-10-16T07:53:07Z",
        "body": "> In training process, only the parameters of MM-DiT and VAE will be updated?\r\n\r\nThe VAE is also frozen during training. We used pre-extracted VAE latents to train the MM-DiT."
      },
      {
        "user": "xuzukang",
        "created_at": "2024-10-16T11:57:53Z",
        "body": "> > In training process, only the parameters of MM-DiT and VAE will be updated?\r\n> \r\n> The VAE is also frozen during training. We used pre-extracted VAE latents to train the MM-DiT.\r\n>\r\n> Thank you very much for your answer, can I understand it as: The paper states that vae comes from MAGVIT, which means that vae encoder and vae decoder both come from the MAGVIT model and are not need training. only the MM-DiT needs trained?\r\n"
      },
      {
        "user": "xuzukang",
        "created_at": "2024-10-16T12:07:00Z",
        "body": "> > > In training process, only the parameters of MM-DiT and VAE will be updated?\r\n> > \r\n> > \r\n> > The VAE is also frozen during training. We used pre-extracted VAE latents to train the MM-DiT.\r\n> > Thank you very much for your answer, can I understand it as: The paper states that vae comes from MAGVIT, which means that vae encoder and vae decoder both come from the MAGVIT model and are not need training. only the MM-DiT needs trained?\r\n\r\n>Thank you for your great work. I really want to figure out the composition of each part of pyramid-flow: I now know that CLIP_1, CLIP_2, T5, MM-DiT come from SD3, of which only MM-DiT needs to be trained in pyramid-flow, VAE-encoder comes from MAGVIT and does not need to be trained. So where does VAE-decoder come from and does it need to be trained?"
      },
      {
        "user": "feifeiobama",
        "created_at": "2024-10-16T12:31:53Z",
        "body": "The VAE encoder and decoder were trained from scratch, with some of the key design choices following MAGVIT-v2."
      },
      {
        "user": "xuzukang",
        "created_at": "2024-10-16T12:50:34Z",
        "body": ">> The VAE encoder and decoder were trained from scratch, with some of the key design choices following MAGVIT-v2.\r\n\r\n>Got it, thank you very much for your answer"
      }
    ]
  },
  {
    "number": 106,
    "title": "Can you share part of you train code to compute loss?",
    "created_at": "2024-10-15T23:27:57Z",
    "closed_at": "2024-11-04T04:07:09Z",
    "labels": [],
    "url": "https://github.com/jy0205/Pyramid-Flow/issues/106",
    "body": null,
    "comments_url": "https://api.github.com/repos/jy0205/Pyramid-Flow/issues/106/comments",
    "author": "cene555",
    "comments": [
      {
        "user": "feifeiobama",
        "created_at": "2024-10-16T01:34:13Z",
        "body": "We are still working on the new model checkpoint, and will share the training code after that."
      },
      {
        "user": "feifeiobama",
        "created_at": "2024-10-30T03:43:57Z",
        "body": "We have open-sourced the training code, please feel free to use them and report any issues."
      }
    ]
  },
  {
    "number": 105,
    "title": "Out of memory error running 2GPU RTX 3060 and RTX 4070",
    "created_at": "2024-10-15T18:16:14Z",
    "closed_at": "2024-11-04T04:06:30Z",
    "labels": [],
    "url": "https://github.com/jy0205/Pyramid-Flow/issues/105",
    "body": "I have a RTX 3060 and RTX 4070 in my system, both 12GB. \r\nSince the X server runs on my RTX 4070 I have only about 11GB VRAM there so with X server running, I can run the single GPU script on the project page successfully only on the RTX 3060. If I switch to run mode 3 (no X sever) then I can run that script on either GPU.\r\nI updated my git repo to current code as of today, Oct 15\r\nI tried text to video with the scripts/inference_multigpu.sh script. I changed the inference_multigpu.py script to set cpu_offloading=True in both places and that did not help.\r\nI tried adding model.enable_sequential_cpu_offload()  and that did not help.\r\nI tried adding model.enable_sequential_cpu_offload() just before the model.to.vae(device) statement and that did not help.\r\nI get the out of memory error for both the 384P and 768P models.\r\nIs the intent of the multi-GPU support to cut memory usage in each GPU by about half and split a single frame's generation across both GPUs or is it to speed up generation by generating single frame each on separate GPUs to shorten run time?",
    "comments_url": "https://api.github.com/repos/jy0205/Pyramid-Flow/issues/105/comments",
    "author": "drwootton",
    "comments": [
      {
        "user": "feifeiobama",
        "created_at": "2024-10-16T01:28:52Z",
        "body": "The intents of multi-gpu infeence are both to reduce memory usage and to speed up. But (1) we haven't tested it with CPU offloading, (2) it's based on Sequence Parallelism, so it requires loading the model on each GPU which has a certain lower bound rather than directly halving the GPU usage.\r\n\r\nFor now, we suggest trying out CPU offloading with the single-GPU inference script, which should be able to run within 12GB memory."
      }
    ]
  },
  {
    "number": 99,
    "title": "生成的视频是黑屏",
    "created_at": "2024-10-14T05:35:00Z",
    "closed_at": "2024-10-29T19:08:19Z",
    "labels": [],
    "url": "https://github.com/jy0205/Pyramid-Flow/issues/99",
    "body": "非常棒的项目，感谢作者开源\r\nRT，生成后，时长是对的，但是播放是黑屏，这是什么原因？",
    "comments_url": "https://api.github.com/repos/jy0205/Pyramid-Flow/issues/99/comments",
    "author": "theoldsong",
    "comments": [
      {
        "user": "sunflower110",
        "created_at": "2024-10-14T05:47:25Z",
        "body": "你是否使用的是fp16数据类型，我也遇到同样的问题"
      },
      {
        "user": "feifeiobama",
        "created_at": "2024-10-14T06:19:02Z",
        "body": "Our model does not support FP16. Please use FP32 if your device does not support BF16. (1) With (sequential) CPU offloading, this may become feasible, but will require more VRAM than our reported 8GB requirement. (2) It would help if you have multiple GPUs to use the multi-GPU inference feature."
      },
      {
        "user": "theoldsong",
        "created_at": "2024-10-14T06:57:46Z",
        "body": "> 你是否使用的是fp16数据类型，我也遇到同样的问题\r\n\r\n是的"
      }
    ]
  },
  {
    "number": 96,
    "title": "Does Pyramid-Flow support video2video?",
    "created_at": "2024-10-13T23:37:45Z",
    "closed_at": "2024-10-15T12:27:38Z",
    "labels": [],
    "url": "https://github.com/jy0205/Pyramid-Flow/issues/96",
    "body": null,
    "comments_url": "https://api.github.com/repos/jy0205/Pyramid-Flow/issues/96/comments",
    "author": "cene555",
    "comments": [
      {
        "user": "feifeiobama",
        "created_at": "2024-10-14T02:16:09Z",
        "body": "No, it does not. I believe Pyramid Flow is a specific design for generation, and would not work well with video2video translation. This is due to too much information loss in the early pyramid stages. However, it may be interesting to test an hourglass-like flow for video2video translation."
      }
    ]
  },
  {
    "number": 94,
    "title": "Make cpu offloading the default when sequential is enabled",
    "created_at": "2024-10-13T21:44:26Z",
    "closed_at": "2024-10-14T02:12:39Z",
    "labels": [],
    "url": "https://github.com/jy0205/Pyramid-Flow/pull/94",
    "body": "This makes cpu offloading the default when sequential is enabled, in order to fix #87 ",
    "comments_url": "https://api.github.com/repos/jy0205/Pyramid-Flow/issues/94/comments",
    "author": "Ednaordinary",
    "comments": [
      {
        "user": "feifeiobama",
        "created_at": "2024-10-14T02:13:48Z",
        "body": "Makes sense, thank you for the commit"
      }
    ]
  },
  {
    "number": 93,
    "title": "image generation?",
    "created_at": "2024-10-13T21:36:20Z",
    "closed_at": "2024-10-14T09:20:39Z",
    "labels": [],
    "url": "https://github.com/jy0205/Pyramid-Flow/issues/93",
    "body": "if duration set to 1 - may be output PNG for testing t2v first frame?\r\njust an idea\r\nrequiring  fixing seed of course",
    "comments_url": "https://api.github.com/repos/jy0205/Pyramid-Flow/issues/93/comments",
    "author": "ptits",
    "comments": [
      {
        "user": "dillfrescott",
        "created_at": "2024-10-13T22:07:02Z",
        "body": "I think you might be better off using flux if you want to do text to image as it can't do video but might yield higher results on single frames."
      },
      {
        "user": "feifeiobama",
        "created_at": "2024-10-14T02:21:02Z",
        "body": "The image generation capability of this model is from 100m+ images (and 10m video initial frames), with some knowledge inherited from SD3. The training dataset is very small, so we suggest using specialized image generation models instead."
      }
    ]
  },
  {
    "number": 90,
    "title": "prompting style",
    "created_at": "2024-10-13T21:11:57Z",
    "closed_at": "2024-10-20T16:10:15Z",
    "labels": [],
    "url": "https://github.com/jy0205/Pyramid-Flow/issues/90",
    "body": "should it be more natural text like for SD3 and Flux (due to DiT)?\r\nor it has been trained on oldschool danburu tags and shamanic language of SD1.5 and we need to use all this 1girl, artstation and so on\r\n\r\n\r\n\r\n",
    "comments_url": "https://api.github.com/repos/jy0205/Pyramid-Flow/issues/90/comments",
    "author": "ptits",
    "comments": [
      {
        "user": "feifeiobama",
        "created_at": "2024-10-14T02:12:18Z",
        "body": "I suppose short natural text is more suitable. This is due to (1) we use T5 text encoder as in SD3 and FLUX so it supports natural text well. (2) during recaptioning, we set our recaptioner (Video-LLaMA2) to produce short natural caption without tags.\r\n\r\nThat being said, since we used some image dataset where  the caption may not look like natural text (e.g. MidJourney synthetic dataset), our model may work better with proper tags. I am not a prompting expert and haven't tested the effect of those tags."
      },
      {
        "user": "ptits",
        "created_at": "2024-10-14T09:15:37Z",
        "body": "thanks for reply\r\nI will make more tests\r\n\r\nit looks like model TRIES to understand natural language but is very dependent to dataset"
      }
    ]
  },
  {
    "number": 89,
    "title": "positive prompt",
    "created_at": "2024-10-13T21:07:59Z",
    "closed_at": "2024-10-20T16:10:11Z",
    "labels": [],
    "url": "https://github.com/jy0205/Pyramid-Flow/issues/89",
    "body": "I see it has been added with\r\nprompt = prompt + \", hyper quality, Ultra HD, 8K\" \r\n\r\nI am not sure it is good idea to have hidden addition to prompt\r\n\r\nIt can be in conflict with some user ideas.\r\nSo user can add it himself if needed (imho)\r\n\r\n",
    "comments_url": "https://api.github.com/repos/jy0205/Pyramid-Flow/issues/89/comments",
    "author": "ptits",
    "comments": [
      {
        "user": "feifeiobama",
        "created_at": "2024-10-14T03:47:06Z",
        "body": "Thank you for raising this issue. We added this prompt because it improves the realism and quality of the first generated frame, which is helpful for subsequent video generation. Although this prompt may conflict with stylistic generation, we recommend keeping it for other generation purposes."
      }
    ]
  },
  {
    "number": 88,
    "title": "Negative prompt",
    "created_at": "2024-10-13T21:04:58Z",
    "closed_at": "2024-10-20T16:09:55Z",
    "labels": [],
    "url": "https://github.com/jy0205/Pyramid-Flow/issues/88",
    "body": "Will it work? I see it is presented as an argument for model input and defaulted to:\r\n\"cartoon style, worst quality, low quality, blurry, absolute black, absolute white, low res, extra limbs, extra digits, misplaced objects, mutated anatomy, monochrome, horror\"\r\n\r\n\r\nI did not test it - just need to ask, does it make sense to play with it? Will it influence generation?",
    "comments_url": "https://api.github.com/repos/jy0205/Pyramid-Flow/issues/88/comments",
    "author": "ptits",
    "comments": [
      {
        "user": "feifeiobama",
        "created_at": "2024-10-14T03:42:34Z",
        "body": "Yes, we find that the negative prompt is helpful for both visual quality and temporal stability. We do not yet know the mechanism, as the captions we used did not include these prompts. We will investigate this in the new model training process."
      }
    ]
  },
  {
    "number": 87,
    "title": "NotImplementedError: Cannot copy out of meta tensor; no data!",
    "created_at": "2024-10-13T20:46:45Z",
    "closed_at": "2024-10-14T02:12:40Z",
    "labels": [],
    "url": "https://github.com/jy0205/Pyramid-Flow/issues/87",
    "body": "```python\r\nimport torch\r\nfrom PIL import Image\r\nfrom pyramid_dit import PyramidDiTForVideoGeneration\r\nfrom diffusers.utils import load_image, export_to_video\r\nfrom accelerate import Accelerator, cpu_offload\r\n\r\ntorch.cuda.set_device(0)\r\nmodel_dtype, torch_dtype = 'bf16', torch.bfloat16   # Use bf16 (not support fp16 yet)\r\n\r\nmodel = PyramidDiTForVideoGeneration(\r\n    'PATH',                                         # The downloaded checkpoint dir\r\n    model_dtype,\r\n    model_variant='diffusion_transformer_768p',     # 'diffusion_transformer_384p'\r\n)\r\n\r\nmodel.vae.enable_tiling()\r\nmodel.enable_sequential_cpu_offload()\r\n\r\nprompt = \"A dog walking on the beach.\"\r\n\r\nwith torch.no_grad(), torch.cuda.amp.autocast(enabled=True, dtype=torch_dtype):\r\n    frames = model.generate(\r\n        prompt=prompt,\r\n        num_inference_steps=[20, 20, 20],\r\n        video_num_inference_steps=[10, 10, 10],\r\n        height=768,     \r\n        width=1280,\r\n        temp=31,                    # temp=16: 5s, temp=31: 10s\r\n        guidance_scale=9.0,         # The guidance for the first frame, set it to 7 for 384p variant\r\n        video_guidance_scale=5.0,   # The guidance for the other video latent\r\n        output_type=\"pil\",\r\n        save_memory=True,           # If you have enough GPU memory, set it to `False` to improve vae decoding speed\r\n    )\r\n\r\nexport_to_video(frames, \"./text_to_video_sample.mp4\", fps=24)\r\n```\r\n\r\nWith this config it says:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"text.py\", line 22, in <module>\r\n    frames = model.generate(\r\n  File \"C:\\Users\\cross\\miniconda3\\envs\\pyramid\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 115, in decorate_context\r\n    return func(*args, **kwargs)\r\n  File \"C:\\Users\\cross\\Downloads\\Pyramid-Flow\\pyramid_dit\\pyramid_dit_for_video_gen_pipeline.py\", line 586, in generate\r\n    prompt_embeds, prompt_attention_mask, pooled_prompt_embeds = self.text_encoder(prompt, device)\r\n  File \"C:\\Users\\cross\\miniconda3\\envs\\pyramid\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1518, in _wrapped_call_impl\r\n    return self._call_impl(*args, **kwargs)\r\n  File \"C:\\Users\\cross\\miniconda3\\envs\\pyramid\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1527, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n  File \"C:\\Users\\cross\\miniconda3\\envs\\pyramid\\lib\\site-packages\\accelerate\\hooks.py\", line 166, in new_forward\r\n    output = module._old_forward(*args, **kwargs)\r\n  File \"C:\\Users\\cross\\Downloads\\Pyramid-Flow\\pyramid_dit\\modeling_text_encoder.py\", line 138, in forward\r\n    prompt_embeds, prompt_attention_mask, pooled_prompt_embeds = self.encode_prompt(input_prompts, 1, clip_skip=None, device=device)\r\n  File \"C:\\Users\\cross\\Downloads\\Pyramid-Flow\\pyramid_dit\\modeling_text_encoder.py\", line 113, in encode_prompt\r\n    pooled_prompt_embed = self._get_clip_prompt_embeds(\r\n  File \"C:\\Users\\cross\\Downloads\\Pyramid-Flow\\pyramid_dit\\modeling_text_encoder.py\", line 98, in _get_clip_prompt_embeds\r\n    prompt_embeds = text_encoder(text_input_ids.to(device), output_hidden_states=True)\r\n  File \"C:\\Users\\cross\\miniconda3\\envs\\pyramid\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1518, in _wrapped_call_impl\r\n    return self._call_impl(*args, **kwargs)\r\n  File \"C:\\Users\\cross\\miniconda3\\envs\\pyramid\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1527, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n  File \"C:\\Users\\cross\\miniconda3\\envs\\pyramid\\lib\\site-packages\\transformers\\models\\clip\\modeling_clip.py\", line 1216, in forward\r\n    text_outputs = self.text_model(\r\n  File \"C:\\Users\\cross\\miniconda3\\envs\\pyramid\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1518, in _wrapped_call_impl\r\n    return self._call_impl(*args, **kwargs)\r\n  File \"C:\\Users\\cross\\miniconda3\\envs\\pyramid\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1527, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n  File \"C:\\Users\\cross\\miniconda3\\envs\\pyramid\\lib\\site-packages\\transformers\\models\\clip\\modeling_clip.py\", line 699, in forward\r\n    hidden_states = self.embeddings(input_ids=input_ids, position_ids=position_ids)\r\n  File \"C:\\Users\\cross\\miniconda3\\envs\\pyramid\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1518, in _wrapped_call_impl\r\n    return self._call_impl(*args, **kwargs)\r\n  File \"C:\\Users\\cross\\miniconda3\\envs\\pyramid\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1527, in _call_impl\r\n    return forward_call(*args, **kwargs)\r\n  File \"C:\\Users\\cross\\miniconda3\\envs\\pyramid\\lib\\site-packages\\accelerate\\hooks.py\", line 161, in new_forward\r\n    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)\r\n  File \"C:\\Users\\cross\\miniconda3\\envs\\pyramid\\lib\\site-packages\\accelerate\\hooks.py\", line 356, in pre_forward\r\n    return send_to_device(args, self.execution_device), send_to_device(\r\n  File \"C:\\Users\\cross\\miniconda3\\envs\\pyramid\\lib\\site-packages\\accelerate\\utils\\operations.py\", line 186, in send_to_device\r\n    {\r\n  File \"C:\\Users\\cross\\miniconda3\\envs\\pyramid\\lib\\site-packages\\accelerate\\utils\\operations.py\", line 187, in <dictcomp>\r\n    k: t if k in skip_keys else send_to_device(t, device, non_blocking=non_blocking, skip_keys=skip_keys)\r\n  File \"C:\\Users\\cross\\miniconda3\\envs\\pyramid\\lib\\site-packages\\accelerate\\utils\\operations.py\", line 158, in send_to_device\r\n    return tensor.to(device, non_blocking=non_blocking)\r\nNotImplementedError: Cannot copy out of meta tensor; no data!\r\n```\r\n\r\nWhat is wrong?",
    "comments_url": "https://api.github.com/repos/jy0205/Pyramid-Flow/issues/87/comments",
    "author": "dillfrescott",
    "comments": [
      {
        "user": "Ednaordinary",
        "created_at": "2024-10-13T21:29:10Z",
        "body": "This seems to be a by-product of trying to sequential offload when cpu_offloading is not enabled. Adding `cpu_offloading=True` to the generation call should fix this. I'll make a PR to make it the default when sequential is enabled."
      },
      {
        "user": "dillfrescott",
        "created_at": "2024-10-13T21:30:07Z",
        "body": "Okay!"
      }
    ]
  },
  {
    "number": 84,
    "title": "Optimzing the image decoding process",
    "created_at": "2024-10-13T17:38:05Z",
    "closed_at": "2024-10-13T18:00:28Z",
    "labels": [],
    "url": "https://github.com/jy0205/Pyramid-Flow/pull/84",
    "body": "This is a more memory friendly version of converting the GPU video frames to CPU and PIL that does not require any multiplications and type conversions on the numpy array.",
    "comments_url": "https://api.github.com/repos/jy0205/Pyramid-Flow/issues/84/comments",
    "author": "Quasimondo",
    "comments": [
      {
        "user": "feifeiobama",
        "created_at": "2024-10-13T18:00:45Z",
        "body": "Thank you for the commit!"
      }
    ]
  },
  {
    "number": 83,
    "title": "DO I NEED CUDA?! What about solely GPU processing?",
    "created_at": "2024-10-13T17:01:43Z",
    "closed_at": "2024-10-16T18:10:15Z",
    "labels": [],
    "url": "https://github.com/jy0205/Pyramid-Flow/issues/83",
    "body": "soo this is my output:\r\n[DEBUG] generate_text_to_video called.\r\n[INFO] Initializing model with variant='768p', using bf16 precision...\r\n[DEBUG] Model base path: C:\\Users\\user\\OneDrive\\Desktop\\coding\\Python\\Pyramid-Flow\\PATH\r\nusing half precision\r\nUsing temporal causal attention\r\nWe interp the position embedding of condition latents\r\nYou set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\r\nLoading checkpoint shards: 100%|█████████████████████████████████████████████████████████| 2/2 [00:08<00:00,  4.41s/it]\r\nThe latent dimmension channes is 16\r\nThe start sigmas and end sigmas of each stage is Start: {0: 1.0, 1: 0.8002399489209289, 2: 0.5007496155411024}, End: {0: 0.6669999957084656, 1: 0.33399999141693115, 2: 0.0}, Ori_start: {0: 1.0, 1: 0.6669999957084656, 2: 0.33399999141693115}\r\n[WARNING] CUDA is not available. Proceeding without GPU.\r\n[INFO] Model initialized successfully.\r\n[INFO] Starting text-to-video generation...\r\nC:\\Python312\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:265: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\r\n  warnings.warn(\r\n[ERROR] Error during text-to-video generation: Torch not compiled with CUDA enabled\r\n\r\n\r\nI dont want to use cuda like brooo\r\n",
    "comments_url": "https://api.github.com/repos/jy0205/Pyramid-Flow/issues/83/comments",
    "author": "Loganius-II",
    "comments": [
      {
        "user": "feifeiobama",
        "created_at": "2024-10-13T17:55:21Z",
        "body": "Our codebase only supports PyTorch with CUDA enabled, since it is more friendly for training and inference. Feel free to share your thoughts :)"
      }
    ]
  },
  {
    "number": 56,
    "title": "error with  inference_multigpu.py ",
    "created_at": "2024-10-13T00:01:53Z",
    "closed_at": "2024-10-14T03:01:08Z",
    "labels": [],
    "url": "https://github.com/jy0205/Pyramid-Flow/issues/56",
    "body": "if i run \r\n\r\ntorchrun --nproc_per_node 2 inference_multigpu.py --temp 5 --model_path \"/home/jovyan/Pyramid-Flow/pyramid_flow_model\" --sp_group_size 2\r\n\r\ni got\r\n\r\n[2024-10-13 00:16:18,649] torch.distributed.run: [WARNING] \r\n[2024-10-13 00:16:18,649] torch.distributed.run: [WARNING] *****************************************\r\n[2024-10-13 00:16:18,649] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \r\n[2024-10-13 00:16:18,649] torch.distributed.run: [WARNING] *****************************************\r\n| distributed init (rank 0): env://, gpu 0\r\nTraceback (most recent call last):\r\n  File \"inference_multigpu.py\", line 121, in <module>\r\n    main()\r\n  File \"inference_multigpu.py\", line 33, in main\r\n    init_distributed_mode(args)\r\n  File \"/home/jovyan/Pyramid-Flow/trainer_misc/utils.py\", line 90, in init_distributed_mode\r\n    torch.cuda.set_device(args.gpu)\r\n  File \"/opt/conda/envs/pyramid/lib/python3.8/site-packages/torch/cuda/__init__.py\", line 404, in set_device\r\n    torch._C._cuda_setDevice(device)\r\nRuntimeError: CUDA error: invalid device ordinal\r\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\r\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\r\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\r\n\r\n[2024-10-13 00:16:23,675] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 91207 closing signal SIGTERM\r\n[2024-10-13 00:16:23,839] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 1 (pid: 91208) of binary: /opt/conda/envs/pyramid/bin/python3.8\r\nTraceback (most recent call last):\r\n  File \"/opt/conda/envs/pyramid/bin/torchrun\", line 8, in <module>\r\n    sys.exit(main())\r\n  File \"/opt/conda/envs/pyramid/lib/python3.8/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 346, in wrapper\r\n    return f(*args, **kwargs)\r\n  File \"/opt/conda/envs/pyramid/lib/python3.8/site-packages/torch/distributed/run.py\", line 806, in main\r\n    run(args)\r\n  File \"/opt/conda/envs/pyramid/lib/python3.8/site-packages/torch/distributed/run.py\", line 797, in run\r\n    elastic_launch(\r\n  File \"/opt/conda/envs/pyramid/lib/python3.8/site-packages/torch/distributed/launcher/api.py\", line 134, in __call__\r\n    return launch_agent(self._config, self._entrypoint, list(args))\r\n  File \"/opt/conda/envs/pyramid/lib/python3.8/site-packages/torch/distributed/launcher/api.py\", line 264, in launch_agent\r\n    raise ChildFailedError(\r\ntorch.distributed.elastic.multiprocessing.errors.ChildFailedError: \r\n============================================================\r\ninference_multigpu.py FAILED\r\n------------------------------------",
    "comments_url": "https://api.github.com/repos/jy0205/Pyramid-Flow/issues/56/comments",
    "author": "ptits",
    "comments": [
      {
        "user": "feifeiobama",
        "created_at": "2024-10-13T00:28:33Z",
        "body": "According to `| distributed init (rank 0): env://, gpu 0`, the inference is only on the first GPU. You might add `CUDA_VISIBLE_DEVICES=0,1` at the beginning and see how it goes."
      },
      {
        "user": "feifeiobama",
        "created_at": "2024-10-14T03:01:02Z",
        "body": "Closed as the issue seems to be solved."
      }
    ]
  },
  {
    "number": 50,
    "title": "What is exact optimal version of python for Pyramid?",
    "created_at": "2024-10-12T16:21:52Z",
    "closed_at": "2024-10-13T00:48:02Z",
    "labels": [],
    "url": "https://github.com/jy0205/Pyramid-Flow/issues/50",
    "body": "What is exact optimal version of python for Pyramid?",
    "comments_url": "https://api.github.com/repos/jy0205/Pyramid-Flow/issues/50/comments",
    "author": "ptits",
    "comments": [
      {
        "user": "feifeiobama",
        "created_at": "2024-10-12T23:47:33Z",
        "body": "I recommend using Python 3.8.10 as we originally did."
      },
      {
        "user": "ptits",
        "created_at": "2024-10-13T00:02:56Z",
        "body": "thanks! works fine!"
      }
    ]
  },
  {
    "number": 48,
    "title": "Update opimizations to Gradio",
    "created_at": "2024-10-12T14:38:10Z",
    "closed_at": "2024-10-12T14:55:17Z",
    "labels": [],
    "url": "https://github.com/jy0205/Pyramid-Flow/pull/48",
    "body": "Now user can choose between 768p and 384p models in the UI \r\ncpuoffloading is now use by default\r\nupdates to model loader and functions\r\nhf download double checks model locally\r\nterminal --verbose with more info to the user",
    "comments_url": "https://api.github.com/repos/jy0205/Pyramid-Flow/issues/48/comments",
    "author": "tpc2233",
    "comments": [
      {
        "user": "FurkanGozukara",
        "created_at": "2024-10-12T14:41:29Z",
        "body": "very nice. i think all settings as cpu offloading or tile size like 256 128 should be optional from interface"
      },
      {
        "user": "feifeiobama",
        "created_at": "2024-10-12T14:57:02Z",
        "body": "This is very thoughtful, thank you @tpc2233 for the contribution!"
      }
    ]
  },
  {
    "number": 45,
    "title": "gradio app should be share=False by default for security",
    "created_at": "2024-10-12T07:54:04Z",
    "closed_at": "2024-10-12T23:46:19Z",
    "labels": [],
    "url": "https://github.com/jy0205/Pyramid-Flow/issues/45",
    "body": "ie last line in app.py\r\n`demo.launch(share=False)`\r\nRuns fine (but slow) on a local 24GB VRAM 4090.",
    "comments_url": "https://api.github.com/repos/jy0205/Pyramid-Flow/issues/45/comments",
    "author": "SoftologyPro",
    "comments": [
      {
        "user": "ptits",
        "created_at": "2024-10-12T08:52:07Z",
        "body": "No, please.\r\n90% runs are remotely on a100.\r\nWhere else to get 65gb of VRAM?\r\n\r\nkwargs --share can also solve this"
      }
    ]
  },
  {
    "number": 41,
    "title": "Stuck at flash attention installation",
    "created_at": "2024-10-11T20:17:46Z",
    "closed_at": "2024-10-12T23:36:30Z",
    "labels": [],
    "url": "https://github.com/jy0205/Pyramid-Flow/issues/41",
    "body": "Command prompt shows flash attention installation since an hour, but it's not dead. The ram has some activities spikes every 3-5 minutes. What should I do? Cancel it?",
    "comments_url": "https://api.github.com/repos/jy0205/Pyramid-Flow/issues/41/comments",
    "author": "Yogesh-DevHub",
    "comments": [
      {
        "user": "feifeiobama",
        "created_at": "2024-10-12T00:09:09Z",
        "body": "Yes, cancel it. We do not rely on flash attention during inference and training, since our model use a blockwise causal attention which is not supported by flash attention."
      }
    ]
  },
  {
    "number": 25,
    "title": "fp16 generates NaNs for latents",
    "created_at": "2024-10-11T01:43:01Z",
    "closed_at": "2024-10-16T18:08:50Z",
    "labels": [],
    "url": "https://github.com/jy0205/Pyramid-Flow/issues/25",
    "body": "Trying the sample code using fp16 instead of bf16, latents are generated as all NaN. Is fp16 expected to work?",
    "comments_url": "https://api.github.com/repos/jy0205/Pyramid-Flow/issues/25/comments",
    "author": "vvuk",
    "comments": [
      {
        "user": "feifeiobama",
        "created_at": "2024-10-11T02:15:15Z",
        "body": "Thank you for the feedback. We reproduced the issue, and will fix it as soon as possible."
      },
      {
        "user": "jy0205",
        "created_at": "2024-10-11T04:16:18Z",
        "body": "The whole models are trained using bf16. I guess the fp16 may not work well."
      },
      {
        "user": "vvuk",
        "created_at": "2024-10-11T04:45:07Z",
        "body": "Seems like it. fp32 seems to work fine. It would be interesting to know where the loss of precision is most an issue."
      },
      {
        "user": "zhjf3888",
        "created_at": "2024-10-12T03:38:31Z",
        "body": "> 看起来是这样的。fp32 似乎工作正常。想知道精度损失在哪里最成问题会很有趣。\r\n\r\nMy 2080ti isn't running yet."
      },
      {
        "user": "Kvento",
        "created_at": "2024-10-13T20:06:05Z",
        "body": "Any progress in fixing fp16?"
      },
      {
        "user": "feifeiobama",
        "created_at": "2024-10-14T03:07:13Z",
        "body": "> Any progress in fixing fp16?\r\n\r\nSorry, we are unable to fix this in the short term."
      }
    ]
  },
  {
    "number": 20,
    "title": "Gradio app for 720p i2v and t2v",
    "created_at": "2024-10-10T19:51:03Z",
    "closed_at": "2024-10-11T07:10:27Z",
    "labels": [],
    "url": "https://github.com/jy0205/Pyramid-Flow/pull/20",
    "body": null,
    "comments_url": "https://api.github.com/repos/jy0205/Pyramid-Flow/issues/20/comments",
    "author": "tpc2233",
    "comments": [
      {
        "user": "feifeiobama",
        "created_at": "2024-10-10T20:01:38Z",
        "body": "Thanks for the commit, which is very helpful to us. We will merge it after testing it locally."
      },
      {
        "user": "FurkanGozukara",
        "created_at": "2024-10-11T07:48:11Z",
        "body": "Any optimizations? Quant fp8 cpu offloading?\r\n\r\nThis probably would require 48gb 80gb? "
      }
    ]
  },
  {
    "number": 18,
    "title": "Can you fix the demo huggingface please?",
    "created_at": "2024-10-10T18:45:15Z",
    "closed_at": "2024-10-11T12:08:38Z",
    "labels": [],
    "url": "https://github.com/jy0205/Pyramid-Flow/issues/18",
    "body": "the question is solved thanks for replying! not sure how to delete the issue im sorry",
    "comments_url": "https://api.github.com/repos/jy0205/Pyramid-Flow/issues/18/comments",
    "author": "ghost",
    "comments": [
      {
        "user": "feifeiobama",
        "created_at": "2024-10-10T18:51:52Z",
        "body": "This is due to the GPU quota limit, the demo can only generate 25 frames at a time. We have two options to play it at 1 second & 24 fps or 3 seconds & 8 fps. We could not decide which is better, both are very unfortunate compromises.\r\n\r\nWe initially chose 3 seconds & 8 fps, but now we have added an FPS control slider so you can choose for yourself."
      },
      {
        "user": "feifeiobama",
        "created_at": "2024-10-10T19:11:17Z",
        "body": "Thank you for your suggestion, we will continue to improve the model and look into these hosting platforms."
      }
    ]
  },
  {
    "number": 17,
    "title": "License",
    "created_at": "2024-10-10T15:57:53Z",
    "closed_at": "2024-10-10T17:39:22Z",
    "labels": [],
    "url": "https://github.com/jy0205/Pyramid-Flow/issues/17",
    "body": "Could you clarify the license, please? Are the weights also available under MIT license? If so, could you explain, please, how do you base your model on SD3, if SD3 had a custom license, which is probably not commercial friendly (but I'm not a lawyer, so sorry if the wording is wrong here), while MIT allows commercial use? ",
    "comments_url": "https://api.github.com/repos/jy0205/Pyramid-Flow/issues/17/comments",
    "author": "nikolay-ulyanov",
    "comments": [
      {
        "user": "feifeiobama",
        "created_at": "2024-10-10T16:45:04Z",
        "body": "Sorry, we are not specialists in these licenses. We will modify the license of the SD3 initialized weight if there are such requests. In the meantime, we commit to releasing the next model checkpoint trained from scratch under the MIT license."
      },
      {
        "user": "nikolay-ulyanov",
        "created_at": "2024-10-10T17:00:48Z",
        "body": "Thanks for reply! Yeah, I also think MIT license would be awesome, but let's see.\r\n(Just to reiterate, I'm also not a specialist (and not a representative of stability ai anyway))"
      },
      {
        "user": "jy0205",
        "created_at": "2024-10-10T17:30:34Z",
        "body": "Thanks for your kind reminder! We have updated the model weight license based on SD3."
      }
    ]
  },
  {
    "number": 15,
    "title": "inference GPU",
    "created_at": "2024-10-10T13:43:56Z",
    "closed_at": "2024-10-10T18:24:15Z",
    "labels": [],
    "url": "https://github.com/jy0205/Pyramid-Flow/issues/15",
    "body": "hi,\r\ncan we run inference using multiple gpus ?\r\ni don't have A100, i have 4 with 24gb ech",
    "comments_url": "https://api.github.com/repos/jy0205/Pyramid-Flow/issues/15/comments",
    "author": "fefespn",
    "comments": [
      {
        "user": "jy0205",
        "created_at": "2024-10-10T13:48:40Z",
        "body": "Yes, it will be possible to use multiple GPUs for inference. We will try our best to support in the next few days."
      }
    ]
  },
  {
    "number": 14,
    "title": "Setup instructions ",
    "created_at": "2024-10-10T13:18:45Z",
    "closed_at": "2024-10-10T15:57:18Z",
    "labels": [],
    "url": "https://github.com/jy0205/Pyramid-Flow/issues/14",
    "body": "I create a new conda env on a Ubuntu 24 linux \r\nconda create --name pyramid python=3.10\r\n\r\nDid a git clone of this project and then ran pip install -r requirements.txt\r\nAnd it throws errors that it can't find a compatible scipy package and tries to build one and fail. \r\n\r\nDo you have alternate setup instructions?\r\n\r\nThanks,\r\nAsh\r\n",
    "comments_url": "https://api.github.com/repos/jy0205/Pyramid-Flow/issues/14/comments",
    "author": "AshD",
    "comments": [
      {
        "user": "feifeiobama",
        "created_at": "2024-10-10T13:24:44Z",
        "body": "Thank you for your interest in our project. We are using a Python version of 3.8.10, perhaps re-running the commands with `conda create --name ENV_NAME python==3.8.10` will solve the problem."
      },
      {
        "user": "FurkanGozukara",
        "created_at": "2024-10-10T15:25:24Z",
        "body": "@feifeiobama please upgrade to python 3.10\r\n\r\npython 3.8 is history"
      },
      {
        "user": "AshD",
        "created_at": "2024-10-10T15:57:18Z",
        "body": "Thanks python 3.8.10 worked! closing..."
      }
    ]
  },
  {
    "number": 11,
    "title": " Error no file named diffusion_pytorch_model.safetensors found in directory ",
    "created_at": "2024-10-10T10:15:46Z",
    "closed_at": "2024-10-10T11:04:45Z",
    "labels": [],
    "url": "https://github.com/jy0205/Pyramid-Flow/issues/11",
    "body": "Getting this error while following the demo codes: Actually the safetensors file isn't present when downloading the model checkpoints (verified in the folder)\r\n\r\nPlease install flash attention\r\nAn error occurred while trying to fetch /content/diffusion_transformer_384p: Error no file named diffusion_pytorch_model.safetensors found in directory /content/diffusion_transformer_384p.\r\nDefaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\r\nusing half precision\r\nUsing temporal causal attention\r\nWe interp the position embedding of condition latents",
    "comments_url": "https://api.github.com/repos/jy0205/Pyramid-Flow/issues/11/comments",
    "author": "mehulgupta2016154",
    "comments": [
      {
        "user": "jy0205",
        "created_at": "2024-10-10T10:24:29Z",
        "body": "Thanks for your attention! You can ignore this ERROR message from huggingface transformers (Since we do not use safetensors). It does not effect the usage,"
      }
    ]
  },
  {
    "number": 8,
    "title": "Very good work, when Training code release?",
    "created_at": "2024-10-10T09:29:52Z",
    "closed_at": "2024-11-04T04:07:39Z",
    "labels": [],
    "url": "https://github.com/jy0205/Pyramid-Flow/issues/8",
    "body": null,
    "comments_url": "https://api.github.com/repos/jy0205/Pyramid-Flow/issues/8/comments",
    "author": "huangjch526",
    "comments": [
      {
        "user": "Delong-liu-bupt",
        "created_at": "2024-10-10T09:37:49Z",
        "body": "+1"
      },
      {
        "user": "feifeiobama",
        "created_at": "2024-10-10T09:46:01Z",
        "body": "We are currently working on two priorities: a Huggingface demo, and a new model checkpoint trained from scratch (we have almost finished its 384p video training). We plan to start cleaning up the training code after these two issues and will release it as soon as possible."
      },
      {
        "user": "jquintanilla4",
        "created_at": "2024-10-10T12:04:34Z",
        "body": "Great work. Looking forward to learning more about the training. Thanks for the paper as well, really interesting read."
      },
      {
        "user": "runzeer",
        "created_at": "2024-10-11T04:34:31Z",
        "body": "@feifeiobama Could you release the 384p video training version in advance? Really looking forward to the details of the training."
      },
      {
        "user": "feifeiobama",
        "created_at": "2024-11-04T04:07:39Z",
        "body": "We have open-sourced the training code :D"
      }
    ]
  },
  {
    "number": 7,
    "title": "not found CombinedTimestepLabelEmbeddings ",
    "created_at": "2024-10-10T09:17:25Z",
    "closed_at": "2024-10-10T10:14:25Z",
    "labels": [],
    "url": "https://github.com/jy0205/Pyramid-Flow/issues/7",
    "body": null,
    "comments_url": "https://api.github.com/repos/jy0205/Pyramid-Flow/issues/7/comments",
    "author": "Mr-Harry",
    "comments": [
      {
        "user": "jy0205",
        "created_at": "2024-10-10T09:31:15Z",
        "body": "Thanks for your advice. We have fixed this."
      }
    ]
  },
  {
    "number": 1,
    "title": "Requirements.txt for the demo please",
    "created_at": "2024-10-10T01:50:44Z",
    "closed_at": "2024-10-10T09:28:03Z",
    "labels": [],
    "url": "https://github.com/jy0205/Pyramid-Flow/issues/1",
    "body": "Hi, it's unclear which library versions are required to run your demo, could you please provide a requirements.txt for the demo to run it in a repeatable way? Thanks!",
    "comments_url": "https://api.github.com/repos/jy0205/Pyramid-Flow/issues/1/comments",
    "author": "CoffeeVampir3",
    "comments": [
      {
        "user": "jy0205",
        "created_at": "2024-10-10T04:13:03Z",
        "body": "Thanks for your suggestions! We have attached the requirements.txt."
      }
    ]
  }
]