[
  {
    "number": 401,
    "title": "Error with Finetune API: Value error, Suspicious file attributes detected: 001.jpg",
    "created_at": "2025-01-17T17:26:35Z",
    "closed_at": "2025-01-27T08:04:30Z",
    "labels": [],
    "url": "https://github.com/black-forest-labs/flux/issues/401",
    "body": "I've checked over the images there is nothing suspicious about them!",
    "comments_url": "https://api.github.com/repos/black-forest-labs/flux/issues/401/comments",
    "author": "newideas99",
    "comments": [
      {
        "user": "boeselfr",
        "created_at": "2025-01-27T08:04:30Z",
        "body": "The issue should be resolved by now, we had a few false positives here. Should not happen anymore! "
      }
    ]
  },
  {
    "number": 394,
    "title": "Fix param name error in fill docs",
    "created_at": "2024-12-04T10:44:05Z",
    "closed_at": "2025-01-09T22:54:25Z",
    "labels": [],
    "url": "https://github.com/black-forest-labs/flux/pull/394",
    "body": "Fix param name error in fill docs \r\n\r\n`img_cond_mask` -> `img_mask_path`",
    "comments_url": "https://api.github.com/repos/black-forest-labs/flux/issues/394/comments",
    "author": "Adenialzz",
    "comments": [
      {
        "user": "yaogang2060",
        "created_at": "2024-12-12T02:24:08Z",
        "body": "same here"
      }
    ]
  },
  {
    "number": 205,
    "title": "i met an issue when using the the latest flux fill model in comfyui",
    "created_at": "2024-11-22T05:00:55Z",
    "closed_at": "2024-11-22T14:57:46Z",
    "labels": [],
    "url": "https://github.com/black-forest-labs/flux/issues/205",
    "body": "unfortunately i met an issue when using the the latest flux fill model in comfyui, it says:\r\n```\r\nUNETLoader\r\nError(s) in loading state_dict for Flux:\r\nsize mismatch for img_in.weight: copying a param with shape torch.Size([3072, 384]) from checkpoint, the shape in current model is torch.Size([3072, 64]).\r\n```\r\nwhat does it means? how can i fix it?\r\n\r\nhere is the log:\r\n```\r\ngot prompt\r\nRequested to load FluxClipModel_\r\nLoading 1 new model\r\nloaded completely 0.0 9319.23095703125 True\r\nclip missing: ['text_projection.weight']\r\nmodel weight dtype torch.bfloat16, manual cast: None\r\nmodel_type FLUX\r\n!!! Exception during processing !!! Error(s) in loading state_dict for Flux:\r\n        size mismatch for img_in.weight: copying a param with shape torch.Size([3072, 384]) from checkpoint, the shape in current model is torch.Size([3072, 64]).\r\nTraceback (most recent call last):\r\n  File \"D:\\ComfyUI_windows_portable\\ComfyUI\\execution.py\", line 323, in execute\r\n    output_data, output_ui, has_subgraph = get_output_data(obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\r\n                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\ComfyUI_windows_portable\\ComfyUI\\execution.py\", line 198, in get_output_data\r\n    return_values = _map_node_over_list(obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\r\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\ComfyUI_windows_portable\\ComfyUI\\execution.py\", line 169, in _map_node_over_list\r\n    process_inputs(input_dict, i)\r\n  File \"D:\\ComfyUI_windows_portable\\ComfyUI\\execution.py\", line 158, in process_inputs\r\n    results.append(getattr(obj, func)(**inputs))\r\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\ComfyUI_windows_portable\\ComfyUI\\nodes.py\", line 875, in load_unet\r\n    model = comfy.sd.load_diffusion_model(unet_path, model_options=model_options)\r\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\ComfyUI_windows_portable\\ComfyUI\\comfy\\sd.py\", line 660, in load_diffusion_model\r\n    model = load_diffusion_model_state_dict(sd, model_options=model_options)\r\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\ComfyUI_windows_portable\\ComfyUI\\comfy\\sd.py\", line 651, in load_diffusion_model_state_dict\r\n    model.load_model_weights(new_sd, \"\")\r\n  File \"D:\\ComfyUI_windows_portable\\ComfyUI\\comfy\\model_base.py\", line 222, in load_model_weights\r\n    m, u = self.diffusion_model.load_state_dict(to_load, strict=False)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"D:\\ComfyUI_windows_portable\\python_embeded\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 2584, in load_state_dict\r\n    raise RuntimeError(\r\nRuntimeError: Error(s) in loading state_dict for Flux:\r\n        size mismatch for img_in.weight: copying a param with shape torch.Size([3072, 384]) from checkpoint, the shape in current model is torch.Size([3072, 64]).\r\n\r\nPrompt executed in 55.84 seconds\r\n```",
    "comments_url": "https://api.github.com/repos/black-forest-labs/flux/issues/205/comments",
    "author": "huangkun1985",
    "comments": [
      {
        "user": "tarunm14",
        "created_at": "2024-11-22T05:34:21Z",
        "body": "Update ComfyUI to v0.3.1  That solved it for me."
      },
      {
        "user": "huangkun1985",
        "created_at": "2024-11-22T14:57:42Z",
        "body": "> Update ComfyUI to v0.3.1 That solved it for me.\r\n\r\nthanks, it works!"
      }
    ]
  },
  {
    "number": 159,
    "title": "Question about the meaning of `guidance` in model forward",
    "created_at": "2024-09-23T11:10:33Z",
    "closed_at": "2024-09-23T12:39:31Z",
    "labels": [],
    "url": "https://github.com/black-forest-labs/flux/issues/159",
    "body": "I read the code about flux and found that there are two guidance parameters during model inference, one is `guidance_vec` and the other is `true_gs`.\r\n\r\n```\r\ndef forward(\r\n        self,\r\n        img: Tensor,\r\n        img_ids: Tensor,\r\n        txt: Tensor,\r\n        txt_ids: Tensor,\r\n        timesteps: Tensor,\r\n        y: Tensor,\r\n        guidance: Tensor | None = None,    ## <---- this one\r\n    ) -> Tensor:\r\n        if img.ndim != 3 or txt.ndim != 3:\r\n            raise ValueError(\"Input img and txt tensors must have 3 dimensions.\")\r\n\r\n        # running on sequences img\r\n        img = self.img_in(img)\r\n        vec = self.time_in(timestep_embedding(timesteps, 256))\r\n        if self.params.guidance_embed:\r\n            if guidance is None:\r\n                raise ValueError(\"Didn't get guidance strength for guidance distilled model.\")\r\n            vec = vec + self.guidance_in(timestep_embedding(guidance, 256))\r\n        vec = vec + self.vector_in(y)\r\n\r\nguidance_vec = torch.full((img.shape[0],), guidance, device=img.device, dtype=img.dtype)\r\nfor t_curr, t_prev in zip(timesteps[:-1], timesteps[1:]):\r\n    t_vec = torch.full((img.shape[0],), t_curr, dtype=img.dtype, device=img.device)\r\n    pred = model(\r\n        img=img,\r\n        img_ids=img_ids,\r\n        txt=txt,\r\n        txt_ids=txt_ids,\r\n        y=vec,\r\n        timesteps=t_vec,\r\n        guidance=guidance_vec,\r\n        image_proj=image_proj,\r\n        ip_scale=ip_scale, \r\n    )\r\n    if i >= timestep_to_start_cfg:\r\n        neg_pred = model(\r\n            img=img,\r\n            img_ids=img_ids,\r\n            txt=neg_txt,\r\n            txt_ids=neg_txt_ids,\r\n            y=neg_vec,\r\n            timesteps=t_vec,\r\n            guidance=guidance_vec, \r\n            image_proj=neg_image_proj,\r\n            ip_scale=neg_ip_scale, \r\n        )     \r\n        pred = neg_pred + true_gs * (pred - neg_pred)\r\n```\r\ntrue_gs is used for denoising, which is the famous CFG, which I understand.\r\nBut `guidance_vec`, called `guidance` in the model forward function, seems to control the time step embedding. My question is what is the role of this guidance. I donâ€™t seem to find a clear reference, and itâ€™s hard for me to understand how this parameter works during training.\r\nIf anyone can answer, Iâ€™d be grateful!",
    "comments_url": "https://api.github.com/repos/black-forest-labs/flux/issues/159/comments",
    "author": "huayecaibcc",
    "comments": [
      {
        "user": "huayecaibcc",
        "created_at": "2024-09-23T12:39:02Z",
        "body": "Sorry, I checked the code again and found that the use of the two guidance are in x-flux codes. The true_gs parameter does not exist in the flux code of BFL.\r\nI'll leave this question for people who have the same doubts. \r\nIn the BFL code, this guidance is actually CFG, but when distilling the model, it is turned into an embedding to learn the result of the teacher model adjusting the CFG parameters. Therefore, after the distillation is completed, that is, in the inference of flux-dev, it is not necessary to use CFG inferencing twice (conditional and unconditional) to get the result, thereby speeding up the entire inferencing process.\r\nAt the same time, the x-flux code changed true_gs from 4 to 1 in one submission, which should be the reason."
      },
      {
        "user": "huayecaibcc",
        "created_at": "2024-09-23T12:39:31Z",
        "body": "issue closed"
      },
      {
        "user": "maxin-cn",
        "created_at": "2024-09-27T08:26:27Z",
        "body": "Hi @huayecaibcc, I am also confused about guidance_vec. Why can it achieve the effect of distillation when it is added? I see it only adds to the timestep."
      }
    ]
  },
  {
    "number": 108,
    "title": "Fix Logical and Runtime Errors",
    "created_at": "2024-08-21T09:41:53Z",
    "closed_at": "2024-08-21T22:16:30Z",
    "labels": [],
    "url": "https://github.com/black-forest-labs/flux/pull/108",
    "body": "### Issue Addressed:\r\n\r\nThe `prepare` function previously faced challenges with mismatched numbers of prompts and images. This issue was particularly evident when multiple prompts were associated with a single image, leading to inconsistent batch sizes and potential runtime errors. The original function lacked sufficient mechanisms for aligning image and text data properly, which could result in misaligned processing inputs.\r\n\r\n### Implemented Fixes:\r\n\r\n##### 1. Automatic Image Replication: \r\nEnhanced the function to automatically replicate images when multiple prompts are provided with fewer images. This ensures that each prompt is paired with an image, preventing mismatches and potential processing errors.\r\nError Handling for Mismatched Inputs: Introduced error checks that trigger if the number of prompts and images do not align when multiple images are provided. This preemptive check prevents confusing errors deeper in the processing pipeline.\r\n\r\n##### 2. Text Processing: \r\nStrengthened text handling by ensuring text embeddings are consistently replicated across the calculated batch size. This change guarantees that each image in a batch is paired with corresponding text data, which is crucial for models leveraging both visual and textual inputs.\r\n\r\n\r\n##### 3. Tensor Consistency: \r\nImproved the handling of tensor device and data type settings, ensuring all tensors involved in the computation are consistently configured. This uniformity is key for avoiding device-related errors and optimizing computational efficiency.\r\n\r\nThese enhancements make the function more reliable and user-friendly, streamlining the handling of batch sizes and prompt associations, and reducing the risk of runtime errors in your data processing workflow.\r\n\r\n",
    "comments_url": "https://api.github.com/repos/black-forest-labs/flux/issues/108/comments",
    "author": "DrHazemAli",
    "comments": [
      {
        "user": "timudk",
        "created_at": "2024-08-21T18:44:24Z",
        "body": "@DrHazemAli could you give a command to replicate the issue? i am not entirely sure what you mean with \"when multiple prompts were associated with a single image\""
      },
      {
        "user": "DrHazemAli",
        "created_at": "2024-08-21T19:57:30Z",
        "body": "Sure, The below code can demonstrate the mismatch handling where one image is expected to correspond to multiple text prompts:\r\n\r\n```\r\n# Assuming HFEmbedder and other necessary components are properly implemented and imported\r\nt5_embedder = HFEmbedder()  # Hypothetical initializer for text embedding\r\nclip_embedder = HFEmbedder()  # Hypothetical initializer for clip embedding\r\n\r\nsingle_image = torch.randn(1, 3, 256, 256)  \r\nmultiple_prompts = [\"A sunny day in the park\", \"A snowy mountain\", \"A bustling city night\"]\r\nprepared_data = prepare(t5_embedder, clip_embedder, single_image, multiple_prompts)\r\nprint(prepared_data)\r\n```\r\n\r\nThis code will trigger the original prepare function with one image and several prompts. Depending on the initial implementation, you may see that the function doesnâ€™t handle the replication of the single image across multiple prompts correctly, which would typically lead to a runtime error or sometimes incorrect data processing."
      },
      {
        "user": "timudk",
        "created_at": "2024-08-21T21:49:37Z",
        "body": "@DrHazemAli this snippet is never used though?\r\n\r\nthis codebase is only meant to support standard single prompt sampling via the `cli`, `streamlit` demo, and `gradio` demo."
      },
      {
        "user": "DrHazemAli",
        "created_at": "2024-08-21T22:01:54Z",
        "body": "I do understand that, But as of my vision this project will grow, and it may need such a thing as the development keeps up.\r\nSo using such a way of handling will be great for the future as the project grows with development."
      },
      {
        "user": "timudk",
        "created_at": "2024-08-21T22:16:30Z",
        "body": "> But as of my vision this project will grow, and it may need such a thing as the development keeps up.\r\n\r\nwe can reopen this once necessary, but i will close it for now"
      }
    ]
  },
  {
    "number": 102,
    "title": "Can someone contact me from Black Forest Labs?",
    "created_at": "2024-08-20T16:22:23Z",
    "closed_at": "2024-08-30T16:09:53Z",
    "labels": [],
    "url": "https://github.com/black-forest-labs/flux/issues/102",
    "body": "Can someone contact me from Black Forest Labs?",
    "comments_url": "https://api.github.com/repos/black-forest-labs/flux/issues/102/comments",
    "author": "PierrunoYT",
    "comments": [
      {
        "user": "jasmine-wood",
        "created_at": "2024-08-21T16:26:07Z",
        "body": "> Can someone contact me from Black Forest Labs?\r\n\r\nYou can try e-mailing them at flux@blackforestlabs.ai."
      },
      {
        "user": "PierrunoYT",
        "created_at": "2024-08-30T16:34:24Z",
        "body": "@timudk I send an email regarding to Discord"
      },
      {
        "user": "PierrunoYT",
        "created_at": "2024-08-30T17:59:44Z",
        "body": "> > Can someone contact me from Black Forest Labs?\n> \n> \n> \n> You can try e-mailing them at flux@blackforestlabs.ai.\n\nThey dont reply for a reason."
      }
    ]
  },
  {
    "number": 28,
    "title": "int4ï¼Ÿ",
    "created_at": "2024-08-03T06:50:37Z",
    "closed_at": "2024-08-03T15:10:33Z",
    "labels": [],
    "url": "https://github.com/black-forest-labs/flux/issues/28",
    "body": "With the variety of quantization methods available, could we select an optimal one for INT4 quantization? This would enable users with low-memory devices to utilize the model, and the potential quality loss seems acceptable",
    "comments_url": "https://api.github.com/repos/black-forest-labs/flux/issues/28/comments",
    "author": "kakaxixx",
    "comments": [
      {
        "user": "nalf3in",
        "created_at": "2024-08-05T00:26:16Z",
        "body": "Can you tells us how you achieved this ?"
      }
    ]
  },
  {
    "number": 27,
    "title": "there is a .to() without a target",
    "created_at": "2024-08-03T02:05:56Z",
    "closed_at": "2024-08-05T08:58:32Z",
    "labels": [],
    "url": "https://github.com/black-forest-labs/flux/pull/27",
    "body": null,
    "comments_url": "https://api.github.com/repos/black-forest-labs/flux/issues/27/comments",
    "author": "deforum",
    "comments": [
      {
        "user": "jenuk",
        "created_at": "2024-08-05T08:58:43Z",
        "body": "Thanks"
      }
    ]
  },
  {
    "number": 25,
    "title": "useless due censorship",
    "created_at": "2024-08-03T00:28:02Z",
    "closed_at": "2024-08-14T14:22:12Z",
    "labels": [],
    "url": "https://github.com/black-forest-labs/flux/issues/25",
    "body": "you reach chinese kling censorship level. this is good model but useless due censorship. if it hasn't breasts, I don't wanna see it.",
    "comments_url": "https://api.github.com/repos/black-forest-labs/flux/issues/25/comments",
    "author": "cerulliber",
    "comments": [
      {
        "user": "CCpt5",
        "created_at": "2024-08-03T02:26:29Z",
        "body": "Hey bro, then don't see it. SD3 is available.\r\n\r\nThis isn't an \"issue\"  \r\n\r\nFrankly your usecase sucks."
      },
      {
        "user": "shivshankar11",
        "created_at": "2024-08-03T06:38:58Z",
        "body": "But he has valid point about censorship, i think flux said their model has accurate anatomy which is not true, shat is the point of this kind of censorship? are we adults or child who need need protection from human anatomy."
      },
      {
        "user": "HenryThe1st",
        "created_at": "2024-08-03T10:54:24Z",
        "body": "agree... this is not close to accurate anatomy... Its a great model but if there will be no possibility to improve in some aspects with LORAS it will be dead at arrival... "
      },
      {
        "user": "shivshankar11",
        "created_at": "2024-08-03T14:15:27Z",
        "body": "without finetune and lora support, community engagement will be significantly less.\r\nbut i am hopeful dev version will support finetuning. maybe pro version itself is finetuned with better database."
      },
      {
        "user": "CasualDev242",
        "created_at": "2024-08-03T14:22:09Z",
        "body": "What are you guys talking about? The model is uncensored, but wasn't trained on certain images like porn if that's what you were after. That doesn't mean it's censored. Hell, I just tested it, it creates accurate boobies. It's all good."
      },
      {
        "user": "HenryThe1st",
        "created_at": "2024-08-03T14:55:40Z",
        "body": "> What are you guys talking about? The model is uncensored, but wasn't trained on certain images like porn if that's what you were after. That doesn't mean it's censored. Hell, I just tested it, it creates accurate boobies. It's all good.\r\n\r\nIt actually cannot make accurate breasts (no real nipples). Nevertheless, the real downfall will happen if no LORA are permitted "
      },
      {
        "user": "CasualDev242",
        "created_at": "2024-08-03T16:12:50Z",
        "body": "> > What are you guys talking about? The model is uncensored, but wasn't trained on certain images like porn if that's what you were after. That doesn't mean it's censored. Hell, I just tested it, it creates accurate boobies. It's all good.\r\n> \r\n> It actually cannot make accurate breasts (no real nipples). Nevertheless, the real downfall will happen if no LORA are permitted\r\n\r\nYes it can. I just tested again: realistic nipples, nice looking boobs.\r\n\r\nPrompting it correctly seems like the issue around here.\r\n\r\nNote that I am using the Dev version, maybe you guys are using Schnell, which may have this issue?"
      },
      {
        "user": "cerulliber",
        "created_at": "2024-08-03T16:33:18Z",
        "body": "> \r\n> Yes it can. I just tested again: realistic nipples, nice looking boobs.\r\n> \r\n> Prompting it correctly seems like the issue around here.\r\n> \r\n> Note that I am using the Dev version, maybe you guys are using Schnell, which may have this issue?\r\n\r\ncan you proof it ? for demonstrative purposes only."
      },
      {
        "user": "CCpt5",
        "created_at": "2024-08-04T03:17:08Z",
        "body": "cerulliber, Revln9, and zewt reacted with thumbs down emoji\r\n\r\nThere's tons of porno models for SDXL on civitai. It's day 3.....take a shower."
      },
      {
        "user": "cerulliber",
        "created_at": "2024-08-05T08:56:20Z",
        "body": "> cerulliber, Revln9, and zewt reacted with thumbs down emoji\r\n> \r\n> \r\n\r\nare you so censorship-oreinted that you even can't support one emoji in online space?"
      },
      {
        "user": "shivshankar11",
        "created_at": "2024-08-05T09:44:18Z",
        "body": "well accurate anatomy mean accurate genitalia, flux fail terribly here due to blackmask pasted on dataset. we call that censorship right."
      },
      {
        "user": "BrechtCorbeel",
        "created_at": "2024-08-06T05:02:00Z",
        "body": "Although I do not look into using this for NSFW content I do agree that where Midjourney falls apart is that sometimes prompting and veering slightly NSFW enhances a look and feel or a level of sophistication you cannot reach without it, but on the other hand I am 100% agreeing on the danger of a model that can produce nudity and images of kids.\r\n\r\nI think people overestimate the danger of \"dangerous\" text or images, we've been doing this for years now and really I have not yet ever really seen extreme adverse effects, it's anticipated by many and people a desensitized to it."
      },
      {
        "user": "eddiepot",
        "created_at": "2024-08-27T17:01:18Z",
        "body": "It _is_ censored! They purposely cover up the beautiful female body with pasties! Now _that_ is sick!"
      },
      {
        "user": "apollo0510",
        "created_at": "2024-10-20T17:10:36Z",
        "body": "This thing is completely censored. It refuses to create anything that is slightly NSFW. At least not by default. Even explicit prompts create child safe images."
      }
    ]
  },
  {
    "number": 20,
    "title": "Need more Inference Command",
    "created_at": "2024-08-02T10:37:07Z",
    "closed_at": "2024-08-30T16:20:36Z",
    "labels": [],
    "url": "https://github.com/black-forest-labs/flux/issues/20",
    "body": "Can you provide a detailed list of the Inference commandsï¼ŸThanks",
    "comments_url": "https://api.github.com/repos/black-forest-labs/flux/issues/20/comments",
    "author": "dunanyang",
    "comments": [
      {
        "user": "potato-creator",
        "created_at": "2024-08-15T05:53:14Z",
        "body": "Maybe you an use the diffusers as the just like the code demonstration on the homepage."
      }
    ]
  },
  {
    "number": 18,
    "title": "Add a gradio demo and diffusers code reference",
    "created_at": "2024-08-02T10:13:31Z",
    "closed_at": "2024-08-05T11:47:16Z",
    "labels": [],
    "url": "https://github.com/black-forest-labs/flux/pull/18",
    "body": "Add a Gradio demo that runs with the original pipeline code (incl. image-to-image)",
    "comments_url": "https://api.github.com/repos/black-forest-labs/flux/issues/18/comments",
    "author": "apolinario",
    "comments": [
      {
        "user": "apolinario",
        "created_at": "2024-08-03T08:48:46Z",
        "body": "> Can you also add gradio to the requirements in the pyproject-file? Please do it as a separate requirements just as the streamlit requirement? Feel free to add it to all too.\r\n\r\nDone!\r\n\r\n> If you take the seed of a previous calculation and pass it through the demo again you will get a different output. If you generate another time afterwards it will give you the same image again. I'm assuming that gradio has an internal representation of that seed as a float somewhere in the middle and loses precision. This should be fixed.\r\n\r\nI found the issue. The issue is that the seed is normally calculated in Python, however when passed to the Javascript front-end, Gradio uses Javascript's `Number`, which has a maximum value of `2^53 - 1` or `9007199254740992` so if the seed is larger than that, it will replace the extra characters with zeroes ðŸ˜…. The workaround I did is to do `str` in Javascript but convert to `int` for Python that can handle the larger numbers."
      },
      {
        "user": "apolinario",
        "created_at": "2024-08-03T08:49:16Z",
        "body": "I also externalized from the advanced options accordion the image2image option!"
      },
      {
        "user": "jenuk",
        "created_at": "2024-08-05T09:19:50Z",
        "body": "Looks good! One last thing: Can you move the jpg that are generated into either a tempdir or into the `output` (or `output/gradio/`) dir that is also used in the other demos? Otherwise the script will spam the root in which it is executed."
      },
      {
        "user": "apolinario",
        "created_at": "2024-08-05T10:20:34Z",
        "body": "Makes sense, done! "
      }
    ]
  },
  {
    "number": 4,
    "title": "Incompetence?",
    "created_at": "2024-08-01T15:21:56Z",
    "closed_at": "2024-08-01T21:13:11Z",
    "labels": [],
    "url": "https://github.com/black-forest-labs/flux/issues/4",
    "body": "Who decided to put 'cd $HOME' in the local installation commands?\r\n\r\nAnd no requirements.txt? I have to use a -e '[.all]'??? wtf is that?\r\n\r\nWhy not just be normal, and provide instructions that work like literally every other Python  program on the planet?",
    "comments_url": "https://api.github.com/repos/black-forest-labs/flux/issues/4/comments",
    "author": "Subash-Chandra",
    "comments": [
      {
        "user": "JonasLoos",
        "created_at": "2024-08-01T17:12:35Z",
        "body": "You could just ignore `cd $HOME` if you don't want to have it in your home dir but somewhere else.\r\n\r\n`-e` stands for editable mode and `.[all]` for installing the package in the current directory with all dependencies (which are listed in `pyproject.toml`).\r\n\r\nI guess they might provide the code like this, because it allows for easy importing of the code and so that it can be run by just typing `flux`. This is actually not too uncommon."
      },
      {
        "user": "Subash-Chandra",
        "created_at": "2024-08-01T21:13:11Z",
        "body": "I see makes sense. Thanks for explaining. Still doesn't work when trying to run it via Anaconda. Guess I have to do it with a venv."
      }
    ]
  }
]