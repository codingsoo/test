[
  {
    "number": 93,
    "title": "Add docstrings and other comments in the functions",
    "created_at": "2024-11-06T09:19:03Z",
    "closed_at": "2024-11-19T12:16:15Z",
    "labels": [],
    "url": "https://github.com/gusye1234/nano-graphrag/issues/93",
    "body": "Most of the private functions and other modules don't have comprehensive docstrings, making it harder to read the code and fit the custom usecase. Please provide those as early as possible.\r\n\r\nFor example,\r\nI am having a hard time understanding many things in the code which could have been easier had I had the comments and docstrings\r\n\r\n```    chunk_token_size: int = 1200\r\n    chunk_overlap_token_size: int = 100\r\n    tiktoken_model_name: str = \"gpt-4o\"\r\n\r\n    # entity extraction\r\n    entity_extract_max_gleaning: int = 1\r\n    entity_summary_to_max_tokens: int = 500",
    "comments_url": "https://api.github.com/repos/gusye1234/nano-graphrag/issues/93/comments",
    "author": "yagneshgooglegithub",
    "comments": [
      {
        "user": "rangehow",
        "created_at": "2024-11-19T11:42:20Z",
        "body": "As an open source project, we welcome anyone to contribute, including adding comments you deem necessary. \r\nSpeaking of the 4 variables in the example: the first variable refers to the overlapping portions between different chunks when splitting documents using a sliding window approach - this concept is extremely common in RAG. The second is the tokenizer used to calculate document length. For the remaining two concepts, \"gleaning\" refers to the number of times entities are extracted from the same chunk, as mentioned in the GraphRAG paper. The last one is the token threshold that triggers summarization when extracted entities exceed a certain length."
      },
      {
        "user": "yagneshgooglegithub",
        "created_at": "2024-11-19T12:16:15Z",
        "body": "> As an open source project, we welcome anyone to contribute, including adding comments you deem necessary. Speaking of the 4 variables in the example: the first variable refers to the overlapping portions between different chunks when splitting documents using a sliding window approach - this concept is extremely common in RAG. The second is the tokenizer used to calculate document length. For the remaining two concepts, \"gleaning\" refers to the number of times entities are extracted from the same chunk, as mentioned in the GraphRAG paper. The last one is the token threshold that triggers summarization when extracted entities exceed a certain length.\r\n\r\nThanks for the reply. I get the point that it's an open source project. But try to add comments to all the fields of various class if possible. For others, it could take 2 to 3 hours of here and there which authors could do in 2 to 3 seconds. Thanks again, the repo is very easy to use in comparison to microsoft's one."
      }
    ]
  },
  {
    "number": 91,
    "title": "how to use local ollama model as llm and embedding",
    "created_at": "2024-10-31T07:00:36Z",
    "closed_at": "2024-11-04T03:54:31Z",
    "labels": [],
    "url": "https://github.com/gusye1234/nano-graphrag/issues/91",
    "body": "how can i set api_url",
    "comments_url": "https://api.github.com/repos/gusye1234/nano-graphrag/issues/91/comments",
    "author": "WangAo-0",
    "comments": [
      {
        "user": "thundax-lyp",
        "created_at": "2024-10-31T07:35:33Z",
        "body": "see: examples/using_llm_api_as_llm+ollama_embedding.py"
      },
      {
        "user": "WangAo-0",
        "created_at": "2024-10-31T07:39:28Z",
        "body": "> see: examples/using_llm_api_as_llm+ollama_embedding.py\r\n\r\nbut , I didn't find a place to set the ollama embedding url"
      },
      {
        "user": "WangAo-0",
        "created_at": "2024-11-04T03:54:31Z",
        "body": "When the Ollama server is not on the same host, use export OLLAMA_HOST = \"remote_addr\" to set the URL"
      }
    ]
  },
  {
    "number": 83,
    "title": "construction problem",
    "created_at": "2024-10-21T12:42:15Z",
    "closed_at": "2024-10-22T14:36:31Z",
    "labels": [],
    "url": "https://github.com/gusye1234/nano-graphrag/issues/83",
    "body": "when i input the construction \"pip install -e .\", there is a error hint\"ERROR: file:///Users/liuxiang/Desktop/nano-graphrag-main/nano_graphrag does not appear to be a Python project: neither 'setup.py' nor 'pyproject.toml' found.\" I can't find such files in that directory.",
    "comments_url": "https://api.github.com/repos/gusye1234/nano-graphrag/issues/83/comments",
    "author": "qhlx",
    "comments": [
      {
        "user": "gusye1234",
        "created_at": "2024-10-21T14:59:00Z",
        "body": "You maybe in the wrong dir. Make sure you're running the command in the root dir of this project, where `setup.py` is located"
      },
      {
        "user": "qhlx",
        "created_at": "2024-10-22T00:27:07Z",
        "body": "thank you very much!"
      }
    ]
  },
  {
    "number": 65,
    "title": "Question: What is node2vec used for",
    "created_at": "2024-09-27T00:52:58Z",
    "closed_at": "2024-10-08T13:26:49Z",
    "labels": [],
    "url": "https://github.com/gusye1234/nano-graphrag/issues/65",
    "body": "It looks like embed_nodes is defined but not called anywhere?",
    "comments_url": "https://api.github.com/repos/gusye1234/nano-graphrag/issues/65/comments",
    "author": "rawsh-rubrik",
    "comments": [
      {
        "user": "gusye1234",
        "created_at": "2024-09-29T02:56:12Z",
        "body": "embed_nodes is something we have in official GraphRAG but not used in default setting.\r\n`nano-graphrag` implements it and doesn't plan to use it either."
      }
    ]
  },
  {
    "number": 63,
    "title": "The error in UTF-8 encoding when storing extracted Chinese entity names in vdb_entities.json.",
    "created_at": "2024-09-26T08:04:55Z",
    "closed_at": "2024-10-08T10:05:15Z",
    "labels": [],
    "url": "https://github.com/gusye1234/nano-graphrag/issues/63",
    "body": "When I use all-MiniLM-L6-v2 as the local vector encoding model to store the extracted Chinese entities in vdb_entities.json, the content I see is as follows, which is the Unicode encoding of Chinese, not UTF-8 encoding. The encoding method for writing to the JSON file in _utils.py is \"utf-8\". Is it related to the vector model I chose? How should I modify it?\r\n\r\n---------------------------------------------------\r\n{\"embedding_dim\": 384, \"data\": [{\"__id__\": \"ent-3823944778412382ad171c8152055cdd\", \"entity_name\": \"\\\"\\u592a\\u767d\\u91d1\\u661f\\u674e\\u957f\\u5e9a\\\"\"}, {\"__id__\": \"ent-d6bbc7e0fc25691f48df9a5550de5c64\", \"entity_name\": \"\\\"\\u8001\\u9e64\\\"\"}, {\"__id__\": \"ent-71cc9a28268df396b25d165ae4b899a6\", \"entity_name\": \"\\\"\\u542f\\u660e\\u6bbf\\\"\"},\r\n……\r\n---------------------------------------------------\r\n",
    "comments_url": "https://api.github.com/repos/gusye1234/nano-graphrag/issues/63/comments",
    "author": "zhouyujin",
    "comments": [
      {
        "user": "gusye1234",
        "created_at": "2024-09-26T12:18:20Z",
        "body": "Are you using the latest commit?"
      },
      {
        "user": "zhouyujin",
        "created_at": "2024-10-08T10:04:27Z",
        "body": "Thank you for your reply, I just downloaded the latest source code before and  did not update the dependency packages inside. After installing the latest version of nano-vectordb, the problem is resolved.\r\n\r\n"
      }
    ]
  },
  {
    "number": 51,
    "title": "使用llama3.1:8b的时候，出现警告：Didn't extract any entities, maybe your LLM is not working",
    "created_at": "2024-09-18T09:25:29Z",
    "closed_at": "2024-10-09T15:18:14Z",
    "labels": [],
    "url": "https://github.com/gusye1234/nano-graphrag/issues/51",
    "body": "INFO:nano-graphrag:[New Chunks] inserting 42 chunks\r\nINFO:nano-graphrag:[Entity Extraction]...\r\n⠹ Processed 42 chunks, 0 entities(duplicated), 0 relations(duplicated)\r\nWARNING:nano-graphrag:Didn't extract any entities, maybe your LLM is not working\r\nWARNING:nano-graphrag:No new entities found\r\nINFO:nano-graphrag:Writing graph with 0 nodes, 0 edges\r\nindexing time: 3.8695967197418213\r\n是不是要更换LLM呢，以前使用graphrag的时候，使用llama3.1:8b也出错。",
    "comments_url": "https://api.github.com/repos/gusye1234/nano-graphrag/issues/51/comments",
    "author": "blueskydata",
    "comments": [
      {
        "user": "gusye1234",
        "created_at": "2024-09-18T12:37:46Z",
        "body": "checkout docs/FAQ.md~ This is a common problem"
      },
      {
        "user": "guanzy2012",
        "created_at": "2024-09-26T09:23:42Z",
        "body": "出现这个问题，程序自动停了怎么办\r\n\r\n"
      }
    ]
  },
  {
    "number": 40,
    "title": "feature: allow custom chunking method",
    "created_at": "2024-09-15T09:47:53Z",
    "closed_at": "2024-09-17T10:16:12Z",
    "labels": [],
    "url": "https://github.com/gusye1234/nano-graphrag/pull/40",
    "body": "In mature RAG frameworks, providing custom chunking methods is a very common choice. Fixed-length splitting brings many disadvantages, such as causing incomplete grammatical inputs, which challenges small models to produce normal outputs. Therefore, we have added an optional feature, allowing users to customize the chunking method, just like they can provide custom LLMs and embedding functions. At the same time, we have provided a separator-based splitting method that can ensure each chunk is grammatically complete.",
    "comments_url": "https://api.github.com/repos/gusye1234/nano-graphrag/issues/40/comments",
    "author": "rangehow",
    "comments": [
      {
        "user": "gusye1234",
        "created_at": "2024-09-17T10:12:56Z",
        "body": "LGTM"
      }
    ]
  },
  {
    "number": 39,
    "title": "JSON parse failed",
    "created_at": "2024-09-15T08:08:43Z",
    "closed_at": "2024-10-09T15:17:12Z",
    "labels": [],
    "url": "https://github.com/gusye1234/nano-graphrag/issues/39",
    "body": "Hi, I tried to insert a large document into the graphrag so I set gpt-4o-mini as the best_model_func:\r\n```\r\ngraph_func = GraphRAG(working_dir=\"./test\", best_model_func=gpt_4o_mini_complete)\r\n```\r\n.Then, I encountered an error:\r\n```\r\nINFO:nano-graphrag:Writing graph with 15585 nodes, 6276 edges\r\nTraceback (most recent call last):\r\n  File \"/root/test_build.py\", line 14, in <module>\r\n    graph_func.insert(content)\r\n  File \"/root/.env/lib/python3.11/site-packages/nano_graphrag/graphrag.py\", line 181, in insert\r\n    return loop.run_until_complete(self.ainsert(string_or_strings))\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 653, in run_until_complete\r\n    return future.result()\r\n           ^^^^^^^^^^^^^^^\r\n  File \"/root/.env/lib/python3.11/site-packages/nano_graphrag/graphrag.py\", line 291, in ainsert\r\n    await generate_community_report(\r\n  File \"/root/.env/lib/python3.11/site-packages/nano_graphrag/_op.py\", line 578, in generate_community_report\r\n    this_level_communities_reports = await asyncio.gather(\r\n                                     ^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/root/.env/lib/python3.11/site-packages/nano_graphrag/_op.py\", line 555, in _form_single_community_report\r\n    data = use_string_json_convert_func(response)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/root/.env/lib/python3.11/site-packages/nano_graphrag/_utils.py\", line 31, in convert_response_to_json\r\n    assert json_str is not None, f\"Unable to parse JSON from response: {response}\"\r\n           ^^^^^^^^^^^^^^^^^^^^\r\n```\r\n\r\nIs there any retry option or only gpt-4o can do this kind of task?\r\n\r\nThanks.",
    "comments_url": "https://api.github.com/repos/gusye1234/nano-graphrag/issues/39/comments",
    "author": "Dorbmon",
    "comments": [
      {
        "user": "gusye1234",
        "created_at": "2024-09-15T08:56:19Z",
        "body": "Hi, maybe you can give the total error log? It seems like the gpt-4o-mini returns an empty string"
      },
      {
        "user": "Dorbmon",
        "created_at": "2024-09-15T12:04:03Z",
        "body": "The is the error information: \r\n```\r\nAssertionError: Unable to parse JSON from response: {\r\n    \"title\": \"Binomial Distribution and Related Concepts\",\r\n    \"summary\": \"This community centers around the Binomial Distribution, which encapsulates the probabilities of successes in a fixed number of Bernoulli Trials. Key entities include various mathematical concepts and corollaries that are intricately linked to the Binomial Distribution, providing a comprehensive framework for understanding probability theory.\",\r\n    \"rating\": 7.5,\r\n    \"rating_explanation\": \"The impact severity rating is significant due to the foundational nature of the Binomial Distribution in probability and statistics, influencing numerous applications in diverse fields.\",\r\n    \"findings\": [\r\n        {\r\n            \"summary\": \"Centrality of Binomial Distribution\",\r\n            \"explanation\": \"The Binomial Distribution serves as a core entity in this community, defining the mathematical framework for studying the number of successes in a fixed number of Bernoulli trials. It is characterized by parameters such as the number of trials (n) and the success probability (p), making it vital for foundational statistics. This distribution aids in predicting outcomes in scenarios where the results are binary, such as success/failure or win/lose situations.\",\r\n        \"In practical terms, the significance of the Binomial Distribution extends across various fields, including finance, science, and social research. It lays the groundwork for advanced statistical theories, making its understanding crucial for anyone delving into data analysis or inferential statistics.\"\r\n       \r\n       \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                              \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                              \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                          \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                          \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                              \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n                      \r\n```"
      },
      {
        "user": "gusye1234",
        "created_at": "2024-09-15T13:17:39Z",
        "body": "Seem like it reached the max new token"
      },
      {
        "user": "Dorbmon",
        "created_at": "2024-09-15T13:20:28Z",
        "body": "Is there any way to solve this? If we use gpt-4o, the cost will be too much for us."
      }
    ]
  },
  {
    "number": 38,
    "title": "The progress of intergrating neo4j",
    "created_at": "2024-09-14T03:23:40Z",
    "closed_at": "2024-09-15T08:52:33Z",
    "labels": [],
    "url": "https://github.com/gusye1234/nano-graphrag/issues/38",
    "body": "Hi,\r\nThank you for your excellent work. I am curious about the progress on integrating Neo4j and also vector databases. If the project is still in its early stages, I would be interested in taking on this task.",
    "comments_url": "https://api.github.com/repos/gusye1234/nano-graphrag/issues/38/comments",
    "author": "Dorbmon",
    "comments": [
      {
        "user": "gusye1234",
        "created_at": "2024-09-14T05:42:24Z",
        "body": "Thanks for the interests! \r\nI'm still looking at Neo4j now. Neo4j will be a GraphStorage and requires some efforts.\r\nIn the other way, VectorDatabase's integration is relatively easy. For example, in #2 , some of them requires pg-vector as the backend. Maybe you can start with this.\r\n\r\nAnd yes, `nano-graphrag` is absolutely on its early-stage. Check out our ROADMAP and maybe add some things you find interesting"
      },
      {
        "user": "Dorbmon",
        "created_at": "2024-09-15T08:06:21Z",
        "body": "OK. I will take a try. Thanks."
      }
    ]
  },
  {
    "number": 37,
    "title": "fix: Resolve the issue of graphml_fisualize.py not functioning properly when data is too long",
    "created_at": "2024-09-13T03:39:22Z",
    "closed_at": "2024-09-14T07:03:38Z",
    "labels": [],
    "url": "https://github.com/gusye1234/nano-graphrag/pull/37",
    "body": "I found an issue while running the file 'examples/graphml-visualize.py'. Excessive JSON data can cause the JSON content in the HTML to be too long, making it unable to run properly. Therefore, I moved this JSON data file to another file to solve this problem",
    "comments_url": "https://api.github.com/repos/gusye1234/nano-graphrag/issues/37/comments",
    "author": "akai-shuuichi",
    "comments": [
      {
        "user": "gusye1234",
        "created_at": "2024-09-13T06:09:34Z",
        "body": "LGTM, @handsomecaoyu  maybe you want to check this PR?"
      }
    ]
  },
  {
    "number": 36,
    "title": "有没有超时参数可以设置？ 我发现一旦超时就死在哪里，既不会重试也不会退出",
    "created_at": "2024-09-12T11:00:40Z",
    "closed_at": "2024-10-09T15:16:07Z",
    "labels": [],
    "url": "https://github.com/gusye1234/nano-graphrag/issues/36",
    "body": "```bash\r\nFile \"/data/miniconda3/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 1295, in create\r\n    return await self._post(\r\n  File \"/data/miniconda3/lib/python3.10/site-packages/openai/_base_client.py\", line 1836, in post\r\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\r\n  File \"/data/miniconda3/lib/python3.10/site-packages/openai/_base_client.py\", line 1524, in request\r\n    return await self._request(\r\n  File \"/data/miniconda3/lib/python3.10/site-packages/openai/_base_client.py\", line 1610, in _request\r\n    return await self._retry_request(\r\n  File \"/data/miniconda3/lib/python3.10/site-packages/openai/_base_client.py\", line 1657, in _retry_request\r\n    return await self._request(\r\n  File \"/data/miniconda3/lib/python3.10/site-packages/openai/_base_client.py\", line 1610, in _request\r\n    return await self._retry_request(\r\n  File \"/data/miniconda3/lib/python3.10/site-packages/openai/_base_client.py\", line 1657, in _retry_request\r\n    return await self._request(\r\n  File \"/data/miniconda3/lib/python3.10/site-packages/openai/_base_client.py\", line 1582, in _request\r\n    raise APITimeoutError(request=request) from err\r\nopenai.APITimeoutError: Request timed out.\r\n```",
    "comments_url": "https://api.github.com/repos/gusye1234/nano-graphrag/issues/36/comments",
    "author": "luckfu",
    "comments": [
      {
        "user": "buchikeke",
        "created_at": "2024-09-13T02:06:32Z",
        "body": "`openai_async_client = AsyncOpenAI(\r\n        api_key=DEEPSEEK_API_KEY, base_url=\"*******\",timeout=90.0,\r\n    )`"
      }
    ]
  },
  {
    "number": 31,
    "title": "Add azure openai as an option in _llm.py",
    "created_at": "2024-09-09T06:31:53Z",
    "closed_at": "2024-09-09T09:43:03Z",
    "labels": [],
    "url": "https://github.com/gusye1234/nano-graphrag/pull/31",
    "body": "## Description\r\n\r\nThanks a lot for sharing this light accomplishment version of graphrag with the support of incremental insert.  \r\n\r\nWhen you have an `AZURE_OPENAI_API_KEY` instead of `OPENAI_API_KEY` like me, you can use this PR to handle it.\r\nMimicking the author's writeup, I wrote the asynchronous call to azure openai.\r\nThis pull request introduces an azure openai option to LLM and embedding, allowing users who have azure openai key instead of openai key.\r\n\r\n\r\n## Checklist\r\n\r\n- [√ ] I have tested these changes locally.\r\n- [ √] I have reviewed the code changes.\r\n- [ ] I have updated the documentation (if necessary).\r\n- [ ] I have added appropriate unit tests (if applicable).\r\n\r\n\r\n\r\n## How to use\r\n\r\ndemos are like, I use load_dotenv to load environment variables.\r\n```\r\nfrom nano_graphrag import GraphRAG, QueryParam\r\nfrom dotenv import load_dotenv\r\n\r\nload_dotenv()\r\n\r\ngraph_func = GraphRAG(working_dir=\"./dickens\")\r\n\r\nwith open(\"./book.txt\") as f:\r\n    graph_func.insert(f.read())\r\n\r\n# Perform global graphrag search\r\nprint(graph_func.query(\"What are the top themes in this story?\"))\r\n\r\n# Perform local graphrag search (I think is better and more scalable one)\r\nprint(graph_func.query(\"What are the top themes in this story?\", param=QueryParam(mode=\"local\")))\r\n```\r\n\r\nyou can add an .env file like in your demo.py\r\n```\r\nAPI_KEY_EMB = \"<your azure openai key for embedding>\"\r\nAZURE_ENDPOINT_EMB = \"<your azure openai endpoint for embedding>\"\r\nAPI_VERSION_EMB =\"<api version>\"\r\n\r\nAZURE_OPENAI_API_KEY=\"<your azure openai key for embedding>\"\r\nAZURE_OPENAI_ENDPOINT=\"<AZURE_OPENAI_ENDPOINT>\"\r\nOPENAI_API_VERSION=\"<OPENAI_API_VERSION>\"\r\n```\r\n\r\nor run `export API_KEY_EMB = \"<your azure openai key for embedding>\"` in your terminal.\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "comments_url": "https://api.github.com/repos/gusye1234/nano-graphrag/issues/31/comments",
    "author": "SliverBulle",
    "comments": [
      {
        "user": "gusye1234",
        "created_at": "2024-09-09T09:22:07Z",
        "body": "LGTM! \r\nDo you finish your PR? If so, I will fix some small things and merge this PR"
      },
      {
        "user": "SliverBulle",
        "created_at": "2024-09-09T09:30:37Z",
        "body": "> LGTM! Do you finish your PR? If so, I will fix some small things and merge this PR\r\n\r\nI think it's finished, thanks for your time."
      }
    ]
  },
  {
    "number": 16,
    "title": "Modified the wrong file call in line 234 of nano_graphrag/graphrag.py",
    "created_at": "2024-08-27T10:49:59Z",
    "closed_at": "2024-08-27T11:16:56Z",
    "labels": [],
    "url": "https://github.com/gusye1234/nano-graphrag/pull/16",
    "body": "I found that chunks should be filtered here, because the documents have been filtered in line 211 of the code, and this line of operation is to operate on chunks.",
    "comments_url": "https://api.github.com/repos/gusye1234/nano-graphrag/issues/16/comments",
    "author": "zzzcccxx",
    "comments": [
      {
        "user": "gusye1234",
        "created_at": "2024-08-27T11:15:28Z",
        "body": "LGTM!"
      }
    ]
  },
  {
    "number": 14,
    "title": "Are there any way to visualize the graph from the extracted graphml file",
    "created_at": "2024-08-24T16:22:14Z",
    "closed_at": "2024-09-10T07:55:30Z",
    "labels": [],
    "url": "https://github.com/gusye1234/nano-graphrag/issues/14",
    "body": null,
    "comments_url": "https://api.github.com/repos/gusye1234/nano-graphrag/issues/14/comments",
    "author": "skywateryang",
    "comments": [
      {
        "user": "gusye1234",
        "created_at": "2024-08-25T06:29:32Z",
        "body": "Check out this PR #12 "
      }
    ]
  },
  {
    "number": 12,
    "title": "添加了faiss作为向量数据库的example，增加了可视化",
    "created_at": "2024-08-21T11:25:52Z",
    "closed_at": "2024-09-06T07:34:46Z",
    "labels": [],
    "url": "https://github.com/gusye1234/nano-graphrag/pull/12",
    "body": null,
    "comments_url": "https://api.github.com/repos/gusye1234/nano-graphrag/issues/12/comments",
    "author": "handsomecaoyu",
    "comments": [
      {
        "user": "akai-shuuichi",
        "created_at": "2024-09-04T11:27:07Z",
        "body": "json过大会导致可视化时script中的内容被省略，可以考虑将json单独创建一个文件引入"
      }
    ]
  },
  {
    "number": 7,
    "title": "_remove_dups_flatten出现TypeError: unhashable type: 'list'",
    "created_at": "2024-08-19T09:20:51Z",
    "closed_at": "2024-08-19T10:52:22Z",
    "labels": [],
    "url": "https://github.com/gusye1234/nano-graphrag/issues/7",
    "body": "在执行到await self._clustering_algorithms[algorithm]()的时候出现报错：\r\n\r\nfrom graspologic.partition import hierarchical_leiden\r\n  File \"/data/newssd/anaconda3/envs/graphrag/lib/python3.9/site-packages/graspologic/__init__.py\", line 6, in <module>\r\n    import graspologic.datasets\r\n  File \"/data/newssd/anaconda3/envs/graphrag/lib/python3.9/site-packages/graspologic/datasets/__init__.py\", line 4, in <module>\r\n    from .base import load_drosophila_left, load_drosophila_right, load_mice\r\n  File \"/data/newssd/anaconda3/envs/graphrag/lib/python3.9/site-packages/graspologic/datasets/base.py\", line 14, in <module>\r\n    from ..utils import import_edgelist\r\n  File \"/data/newssd/anaconda3/envs/graphrag/lib/python3.9/site-packages/graspologic/utils/__init__.py\", line 4, in <module>\r\n    from .ptr import pass_to_ranks\r\n  File \"/data/newssd/anaconda3/envs/graphrag/lib/python3.9/site-packages/graspologic/utils/ptr.py\", line 8, in <module>\r\n    from .utils import import_graph, is_loopless, is_symmetric, is_unweighted, symmetrize\r\n  File \"/data/newssd/anaconda3/envs/graphrag/lib/python3.9/site-packages/graspologic/utils/utils.py\", line 13, in <module>\r\n    from beartype import beartype\r\n  File \"/data/newssd/anaconda3/envs/graphrag/lib/python3.9/site-packages/beartype/__init__.py\", line 58, in <module>\r\n    from beartype._decor.decormain import (\r\n  File \"/data/newssd/anaconda3/envs/graphrag/lib/python3.9/site-packages/beartype/_decor/decormain.py\", line 26, in <module>\r\n    from beartype._conf.confcls import (\r\n  File \"/data/newssd/anaconda3/envs/graphrag/lib/python3.9/site-packages/beartype/_conf/confcls.py\", line 46, in <module>\r\n    from beartype._conf.confoverrides import (\r\n  File \"/data/newssd/anaconda3/envs/graphrag/lib/python3.9/site-packages/beartype/_conf/confoverrides.py\", line 15, in <module>\r\n    from beartype._data.hint.datahinttyping import (\r\n  File \"/data/newssd/anaconda3/envs/graphrag/lib/python3.9/site-packages/beartype/_data/hint/datahinttyping.py\", line 290, in <module>\r\n    BeartypeReturn = Union[BeartypeableT, BeartypeConfedDecorator]\r\n  File \"/data/newssd/anaconda3/envs/graphrag/lib/python3.9/typing.py\", line 244, in inner\r\n    return func(*args, **kwds)\r\n  File \"/data/newssd/anaconda3/envs/graphrag/lib/python3.9/typing.py\", line 317, in __getitem__\r\n    return self._getitem(self, parameters)\r\n  File \"/data/newssd/anaconda3/envs/graphrag/lib/python3.9/typing.py\", line 422, in Union\r\n    parameters = _remove_dups_flatten(parameters)\r\n  File \"/data/newssd/anaconda3/envs/graphrag/lib/python3.9/typing.py\", line 216, in _remove_dups_flatten\r\n    all_params = set(params)\r\nTypeError: unhashable type: 'list'\r\n\r\n当前params为：[~BeartypeableT, collections.abc.Callable[[~BeartypeableT], ~BeartypeableT]]\r\n\r\nparams一共在下面几种场景下会出现错误：\r\nwrong!!!!!\r\n[~BeartypeableT, collections.abc.Callable[[~BeartypeableT], ~BeartypeableT]]\r\nunhashable type: 'list'\r\n\r\nwrong!!!!!\r\n[<class 'type'>, collections.abc.Callable[[], object]]\r\nunhashable type: 'list'\r\n\r\nwrong!!!!!\r\n[collections.abc.Callable[[<class 'int'>], typing.Optional[frame]], <class 'NoneType'>]\r\n\r\n对应代码：\r\ndef _remove_dups_flatten(parameters):\r\n    \"\"\"An internal helper for Union creation and substitution: flatten Unions\r\n    among parameters, then remove duplicates.\r\n    \"\"\"\r\n    # Flatten out Union[Union[...], ...].\r\n    \r\n    params = []\r\n    for p in parameters:\r\n        if isinstance(p, _UnionGenericAlias):\r\n            params.extend(p.__args__)\r\n        elif isinstance(p, tuple) and len(p) > 0 and p[0] is Union:\r\n            params.extend(p[1:])\r\n        else:\r\n            params.append(p)\r\n    # Weed out strict duplicates, preserving the first of each occurrence.\r\n    all_params = set(params)  # 应该是这一句？\r\n    if len(all_params) < len(params):\r\n        new_params = []\r\n        for t in params:\r\n            if t in all_params:\r\n                new_params.append(t)\r\n                all_params.remove(t)\r\n        params = new_params\r\n        assert not all_params, all_params\r\n    return tuple(params)\r\n\r\n报错忽略直接返回tuple(params)似乎也能继续跑下去",
    "comments_url": "https://api.github.com/repos/gusye1234/nano-graphrag/issues/7/comments",
    "author": "Zack14159",
    "comments": [
      {
        "user": "gusye1234",
        "created_at": "2024-08-19T09:35:07Z",
        "body": "看起来是python版本和`graspologic`库的问题 你的python版本是什么？"
      },
      {
        "user": "Zack14159",
        "created_at": "2024-08-19T10:01:49Z",
        "body": "我的的python版本是 Python 3.9.0"
      },
      {
        "user": "Zack14159",
        "created_at": "2024-08-19T10:09:50Z",
        "body": "换成3.10.0以后ok了，不报错了，谢谢老师"
      }
    ]
  },
  {
    "number": 4,
    "title": "syntax errors in readme.md",
    "created_at": "2024-08-16T07:27:59Z",
    "closed_at": "2024-08-16T07:32:13Z",
    "labels": [],
    "url": "https://github.com/gusye1234/nano-graphrag/pull/4",
    "body": null,
    "comments_url": "https://api.github.com/repos/gusye1234/nano-graphrag/issues/4/comments",
    "author": "spro",
    "comments": [
      {
        "user": "gusye1234",
        "created_at": "2024-08-16T07:31:17Z",
        "body": "Sorry! LGTM"
      }
    ]
  },
  {
    "number": 1,
    "title": "Add list of TODOs in README",
    "created_at": "2024-08-15T14:57:24Z",
    "closed_at": "2024-08-16T11:03:36Z",
    "labels": [],
    "url": "https://github.com/gusye1234/nano-graphrag/issues/1",
    "body": "Hey guys,\r\n\r\nLooks great! Would you be willing to add a list of TODOs to the README, could be interesting to gather ideas for contributions. Or maybe smaller things like supporting local LLMs for instance.\r\n\r\n",
    "comments_url": "https://api.github.com/repos/gusye1234/nano-graphrag/issues/1/comments",
    "author": "NumberChiffre",
    "comments": [
      {
        "user": "gusye1234",
        "created_at": "2024-08-15T15:04:00Z",
        "body": "Exactly！\r\nWill add a TODO section to readme"
      }
    ]
  }
]