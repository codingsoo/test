[
  {
    "number": 71,
    "title": "[Example] Example usage of GraphRAG with Gemini LLM and Embeddings from VertexAI",
    "created_at": "2025-01-21T23:57:12Z",
    "closed_at": "2025-01-22T07:56:22Z",
    "labels": [],
    "url": "https://github.com/circlemind-ai/fast-graphrag/pull/71",
    "body": "This example demonstrates how to use Google Cloud's Vertex AI services with fast-GraphRAG\r\nBecause Gemini is not OpenAI API compatible and Instructor does not fully support Vertex AI - inheriting from base classes.\r\n\r\nThis example demonstrates how to use Google Cloud's Vertex AI services with GraphRAG:\r\n- Gemini LLM for fast-graphrag\r\n- Vertex AI model for text embeddings\r\n\r\nPrerequisites:\r\n- Google Cloud account with Vertex AI API enabled\r\n- Appropriate credentials or IAM auth configured\r\n- Python 3.9+\r\n\r\nDependencies:\r\n    pip install fast-graphrag google-cloud-aiplatform\r\n\r\nAuthentication:\r\n    gcloud auth application-default login\r\n\r\nUsage:\r\n    python gemini_vertexai_llm.py",
    "comments_url": "https://api.github.com/repos/circlemind-ai/fast-graphrag/issues/71/comments",
    "author": "tensoralex",
    "comments": [
      {
        "user": "liukidar",
        "created_at": "2025-01-22T07:56:22Z",
        "body": "Looks good to me!"
      }
    ]
  },
  {
    "number": 66,
    "title": "【question】About benchmark comparison",
    "created_at": "2025-01-14T08:40:11Z",
    "closed_at": "2025-02-18T08:51:28Z",
    "labels": [],
    "url": "https://github.com/circlemind-ai/fast-graphrag/issues/66",
    "body": "In benchmark experiments, the test set contains data from multiple domains. Will this lead to the recall of data from other incorrect domains during queries, or do you also consider this as a kind of capability test?\r\n\r\n",
    "comments_url": "https://api.github.com/repos/circlemind-ai/fast-graphrag/issues/66/comments",
    "author": "wangzhen38",
    "comments": [
      {
        "user": "liukidar",
        "created_at": "2025-01-14T11:18:44Z",
        "body": "Hello, yes, indeed when you recall data given a query, it is possible to touch multiple domains, but as the RAG quality improves, this becomes less and less likely "
      }
    ]
  },
  {
    "number": 65,
    "title": "How to get the entity count?",
    "created_at": "2025-01-14T04:20:00Z",
    "closed_at": "2025-01-17T03:27:17Z",
    "labels": [],
    "url": "https://github.com/circlemind-ai/fast-graphrag/issues/65",
    "body": "After generating the pkl files, how to get the total number of entities?\r\n",
    "comments_url": "https://api.github.com/repos/circlemind-ai/fast-graphrag/issues/65/comments",
    "author": "timelesshc",
    "comments": [
      {
        "user": "liukidar",
        "created_at": "2025-01-15T11:23:29Z",
        "body": "Hello, once you load the graph class, you can call `await graph.state_manager.get_num_entities()`"
      },
      {
        "user": "timelesshc",
        "created_at": "2025-01-16T10:06:05Z",
        "body": "@liukidar hi, thanks so much for the response. I tried your method but it gives me below error. Any suggestions?\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"E:\\zhipu\\项目\\fast-graphrag\\hotpotQA\\fast-graphrag_zhipu.py\", line 46, in <module>\r\n    count = asyncio.run(get_entity_count())\r\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"E:\\Program Files\\conda_env\\envs\\GraphRAG\\Lib\\asyncio\\runners.py\", line 194, in run\r\n    return runner.run(main)\r\n           ^^^^^^^^^^^^^^^^\r\n  File \"E:\\Program Files\\conda_env\\envs\\GraphRAG\\Lib\\asyncio\\runners.py\", line 118, in run\r\n    return self._loop.run_until_complete(task)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"E:\\Program Files\\conda_env\\envs\\GraphRAG\\Lib\\asyncio\\base_events.py\", line 687, in run_until_complete\r\n    return future.result()\r\n           ^^^^^^^^^^^^^^^\r\n  File \"E:\\zhipu\\项目\\fast-graphrag\\hotpotQA\\fast-graphrag_zhipu.py\", line 43, in get_entity_count\r\n    count = await grag.state_manager.get_num_entities()\r\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"E:\\Program Files\\conda_env\\envs\\GraphRAG\\Lib\\site-packages\\fast_graphrag\\_services\\_state_manager.py\", line 56, in get_num_entities\r\n    return await self.graph_storage.node_count()\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"E:\\Program Files\\conda_env\\envs\\GraphRAG\\Lib\\site-packages\\fast_graphrag\\_storage\\_gdb_igraph.py\", line 41, in node_count\r\n    return self._graph.vcount()  # type: ignore\r\n           ^^^^^^^^^^^^^^^^^^\r\nAttributeError: 'NoneType' object has no attribute 'vcount'\r\n```\r\n\r\nMy code:\r\n```\r\nworking_dir = \"./output\"\r\ngrag = GraphRAG(\r\n    working_dir=working_dir,\r\n    domain=DOMAIN,\r\n    example_queries=\"\\n\".join(EXAMPLE_QUERIES),\r\n    entity_types=ENTITY_TYPES,\r\n    config=GraphRAG.Config(\r\n        llm_service=OpenAILLMService(\r\n            model=LLM, base_url=URL, api_key=API_KEY\r\n        ),\r\n        embedding_service=OpenAIEmbeddingService(\r\n            model=EMBEDDER,\r\n            base_url=URL,\r\n            api_key=API_KEY,\r\n            embedding_dim=2048,  # the output embedding dim of the chosen model\r\n        )\r\n    ),\r\n)\r\nasync def get_entity_count():\r\n    count = await grag.state_manager.get_num_entities()\r\n    return count\r\n\r\ncount = asyncio.run(get_entity_count())\r\nprint(count)\r\n```"
      },
      {
        "user": "liukidar",
        "created_at": "2025-01-16T14:54:05Z",
        "body": "Sorry, i forgot to explain what I meant with \"load the graph class\". The following code should work:\n\n```python\nworking_dir = \"./output\"\ngrag = GraphRAG(\n    working_dir=working_dir,\n    domain=DOMAIN,\n    example_queries=\"\\n\".join(EXAMPLE_QUERIES),\n    entity_types=ENTITY_TYPES,\n    config=GraphRAG.Config(\n        llm_service=OpenAILLMService(\n            model=LLM, base_url=URL, api_key=API_KEY\n        ),\n        embedding_service=OpenAIEmbeddingService(\n            model=EMBEDDER,\n            base_url=URL,\n            api_key=API_KEY,\n            embedding_dim=2048,  # the output embedding dim of the chosen model\n        )\n    ),\n)\nasync def get_entity_count():\n    await grag.state_manager.query_start()\n    count = await grag.state_manager.get_num_entities()\n    await grag.state_manager.query_done()\n    return count\n\ncount = asyncio.run(get_entity_count())\nprint(count)\n```"
      },
      {
        "user": "timelesshc",
        "created_at": "2025-01-17T03:27:17Z",
        "body": "@liukidar this worked! Thanks!"
      }
    ]
  },
  {
    "number": 64,
    "title": "Question about QFS task",
    "created_at": "2025-01-13T11:42:45Z",
    "closed_at": "2025-01-17T15:05:38Z",
    "labels": [],
    "url": "https://github.com/circlemind-ai/fast-graphrag/issues/64",
    "body": "I noticed that fast-graphrag ignore the concept of community(introduce personalized pagerank instead, amazing idea) to improve efficiency. I wonder how fast-graphrag handle QFS task like \"What's the top theme of the passage\"? Thank you for your time and consideration.",
    "comments_url": "https://api.github.com/repos/circlemind-ai/fast-graphrag/issues/64/comments",
    "author": "Dormiveglia-elf",
    "comments": [
      {
        "user": "liukidar",
        "created_at": "2025-01-14T11:15:09Z",
        "body": "Hello, we believe that QFS questions are not really RAG in the sense of \"finding the piece of context for this query\" but they can be approximated by it if enough chunks are gathered. "
      }
    ]
  },
  {
    "number": 62,
    "title": "[bug fix] update azure example",
    "created_at": "2025-01-09T09:22:45Z",
    "closed_at": "2025-01-11T11:58:36Z",
    "labels": [],
    "url": "https://github.com/circlemind-ai/fast-graphrag/pull/62",
    "body": "the former custom_llm.py cannont run succeefully in azure.",
    "comments_url": "https://api.github.com/repos/circlemind-ai/fast-graphrag/issues/62/comments",
    "author": "wangzhen38",
    "comments": [
      {
        "user": "liukidar",
        "created_at": "2025-01-11T11:58:28Z",
        "body": "Looks good!"
      }
    ]
  },
  {
    "number": 58,
    "title": "Wrong Dimensionality of Vectors Error",
    "created_at": "2025-01-06T10:26:22Z",
    "closed_at": "2025-01-06T10:40:31Z",
    "labels": [],
    "url": "https://github.com/circlemind-ai/fast-graphrag/issues/58",
    "body": "Hi there, I am facing this error of wrong dimensionality of vectors.\r\nFollowing is my python code\r\n```python\r\n  working_dir = \"./myFile\"\r\n  grag = GraphRAG(\r\n      working_dir=working_dir,\r\n      domain=DOMAIN,\r\n      example_queries=\"\\n\".join(QUERIES),\r\n      entity_types=ENTITY_TYPES,\r\n      config=GraphRAG.Config(\r\n          llm_service=OpenAILLMService(\r\n              model=\"gpt-4o\",\r\n              base_url= os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\r\n              api_key= os.getenv(\"AZURE_OPENAI_API_KEY\"),\r\n              client= os.getenv(\"OPENAI_API_TYPE\"), \r\n              mode=instructor.Mode.JSON\r\n          ),\r\n          embedding_service=OpenAIEmbeddingService(\r\n              model=\"text-embedding-3-large\",\r\n              base_url= os.getenv(\"AZURE_OPENAI_EMBED_ENDPOINT\"),\r\n              api_key= os.getenv(\"AZURE_OPENAI_API_KEY\"),\r\n              client= os.getenv(\"OPENAI_API_TYPE\"), \r\n              embedding_dim=512,  # the output embedding dim of the chosen model\r\n          ),\r\n      ),\r\n  )\r\n  with open(\"./data.txt\", encoding=\"utf8\") as f:\r\n    grag.insert(f.read())\r\n```\r\nAnd I am facing this error\r\n\r\n```python\r\nExtracting data: 100%|██████████| 1/1 [00:18<00:00, 18.24s/it]\r\nError during insertion: Wrong dimensionality of the vectors\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\nCell In[11], [line 2](vscode-notebook-cell:?execution_count=11&line=2)\r\n      [1](vscode-notebook-cell:?execution_count=11&line=1) with open(\"./data.txt\", encoding=\"utf8\") as f:\r\n----> [2](vscode-notebook-cell:?execution_count=11&line=2)     grag.insert(f.read())\r\n\r\nFile c:\\Users\\user\\Downloads\\python\\Expedio\\env\\Lib\\site-packages\\fast_graphrag\\_graphrag.py:75, in BaseGraphRAG.insert(self, content, metadata, params, show_progress)\r\n     [68](file:///C:/Users/user/Downloads/python/Expedio/env/Lib/site-packages/fast_graphrag/_graphrag.py:68) def insert(\r\n     [69](file:///C:/Users/user/Downloads/python/Expedio/env/Lib/site-packages/fast_graphrag/_graphrag.py:69)     self,\r\n     [70](file:///C:/Users/user/Downloads/python/Expedio/env/Lib/site-packages/fast_graphrag/_graphrag.py:70)     content: Union[str, List[str]],\r\n   (...)\r\n     [73](file:///C:/Users/user/Downloads/python/Expedio/env/Lib/site-packages/fast_graphrag/_graphrag.py:73)     show_progress: bool = True\r\n     [74](file:///C:/Users/user/Downloads/python/Expedio/env/Lib/site-packages/fast_graphrag/_graphrag.py:74) ) -> Tuple[int, int, int]:\r\n---> [75](file:///C:/Users/user/Downloads/python/Expedio/env/Lib/site-packages/fast_graphrag/_graphrag.py:75)     return get_event_loop().run_until_complete(self.async_insert(content, metadata, params, show_progress))\r\n\r\nFile c:\\Users\\user\\Downloads\\python\\Expedio\\env\\Lib\\site-packages\\nest_asyncio.py:98, in _patch_loop.<locals>.run_until_complete(self, future)\r\n     [95](file:///C:/Users/user/Downloads/python/Expedio/env/Lib/site-packages/nest_asyncio.py:95) if not f.done():\r\n     [96](file:///C:/Users/user/Downloads/python/Expedio/env/Lib/site-packages/nest_asyncio.py:96)     raise RuntimeError(\r\n     [97](file:///C:/Users/user/Downloads/python/Expedio/env/Lib/site-packages/nest_asyncio.py:97)         'Event loop stopped before Future completed.')\r\n---> [98](file:///C:/Users/user/Downloads/python/Expedio/env/Lib/site-packages/nest_asyncio.py:98) return f.result()\r\n\r\nFile C:\\Python312\\Lib\\asyncio\\futures.py:203, in Future.result(self)\r\n    [201](file:///C:/Python312/Lib/asyncio/futures.py:201) self.__log_traceback = False\r\n    [202](file:///C:/Python312/Lib/asyncio/futures.py:202) if self._exception is not None:\r\n--> [203](file:///C:/Python312/Lib/asyncio/futures.py:203)     raise self._exception.with_traceback(self._exception_tb)\r\n...\r\n     [63](file:///C:/Users/user/Downloads/python/Expedio/env/Lib/site-packages/fast_graphrag/_storage/_vdb_hnswlib.py:63) if metadata:\r\n     [64](file:///C:/Users/user/Downloads/python/Expedio/env/Lib/site-packages/fast_graphrag/_storage/_vdb_hnswlib.py:64)     self._metadata.update(dict(zip(ids, metadata)))\r\n---> [65](file:///C:/Users/user/Downloads/python/Expedio/env/Lib/site-packages/fast_graphrag/_storage/_vdb_hnswlib.py:65) self._index.add_items(data=embeddings, ids=ids, num_threads=self.config.num_threads)\r\n\r\nRuntimeError: Wrong dimensionality of the vectors\r\n```\r\nThe models are set correctly, but this weird error is occuring",
    "comments_url": "https://api.github.com/repos/circlemind-ai/fast-graphrag/issues/58/comments",
    "author": "idreesghazi",
    "comments": [
      {
        "user": "liukidar",
        "created_at": "2025-01-06T10:30:51Z",
        "body": "Hello, the line `embedding_dim=512` should be modified to reflect the size of the output of your chosen embedding model. In this case, `\"text-embedding-3-large\"` uses 1536 dimensions."
      },
      {
        "user": "idreesghazi",
        "created_at": "2025-01-06T10:35:24Z",
        "body": "I have tried this too, but the error is still the same\r\n\r\n```pyhon\r\nworking_dir = \"./myFile\"\r\ngrag = GraphRAG(\r\n    working_dir=working_dir,\r\n    domain=DOMAIN,\r\n    example_queries=\"\\n\".join(QUERIES),\r\n    entity_types=ENTITY_TYPES,\r\n    config=GraphRAG.Config(\r\n        llm_service=OpenAILLMService(\r\n            model=\"gpt-4o\",\r\n            base_url= os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\r\n            api_key= os.getenv(\"AZURE_OPENAI_API_KEY\"),\r\n            client= os.getenv(\"OPENAI_API_TYPE\"), \r\n            mode=instructor.Mode.JSON\r\n        ),\r\n        embedding_service=OpenAIEmbeddingService(\r\n            model=\"text-embedding-3-large\",\r\n            base_url= os.getenv(\"AZURE_OPENAI_EMBED_ENDPOINT\"),\r\n            api_key= os.getenv(\"AZURE_OPENAI_API_KEY\"),\r\n            client= os.getenv(\"OPENAI_API_TYPE\"), \r\n            embedding_dim=1536,\r\n        ),\r\n    ),\r\n)\r\nwith open(\"./data.txt\", encoding=\"utf8\") as f:\r\n    grag.insert(f.read())\r\n```\r\n```python\r\nExtracting data: 100%|██████████| 1/1 [00:18<00:00, 18.24s/it]\r\nError during insertion: Wrong dimensionality of the vectors\r\n```"
      },
      {
        "user": "liukidar",
        "created_at": "2025-01-06T10:38:51Z",
        "body": "Sorry, didn't notice the \"-large\", that embedding model uses 3072 dimensions. It could be a bit overkill for this usage, but it would be interesting to benchmark against the default \"-small\" one."
      },
      {
        "user": "idreesghazi",
        "created_at": "2025-01-06T10:40:31Z",
        "body": "Thank you very much brother, this solved my problem"
      }
    ]
  },
  {
    "number": 56,
    "title": "self.state_manager.query_start() missing in GraphRAG.async_query()",
    "created_at": "2024-12-27T08:03:29Z",
    "closed_at": "2025-02-18T09:03:23Z",
    "labels": [],
    "url": "https://github.com/circlemind-ai/fast-graphrag/issues/56",
    "body": "When retaining a built knowledge graph from a working directory, the data is not loaded until `self.state_manager.query_start()` is called， I guess.\r\n\r\nI realized `self.state_manager.query_start()` is called in the method `GraphRAG.query()`, but not in the method `GraphRAG.async_query()`. It seems that I need to call `grag.manager.query_start()` manually when querying asyncly. Is it better to add `self.state_manager.query_start()` inside `GraphRAG.async_query()`？",
    "comments_url": "https://api.github.com/repos/circlemind-ai/fast-graphrag/issues/56/comments",
    "author": "crasylph",
    "comments": [
      {
        "user": "liukidar",
        "created_at": "2024-12-27T08:09:58Z",
        "body": "Hello @crasylph!\r\nThe asynch method exists to answer multiple queries asynchronously. Let me know if the following example answers your doubts:\r\n```python\r\nfrom fast_graphrag import GraphRAG, QueryParam\r\nfrom fast_graphrag._utils import get_event_loop\r\n\r\ngrag = GraphRAG(\r\n        working_dir=working_dir,\r\n        domain=DOMAIN[args.dataset],\r\n        example_queries=\"\\n\".join(QUERIES),\r\n        entity_types=ENTITY_TYPES[args.dataset],\r\n)\r\n\r\nasync def _query_task(query: Query) -> Dict[str, Any]:\r\n        answer = await grag.async_query(query.question, QueryParam(only_context=True))\r\n        return {\r\n            \"question\": query.question,\r\n            \"answer\": answer.response,\r\n            \"evidence\": [\r\n                corpus[chunk.metadata[\"id\"]][0]\r\n                    if isinstance(chunk.metadata[\"id\"], int)\r\n                    else chunk.metadata[\"id\"]\r\n                for chunk, _ in answer.context.chunks\r\n            ],\r\n            \"ground_truth\": [e[0] for e in query.evidence],\r\n        }\r\n\r\nasync def _run():\r\n        await grag.state_manager.query_start()\r\n        answers = [\r\n            await a\r\n            for a in tqdm(asyncio.as_completed([_query_task(query) for query in queries]), total=len(queries))\r\n        ]\r\n        await grag.state_manager.query_done()\r\n        return answers\r\n\r\nanswers = get_event_loop().run_until_complete(_run())\r\n```\r\n(this script is taken from the graph_benchmark.py script if you want the full reference)\r\n\r\nBest,\r\nLuca"
      },
      {
        "user": "jamesfebin",
        "created_at": "2025-01-28T09:27:49Z",
        "body": "Thank you."
      }
    ]
  },
  {
    "number": 47,
    "title": "Compared with GraphRAG, what optimizations are used to cost down? Could you share some info? Thanks",
    "created_at": "2024-12-12T08:15:28Z",
    "closed_at": "2024-12-13T01:07:19Z",
    "labels": [],
    "url": "https://github.com/circlemind-ai/fast-graphrag/issues/47",
    "body": "**Describe the bug**\r\nA clear and concise description of what the bug is.\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Go to '...'\r\n2. Click on '....'\r\n3. Scroll down to '....'\r\n4. See error\r\n\r\n**Expected behavior**\r\nA clear and concise description of what you expected to happen.\r\n\r\n**Screenshots**\r\nIf applicable, add screenshots to help explain your problem.\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n",
    "comments_url": "https://api.github.com/repos/circlemind-ai/fast-graphrag/issues/47/comments",
    "author": "FrankWhh",
    "comments": [
      {
        "user": "liukidar",
        "created_at": "2024-12-12T20:31:57Z",
        "body": "Hello, compared to GraphRAG, we explore the graph using an algorithmic approach (i.e., variations of PageRank) instead of relying on LLM summarisation capabilities that significantly increases the cost of generating a graph."
      }
    ]
  },
  {
    "number": 36,
    "title": "unit test fix: add missing required 'keywords' parameter in TRelation",
    "created_at": "2024-12-01T18:59:29Z",
    "closed_at": "2024-12-01T19:33:00Z",
    "labels": [],
    "url": "https://github.com/circlemind-ai/fast-graphrag/pull/36",
    "body": null,
    "comments_url": "https://api.github.com/repos/circlemind-ai/fast-graphrag/issues/36/comments",
    "author": "9prodhi",
    "comments": [
      {
        "user": "antoniocirclemind",
        "created_at": "2024-12-01T19:32:41Z",
        "body": "LGTM, thanks!"
      }
    ]
  },
  {
    "number": 33,
    "title": "It is not able to answer general questions",
    "created_at": "2024-11-26T09:59:36Z",
    "closed_at": "2024-12-07T08:56:53Z",
    "labels": [],
    "url": "https://github.com/circlemind-ai/fast-graphrag/issues/33",
    "body": "**Describe the bug**\r\nI tested the example snippet available on README.md with my own questions and I got \r\n_\"Sorry, I'm not able to provide an answer to that question.\"_\r\nresponses.\r\n\r\nMy questions were general, **not entity focused**, like:\r\n- What is the story about?\r\n- Pls. summarize me the story!\r\n- Where does the story happen mainly?\r\n\r\n**To Reproduce**\r\nTry to test it with such questions.\r\n\r\n**Expected behavior**\r\nit answers correctly.\r\n\r\nI think the workflow should be modified to be able to handle such general questions.",
    "comments_url": "https://api.github.com/repos/circlemind-ai/fast-graphrag/issues/33/comments",
    "author": "vanetreg",
    "comments": [
      {
        "user": "9prodhi",
        "created_at": "2024-11-28T17:11:03Z",
        "body": "For generic queries that are not entity-focused, such as:\r\n\r\n- *What is the story about?*\r\n- *Please summarize the story for me!*\r\n- *Where does the story mainly happen?*\r\n\r\nIn `fast_graphrag/_graphrag.py`, the following code attempts to extract entities from the query:\r\n\r\n```python\r\n# Extract entities from query\r\nextracted_entities = await self.information_extraction_service.extract_entities_from_query(\r\n    llm=self.llm_service, query=query, prompt_kwargs={}\r\n)\r\n```\r\n\r\n\r\nHowever, in these cases, ```extracted_entities``` returns:\r\n\r\n```json\r\n{\"entities\": [], \"n\": 0}\r\n```\r\n\r\nThis leads to an issue in the ```get_context``` function within ```fast_graphrag/_services/_state_manager.py```, where the function returns None:\r\n\r\n```python\r\nasync def get_context(\r\n    self, query: str, entities: Iterable[TEntity]\r\n) -> Optional[TContext[TEntity, TRelation, THash, TChunk]]:\r\n    if self.entity_storage.size == 0:\r\n        return None\r\n\r\n    try:\r\n        entity_names = [entity.name for entity in entities]\r\n        if len(entity_names) == 0:\r\n            return None\r\n```\r\nAs a result, we receive the response:\r\n\r\n    \"Sorry, I'm not able to provide an answer to that question.\"\r\n    \r\n \r\nFor generic questions like these, we should consider the entire graph as the context and filtering key entities and relations based on specific filtering criteria.\r\n\r\n@liukidar What are your thoughts on how we could address this?\r\n"
      },
      {
        "user": "liukidar",
        "created_at": "2024-11-28T17:17:33Z",
        "body": "@9prodhi You are totally right here. The second if should definitely not be there now that we have hybrid querying (we also select nodes based on query similarity like in graphrag/lightrag). Since you spotted this, I'd be happy if you issued a pull request that skips the embedding step for the entities if there are none and only uses the query in that case. I can also do that if you prefer :)"
      },
      {
        "user": "liukidar",
        "created_at": "2024-11-28T17:19:54Z",
        "body": "More in general, @vanetreg, we are looking at taking some inspiration from lightrag and introducing an idea of \"generic concepts\" that can be useful to connect far away nodes and hopefully help in answering more general quesitons (also right now the llm prompt may not be really tuned for that kind of questions, but we have to try and see)."
      },
      {
        "user": "9prodhi",
        "created_at": "2024-11-28T17:29:02Z",
        "body": "@liukidar Thanks for the prompt response! I’ll take a look and implement some logic similar to MS graphrag/lightrag."
      },
      {
        "user": "liukidar",
        "created_at": "2024-11-28T17:33:02Z",
        "body": "> @liukidar Thanks for the prompt response! I’ll take a look and implement some logic similar to MS graphrag/lightrag.\r\n\r\nAhah, no need to do that (but I'm very happy to chat about it if you're keen to) :) I simply thought that it would have been nice for you to contribute to the repo by changing the couple of lines of code of that wrong `if`, but no worries if it's too bothering, I can do that.\r\nBasically the if should be around\r\n```python\r\nvdb_entity_scores_by_name = await self._score_entities_by_vectordb(\r\n        query_embeddings=query_embeddings[:-1], top_k=1\r\n)\r\n```\r\ninstead of returning None."
      },
      {
        "user": "vanetreg",
        "created_at": "2024-11-28T20:59:25Z",
        "body": "I think an agent can decide if the question / query is stored entity related or not. If so use graph retriever, if not stored entity related, use a hybrid retriever (eg. BM25 + vector)"
      },
      {
        "user": "liukidar",
        "created_at": "2024-11-29T16:14:54Z",
        "body": "We kinda do this already, however there was an if preventing the llm to try to answer if the question contained no relevant entities."
      },
      {
        "user": "liukidar",
        "created_at": "2024-12-07T00:53:38Z",
        "body": "Any feedback on this? I believe this is now fixed."
      },
      {
        "user": "vanetreg",
        "created_at": "2024-12-07T08:56:53Z",
        "body": "> Any feedback on this? I believe this is now fixed.\r\n\r\nI tested it with 2 of the mentioned generic questions and the response seemed to be OK. ( I don't know the book )"
      }
    ]
  },
  {
    "number": 25,
    "title": "i'm stack with Extracting data",
    "created_at": "2024-11-21T02:22:47Z",
    "closed_at": "2024-12-07T00:52:10Z",
    "labels": [],
    "url": "https://github.com/circlemind-ai/fast-graphrag/issues/25",
    "body": "**Describe the bug**\r\nA clear and concise description of what the bug is.\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Go to '...'\r\n2. Click on '....'\r\n3. Scroll down to '....'\r\n4. See error\r\n\r\n**Expected behavior**\r\nA clear and concise description of what you expected to happen.\r\n\r\n**Screenshots**\r\nIf applicable, add screenshots to help explain your problem.\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\nExtracting data:   0%|                                                                                                                                                                                                                                                                                                                            | 0/1 [00:00<?, ?it/s]",
    "comments_url": "https://api.github.com/repos/circlemind-ai/fast-graphrag/issues/25/comments",
    "author": "GanQiao1990",
    "comments": [
      {
        "user": "Z-oo883",
        "created_at": "2024-11-21T08:57:14Z",
        "body": "me too! Have you found a solution yet？"
      },
      {
        "user": "GanQiao1990",
        "created_at": "2024-11-21T09:09:33Z",
        "body": "> me too! Have you found a solution yet？\r\n\r\nnone"
      },
      {
        "user": "antoniocirclemind",
        "created_at": "2024-11-21T09:16:00Z",
        "body": "Hello! Could you expand on your setup and help us reproduce the issue?\r\n\r\n- Are you using local LLMs? If yes, what is your setup?\r\n- What data are you currently trying it on? Is it the book from our example?"
      },
      {
        "user": "Z-oo883",
        "created_at": "2024-11-21T09:31:49Z",
        "body": "I started QWEN on Fastchat, but it got stuck all the time. I'll switch to VLLM to start QWEN and it will run"
      },
      {
        "user": "liukidar",
        "created_at": "2024-11-21T21:17:49Z",
        "body": "Hey, could you try to insert a very small example (if you haven't done that already) and see if it gets stuck anyway?"
      }
    ]
  },
  {
    "number": 22,
    "title": "RuntimeError: Cannot return the results in a contiguous 2D array. Probably ef or M is too small",
    "created_at": "2024-11-19T15:51:28Z",
    "closed_at": "2024-11-21T21:20:32Z",
    "labels": [],
    "url": "https://github.com/circlemind-ai/fast-graphrag/issues/22",
    "body": "**Describe the bug**\r\nRuntimeError: Cannot return the results in a contiguous 2D array. Probably ef or M is too small\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. Simple document in UTF\r\n2. Simple query:\r\n´´\r\nfrom fast_graphrag import GraphRAG\r\n\r\nDOMAIN = \"Quais os elementos envolvidos na história abaixo.\"\r\n\r\nEXAMPLE_QUERIES = [\r\n    \"Quais são os personagens, elementos e datas envolvidas e como elas se relacionam ?\"\r\n]\r\n\r\nENTITY_TYPES = [\"Pessoas\", \"Lugares\", \"Datas\"]\r\n\r\ngrag = GraphRAG(\r\n    working_dir=\"./book_example\",\r\n    domain=DOMAIN,\r\n    example_queries=\"\\n\".join(EXAMPLE_QUERIES),\r\n    entity_types=ENTITY_TYPES\r\n)\r\n\r\nwith open(\"./book.txt\") as f:\r\n    grag.insert(f.read())\r\n\r\nprint(grag.query(\"Quais os elementos envolvidos?\").response)\r\n´´\r\n\r\n",
    "comments_url": "https://api.github.com/repos/circlemind-ai/fast-graphrag/issues/22/comments",
    "author": "oliveiracwb",
    "comments": [
      {
        "user": "liukidar",
        "created_at": "2024-11-19T17:26:34Z",
        "body": "This should have been fixed with the last commit, please try!"
      },
      {
        "user": "liukidar",
        "created_at": "2024-11-21T21:20:32Z",
        "body": "Please feel free to reopen this is the issue persist, but I believe it should be fixed now."
      },
      {
        "user": "oliveiracwb",
        "created_at": "2024-11-25T10:57:41Z",
        "body": "I wanted to let you know that the issue has been resolved, and everything is working perfectly now. Thank you so much for your prompt attention and support!"
      }
    ]
  },
  {
    "number": 19,
    "title": "Update _llm_openai.py",
    "created_at": "2024-11-19T10:30:09Z",
    "closed_at": "2024-11-19T16:51:41Z",
    "labels": [],
    "url": "https://github.com/circlemind-ai/fast-graphrag/pull/19",
    "body": "For initializing the llm_async_client by user passed value(base_url、api_key、model)\r\n\r\nwe also need to pass the base_url info to AsyncOpenAI. Otherwise, we cannot initialize an llm_async_client with a customized oai-api like service.\r\n\r\nThis commit just passing the base_utl to AsyncOpenAI",
    "comments_url": "https://api.github.com/repos/circlemind-ai/fast-graphrag/issues/19/comments",
    "author": "ZeyuTeng96",
    "comments": [
      {
        "user": "liukidar",
        "created_at": "2024-11-19T16:54:16Z",
        "body": "Thanks for this, I completelty missed that :(\r\nI also added it to the embedder"
      }
    ]
  },
  {
    "number": 9,
    "title": "pip dependencies conflict",
    "created_at": "2024-11-12T03:35:37Z",
    "closed_at": "2024-11-20T01:02:35Z",
    "labels": [],
    "url": "https://github.com/circlemind-ai/fast-graphrag/issues/9",
    "body": "**Describe the bug**\r\nWhen I first execute pip install fast-graphrag:\r\nERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\ngraspologic 3.4.1 requires scipy==1.12.0, but you have scipy 1.14.1 which is incompatible.\r\ngensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.14.1 which is incompatible.\r\n\r\nif I pip install scipy==1.12.0\r\nERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\nfast-graphrag 0.0.1.post0 requires scipy<2.0.0,>=1.14.1, but you have scipy 1.12.0 which is incompatible.\r\n\r\nI think it is impossible to solve the conflict now.\r\n**To Reproduce**\r\nSteps to reproduce the behavior:\r\n1. pip install fast-graphrag\r\n2. pip install scipy==1.12.0\r\n3. pip check\r\n\r\n**Expected behavior**\r\nNo conflict\r\n\r\n**Screenshots**\r\nIf applicable, add screenshots to help explain your problem.\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n",
    "comments_url": "https://api.github.com/repos/circlemind-ai/fast-graphrag/issues/9/comments",
    "author": "Dormiveglia-elf",
    "comments": [
      {
        "user": "liukidar",
        "created_at": "2024-11-13T03:14:48Z",
        "body": "Hello! I have tried running it with scipy==1.12.0 and nothing seems to break, so you should be good by just running `pip install scipy==1.12.0` and then using the code as normally. (However, note that those packages you plan to use are not officially supported)."
      },
      {
        "user": "Dormiveglia-elf",
        "created_at": "2024-11-13T07:14:20Z",
        "body": "> Hello! I have tried running it with scipy==1.12.0 and nothing seems to break, so you should be good by just running `pip install scipy==1.12.0` and then using the code as normally. (However, note that those packages you plan to use are not officially supported).\r\n\r\nI just clone your repo from github, still get the error below\r\nERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\nfast-graphrag 0.0.1.post0 requires scipy<2.0.0,>=1.14.1, but you have scipy 1.12.0 which is incompatible.\r\nSuccessfully installed scipy-1.12.0\r\n"
      },
      {
        "user": "liukidar",
        "created_at": "2024-11-15T02:06:13Z",
        "body": "> > Hello! I have tried running it with scipy==1.12.0 and nothing seems to break, so you should be good by just running `pip install scipy==1.12.0` and then using the code as normally. (However, note that those packages you plan to use are not officially supported).\r\n> \r\n> I just clone your repo from github, still get the error below ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. fast-graphrag 0.0.1.post0 requires scipy<2.0.0,>=1.14.1, but you have scipy 1.12.0 which is incompatible. Successfully installed scipy-1.12.0\r\n\r\nIt looks like in the environment where you are trying to install the library you have already some other packages that require scipy 1.12.0 which is not (officialy) compatible with fast-graphrag. To solve this issue you should either remove those packages before installing fast-graphrag or install it in a different virtual environment.\r\n\r\nLet me know if this solves your issue."
      }
    ]
  },
  {
    "number": 7,
    "title": "invalid edge id ",
    "created_at": "2024-11-04T09:51:27Z",
    "closed_at": "2024-11-15T02:04:12Z",
    "labels": [],
    "url": "https://github.com/circlemind-ai/fast-graphrag/issues/7",
    "body": "```\r\nError during insertion: Error at src/graph/iterators.c:1999: Cannot create iterator, invalid edge ID. -- Invalid value\r\nTraceback (most recent call last):\r\n  File \"/Users/mipl/ramen/backend/fast-graph-rag/main.py\", line 42, in <module>\r\n    grag.insert(f.read())\r\n  File \"/Users/mipl/ramen/backend/fast-graph-rag/fast-graphrag/fast_graphrag/_graphrag.py\", line 53, in insert\r\n    return get_event_loop().run_until_complete(self.async_insert(content, metadata))\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/homebrew/Cellar/python@3.12/3.12.3/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 687, in run_until_complete\r\n    return future.result()\r\n           ^^^^^^^^^^^^^^^\r\n  File \"/Users/mipl/ramen/backend/fast-graph-rag/fast-graphrag/fast_graphrag/_graphrag.py\", line 99, in async_insert\r\n    raise e\r\n  File \"/Users/mipl/ramen/backend/fast-graph-rag/fast-graphrag/fast_graphrag/_graphrag.py\", line 96, in async_insert\r\n    await self.state_manager.upsert(llm=self.llm_service, subgraphs=subgraphs, documents=new_chunks_per_data)\r\n  File \"/Users/mipl/ramen/backend/fast-graph-rag/fast-graphrag/fast_graphrag/_services/_state_manager.py\", line 96, in upsert\r\n    _, _ = await self.edge_upsert_policy(\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/mipl/ramen/backend/fast-graph-rag/fast-graphrag/fast_graphrag/_policies/_graph_upsert.py\", line 305, in __call__\r\n    return target, chain(*await asyncio.gather(*edge_upsert_tasks))\r\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/mipl/ramen/backend/fast-graph-rag/fast-graphrag/fast_graphrag/_policies/_graph_upsert.py\", line 211, in _upsert_edge\r\n    upserted_eges = await self._merge_similar_edges(llm, target, existing_edges, edges)\r\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/mipl/ramen/backend/fast-graph-rag/fast-graphrag/fast_graphrag/_policies/_graph_upsert.py\", line 288, in _merge_similar_edges\r\n    await target.delete_edges_by_index([i for i, v in indices_to_delete.items() if v])\r\n  File \"/Users/mipl/ramen/backend/fast-graph-rag/fast-graphrag/fast_graphrag/_storage/_gdb_igraph.py\", line 120, in delete_edges_by_index\r\n    self._graph.delete_edges(indices)  # type: ignore\r\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/mipl/ramen/backend/venv/lib/python3.12/site-packages/igraph/basic.py\", line 158, in _delete_edges\r\n    return GraphBase.delete_edges(graph, edge_seq)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nigraph._igraph.InternalError: Error at src/graph/iterators.c:1999: Cannot create iterator, invalid edge ID. -- Invalid value\r\n```",
    "comments_url": "https://api.github.com/repos/circlemind-ai/fast-graphrag/issues/7/comments",
    "author": "manishiitg",
    "comments": [
      {
        "user": "liukidar",
        "created_at": "2024-11-04T19:31:10Z",
        "body": "Hello, there was a race condition going on, hopefully that is fixed now. I have updated the main branch. Let me know."
      }
    ]
  },
  {
    "number": 4,
    "title": "indexing issue",
    "created_at": "2024-11-03T03:39:18Z",
    "closed_at": "2024-11-04T09:51:00Z",
    "labels": [],
    "url": "https://github.com/circlemind-ai/fast-graphrag/issues/4",
    "body": "got this error when trying to grag.insert(f.read())\r\n\r\n```\r\nfile_path ./SantaClaraData/other_city_files/Santa_Clara_University_Five_Year_Master_Plan/Santa_Clara_University_Five_Year_Master_Plan_Santa_Clara_University_Development_Plan.txt\r\nError during insertion: Python int too large to convert to C long\r\nTraceback (most recent call last):\r\n  File \"/Users/mipl/ramen/backend/fast-graph-rag/main.py\", line 42, in <module>\r\n    grag.insert(f.read())\r\n  File \"/Users/mipl/ramen/backend/venv/lib/python3.12/site-packages/fast_graphrag/_graphrag.py\", line 53, in insert\r\n    return get_event_loop().run_until_complete(self.async_insert(content, metadata))\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/homebrew/Cellar/python@3.12/3.12.3/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 687, in run_until_complete\r\n    return future.result()\r\n           ^^^^^^^^^^^^^^^\r\n  File \"/Users/mipl/ramen/backend/venv/lib/python3.12/site-packages/fast_graphrag/_graphrag.py\", line 99, in async_insert\r\n    raise e\r\n  File \"/Users/mipl/ramen/backend/venv/lib/python3.12/site-packages/fast_graphrag/_graphrag.py\", line 80, in async_insert\r\n    new_chunks_per_data = await self.state_manager.filter_new_chunks(chunks_per_data=chunked_documents)\r\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/mipl/ramen/backend/venv/lib/python3.12/site-packages/fast_graphrag/_services/_state_manager.py\", line 58, in filter_new_chunks\r\n    new_chunks_mask = await self.chunk_storage.mask_new(keys=[c.id for c in flattened_chunks])\r\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/mipl/ramen/backend/venv/lib/python3.12/site-packages/fast_graphrag/_storage/_ikv_pickle.py\", line 66, in mask_new\r\n    self._np_keys = np.fromiter(\r\n                    ^^^^^^^^^^^^\r\nOverflowError: Python int too large to convert to C long\r\n```",
    "comments_url": "https://api.github.com/repos/circlemind-ai/fast-graphrag/issues/4/comments",
    "author": "manishiitg",
    "comments": [
      {
        "user": "liukidar",
        "created_at": "2024-11-03T17:06:01Z",
        "body": "Hello, I think there was a mixing of 32 and 64 bit integers for the indices. Hopefully now it's fixed. Can you check out the fix-chunk-id branch and let me know if it fixes the problem. Otherwise, do you mind sharing the code causing the issue? You can also reach out to me on Discord if you do not want to share the data publicly :)"
      },
      {
        "user": "liukidar",
        "created_at": "2024-11-04T03:48:40Z",
        "body": "> Hello, I think there was a mixing of 32 and 64 bit integers for the indices. Hopefully now it's fixed. Can you check out the fix-chunk-id branch and let me know if it fixes the problem. Otherwise, do you mind sharing the code causing the issue? You can also reach out to me on Discord if you do not want to share the data publicly :)\r\n\r\nI have also merged this into main."
      }
    ]
  }
]