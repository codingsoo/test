[
  {
    "number": 680,
    "title": "Update model.py",
    "created_at": "2025-02-18T18:52:32Z",
    "closed_at": "2025-02-19T13:00:33Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/pull/680",
    "body": "hggchfcchchchchgchc",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/680/comments",
    "author": "Helmirinaldi45",
    "comments": [
      {
        "user": "mowentian",
        "created_at": "2025-02-19T13:00:33Z",
        "body": "meaningless"
      }
    ]
  },
  {
    "number": 677,
    "title": "请问deepseekV3使用的什么训练框架",
    "created_at": "2025-02-17T13:42:21Z",
    "closed_at": "2025-02-18T10:08:34Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/issues/677",
    "body": "**Is your feature request related to a problem? Please describe.**\n我在DEEPSEEK_LLM的论文中看到你们使用HAI_LLM框架作为你们的模型训练框架，并且用到了3D并行，我想请问你下V3和R1仍然使用的是该框架吗，并且3D并行是如何实现的，能否分享一下\n\n**Describe the solution you'd like**\nA clear and concise description of what you want to happen.\n\n**Describe alternatives you've considered**\nA clear and concise description of any alternative solutions or features you've considered.\n\n**Additional context**\nAdd any other context or screenshots about the feature request here.\n",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/677/comments",
    "author": "AndreWanga",
    "comments": [
      {
        "user": "mowentian",
        "created_at": "2025-02-18T10:08:34Z",
        "body": "建议移步开源社区以研究 3D并行 的实现"
      },
      {
        "user": "AndreWanga",
        "created_at": "2025-02-18T14:19:44Z",
        "body": "> 建议移步开源社区以研究 3D并行 的实现\n\n请问开源社区的网址是什么 @mowentian "
      }
    ]
  },
  {
    "number": 673,
    "title": "推理示例中的3份config文件分别代表什么意思？",
    "created_at": "2025-02-17T06:53:31Z",
    "closed_at": "2025-02-18T10:11:29Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/issues/673",
    "body": "inference 目录下有3份配置文件，分别代表什么意思？",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/673/comments",
    "author": "cason0126",
    "comments": [
      {
        "user": "mowentian",
        "created_at": "2025-02-18T10:11:29Z",
        "body": "不同尺度的模型"
      }
    ]
  },
  {
    "number": 665,
    "title": "是否可以采取 map/reduce 的策略，在集群中节点本地进行计算，降低数据搬运的开销",
    "created_at": "2025-02-15T02:58:10Z",
    "closed_at": "2025-02-18T10:12:34Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/issues/665",
    "body": null,
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/665/comments",
    "author": "jeffery9",
    "comments": [
      {
        "user": "mowentian",
        "created_at": "2025-02-18T10:12:34Z",
        "body": "听上去并不可行"
      }
    ]
  },
  {
    "number": 660,
    "title": "源码中world size是什么含义",
    "created_at": "2025-02-14T02:46:30Z",
    "closed_at": "2025-02-17T07:06:46Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/issues/660",
    "body": "rt，想问一下 源码中的world size是什么含义，源码中 整除world size的意义是啥",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/660/comments",
    "author": "huangjie-nlp",
    "comments": [
      {
        "user": "fangtaosong",
        "created_at": "2025-02-17T02:06:49Z",
        "body": "world size 指的是每个模型所运行在的 GPU 或其他计算设备的总数"
      }
    ]
  },
  {
    "number": 654,
    "title": "demo project",
    "created_at": "2025-02-13T08:58:19Z",
    "closed_at": "2025-02-14T01:01:26Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/issues/654",
    "body": "\nI'm a newbie and want to learn how to generate my own model based on DeepSeek's knowledge distillation technology.\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nimport torchvision.transforms as transforms\n \n# 设置设备\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n \n# 超参数\nepochs = 20\nbatch_size = 256\ntemperature = 4  # 温度参数\nalpha = 0.7      # 软标签损失权重\n \n# 数据加载\ntransform = transforms.Compose([\n    transforms.RandomCrop(32, padding=4),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n])\n \ntrain_set = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\ntrain_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n \n# 定义老师模型（ResNet-18）\nteacher = torchvision.models.resnet18(pretrained=True)\nteacher.fc = nn.Linear(teacher.fc.in_features, 10)  # CIFAR-10有10类\nteacher = teacher.to(device)\n \n# 定义学生模型（MobileNetV2）\nstudent = torchvision.models.mobilenet_v2(pretrained=True)\nstudent.classifier[1] = nn.Linear(student.last_channel, 10)\nstudent = student.to(device)\n \n# 训练老师模型（此处假设老师已预训练好，直接加载）\n# 实际中需要先训练老师模型，此处为简化跳过\n \n# 定义损失函数和优化器\ncriterion_hard = nn.CrossEntropyLoss()           # 硬标签损失\ncriterion_soft = nn.KLDivLoss(reduction='batchmean')  # 软标签损失\noptimizer = optim.Adam(student.parameters(), lr=0.001)\n \n# 蒸馏训练循环\nfor epoch in range(epochs):\n    teacher.eval()   # 固定老师模型\n    student.train()  # 训练学生模型\n    \n    running_loss = 0.0\n    for inputs, labels in train_loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n        \n        # 前向传播\n        with torch.no_grad():\n            teacher_logits = teacher(inputs)\n        \n        student_logits = student(inputs)\n        \n        # 计算损失\n        # 软标签损失（使用温度参数软化）\n        soft_loss = criterion_soft(\n            nn.functional.log_softmax(student_logits / temperature, dim=1),\n            nn.functional.softmax(teacher_logits / temperature, dim=1)\n        ) * (alpha * temperature * temperature)  # 缩放损失\n        \n        # 硬标签损失\n        hard_loss = criterion_hard(student_logits, labels) * (1 - alpha)\n        \n        total_loss = soft_loss + hard_loss\n        \n        # 反向传播\n        optimizer.zero_grad()\n        total_loss.backward()\n        optimizer.step()\n        \n        running_loss += total_loss.item()\n    \n    print(f'Epoch {epoch+1}, Loss: {running_loss/len(train_loader):.4f}')\n \nprint(\"Distillation finished!\")",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/654/comments",
    "author": "lizhichao999",
    "comments": [
      {
        "user": "mowentian",
        "created_at": "2025-02-14T01:01:26Z",
        "body": "烦请移步其他社区以寻求支持~"
      }
    ]
  },
  {
    "number": 645,
    "title": "如何挣钱，求高人指点",
    "created_at": "2025-02-12T07:10:26Z",
    "closed_at": "2025-02-13T08:50:19Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/issues/645",
    "body": "自己包装api开发的咨询平台用户付费太少，大家都选择大厂包装的免费app。\n个人创业者应该如何破局呢",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/645/comments",
    "author": "richcorgi",
    "comments": [
      {
        "user": "lixx174",
        "created_at": "2025-02-12T07:33:01Z",
        "body": "先这样... 然后这样..."
      },
      {
        "user": "yijianguanzhu",
        "created_at": "2025-02-12T09:17:52Z",
        "body": "V50告诉你方案"
      }
    ]
  },
  {
    "number": 643,
    "title": "Deepseek在Rocky Linux 8.9 (64位)上面部署Docker服务",
    "created_at": "2025-02-12T01:55:35Z",
    "closed_at": "2025-02-18T10:10:29Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/issues/643",
    "body": "我想咨询关于在 Rocky Linux 8.9（64 位）系统上部署 Deepseek API 的问题，具体有以下几点：\n\n1. 是否可以使用 Docker 单独部署 Deepseek 服务？类似于其他服务（如接入微信机器人的 link-ai）的部署方式。\n2. 或者是否有类似 ChatGPTNextWeb 的独立部署方案？\n\n期待您的解答，感谢！",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/643/comments",
    "author": "qierkang",
    "comments": [
      {
        "user": "mowentian",
        "created_at": "2025-02-18T10:10:30Z",
        "body": "烦请移步其他开源部署社区以寻求支持"
      }
    ]
  },
  {
    "number": 630,
    "title": "请问下，部署BF16和FP8的deepseek v3，分别需要多少显存",
    "created_at": "2025-02-10T07:12:22Z",
    "closed_at": "2025-02-13T09:45:48Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/issues/630",
    "body": "目前看到的都是第三方博客上的，官方文档可以更新下啊",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/630/comments",
    "author": "liguoyu666",
    "comments": [
      {
        "user": "mowentian",
        "created_at": "2025-02-13T09:45:48Z",
        "body": "不好意思，官方不提供私有化部署及相关支持，烦请开源社区以寻求支持"
      }
    ]
  },
  {
    "number": 629,
    "title": "寻求从零开始训练大语言模型（LLM）的教程或指导",
    "created_at": "2025-02-10T06:29:29Z",
    "closed_at": "2025-02-10T07:07:45Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/issues/629",
    "body": "大家好！我是一个LLM小白，最近想从零开始学习如何训练一个大模型，但发现网上的教程要么太零散，要么门槛太高。\n希望有经验的大神能提供一个保姆级的教程，帮助我从0到1完成大模型的训练。\n\n### 目前我遇到的挑战：\n数据准备：如何准备训练所需的高质量数据？需要多少数据量才足够？\n模型架构：如何选择合适的模型架构（比如 Transformer、GPT、BERT等）？\n训练环境：如何搭建训练环境（GPU、TPU的配置、训练框架如 PyTorch 或 TensorFlow 等）？\n优化与调参：如何调整超参数，保证模型收敛？\n分布式训练：如何利用多台机器或多GPU进行训练，避免内存限制？\n其他问题：如何评估训练效果，如何避免过拟合等问题？\n\n### 希望获得的帮助：\n是否有推荐的教程或文档，从头到尾讲解如何训练一个大模型？\n如果有相关的 GitHub 项目或开源代码，可以参考的资料也请分享！\n任何实用的经验和建议都会非常感谢，尤其是对于初学者来说，如何避免常见的坑。\n非常感谢大家的帮助，期待得到你们的宝贵意见！\n\n",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/629/comments",
    "author": "gimlee",
    "comments": [
      {
        "user": "mowentian",
        "created_at": "2025-02-10T07:07:45Z",
        "body": "烦请前往其他开源社区寻求支持"
      }
    ]
  },
  {
    "number": 627,
    "title": "Create DeepSeek-V3،",
    "created_at": "2025-02-10T03:34:50Z",
    "closed_at": "2025-02-17T08:33:07Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/pull/627",
    "body": null,
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/627/comments",
    "author": "ASA700",
    "comments": [
      {
        "user": "ruchirmehta07",
        "created_at": "2025-02-13T15:31:18Z",
        "body": "Can you please close the PR."
      }
    ]
  },
  {
    "number": 624,
    "title": "Can a  4060 GPU of laptop version run the DeepSeek model locally?",
    "created_at": "2025-02-10T01:44:01Z",
    "closed_at": "2025-02-10T07:09:23Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/issues/624",
    "body": "Thanks for your great contribution in development of LLM. I would like to know if a  4060 GPU of laptop version can run the DeepSeek locally.",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/624/comments",
    "author": "sysu-firework",
    "comments": [
      {
        "user": "jtyy115115",
        "created_at": "2025-02-10T02:37:25Z",
        "body": "> 感谢您对 LLM 开发的巨大贡献。我想知道笔记本电脑版本的 4060 GPU 是否可以在本地运行 DeepSeek。\n\n试一试\n"
      },
      {
        "user": "LucienTao",
        "created_at": "2025-02-10T09:18:10Z",
        "body": "it's ok to run 14b ver on 4060 with about 10 tokens/s, using ollama"
      }
    ]
  },
  {
    "number": 621,
    "title": "怎么样能最快从自动驾驶算法工程师转到大模型算法工程师?",
    "created_at": "2025-02-09T14:27:12Z",
    "closed_at": "2025-02-10T07:09:00Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/issues/621",
    "body": "我的日常工作会涉及transformer。之前项目也有融合激光雷达和相机数据的，可以拿来学习。我日常工作也涉及一些模型小型化的工作，比如混合精度训练。另外，我也会用openmmlab的分布式训练。我怎么样能最快从自动驾驶算法工程师转到大模型算法",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/621/comments",
    "author": "yushengjiexy",
    "comments": [
      {
        "user": "Vector-Cross",
        "created_at": "2025-02-10T01:22:59Z",
        "body": "跳槽"
      },
      {
        "user": "yushengjiexy",
        "created_at": "2025-02-10T02:11:03Z",
        "body": "> 跳槽\n\n工作几年了，需要先更新下技能库，不然面试公司不要啊"
      },
      {
        "user": "Vector-Cross",
        "created_at": "2025-02-10T03:40:19Z",
        "body": "> > 跳槽\n> \n> 工作几年了，需要先更新下技能库，不然面试公司不要啊\n\n降薪跳槽，先切换赛道。不过我没这个魄力，就一直换不了岗位了"
      }
    ]
  },
  {
    "number": 615,
    "title": "It's not a multimodel, why can it do multimodel understanding",
    "created_at": "2025-02-08T09:27:28Z",
    "closed_at": "2025-02-13T09:42:16Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/issues/615",
    "body": "It seems that v3 is not a multimodel, but by experiencing the web application(chat.deepseek.com), it appears that it can upload image and understand the content of the image. I'm curious why can it do so.",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/615/comments",
    "author": "kaiwang0112006",
    "comments": [
      {
        "user": "RUI0909",
        "created_at": "2025-02-08T09:53:38Z",
        "body": "As u can see, the web application allow user to upload picture while just recognizing text. Maybe web app uses some OCR tools, such as CLIP, converting images into text descriptions. Then send the text description along with the user's question."
      },
      {
        "user": "mowentian",
        "created_at": "2025-02-13T09:42:16Z",
        "body": "only support OCR，may be you image contains words info"
      }
    ]
  },
  {
    "number": 613,
    "title": "Enhancing DeepSeek 70B Usability in Low-Resource Environments",
    "created_at": "2025-02-08T08:47:00Z",
    "closed_at": "2025-02-08T09:15:31Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/issues/613",
    "body": "#### **Description**  \nDeepSeek 70B is a powerful language model that performs exceptionally well on high-performance hardware (e.g., 8xA100 80GB). However, its deployment is challenging in low-resource environments (e.g., consumer GPUs or CPU-only servers).  \n\n#### **Problem Statement**  \nCurrently, DeepSeek 70B has high VRAM requirements, making local deployment difficult for many small businesses and individual developers. Are there any plans to improve accessibility through the following optimizations?  \n\n1. **Multi-GPU Optimization for Low VRAM**  \n   - Implement more efficient model parallelization techniques (e.g., ZeRO-Offload, FlashAttention) to reduce memory consumption.  \n\n2. **Quantization Support**  \n   - Provide 4-bit or 8-bit quantized versions of the model, allowing it to run on consumer GPUs (e.g., RTX 3090/4090).  \n\n3. **Optimized Inference API**  \n   - If local deployment remains costly, is there a plan to offer a more optimized cloud API (similar to OpenAI's API) with reduced cost for inference?  \n\n#### **Expected Benefits**  \n- Enables more developers to run DeepSeek 70B on local machines or small-scale servers, fostering adoption in small businesses and research communities.  \n- Lowers deployment barriers, making open-source large models more practical and accessible.  \n",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/613/comments",
    "author": "Eason1118",
    "comments": [
      {
        "user": "mowentian",
        "created_at": "2025-02-08T09:15:31Z",
        "body": "We do not offer private deployment or related support services. Please seek assistance from other communities."
      }
    ]
  },
  {
    "number": 607,
    "title": "docs(readme): improve table formatting and readability",
    "created_at": "2025-02-07T19:00:42Z",
    "closed_at": "2025-02-08T02:44:55Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/pull/607",
    "body": "This PR optimizes table styling in README to:\r\n**Enhance visual consistency**  \r\n   - Unified column alignment with proper markdown pipe syntax\r\n   - Fixed irregular vertical/horizontal spacing\r\n\r\nThis change is ready for immediate merge as it contains no breaking changes.\r\n\r\n",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/607/comments",
    "author": "lecepin",
    "comments": [
      {
        "user": "mowentian",
        "created_at": "2025-02-08T02:44:55Z",
        "body": "Thank you, but this is not a critical technical issue, so let's hold off on merging for now."
      }
    ]
  },
  {
    "number": 604,
    "title": "General pre-processing question",
    "created_at": "2025-02-07T11:15:03Z",
    "closed_at": "2025-02-08T09:16:17Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/issues/604",
    "body": "Hello everyone,\n\nThe model is amazing but I have this question when sharing  a pdf document with the model ,and ask a question about the pdf document. How DeepSeek handle the processing of the document? Has this part been shared also? \nBecause tesseract or extracting the document text(fitz,PyPDF2 ,pdfplumber,..) is not always accurate.\nIs there any available documentation on how the pre-processing should be done as I am using the model locally?\n\nThx",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/604/comments",
    "author": "mohamadnajiya",
    "comments": [
      {
        "user": "Ext1nguisher",
        "created_at": "2025-02-07T13:11:38Z",
        "body": "> Has this part been shared aslo?\n\nCorrection: \"also\" instead of \"aslo\"."
      },
      {
        "user": "mohamadnajiya",
        "created_at": "2025-02-07T13:49:09Z",
        "body": "> > Has this part been shared aslo?\n> \n> Correction: \"also\" instead of \"aslo\".\n\nThank you fixed"
      },
      {
        "user": "mowentian",
        "created_at": "2025-02-08T09:16:17Z",
        "body": "We do not offer private deployment or related support services. Please seek assistance from other communities."
      }
    ]
  },
  {
    "number": 603,
    "title": "Does the plan support compute use?",
    "created_at": "2025-02-07T10:52:21Z",
    "closed_at": "2025-02-08T03:03:01Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/issues/603",
    "body": "Claude 3.5 sonnet model has supported the feature of compute use, which can greatly improve the efficiency in ai programming plug-ins. deepseek is a great project, which has good code generation ability and hopes to support compute use.",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/603/comments",
    "author": "jacky68147527",
    "comments": [
      {
        "user": "mowentian",
        "created_at": "2025-02-08T03:03:01Z",
        "body": "Possible in the future"
      }
    ]
  },
  {
    "number": 600,
    "title": "Minor grammatical tense corrections to README.md",
    "created_at": "2025-02-07T06:02:12Z",
    "closed_at": "2025-02-08T02:45:11Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/pull/600",
    "body": "Minor changes to correct grammatical tense for activities that took place in the past.",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/600/comments",
    "author": "abwinkler999",
    "comments": [
      {
        "user": "abwinkler999",
        "created_at": "2025-02-07T06:02:26Z",
        "body": "Minor corrections to grammatical tense in README."
      },
      {
        "user": "mowentian",
        "created_at": "2025-02-08T02:45:11Z",
        "body": "Thank you, but this is not a critical technical issue, so let's hold off on merging for now."
      }
    ]
  },
  {
    "number": 593,
    "title": "chore: add issue template config and fix documentation issues",
    "created_at": "2025-02-06T10:58:55Z",
    "closed_at": "2025-02-08T02:44:38Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/pull/593",
    "body": "### 📖 Summary\r\n\r\nThis pull request includes minor but meaningful improvements to the repository to enhance its maintainability, documentation, and user experience.\r\n\r\n### 🛠️ Changes\r\n\r\n1. **Add Issue Template Configuration**\r\n    - This change allows users to either create blank issues or access support via the provided WeChat group link, improving accessibility for non-technical users or those seeking assistance outside of GitHub.\r\n2. **Update Readme File**\r\n    - Corrected the contact email link in the documentation to ensure it directs users to the correct address.\r\n    - Adjusted the casing of the BibTeX citation to follow standard academic conventions, improving readability and professionalism in citations.\r\n\r\n### 🚀 Impact\r\n\r\n- The addition of issue templates improves the overall contributor experience by reducing ambiguity and ensuring that issues are reported in a clear and actionable format.\r\n- Fixing the contact email link ensures that users can reach out for support without encountering errors.\r\n- Standardizing the BibTeX citation enhances the credibility and usability of the repository for academic and research purposes.\r\n\r\n---\r\n\r\nLet me know if there are any questions or further clarifications needed 🙌",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/593/comments",
    "author": "fyvri",
    "comments": [
      {
        "user": "mowentian",
        "created_at": "2025-02-08T02:44:38Z",
        "body": "Thank you, but this is not a critical technical issue, so let's hold off on merging for now."
      },
      {
        "user": "fyvri",
        "created_at": "2025-02-08T02:49:47Z",
        "body": "Thank you for your feedback. I appreciate it, and I hope I can contribute to other parts of the code in the future! 😊"
      }
    ]
  },
  {
    "number": 589,
    "title": "是否可以通过语言直接向deepseek发出请求",
    "created_at": "2025-02-06T05:28:55Z",
    "closed_at": "2025-02-06T08:06:31Z",
    "labels": [
      "enhancement"
    ],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/issues/589",
    "body": "**Is your feature request related to a problem? Please describe.**\nA clear and concise description of what the problem is. Ex. I'm always frustrated when [...]\n\n**Describe the solution you'd like**\nA clear and concise description of what you want to happen.\n\n**Describe alternatives you've considered**\nA clear and concise description of any alternative solutions or features you've considered.\n\n**Additional context**\nAdd any other context or screenshots about the feature request here.\n",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/589/comments",
    "author": "muzisi",
    "comments": [
      {
        "user": "mowentian",
        "created_at": "2025-02-06T08:06:31Z",
        "body": "语音输入在未来 app 的规划之中"
      }
    ]
  },
  {
    "number": 585,
    "title": "R1 vs V3",
    "created_at": "2025-02-05T19:01:45Z",
    "closed_at": "2025-02-06T08:20:28Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/issues/585",
    "body": "What's the difference between DeepSeek R1 and DeepSeek V3?",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/585/comments",
    "author": "ruidazeng",
    "comments": [
      {
        "user": "shipMatserJack",
        "created_at": "2025-02-05T23:49:11Z",
        "body": "> What's the difference between DeepSeek R1 and DeepSeek V3?\n\nNot if you've read the warehouse readme and paper reports, which are also available online"
      }
    ]
  },
  {
    "number": 575,
    "title": "企微群满了，希望再开一个群。",
    "created_at": "2025-02-05T09:47:35Z",
    "closed_at": "2025-02-06T08:17:55Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/issues/575",
    "body": "企微群满了，希望再开一个群。\n",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/575/comments",
    "author": "allenzzmzzm",
    "comments": [
      {
        "user": "mowentian",
        "created_at": "2025-02-06T08:18:37Z",
        "body": "github 上主要关注技术问题，运营相关的请发送相关邮件反馈"
      }
    ]
  },
  {
    "number": 572,
    "title": "Web端开发暂停功能",
    "created_at": "2025-02-05T03:42:13Z",
    "closed_at": "2025-02-06T08:20:59Z",
    "labels": [
      "enhancement"
    ],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/issues/572",
    "body": "生成时无法暂停 用户需等待较长时间",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/572/comments",
    "author": "Star200818",
    "comments": [
      {
        "user": "Ext1nguisher",
        "created_at": "2025-02-05T10:38:29Z",
        "body": "这个有技术上实现难度的，其实可以直接发起新会话。\n当然，我还是希望这个功能被开发出来，不然新会话的历史内容就会丢失。\n\n_______\n\nThis is technically difficult. Yet you can just start a new session directly.\nOf course, I still hope this function can be developed, otherwise the history content will be lost in the new session."
      }
    ]
  },
  {
    "number": 565,
    "title": "updated Model Summary verbiage to be past tense for easier understanding",
    "created_at": "2025-02-04T18:12:46Z",
    "closed_at": "2025-02-06T07:56:44Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/pull/565",
    "body": "Title",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/565/comments",
    "author": "aquashere",
    "comments": [
      {
        "user": "musvaage",
        "created_at": "2025-02-04T19:10:24Z",
        "body": "This should be closed.\r\n\r\nDeepSeek_V3.pdf\r\n\r\nDeepSeek-V3 Technical Report\r\n\r\nStop submitting PRs which propose to modify README.md file content which is derived from the Technical Report."
      },
      {
        "user": "mowentian",
        "created_at": "2025-02-06T07:56:44Z",
        "body": "Thank you, but this is not a critical technical issue, so let's hold off on merging for now."
      }
    ]
  },
  {
    "number": 563,
    "title": "fix(fp8_cast): Add robust memory management and error handling",
    "created_at": "2025-02-04T16:37:15Z",
    "closed_at": "2025-02-08T02:48:13Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/pull/563",
    "body": "\r\n- Add try-catch block for memory management operations\r\n- Implement graceful error handling for memory allocation failures\r\n- Add explicit CUDA memory cleanup\r\n- Protect against potential race conditions in file loading\r\n\r\nThis change improves stability when converting large models by:\r\n- Preventing crashes from out-of-memory conditions\r\n- Ensuring proper cleanup of GPU resources\r\n- Adding error reporting for debugging",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/563/comments",
    "author": "ajwise9",
    "comments": [
      {
        "user": "ajwise9",
        "created_at": "2025-02-04T16:37:33Z",
        "body": "fix(fp8_cast): Add robust memory management and error handling\r\n"
      },
      {
        "user": "mowentian",
        "created_at": "2025-02-08T02:48:13Z",
        "body": "no fallback strategy for oom error,  so just raise err and failed is simple and fine"
      }
    ]
  },
  {
    "number": 560,
    "title": "Huawei Ascend Benchmarking Reports",
    "created_at": "2025-02-04T10:25:49Z",
    "closed_at": "2025-02-06T08:23:23Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/issues/560",
    "body": "**Is your feature request related to a problem? Please describe.**\nI'm looking for a comparison of Huawei Ascend throughput on NPUs versus SGLang on GPUs.\n\n**Describe the solution you'd like**\nCould someone point me towards data on this? Thanks\n",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/560/comments",
    "author": "RonanKMcGovern",
    "comments": [
      {
        "user": "mowentian",
        "created_at": "2025-02-06T08:23:23Z",
        "body": "please ask Huawei Ascend for more support thanks"
      }
    ]
  },
  {
    "number": 556,
    "title": "Fix Linear Layer Bias Initialization",
    "created_at": "2025-02-04T05:10:17Z",
    "closed_at": "2025-02-05T08:23:02Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/pull/556",
    "body": "## Description\r\nFixed bias initialization in the [Linear](cci:2://file:///d:/Github/DeepSeek-V3/inference/model.py:163:0-201:48) class by using `out_features` instead of the undefined `self.part_out_features`. This fix ensures proper bias initialization for all linear layers in the model.\r\n\r\n## Changes Made\r\n- Modified `Linear.__init__` to use `out_features` parameter for bias tensor initialization\r\n- Ensures consistency with parent and child classes (ColumnParallelLinear and RowParallelLinear)\r\n\r\n## Why This Change is Needed\r\nThe previous implementation tried to access `self.part_out_features` which is only defined in child classes (ColumnParallelLinear), causing potential issues when the Linear class is used directly. Using `out_features` is the correct approach as it's always available and matches the weight tensor's output dimension.\r\n\r\n## Testing Done\r\n- Model initialization works correctly with bias enabled\r\n- Compatible with both standard and parallel linear layers\r\n- No impact on existing functionality\r\n## Checklist\r\n- [x] Code follows the project's coding style\r\n- [x] Changes are backward compatible\r\n- [x] No new dependencies added",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/556/comments",
    "author": "XxAlonexX",
    "comments": [
      {
        "user": "MochisCold",
        "created_at": "2025-02-04T13:38:36Z",
        "body": "Oh, great. You’ve fixed something that was never really broken, but sure, I’ll bite. Let’s just toss out self.part_out_features, which was probably put there for a reason—maybe to handle something specific in child classes—because it was \"inconvenient\" when used directly in the Linear class. Using `out_features` now seems like the easiest way to make everything look clean, but it definitely makes the whole thing less flexible. \r\n\r\nAnd I love how you’ve “tested” it—by making sure the model initializes and the functionality is still intact. Could we ask for a bit more rigor, though? Just a thought. No impact on existing functionality? If it’s working just as before, maybe it’s not even a fix—it’s more like an unnecessary tweak for the sake of change.\r\n\r\nBut hey, good job on not breaking things... for now."
      },
      {
        "user": "XxAlonexX",
        "created_at": "2025-02-04T14:09:14Z",
        "body": "Oh boy, you caught me red-handed in my \"let's make things look prettier\" crusade! 😅 \r\n\r\nYou're absolutely right - I was basically trying to reorganize deck chairs on the Titanic here. My \"fix\" was about as necessary as a chocolate teapot. I got a bit too excited seeing `self.part_out_features` and thought \"Hey, I can make this cleaner!\" without considering that maybe, just maybe, the original developers (who built this incredible model) knew what they were doing! 🤔\r\n\r\nMy testing strategy was indeed about as thorough as checking if a parachute works by looking at it. \"Yep, looks like a parachute to me!\" 👍\r\n\r\nConsider this my enthusiastic but slightly misguided attempt at contributing to the project - like bringing a rubber duck to a battleship fight. I promise my next PR will be for an actual problem, not just me trying to \"Marie Kondo\" the codebase!\r\n\r\nThanks for the reality check - it's a good reminder that sometimes code that looks \"inconvenient\" is actually there for a reason. Back to the drawing board! 🎨\r\n\r\nP.S. Would it help if I said I was just trying to spark joy in the codebase? No? I'll see myself out... 🚪🏃‍♂️"
      },
      {
        "user": "GeeeekExplorer",
        "created_at": "2025-02-05T08:22:40Z",
        "body": "Your fix is correct. Thanks!"
      }
    ]
  },
  {
    "number": 551,
    "title": "required voice mode similar to chatgpt",
    "created_at": "2025-02-03T16:40:52Z",
    "closed_at": "2025-02-06T08:25:03Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/issues/551",
    "body": "i m using chatgpt from short of time its will be good if deepseek provide the same voice mode ",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/551/comments",
    "author": "Floki144",
    "comments": [
      {
        "user": "dinithaw",
        "created_at": "2025-02-04T08:26:09Z",
        "body": "> i m using chatgpt from short of time its will be good if deepseek provide the same voice mode\n\nI'm working on such hobby project using NLP and deepseek LLM. BTW it's running locally with single RTX 4090 (24G VRAM)"
      },
      {
        "user": "mowentian",
        "created_at": "2025-02-06T08:25:03Z",
        "body": "thanks，possible in the future..."
      }
    ]
  },
  {
    "number": 549,
    "title": "fixed typo and grammer",
    "created_at": "2025-02-03T10:13:30Z",
    "closed_at": "2025-02-06T07:59:17Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/pull/549",
    "body": "FIXED issue #456 \r\nfixed typos and grammer",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/549/comments",
    "author": "Ankush1oo8",
    "comments": [
      {
        "user": "dinithaw",
        "created_at": "2025-02-03T14:36:06Z",
        "body": "Awesome ❤️"
      },
      {
        "user": "mowentian",
        "created_at": "2025-02-06T07:59:17Z",
        "body": "Thank you, but this is not a critical technical issue, so let's hold off on merging for now."
      }
    ]
  },
  {
    "number": 548,
    "title": "[BUG]",
    "created_at": "2025-02-03T09:02:06Z",
    "closed_at": "2025-02-05T01:33:26Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/issues/548",
    "body": "**Describe the bug**\nA clear and concise description of what the bug is.\n\n**To Reproduce**\nSteps to reproduce the behavior.\n\n**Expected behavior**\nA clear and concise description of what you expected to happen.\n\n**Screenshots**\nIf applicable, add screenshots to help explain your problem.\n\n**Additional context**\nAdd any other context about the problem here.",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/548/comments",
    "author": "NOUFZAHER",
    "comments": [
      {
        "user": "dinithaw",
        "created_at": "2025-02-03T14:42:09Z",
        "body": "> **Describe the bug**\n> A clear and concise description of what the bug is.\n> \n> **To Reproduce**\n> Steps to reproduce the behavior.\n> \n> **Expected behavior**\n> A clear and concise description of what you expected to happen.\n> \n> **Screenshots**\n> If applicable, add screenshots to help explain your problem.\n> \n> **Additional context**\n> Add any other context about the problem here.\n\nU are just one another spammer.\nNOOB!"
      }
    ]
  },
  {
    "number": 544,
    "title": "[BUG] Unable to attach files",
    "created_at": "2025-02-03T05:19:49Z",
    "closed_at": "2025-02-08T03:05:54Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/issues/544",
    "body": "Unable to attach files since Feb 2 afternoon. \n",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/544/comments",
    "author": "mirageshaz",
    "comments": [
      {
        "user": "whitesparkstu",
        "created_at": "2025-02-03T16:56:31Z",
        "body": "same\n"
      },
      {
        "user": "kingcopi",
        "created_at": "2025-02-04T22:28:51Z",
        "body": "You cant attach or use file or image with this version this is not a multimodal model, you can use deepseek VL or janus it you whant to use multimodal feature."
      },
      {
        "user": "whitesparkstu",
        "created_at": "2025-02-05T01:11:09Z",
        "body": "> You cant attach or use file or image with this version this is not a multimodal model, you can use deepseek VL or janus it you whant to use multimodal feature.\n\nNot everyone can run local, and this is a feature that should be working on all models regardless"
      },
      {
        "user": "Sadat41",
        "created_at": "2025-02-05T04:18:46Z",
        "body": "> You cant attach or use file or image with this version this is not a multimodal model, you can use deepseek VL or janus it you whant to use multimodal feature.\n\nThey disabled the attachment feature on February 2nd. I had previously used it and got excellent results compared to GPT."
      },
      {
        "user": "mowentian",
        "created_at": "2025-02-08T03:05:54Z",
        "body": "may be work now"
      }
    ]
  },
  {
    "number": 543,
    "title": "关于图像识别的建议",
    "created_at": "2025-02-03T03:26:07Z",
    "closed_at": "2025-02-06T08:27:03Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/issues/543",
    "body": "我希望图像识别不但能够识别有文字的图片，也能够识别那些无文字的图片。",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/543/comments",
    "author": "Kuila145",
    "comments": [
      {
        "user": "11000100111010101100111",
        "created_at": "2025-02-05T03:05:42Z",
        "body": "它要是会画五彩斑斓的黑就好了🤡"
      },
      {
        "user": "mowentian",
        "created_at": "2025-02-06T08:27:03Z",
        "body": "thanks, possible in the future"
      }
    ]
  },
  {
    "number": 539,
    "title": "GPU Inferencing: CUDA vs PTX",
    "created_at": "2025-02-02T17:03:14Z",
    "closed_at": "2025-02-08T03:08:06Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/issues/539",
    "body": "For GPU inferencing, do you (Deepseek AI) use CUDA or PTX for your commercial service? Also, in general, for open source GPU inferencing software, do you advise using one or the other? What are the expected gains?",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/539/comments",
    "author": "impredicative",
    "comments": [
      {
        "user": "mowentian",
        "created_at": "2025-02-08T03:08:06Z",
        "body": "you can go community like sglang for deploy question"
      }
    ]
  },
  {
    "number": 530,
    "title": "Saw the file to spy on it, hehehehe",
    "created_at": "2025-02-01T22:28:14Z",
    "closed_at": "2025-02-06T07:59:51Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/pull/530",
    "body": null,
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/530/comments",
    "author": "myakoobi",
    "comments": [
      {
        "user": "nikiniki555",
        "created_at": "2025-02-02T12:37:20Z",
        "body": "from \"open ia\"?"
      }
    ]
  },
  {
    "number": 519,
    "title": "Update LICENSE-CODE Copyright Year from 2023 to 2023-2025",
    "created_at": "2025-02-01T07:46:58Z",
    "closed_at": "2025-02-06T08:00:24Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/pull/519",
    "body": "This pull request updates the copyright year in the `LICENSE-CODE` file. Currently, the file shows 2023 as the copyright year, but considering that the project was initially created in 2023, had a major release in 2024, and has continued to receive updates in 2025, this change updates the copyright statement to \"2023‑2025\". \r\n\r\n**Why this change is needed:**  \r\n- **Accuracy:** The new date range accurately reflects the project's timeline and the ongoing updates.  \r\n- **Consistency:** It ensures that the copyright information remains consistent with the release date and subsequent updates, improving legal clarity and overall documentation consistency.\r\n\r\nPlease review the changes and let me know if any further modifications are needed. Thank you for your consideration.\r\n",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/519/comments",
    "author": "koriym",
    "comments": [
      {
        "user": "mowentian",
        "created_at": "2025-02-06T08:00:24Z",
        "body": "Thank you, but this is not a critical technical issue, so let's hold off on merging for now."
      }
    ]
  },
  {
    "number": 518,
    "title": "Please allow control-enter to be used instead of clicking the send button",
    "created_at": "2025-02-01T04:39:04Z",
    "closed_at": "2025-02-08T03:12:17Z",
    "labels": [
      "enhancement"
    ],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/issues/518",
    "body": "**Describe the solution you'd like**\nConfigure the chatbot to consider control-enter as equivalent to clicking the send button.\n\n",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/518/comments",
    "author": "keith555",
    "comments": [
      {
        "user": "kryptokazz",
        "created_at": "2025-02-01T05:58:20Z",
        "body": "so basically pressing ctrl or shift will create white space this has been the standard for most social media for a while and any application with a chat box. All you need to do is press enter by itself and it will send without clicking any buttons. \n"
      }
    ]
  },
  {
    "number": 517,
    "title": "Pinning chats in UI",
    "created_at": "2025-02-01T04:27:31Z",
    "closed_at": "2025-02-08T03:11:57Z",
    "labels": [
      "enhancement"
    ],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/issues/517",
    "body": "**Is your feature request related to a problem? Please describe.**\nI create new chats for quick questions, but I also do work on some chats to have context of the previous work and finding those chats that I worked previously on - is just a waste of time.\n**Describe the solution you'd like**\nCan you add \"Pin chat\" option to each chat ? So that when i come back - I immediate able to open the chat i was working on\n\n**Describe alternatives you've considered**\n-\n**Additional context**\nAdd any other context or screenshots about the feature request here.\n",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/517/comments",
    "author": "a-khash",
    "comments": [
      {
        "user": "shadowxdgamer",
        "created_at": "2025-02-04T16:53:50Z",
        "body": "@akhash-GGUF  hello, i have made a chrome extension that do just that, you can use it until they update the website :d\nit's called deepseekpin in my repositories :d"
      },
      {
        "user": "a-khash",
        "created_at": "2025-02-04T16:55:29Z",
        "body": "Thank you very much !"
      }
    ]
  },
  {
    "number": 508,
    "title": "[FEATURE REQUEST] Provide an option to disable the shortcut of ENTER on the web version",
    "created_at": "2025-01-31T16:01:17Z",
    "closed_at": "2025-02-03T15:25:20Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/issues/508",
    "body": "**Is your feature request related to a problem? Please describe.**\nAs the title shows, currently it's unable to type an enter directly while not sending the message. The only solutioin I found now is to use the clipboard to paste an LF.\n\n**Describe the solution you'd like**\nAdding an option to turn off the shortcut of ENTER, or switch to something other like CTRL + ENTER?\n\n**Describe alternatives you've considered**\nNo. I think the solution above is clear and simple enough.\n\n**Additional context**\nNo.\n",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/508/comments",
    "author": "dragon-archer",
    "comments": [
      {
        "user": "Jangyaseni666",
        "created_at": "2025-02-01T08:14:18Z",
        "body": "If you want to go to a new line while writing the prompt, you can use the Shift+Enter shortcut. Works like a charm. "
      },
      {
        "user": "Igorgro",
        "created_at": "2025-02-01T17:48:02Z",
        "body": "This doesn't work on Android for example. I wanted to put new line, but instead pressing Enter immediately sends the message"
      },
      {
        "user": "Jangyaseni666",
        "created_at": "2025-02-01T17:50:47Z",
        "body": "Yeah but the issue is about the web version. So, I assumed it was about desktop. Are you talking about using the web version on your phone? "
      },
      {
        "user": "Igorgro",
        "created_at": "2025-02-01T19:18:03Z",
        "body": "Yes, I wanted to use web version on android and was disappointed that I cannot place a new line. I usually use it to separate my question from the data"
      },
      {
        "user": "dragon-archer",
        "created_at": "2025-02-03T15:25:20Z",
        "body": "@Jangyaseni666 Thank you for your help!"
      }
    ]
  },
  {
    "number": 504,
    "title": "什么时候支持Comfyui",
    "created_at": "2025-01-31T13:12:10Z",
    "closed_at": "2025-02-08T03:13:37Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/issues/504",
    "body": "什么时候支持Comfyui",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/504/comments",
    "author": "starinskycc",
    "comments": [
      {
        "user": "abelbraaksma",
        "created_at": "2025-01-31T18:46:02Z",
        "body": "In English, please?"
      },
      {
        "user": "LuckyGreyHare",
        "created_at": "2025-02-02T15:06:35Z",
        "body": "> In English, please?\n\nHe means \"when will ComfyUI be supported (if possible)\""
      },
      {
        "user": "AquaJoe",
        "created_at": "2025-02-03T07:35:44Z",
        "body": "I’m sure the Translator would be handy here"
      }
    ]
  },
  {
    "number": 503,
    "title": "Feature Request: Add PDF Generation for Response",
    "created_at": "2025-01-31T10:49:30Z",
    "closed_at": "2025-02-08T09:18:43Z",
    "labels": [
      "enhancement"
    ],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/issues/503",
    "body": "\nI often need to save or share responses from the application in a more permanent and shareable format. \nCurrently, there’s no built-in functionality to generate a PDF of the responses, which means I have to manually copy and paste or take screenshots to save important content. It would be much more efficient and user-friendly if there was an option to generate a PDF directly from the response.\nI would like to see a \"Generate PDF\" feature added to the application. \nThis feature would allow users to easily download responses or reports as PDFs.\nAfter generating a response, users would see a \"Download PDF\" button.\nWhen clicked, this button would trigger the creation of a PDF file containing the response text.\nThe PDF could have a basic layout with options to include a title, response body, and a timestamp.\nThe generated PDF could be styled with simple formatting such as bold, italic, headings, and paragraphs.\nThanks",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/503/comments",
    "author": "Abderrahmanec",
    "comments": [
      {
        "user": "Jaskiranjot-Kaur",
        "created_at": "2025-01-31T13:27:11Z",
        "body": "Hello! I would love to work on this issue. Could you please assign it to me?\n\n"
      }
    ]
  },
  {
    "number": 500,
    "title": "Copyleft",
    "created_at": "2025-01-31T07:03:34Z",
    "closed_at": "2025-02-06T08:40:25Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/issues/500",
    "body": "Hey y'all -\n\nJust wanted to suggest that a breakthrough as big as this should be licensed under the GPL or similar copyleft terms to protect it as open source. It would be huge for the open source movement as this technology gets implemented for it to be copylefted and for companies to have to give back and stay open source to utilize this software.\n\nSincerely,\n\n--reese",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/500/comments",
    "author": "reesericci",
    "comments": [
      {
        "user": "mowentian",
        "created_at": "2025-02-06T08:40:25Z",
        "body": "MIT is good for all"
      }
    ]
  },
  {
    "number": 492,
    "title": "MoE only load activated expert(s) to GPU while rest non-used experts are not loaded (to CPU/GPU) for DeekSeek-R1 or V3 Inference on consumer GPU",
    "created_at": "2025-01-30T23:34:24Z",
    "closed_at": "2025-02-08T09:18:29Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/issues/492",
    "body": "Running DeekSeep-R1 or V3 *inference* needs 8xH100 80GB due to huge memory footprint, and it's very challenging to do R1 or V3 inference on single consumer GPU RAM (e.g. 24GB 4090) + limited CPU memory (say 32GB) with 685B MoE params even with low-bit quantization.\n\nBut since V3 and R1 has only 37B activated params (INT4 37B weights is 18.5GB), is it possible for the MoE inference to only load the 37B \"activated experts (s)\" related weights to GPU mem, and leave other non-activated or non-used expert's weight some in CPU memory(e.g.32GB), but majority weights on disk because CPU memory is also limited, and only load/unload these weights when in use ?\n\nI'm wondering if similar features is available or WIP inside DeepSeek-V3 github or any popular inference frameworks ?\n\nReally appreciate your help!",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/492/comments",
    "author": "marvin-0042",
    "comments": [
      {
        "user": "mowentian",
        "created_at": "2025-02-08T09:18:29Z",
        "body": "We do not offer private deployment or related support services. Please seek assistance from other communities."
      }
    ]
  },
  {
    "number": 490,
    "title": "[FEATURE REQUEST] Images Insertion & documents insertion",
    "created_at": "2025-01-30T18:29:12Z",
    "closed_at": "2025-02-05T02:08:31Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/issues/490",
    "body": "Just wondering when will the image, documents, audio insertion features be released? Thank you so much! \n\n\n",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/490/comments",
    "author": "yingqi955",
    "comments": [
      {
        "user": "Jangyaseni666",
        "created_at": "2025-02-01T08:15:56Z",
        "body": "I think it's already there, right? The clip icon allows to attach any kind of file."
      },
      {
        "user": "GeeeekExplorer",
        "created_at": "2025-02-05T02:08:31Z",
        "body": "The upload of images and docs are already supported."
      },
      {
        "user": "Adytm404",
        "created_at": "2025-02-05T03:11:15Z",
        "body": "where i can found dosc for image uploading API?"
      },
      {
        "user": "dinithaw",
        "created_at": "2025-02-05T04:32:44Z",
        "body": "> Just wondering when will the image, documents, audio insertion features be released? Thank you so much! \n> \n> \n> \n\nDude[noob] Why you spamming it here?\nPost it on FAQ somewhere "
      },
      {
        "user": "Jangyaseni666",
        "created_at": "2025-02-05T07:28:28Z",
        "body": "> where i can found dosc for image uploading API?\n\nYeah I have been searching for the same. Didn't find much except for like local setups. "
      }
    ]
  },
  {
    "number": 487,
    "title": "[BUG]",
    "created_at": "2025-01-30T17:17:21Z",
    "closed_at": "2025-02-06T08:22:11Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/issues/487",
    "body": "When ever I'm trying to run this the whole thing is stuck on here:\n`torchrun --nnodes 2 --nproc-per-node 8 --node-rank 1 --master-addr 127.0.0.1 generate.py --ckpt-path DeepSeek-V3-Demo --config configs/config_671B.json --interactive --temperature 0.7 --max-new-tokens 200`\n\nW0130 23:09:58.895000 139676709838976 torch/distributed/run.py:779] \nW0130 23:09:58.895000 139676709838976 torch/distributed/run.py:779] *****************************************\nW0130 23:09:58.895000 139676709838976 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \nW0130 23:09:58.895000 139676709838976 torch/distributed/run.py:779] *****************************************\n\nWhat can we do about it?\n\nI'm using the 1.7G Model. ",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/487/comments",
    "author": "sr13579",
    "comments": [
      {
        "user": "GeeeekExplorer",
        "created_at": "2025-02-05T01:55:14Z",
        "body": "You may need to run this command on two servers simultaneously."
      }
    ]
  },
  {
    "number": 484,
    "title": "什么时候接入Python？",
    "created_at": "2025-01-30T14:43:33Z",
    "closed_at": "2025-02-05T02:11:38Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/issues/484",
    "body": "就是接入Python之后可以启动大模型，也就是可以实行自动化运维比较快一点这个，因为有好多软件都是Python开发出来的，嗯，他学起来也比较简单一些，希望你们发展的越来越好，祝你们在2025年蛇年大吉，还有请你们赶快优化一下内容，他这个介绍的实在太长了，比如说，9.11和9.0哪个大，他介绍了一大堆东西，没啥用感觉，既然你还有9.0比9.11还要大的，这怎么可能嘛，希望保持免费，希望可以在里面可以做音乐啊，做视频呐以及剪辑等等。",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/484/comments",
    "author": "EEEREEE-ereer",
    "comments": [
      {
        "user": "abelbraaksma",
        "created_at": "2025-01-31T18:49:03Z",
        "body": "Google translate:\n\n> After connecting to Python, you can start a large model, that is, you can implement automated operation and maintenance faster, because many software are developed in Python. Well, it is also easier to learn. I hope you will develop better and better. I wish you good luck in 2025, the Year of the Snake. Also, please optimize the content as soon as possible. His introduction is too long. For example, which is bigger, 9.11 or 9.0? He introduced a lot of things, which doesn’t seem to be useful. Since you still have 9.0 which is bigger than 9.11, how is this possible? I hope it will remain free, and I hope you can make music, videos, editing, etc. in it.\n\nI don't think there's anything actionable here."
      }
    ]
  },
  {
    "number": 480,
    "title": "能把介绍翻译成中文吗",
    "created_at": "2025-01-30T08:33:37Z",
    "closed_at": "2025-02-06T08:22:32Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/issues/480",
    "body": "可以提供多种语言的介绍文档.md",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/480/comments",
    "author": "abcdefqwer1234",
    "comments": [
      {
        "user": "Rainbow-SPY",
        "created_at": "2025-01-30T10:28:52Z",
        "body": "赞同"
      },
      {
        "user": "civilman628",
        "created_at": "2025-01-30T18:41:20Z",
        "body": "chrome有自动翻译"
      }
    ]
  },
  {
    "number": 478,
    "title": "pip3 install -r requirements.txt                                           ERROR: Could not find a version that satisfies the requirement torch==2.4.1 (from versions: 2.6.0) ERROR: No matching distribution found for torch==2.4.1",
    "created_at": "2025-01-30T07:31:04Z",
    "closed_at": "2025-02-05T02:19:48Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/issues/478",
    "body": "pip3 install -r requirements.txt                                          \nERROR: Could not find a version that satisfies the requirement torch==2.4.1 (from versions: 2.6.0)\nERROR: No matching distribution found for torch==2.4.1\n我是Mac pro m1",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/478/comments",
    "author": "harrywu001",
    "comments": [
      {
        "user": "yadavnikhil03",
        "created_at": "2025-01-30T07:49:54Z",
        "body": "This indicates that PyTorch version 2.4.1 is not available for your system, but version 2.6.0 is.\nUpdate your requirements.txt file to specify PyTorch version 2.6.0\n\n"
      },
      {
        "user": "danshuilin",
        "created_at": "2025-01-30T17:50:57Z",
        "body": "Collecting torch==2.6.0 (from -r requirements.txt (line 1))\n  Downloading torch-2.6.0-cp310-cp310-win_amd64.whl.metadata (28 kB)\nERROR: Could not find a version that satisfies the requirement triton==3.0.0 (from versions: none)\nERROR: No matching distribution found for triton==3.0.0"
      },
      {
        "user": "danshuilin",
        "created_at": "2025-01-30T17:51:15Z",
        "body": "Collecting torch==2.4.1 (from -r requirements.txt (line 1))\n  Downloading torch-2.4.1-cp310-cp310-win_amd64.whl.metadata (27 kB)\nERROR: Could not find a version that satisfies the requirement triton==3.0.0 (from versions: none)\nERROR: No matching distribution found for triton==3.0.0"
      },
      {
        "user": "GeeeekExplorer",
        "created_at": "2025-02-05T02:19:48Z",
        "body": "Since the infer demo uses Triton, only Linux is supported."
      }
    ]
  },
  {
    "number": 476,
    "title": "[BUG]",
    "created_at": "2025-01-30T06:33:26Z",
    "closed_at": "2025-02-05T02:20:43Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/issues/476",
    "body": "**Describe the bug**\nA clear and concise description of what the bug is.\n\n**To Reproduce**\nSteps to reproduce the behavior.\n\n**Expected behavior**\nA clear and concise description of what you expected to happen.\n\n**Screenshots**\nIf applicable, add screenshots to help explain your problem.\n\n**Additional context**\nAdd any other context about the problem here.",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/476/comments",
    "author": "LibyanTiger",
    "comments": [
      {
        "user": "yadavnikhil03",
        "created_at": "2025-01-30T07:43:11Z",
        "body": "**\n\n> I believe this issue can be closed since there is no indication that it relates to problem\n\n**"
      }
    ]
  },
  {
    "number": 470,
    "title": "Bug Report: Stored XSS Vulnerability in DeepSeek Chat",
    "created_at": "2025-01-30T01:31:04Z",
    "closed_at": "2025-01-30T10:47:02Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/issues/470",
    "body": "onderteam closed this as completed ",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/470/comments",
    "author": "onderteam",
    "comments": [
      {
        "user": "Some1and2-XC",
        "created_at": "2025-01-30T03:02:15Z",
        "body": "This is not an issue, this is its intended purpose. If you can exploit this I would be very impressed with you. "
      },
      {
        "user": "XieJiSS",
        "created_at": "2025-01-30T03:25:27Z",
        "body": "Hi Onderteam,\n\nThank you for the report. Regarding this attack, we believe the impact is relatively small. Firstly, since we do not support sharing chat session history, the generated page with malicious code can only attack the user who asked the model to generate them. Also, the Run Code function executes codes on cdn.deepseek.com instead of chat.deepseek.com, which means that it's not possible for the attacker to access any sensitive cookies set on chat.deepseek.com, due to browsers' cross origin limitations.\n\nRight now, we consider this as a low severity Self-XSS with relatively limited impacts. In the future, we may add a warning for this feature (e.g. like those warning messages you may see when openning a DevTools Console on google oauth2 authorization page). We are also willing to know if this attack payload can be further developed to gain greater impacts. For reporting vulnerability details, you can contact security@deepseek.com, and we sincerely appreciate your help.\n\nBest Regards,\nDeepSeek Dev Team"
      },
      {
        "user": "sw0rd1ight",
        "created_at": "2025-02-10T03:08:45Z",
        "body": "@XieJiSS 针对这个问题的危害性和影响扩大，我前几天已经通过swordlight666@163这个邮箱发送到过security@deepseek.com、api-service@deepseek.com，请注意查收"
      }
    ]
  },
  {
    "number": 467,
    "title": "Fix the Readme.md issue #456",
    "created_at": "2025-01-29T23:29:47Z",
    "closed_at": "2025-02-06T08:01:50Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/pull/467",
    "body": "Removed the spelling and grammatical mistakes from readme.md file",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/467/comments",
    "author": "harsh1504660",
    "comments": [
      {
        "user": "mowentian",
        "created_at": "2025-02-06T08:01:50Z",
        "body": "Thank you, but this is not a critical technical issue, so let's hold off on merging for now."
      }
    ]
  },
  {
    "number": 456,
    "title": "[BUG] Spelling mistakes / grammatical errors in Readme file",
    "created_at": "2025-01-29T13:43:58Z",
    "closed_at": "2025-02-08T03:19:06Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/issues/456",
    "body": "**Describe the bug**\nSome spelling mistakes and grammatical errors in readme file need to be fixed.\n\n**To Reproduce**\nWill fix the mistakes and errors.\n\n",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/456/comments",
    "author": "DevanshPaliwal",
    "comments": [
      {
        "user": "HyderYash",
        "created_at": "2025-01-29T14:47:23Z",
        "body": "I'd like to contribute by fixing the spelling and grammatical errors in the README file. Could you please assign this issue to me? Thanks!"
      },
      {
        "user": "AayushKarwa",
        "created_at": "2025-01-30T03:50:07Z",
        "body": " I noticed some spelling and grammatical errors in the README file. I'd like to fix them. Could you please assign this issue to me? \n\n"
      },
      {
        "user": "Harikrishna-Srinivasan",
        "created_at": "2025-01-30T15:28:17Z",
        "body": "README.md file still seems to have typos.\nI've noticed two asterisks at the end of \n```shell\n> [!NOTE]\n> Hugging Face's Transformers has not been directly supported yet.**\n```\nI'm gonna fix it. 🪛"
      },
      {
        "user": "musvaage",
        "created_at": "2025-02-03T20:06:30Z",
        "body": "> spelling/grammar in readme\n\n@DevanshPaliwal \n\nDeepSeek_V3.pdf\n\nDeepSeek-V3 Technical Report\n\nPlease identify only that readme content which does not appear in the Technical Report.\n\n"
      },
      {
        "user": "musvaage",
        "created_at": "2025-02-06T23:16:15Z",
        "body": "> Thank you, but this is not a critical technical issue, so let's hold off on merging for now.\n\nAs per comments (above) appearing on recent PRs on the similar subject matter.\n\nThis Issue could probably be closed."
      }
    ]
  },
  {
    "number": 455,
    "title": "[BUG] convert.py does not work for the DeepSeek-R1-Distill-Qwen-7B model",
    "created_at": "2025-01-29T13:42:53Z",
    "closed_at": "2025-02-05T02:35:59Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/issues/455",
    "body": "convert.py asks for --n_experts for the model. For DeepSeek-R1-Distill-Qwen-7B, it gives below error:\n\nassert key in mapping\nAssertionError.\n\nWhat should be the --n_experts value for DeepSeek-R1-Distill-Qwen-7B?\n",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/455/comments",
    "author": "harshitAgr",
    "comments": [
      {
        "user": "GeeeekExplorer",
        "created_at": "2025-02-05T02:35:59Z",
        "body": "The infer demo only supports DeepSeek V2 and V3 models. You can use vllm or sglang for Qwen models."
      }
    ]
  },
  {
    "number": 448,
    "title": "Added redirect links to github repositories of Deepseek-R1 and Deepseek-V2",
    "created_at": "2025-01-29T07:43:09Z",
    "closed_at": "2025-02-06T07:54:31Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/pull/448",
    "body": "Added redirect links to github repositories of Deepseek-R1 and Deepseek-V2 in README",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/448/comments",
    "author": "selligtom",
    "comments": [
      {
        "user": "Some1and2-XC",
        "created_at": "2025-01-29T18:54:06Z",
        "body": "For what reason?"
      },
      {
        "user": "mowentian",
        "created_at": "2025-02-06T07:54:31Z",
        "body": "Thank you, but this is not a critical technical issue, so let's hold off on merging for now."
      }
    ]
  },
  {
    "number": 447,
    "title": "Added various error handlers and Issue templates.",
    "created_at": "2025-01-29T07:33:44Z",
    "closed_at": "2025-02-06T07:53:48Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/pull/447",
    "body": "In this pull request, I have implemented various error handlers and issue templates to enhance the robustness and maintainability of the DeepSeek-V3 project. These additions aim to improve error handling and provide clear guidelines for reporting issues, thereby streamlining the development process and ensuring a more efficient workflow for contributors.",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/447/comments",
    "author": "ankurhalder",
    "comments": [
      {
        "user": "Some1and2-XC",
        "created_at": "2025-01-29T19:05:57Z",
        "body": "That's a lot of things to do in one pull request. You rewrote every single GitHub issue template and added dozens of try catch statements. You might want to split this up. Also you should be careful about adding things like this change:\r\n```\r\n - DEEPSEEK LICENSE AGREEMENT\r\n + # DEEPSEEK LICENSE AGREEMENT\r\n```\r\nThis file isn't a `.md` file so using `.md` syntax so its probably best to be extra careful about changes like this, though the removal of trailing spaces doesn't seem like the worst thing in the world (to that file)."
      },
      {
        "user": "ankurhalder",
        "created_at": "2025-01-30T06:12:54Z",
        "body": "Is it mergeable?"
      },
      {
        "user": "mowentian",
        "created_at": "2025-02-06T07:53:48Z",
        "body": "sorry, but there are too many things to do in one pull request... \r\nissue templates may be good, i think"
      }
    ]
  },
  {
    "number": 438,
    "title": "[BUG]Can't login with google",
    "created_at": "2025-01-28T20:56:49Z",
    "closed_at": "2025-02-08T03:16:49Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/issues/438",
    "body": null,
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/438/comments",
    "author": "mahemudborgave",
    "comments": [
      {
        "user": "mrayushmehrotra",
        "created_at": "2025-01-29T07:57:33Z",
        "body": "Hey @mahemudborgave, it was just a server load issue for a few minutes—not worth creating an issue. The server went down due to massive requests."
      },
      {
        "user": "Prathvi412",
        "created_at": "2025-01-29T08:06:56Z",
        "body": " \"login with Google\" is working properly @mahemudborgave  "
      },
      {
        "user": "Light-Danube",
        "created_at": "2025-01-29T19:59:59Z",
        "body": "Reappeard such issue today again, on 11.00 PM GMT +2."
      }
    ]
  },
  {
    "number": 428,
    "title": "exceptions_generate_models.py",
    "created_at": "2025-01-28T18:38:38Z",
    "closed_at": "2025-02-05T08:43:00Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/pull/428",
    "body": null,
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/428/comments",
    "author": "niteoliveira",
    "comments": [
      {
        "user": "niteoliveira",
        "created_at": "2025-01-28T18:39:11Z",
        "body": "exceptions in generate model"
      },
      {
        "user": "Some1and2-XC",
        "created_at": "2025-01-29T19:38:54Z",
        "body": "You removed so many comments..."
      }
    ]
  },
  {
    "number": 427,
    "title": "[web app] add support for passmail.net email domain",
    "created_at": "2025-01-28T18:35:15Z",
    "closed_at": "2025-02-08T03:20:03Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/issues/427",
    "body": "I tried to make an account on deepseek.com but due to my email address domain not being supported \n\nPlease can you add support.",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/427/comments",
    "author": "pheonixfirewingz",
    "comments": [
      {
        "user": "xigoi",
        "created_at": "2025-01-29T14:00:01Z",
        "body": "Why do e-mail domains even need to be “supported”? E-mail works the same no matter the domain."
      },
      {
        "user": "pheonixfirewingz",
        "created_at": "2025-01-29T14:01:44Z",
        "body": "I tried signing up on the website but said my email domain is not supported so made this request "
      },
      {
        "user": "xigoi",
        "created_at": "2025-01-29T14:03:53Z",
        "body": "I know, my question was aimed at the developers."
      }
    ]
  },
  {
    "number": 421,
    "title": "Appreciation for DeepSeek AI",
    "created_at": "2025-01-28T16:52:49Z",
    "closed_at": "2025-01-29T11:29:23Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/issues/421",
    "body": "Just wanted to say how impressed I am with Deep Seek AI! It’s super easy to use and has really improved my workflow. Big thanks to the team for all the hard work! Anyone else have tips or similar experiences to share?\n\n(You can close this issue)",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/421/comments",
    "author": "saugat2003",
    "comments": [
      {
        "user": "Ubuntufanboy",
        "created_at": "2025-01-28T22:25:25Z",
        "body": "Yeah it's great! Glory to FOSS Software!"
      },
      {
        "user": "mrayushmehrotra",
        "created_at": "2025-01-29T08:07:32Z",
        "body": "you can close this issue now @saugat2003 now ☺️"
      }
    ]
  },
  {
    "number": 419,
    "title": "Update README.md",
    "created_at": "2025-01-28T16:24:55Z",
    "closed_at": "2025-02-05T04:05:09Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/pull/419",
    "body": "Fala Paulo, saudades",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/419/comments",
    "author": "joao57",
    "comments": [
      {
        "user": "mowentian",
        "created_at": "2025-02-05T04:05:09Z",
        "body": "Thank you, but this is not a critical technical issue, so let's hold off on merging for now."
      }
    ]
  },
  {
    "number": 416,
    "title": "code optimization",
    "created_at": "2025-01-28T14:43:42Z",
    "closed_at": "2025-02-08T02:58:03Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/issues/416",
    "body": "`import torch.distributions as dist\n\ndef sample(logits, temperature=1.0):\n    probs = torch. SoftMax(logits / temperature, dim=-1)\n    dist = dist.Categorical(probs=probs)\n    return dist.sample()\n`\n\n\n",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/416/comments",
    "author": "Uttam1230998897987879",
    "comments": [
      {
        "user": "Some1and2-XC",
        "created_at": "2025-01-29T18:20:27Z",
        "body": "You'll find that GitHub implements this feature that allows you to request merging your code into a repo. This is referred to a pull request. Sometimes maintainers prefer people to use those instead of pasting code snippets into their GitHub issues."
      }
    ]
  },
  {
    "number": 412,
    "title": "Amazing AI",
    "created_at": "2025-01-28T13:15:49Z",
    "closed_at": "2025-02-05T02:43:56Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/issues/412",
    "body": "Just came here to say that this is amazing work, and best of all, open sourced. Looking forward to running a low end model on a raspberry-pi AI-hat. :)\n\n(You can close this issue.)",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/412/comments",
    "author": "htoann",
    "comments": [
      {
        "user": "NeKosmico",
        "created_at": "2025-01-28T15:51:25Z",
        "body": "En efecto, un gran proyecto de código abierto. Digno de admiración 🗿."
      }
    ]
  },
  {
    "number": 403,
    "title": "Lite Version V3 weights",
    "created_at": "2025-01-28T09:49:50Z",
    "closed_at": "2025-02-08T03:23:45Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/issues/403",
    "body": "This is really an amazing work done. \n\nI want to ask that is there any chance to have the lite version weights which can support the lower number of GPUs to run locally? Like minimal requirements which can be minimized to between 2 - 4 GPUs Nvidia A40 or so for inference?\n\nPlease guide me if maybe I am wrong and overseen any already implemented workflow.",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/403/comments",
    "author": "Tortoise17",
    "comments": [
      {
        "user": "saugat2003",
        "created_at": "2025-01-28T16:19:20Z",
        "body": "Hey, I totally agree with you! Running DeepSeek-V3 locally with just 2-4 GPUs (like the Nvidia A40s) would make it much more accessible for users with limited hardware resources. It would be great if there could be a lite version of the model that can perform inference without needing such massive setups.\n\nIf anyone has any suggestions on how to optimize the current setup for fewer GPUs, I'd be really interested in hearing them! Maybe pruning certain layers or using more aggressive quantization could help?"
      },
      {
        "user": "Tortoise17",
        "created_at": "2025-02-08T06:43:36Z",
        "body": "@mowentian if the weights are available. can you share link please?"
      }
    ]
  },
  {
    "number": 399,
    "title": "On macOS we can use Ollama and Kerlig",
    "created_at": "2025-01-28T07:16:28Z",
    "closed_at": "2025-02-05T04:00:10Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/pull/399",
    "body": null,
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/399/comments",
    "author": "letavocado",
    "comments": [
      {
        "user": "letavocado",
        "created_at": "2025-01-29T16:44:59Z",
        "body": "Hey DeepSeek team! My congrats, thanks for making real Open-Source AI.\r\n\r\nCan u merge this? It will helpful for most of users that using macOS as primary host.\r\n\r\n@mowentian @kavinmahendran09 \r\n\r\nCheers! :sparkles: "
      },
      {
        "user": "mowentian",
        "created_at": "2025-02-05T04:00:10Z",
        "body": "thanks，but system req is for running demo"
      }
    ]
  },
  {
    "number": 395,
    "title": "Added Try-Catch and Memory optimization in Convert.py",
    "created_at": "2025-01-28T06:21:31Z",
    "closed_at": "2025-01-30T14:22:16Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/pull/395",
    "body": "Optimizations in Convert.py:\r\n\r\n1. Added Try-Catch Block: Prevents crashes by handling unexpected errors gracefully.\r\n2. Optimized Memory Usage: Ensures memory is freed up after use, improving efficiency.",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/395/comments",
    "author": "AzazAhmedLipu79",
    "comments": [
      {
        "user": "kevinanew",
        "created_at": "2025-01-30T12:05:37Z",
        "body": "Putting a lot of lines of code into a try-except block is not a good idea"
      }
    ]
  },
  {
    "number": 393,
    "title": "能否为缓存命中机制增加开关",
    "created_at": "2025-01-28T04:36:59Z",
    "closed_at": "2025-02-05T02:54:07Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/issues/393",
    "body": "我知道这个机制很好很强大，也是为用户着想降低用户的使用成本。\n可问题在于，假如我就想调用api作为一个灵活的NPC，每次生成的内容都不一样呢？\n增加一个开关，让用户可以根据使用场景去选择是否激活，会不会更灵活一些？",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/393/comments",
    "author": "huangmouren2023",
    "comments": [
      {
        "user": "lin-calvin",
        "created_at": "2025-01-28T09:10:14Z",
        "body": "缓存机制不会影响输出多样性吧，"
      },
      {
        "user": "huangmouren2023",
        "created_at": "2025-01-28T14:11:52Z",
        "body": "> 缓存机制不会影响输出多样性吧，\n\n很会啊！问类似的问题。问几次ai就变复读机了"
      },
      {
        "user": "lin-calvin",
        "created_at": "2025-02-03T14:30:47Z",
        "body": "> > 缓存机制不会影响输出多样性吧，\n> \n> 很会啊！问类似的问题。问几次ai就变复读机了\n\n同一上下文？\n"
      },
      {
        "user": "GeeeekExplorer",
        "created_at": "2025-02-05T02:54:07Z",
        "body": "缓存是针对 prompt 的 KV Cache，不影响 completion 的采样"
      }
    ]
  },
  {
    "number": 390,
    "title": "chore: Add tqdm & python to requirements.txt. Format and documents.",
    "created_at": "2025-01-28T03:33:32Z",
    "closed_at": "2025-02-05T03:56:48Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/pull/390",
    "body": "Fixed several minor issues for improved community usability. ",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/390/comments",
    "author": "HarlanHeilman",
    "comments": [
      {
        "user": "FckYrShit56",
        "created_at": "2025-01-31T11:45:55Z",
        "body": "- ### ****"
      },
      {
        "user": "mowentian",
        "created_at": "2025-02-05T03:56:48Z",
        "body": "Thank you, but this is not a critical technical issue, so let's hold off on merging for now."
      }
    ]
  },
  {
    "number": 388,
    "title": "[README_WEIGHTS.md]. Update link and fix grammar",
    "created_at": "2025-01-28T02:53:12Z",
    "closed_at": "2025-02-05T03:54:32Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/pull/388",
    "body": "- Added a link to `config.json` for direct access.\r\n- Fixed minor grammar issues.",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/388/comments",
    "author": "danniely",
    "comments": [
      {
        "user": "mowentian",
        "created_at": "2025-02-05T03:54:32Z",
        "body": "Thank you, but this is not a critical technical issue, so let's hold off on merging for now."
      }
    ]
  },
  {
    "number": 386,
    "title": "Masking: avoid modifying tensor in-place to improve performance",
    "created_at": "2025-01-28T02:09:08Z",
    "closed_at": "2025-02-05T03:54:03Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/pull/386",
    "body": "The new implementation avoids an unnecessary in-place modification (.triu_(1)) by directly applying the triangular mask during the tensor creation using torch.triu. This eliminates redundant memory writes and reduces overhead and is especially beneficial for large sequence lengths (seqlen) and our MoE model in general where we're masking a lot.",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/386/comments",
    "author": "chrischarlesharrison",
    "comments": [
      {
        "user": "Some1and2-XC",
        "created_at": "2025-01-29T18:47:28Z",
        "body": "Do you have any benchmarks for this? I would be surprised if this actually improved anything."
      },
      {
        "user": "mowentian",
        "created_at": "2025-02-05T03:54:03Z",
        "body": "Thank you, but this is not a critical issue, so let's hold off on merging for now."
      }
    ]
  },
  {
    "number": 383,
    "title": "Update README.md",
    "created_at": "2025-01-27T21:32:30Z",
    "closed_at": "2025-02-05T03:45:41Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/pull/383",
    "body": "Part chat model size updated",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/383/comments",
    "author": "Muhammad-Noraeii",
    "comments": [
      {
        "user": "khajasmh",
        "created_at": "2025-01-28T02:02:09Z",
        "body": "Any reason to update the model size?"
      },
      {
        "user": "Muhammad-Noraeii",
        "created_at": "2025-01-28T06:55:13Z",
        "body": "It's bigger and people easily read readme"
      },
      {
        "user": "Muhammad-Noraeii",
        "created_at": "2025-01-30T10:30:05Z",
        "body": "@mowentian\r\ncan you review it please?\r\nplease please please merge it.\r\nplease"
      },
      {
        "user": "mowentian",
        "created_at": "2025-02-05T03:45:41Z",
        "body": "Thank you, but this is not a critical technical issue, so let's hold off on merging for now."
      },
      {
        "user": "dinithaw",
        "created_at": "2025-02-05T03:51:46Z",
        "body": "> This pull makes no sense and should be closed.\n> \n> ```\n> $ sed -n '108, 110p' DeepSeek-V3/README.md\n> ## 4. Evaluation Results\n> ### Base Model\n> #### Standard Benchmarks\n> $ sed -n '166, 167p' DeepSeek-V3/README.md\n> ### Chat Model\n> #### Standard Benchmarks (Models larger than 67B)\n> $ \n> ```\n\nAgreed "
      }
    ]
  },
  {
    "number": 381,
    "title": "Fixed Issue 380",
    "created_at": "2025-01-27T19:02:45Z",
    "closed_at": "2025-01-29T20:13:07Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/pull/381",
    "body": "The text has been formatted into a clearer structure with sections, headings, and bullet points to enhance readability and understanding.\r\nFixed issue #380 ",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/381/comments",
    "author": "Ankush1oo8",
    "comments": [
      {
        "user": "pabl0",
        "created_at": "2025-01-27T20:37:02Z",
        "body": "Should it also be renamed to LICENSE-MODEL.md if the format changes to Markdown?\r\nAlso I see there are significant changes to the wording. This is a legal document, are you sure the changes are approved?"
      },
      {
        "user": "Ankush1oo8",
        "created_at": "2025-01-27T21:31:38Z",
        "body": "The meaning is same just wording is short and easy to read"
      },
      {
        "user": "Ankush1oo8",
        "created_at": "2025-01-27T22:14:44Z",
        "body": "Should I keep the original wording "
      },
      {
        "user": "pabl0",
        "created_at": "2025-01-28T09:22:35Z",
        "body": "> Should I keep the original wording\r\n\r\nSeriously, did you ask the DeepSeek legal team?"
      },
      {
        "user": "Ankush1oo8",
        "created_at": "2025-01-28T17:38:08Z",
        "body": "> > Should I keep the original wording\r\n> \r\n> Seriously, did you ask the DeepSeek legal team?\r\n\r\nwhat should I do then can you please help"
      }
    ]
  },
  {
    "number": 380,
    "title": "LICENCE-MODEL formatting not ideal",
    "created_at": "2025-01-27T18:43:27Z",
    "closed_at": "2025-02-06T16:57:03Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/issues/380",
    "body": "The model license file is plain text without any newlines, so it does not render well in Github or in many text editors, and thus is difficult to read.\n\nPlease consider making the lines shorter (max 80 characters), or converting the file to a flowing format like Markdown.",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/380/comments",
    "author": "pabl0",
    "comments": [
      {
        "user": "musvaage",
        "created_at": "2025-01-29T21:33:13Z",
        "body": "line editor\n\nline wrap occurs running `ed -s DeepSeek-V3/LICENSE-MODEL <<<'1,10p'`\n\nvisual editors\n\nline wrap is present in default emacs and vim when opening the file\n\ngui editors\n\n<s>line</s> dynamic word wrap is present in KDE's default kate/kwrite, and I venture to guess likewise in GNOME's default gedit"
      },
      {
        "user": "musvaage",
        "created_at": "2025-01-29T21:36:52Z",
        "body": "certainly the file has newlines\n\n```\n$ cat DeepSeek-V3/LICENSE-MODEL | wc -l\n90\n$ \n```"
      },
      {
        "user": "pabl0",
        "created_at": "2025-01-30T06:13:30Z",
        "body": "Obviously there are newlines after each paragraph. And yes, most editors do _line_ wrap by default, but not _word_ wrap, so it does not look very nice. (Yes proper editors support word wrap, like `toggle-word-wrap` in emacs.)\n\nThis is a minor detail, of course, but plain text documents with single-line paragraphs don't follow the traditional convention. The `LICENCE-CODE` file is wrapped."
      }
    ]
  },
  {
    "number": 371,
    "title": "Create xxx.py",
    "created_at": "2025-01-27T14:34:49Z",
    "closed_at": "2025-02-05T03:42:03Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/pull/371",
    "body": null,
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/371/comments",
    "author": "Shouvik703",
    "comments": [
      {
        "user": "guiireal",
        "created_at": "2025-01-28T13:27:55Z",
        "body": "WTF"
      },
      {
        "user": "Paiman-Rasoli",
        "created_at": "2025-01-28T14:09:53Z",
        "body": "LMFAO 😃"
      },
      {
        "user": "dinithaw",
        "created_at": "2025-02-05T03:59:37Z",
        "body": "Please get more educated 😂\nDo something useful 🙏"
      }
    ]
  },
  {
    "number": 367,
    "title": "Update model.py",
    "created_at": "2025-01-27T12:04:46Z",
    "closed_at": "2025-02-05T03:41:32Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/pull/367",
    "body": "Enabling mixed precision training to reduce memory usage and potentially speed up training.",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/367/comments",
    "author": "Dessantii",
    "comments": [
      {
        "user": "mowentian",
        "created_at": "2025-02-05T03:41:32Z",
        "body": "The performance and accuracy of the model are related, and it is not recommended to use autocast."
      }
    ]
  },
  {
    "number": 360,
    "title": "Update README.md",
    "created_at": "2025-01-27T09:47:04Z",
    "closed_at": "2025-02-05T03:37:55Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/pull/360",
    "body": "Updated the capitalization of the word \"recommended\" to \"Recommended\" in a heading to ensure consistency with title case formatting throughout the document. This change aligns the heading style with the rest of the README for a more polished and professional appearance.",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/360/comments",
    "author": "Afueth",
    "comments": [
      {
        "user": "Afueth",
        "created_at": "2025-01-28T03:55:56Z",
        "body": "Hi @jacksonpradolima  thanks for reviewing and approving my PR! Could you let me know if there’s anything else needed before it can be merged? 😊"
      },
      {
        "user": "mowentian",
        "created_at": "2025-02-05T03:37:55Z",
        "body": "Thank you, but this is not a critical technical issue, so let's hold off on merging for now."
      },
      {
        "user": "dinithaw",
        "created_at": "2025-02-05T04:07:43Z",
        "body": "Please stop spamming noobs "
      }
    ]
  },
  {
    "number": 359,
    "title": "Update README.md",
    "created_at": "2025-01-27T09:42:10Z",
    "closed_at": "2025-02-05T03:37:04Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/pull/359",
    "body": "Updated the introductory sentence in the \"Introduction\" section to improve clarity and readability.\r\n\r\nChanged:\r\n\"We present DeepSeek-V3, a strong Mixture-of-Experts (MoE) language model with 671B total parameters with 37B activated for each token.\"\r\n\r\nTo: \"DeepSeek-V3 is a powerful Mixture-of-Experts (MoE) language model with 671 billion total parameters, of which 37 billion are activated per token.\"\r\n\r\nThis revision ensures conciseness and better emphasis on key details.",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/359/comments",
    "author": "Afueth",
    "comments": [
      {
        "user": "mowentian",
        "created_at": "2025-02-05T03:37:04Z",
        "body": "Thank you, but this is not a critical technical issue, so let's hold off on merging for now."
      }
    ]
  },
  {
    "number": 357,
    "title": "intel arc a770独显可以本地部署吗",
    "created_at": "2025-01-27T08:35:56Z",
    "closed_at": "2025-02-08T09:23:12Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/issues/357",
    "body": null,
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/357/comments",
    "author": "cnbinwang",
    "comments": [
      {
        "user": "mowentian",
        "created_at": "2025-02-08T09:23:12Z",
        "body": "不提供私有化部署及相关支持服务"
      }
    ]
  },
  {
    "number": 347,
    "title": "Add other payment providers other than Paypal that support all countries.",
    "created_at": "2025-01-26T06:05:42Z",
    "closed_at": "2025-02-08T09:38:03Z",
    "labels": [
      "enhancement"
    ],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/issues/347",
    "body": "**Is your feature request related to a problem? Please describe.**\nCurrently deepseek only receives payment from Paypal supported country.  However, PayPal is not available in my country. So, I can not pay with my card. The card has no issue. I have made payments to other international companies, like Apple, anthropic, openai, etc.\n\n**Describe the solution you'd like**\nAdd other payment providers other than Paypal that support all countries.\n\n",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/347/comments",
    "author": "SNNafi",
    "comments": [
      {
        "user": "arsal-dev",
        "created_at": "2025-01-27T13:50:38Z",
        "body": "this is highly needed as I cannot make payment to use deepseek API, as Paypal is not working in my country nor does alipay or wechat."
      },
      {
        "user": "mowentian",
        "created_at": "2025-02-08T09:38:03Z",
        "body": "Possible in the future..."
      }
    ]
  },
  {
    "number": 345,
    "title": "1",
    "created_at": "2025-01-26T03:03:30Z",
    "closed_at": "2025-01-26T04:56:16Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/issues/345",
    "body": null,
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/345/comments",
    "author": "wo198777",
    "comments": [
      {
        "user": "Reborn-J",
        "created_at": "2025-01-26T03:11:57Z",
        "body": "你玩原神吗？"
      },
      {
        "user": "ZeYuan-lg",
        "created_at": "2025-01-26T04:14:11Z",
        "body": "小丑"
      },
      {
        "user": "yoyokity",
        "created_at": "2025-01-26T04:24:39Z",
        "body": "感觉智商不过100"
      }
    ]
  },
  {
    "number": 334,
    "title": "[BUG] 🔴 Critical Security Bug in Payment System",
    "created_at": "2025-01-24T19:35:00Z",
    "closed_at": "2025-01-25T15:27:19Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/issues/334",
    "body": "**Update: the problem was from the bank**\n\nI attempted to purchase $2 worth of API tokens.\nThe system confirmed the payment as successful and credited the tokens to my account.\nHowever, no corresponding charge was made to my bank account.\nThis indicates a serious flaw in the payment processing system, where tokens are being credited without verifying that the payment has actually been processed and charged.\n\nSteps to Reproduce:\n\nAttempt to purchase API tokens (e.g., $2 worth).\nObserve that the system confirms the payment as successful and credits the tokens.\nCheck the bank account and note that no transaction appears.\nExpected Behavior:\n\n\n\n**Update: the problem was from the bank** ",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/334/comments",
    "author": "MALKIabdessamad",
    "comments": [
      {
        "user": "rodrigozanatta",
        "created_at": "2025-01-29T15:21:19Z",
        "body": "hahaha... this is a scam? "
      }
    ]
  },
  {
    "number": 330,
    "title": "[BUG] convert.py cannot convert DeepSeek-R1-Distill-Qwen-1.5B",
    "created_at": "2025-01-24T08:38:25Z",
    "closed_at": "2025-01-24T08:46:11Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/issues/330",
    "body": "**Describe the bug**\nI tried to convert DeepSeek-R1-Distill-Qwen-1.5B.safetensor into other format, \n\nand then.    code stopped at here:   \n\nfile: convert.py.  line 63: assert key in mapping\n\nAre there any other mappings that need to be replaced?",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/330/comments",
    "author": "mmrip",
    "comments": [
      {
        "user": "gliehu",
        "created_at": "2025-01-27T15:34:58Z",
        "body": "I encountered the same issue. How did you solve it?"
      },
      {
        "user": "tdRPA",
        "created_at": "2025-01-28T07:02:34Z",
        "body": "me too. but how this issue is closed without an answer"
      }
    ]
  },
  {
    "number": 323,
    "title": "train过程模型代码是没有上传吗？",
    "created_at": "2025-01-23T03:39:18Z",
    "closed_at": "2025-02-08T03:24:32Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/issues/323",
    "body": "没有看到预训练阶段代码，想参考 Multi-Token  prediction （MTP）实现细节\n",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/323/comments",
    "author": "liyang-d1c3y7",
    "comments": [
      {
        "user": "suiyan538",
        "created_at": "2025-01-27T05:31:33Z",
        "body": "同问"
      },
      {
        "user": "suiyan538",
        "created_at": "2025-01-27T05:32:08Z",
        "body": "> 没有看到预训练阶段代码，想参考 Multi-Token prediction （MTP）实现细节\n\n您找到了吗？"
      },
      {
        "user": "kuazhangxiaoai",
        "created_at": "2025-02-10T06:01:50Z",
        "body": "同问"
      }
    ]
  },
  {
    "number": 321,
    "title": "Light Mode Support for Code Snippets",
    "created_at": "2025-01-22T17:40:01Z",
    "closed_at": "2025-01-23T01:26:41Z",
    "labels": [
      "enhancement"
    ],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/issues/321",
    "body": "**Description:**\n\nHello guys! Hope you are doing fine. I noticed that the code snippets only support dark mode. It would be great to have an option for light mode as well, especially for users who prefer lighter themes or are working in well-lit environments. A color scheme which is language specific ( Notion ) will be a cherry on top.\n",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/321/comments",
    "author": "sajid755",
    "comments": [
      {
        "user": "mowentian",
        "created_at": "2025-01-23T01:26:41Z",
        "body": "Thank you for your feedback. We have received your request and have forwarded it to the product department."
      }
    ]
  },
  {
    "number": 319,
    "title": "Multiple Features Request",
    "created_at": "2025-01-22T04:53:59Z",
    "closed_at": "2025-01-23T01:27:20Z",
    "labels": [
      "enhancement"
    ],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/issues/319",
    "body": "Hi DeepSeek Team,\n\nAs a dedicated user, I’d like to request the following features to enhance DeepSeek’s usability and user experience:\n\n### **1. Memory System, similar to ChatGPT**\n\nAllows users to save preferences and information about them.\n\n“Remember I prefer lower caps in all messages, and a relevant emoji after every other sentence.”\nAI: “k, got it 😌. all msgs will be in lowercase with emojis when needed 😉.”_\n\n   _User:\"My name is Matthew, I am 16 years old settled in California.\"_\n\n  _AI: \"got it! you are matthew, 16, living in california.\"_\n\nMemory Stored: User prefers lower caps in all messages with relevant emojis when needed. User's name is Matthew. User is 16 years old and lives in California.\n\n### **2. Personas, as seen on character.ai**\n\nLet me save multiple personas with unique vibes/styles.\n\nExample:\n\n    Persona 1: Academic Tutor\n\n        Tone: Formal, detailed explanations.\n\n        Example: “The Krebs cycle involves three key steps:...”\n\n    Persona 2: Casual Friend\n\n        Tone: Slang, emojis, abbreviations.\n\n        Example: “Yo, the Krebs cycle’s like 🔄 energy stuff, ya know?”\n\n**### 3. Easy Switching:**\n\n    Add a UI toggle to switch between saved personas and models.\n\n    Example: Dropdown menu with options like “Persona: Academic Tutor | Casual Friend | Code Mentor”. \n                      Dropdown menu with model changing like V3, R1...\n\n嗨，DeepSeek团队，\n\n作为用户，我想提出以下建议，以提升DeepSeek的可用性：\n\n### **1. 记忆系统（类似于ChatGPT）**\n允许用户保存偏好/信息，实现个性化回复。  \n_示例：用户说“记住我喜欢消息里带表情符号。”AI回复“了解😌。”然后保存记忆。_\n\n### **2. 人设（类似于Character.ai）**\n允许保存多种语气/风格的配置，例如学术导师（正式）、休闲朋友（俚语/表情符号）。\n\n### **3. 快速切换**\n添加下拉菜单，方便快速选择人设或模型（例如，V3、R1）。\n\n谢谢！\nThank you.\n\n\n\n",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/319/comments",
    "author": "CrazyBlobie",
    "comments": [
      {
        "user": "mowentian",
        "created_at": "2025-01-23T01:27:20Z",
        "body": "Thank you for your feedback. We have received your request and have forwarded it to the product department."
      }
    ]
  },
  {
    "number": 316,
    "title": "chat.deepseek.com",
    "created_at": "2025-01-21T16:46:07Z",
    "closed_at": "2025-01-23T02:32:25Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/issues/316",
    "body": "i am not able to access my previous chats on chat.deepseek.com its says \"Failed to load, you can retry loading.\"",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/316/comments",
    "author": "oktrained",
    "comments": [
      {
        "user": "JackietBao",
        "created_at": "2025-01-22T03:04:40Z",
        "body": "what？ i have never hand  this issue .   please description detail"
      },
      {
        "user": "SmiLegoLoth",
        "created_at": "2025-01-27T09:40:08Z",
        "body": "I started a session on my home computer using Windows 11, I had two chat history there.\nThen the next day, I logged in from my work computer (Windows 11), I can see the chat history on the left panel but when I click on it, I get the error message \"Failed to load, you can retry loading.\" The \"retry loading\" is a blue link but when I click it it doesn't do anything.\nI logged off and logged back in and now it is working.\nPerhaps it happens on the first logging on a new computer when there is no initial cookies on the computer?"
      },
      {
        "user": "JackietBao",
        "created_at": "2025-01-28T12:16:13Z",
        "body": "\n\n\n> I started a session on my home computer using Windows 11, I had two chat history there. Then the next day, I logged in from my work computer (Windows 11), I can see the chat history on the left panel but when I click on it, I get the error message \"Failed to load, you can retry loading.\" The \"retry loading\" is a blue link but when I click it it doesn't do anything. I logged off and logged back in and now it is working. Perhaps it happens on the first logging on a new computer when there is no initial cookies on the computer?\n\nI understand that it may be: Cache or Cookie problem when logging in for the first time\nWhen you log in for the first time on a new computer, the system may need more time to synchronize data because there is no relevant initial cache or cookie data. The initial loading failure may be due to the failure of these temporary data to be generated or updated correctly."
      }
    ]
  },
  {
    "number": 315,
    "title": "Alias o1 to deepseek-reasoner",
    "created_at": "2025-01-21T14:21:03Z",
    "closed_at": "2025-01-22T03:25:42Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/issues/315",
    "body": "**Is your feature request related to a problem? Please describe.**\nI user DeepSeek with Cursor but new r1 model not supported there.\n\n**Describe the solution you'd like**\nMake alias o1 to deepseek-reasoner\nSince Cursor support OpenAI's o1 model it should work",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/315/comments",
    "author": "alehano",
    "comments": [
      {
        "user": "mowentian",
        "created_at": "2025-01-22T03:25:42Z",
        "body": "Please wait for the updated version of Cursor. 😊"
      }
    ]
  },
  {
    "number": 313,
    "title": "Ask for Cursor support",
    "created_at": "2025-01-21T12:33:31Z",
    "closed_at": "2025-01-23T02:35:03Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/issues/313",
    "body": "Deepseek can be integrated into Cursor, (or hopefully Deepseek will develop a Cursor-like product on its own to bring the price down).",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/313/comments",
    "author": "Unakar",
    "comments": [
      {
        "user": "mowentian",
        "created_at": "2025-01-23T02:35:03Z",
        "body": "Please proceed to the Cursor community for support. Thank you."
      }
    ]
  },
  {
    "number": 307,
    "title": "Not support langchain embeddings !  能不能支撑langchain 词潜入",
    "created_at": "2025-01-20T04:00:08Z",
    "closed_at": "2025-01-22T07:05:14Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/issues/307",
    "body": "#### 需求说明\n langchain 使用Deepseek v3 做 Rag时，需要embeddings 数据  .\n\n",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/307/comments",
    "author": "RobinYang11",
    "comments": [
      {
        "user": "mowentian",
        "created_at": "2025-01-22T07:05:14Z",
        "body": "Sorry, but we currently do not support this."
      }
    ]
  },
  {
    "number": 305,
    "title": "[Questions] Is that KV Cache in Multihead Latent Attention?",
    "created_at": "2025-01-20T02:45:22Z",
    "closed_at": "2025-01-21T07:21:02Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/issues/305",
    "body": "I'm reading the technical reports of deepseekv2 and deepseekv3, and I see that people are using MLA in conjunction with RoPE. But I have a small question, which is whether KV Cache works here. I understand that we compress K and V into a latent matrix, so isn't the KV Cache used here because K and V are going to be recreated from scratch? ",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/305/comments",
    "author": "DngBack",
    "comments": [
      {
        "user": "GeeeekExplorer",
        "created_at": "2025-01-20T06:10:43Z",
        "body": "With the trick of matrix absorption, we don't need to recover K and V from KVCache. You can read our paper and demo code for more details."
      }
    ]
  },
  {
    "number": 297,
    "title": "请问deepseek要怎么部署才可以支持function call?",
    "created_at": "2025-01-17T08:46:58Z",
    "closed_at": "2025-01-20T01:59:23Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/issues/297",
    "body": "目前使用了sglang、vllm部署都不支持function call，然而我调用官方api的时候时可以的，想问问怎么部署才可以支持呢？\n期待回复~",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/297/comments",
    "author": "SF-evil",
    "comments": [
      {
        "user": "mowentian",
        "created_at": "2025-01-20T01:59:23Z",
        "body": "抱歉，我们暂不提供私有化部署及相关支持服务，还是希望可以前往社区寻求支持"
      }
    ]
  },
  {
    "number": 292,
    "title": "用多台H100机器推理Deepseek V3时，如何启用RDMA网络进行多台机器进行通信？",
    "created_at": "2025-01-16T08:52:22Z",
    "closed_at": "2025-01-17T06:43:05Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/issues/292",
    "body": "用多台H100机器推理Deepseek V3时，如何启用RDMA网络进行多台机器进行通信？",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/292/comments",
    "author": "JustinZou",
    "comments": [
      {
        "user": "mowentian",
        "created_at": "2025-01-17T06:43:05Z",
        "body": "Apologies, but we do not offer support for private deployments. However, you seek assistance from other communities such as sglang, vllm, and so on.\n\n"
      }
    ]
  },
  {
    "number": 286,
    "title": "PDF Upload functionality in API",
    "created_at": "2025-01-15T07:56:35Z",
    "closed_at": "2025-01-17T06:29:25Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/issues/286",
    "body": "The deepseek GUI allows to upload pdf and ask questions from it. Is there a similar functionality available in API?",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/286/comments",
    "author": "Laveena-Sat",
    "comments": [
      {
        "user": "mowentian",
        "created_at": "2025-01-17T06:29:25Z",
        "body": "sorry but not supported yet.."
      }
    ]
  },
  {
    "number": 264,
    "title": "页面字体行间距太大，生成的代码显示不好看，可以参考poe.com的排版",
    "created_at": "2025-01-13T06:42:37Z",
    "closed_at": "2025-01-14T06:21:55Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/issues/264",
    "body": "**Is your feature request related to a problem? Please describe.**\r\nA clear and concise description of what the problem is. Ex. I'm always frustrated when [...]\r\n\r\n**Describe the solution you'd like**\r\nA clear and concise description of what you want to happen.\r\n\r\n**Describe alternatives you've considered**\r\nA clear and concise description of any alternative solutions or features you've considered.\r\n\r\n**Additional context**\r\nAdd any other context or screenshots about the feature request here.\r\n",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/264/comments",
    "author": "hxp0190915",
    "comments": [
      {
        "user": "mowentian",
        "created_at": "2025-01-14T06:21:55Z",
        "body": "谢谢，会反馈给产品"
      },
      {
        "user": "hxp0190915",
        "created_at": "2025-01-14T06:22:27Z",
        "body": "已经收到您的来信，我会尽快回复。胡。"
      }
    ]
  },
  {
    "number": 253,
    "title": "API 接入问题",
    "created_at": "2025-01-10T05:59:35Z",
    "closed_at": "2025-01-10T11:08:18Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/issues/253",
    "body": "该 AI 模型是否支持 PDF 转 Word。若支持，该如何接入呢？",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/253/comments",
    "author": "mylvghb",
    "comments": [
      {
        "user": "mowentian",
        "created_at": "2025-01-10T11:08:18Z",
        "body": "模型并没有这方面的能力，还请移步其他专门的 pdf2word 的项目，谢谢"
      }
    ]
  },
  {
    "number": 242,
    "title": "[BUG]未来会考虑开源HAI-LLM框架吗？",
    "created_at": "2025-01-08T06:22:13Z",
    "closed_at": "2025-01-14T06:23:30Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/issues/242",
    "body": "**Describe the bug**\r\n未来会考虑开源HAI-LLM框架吗？\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior.\r\n\r\n**Expected behavior**\r\nA clear and concise description of what you expected to happen.\r\n\r\n**Screenshots**\r\nIf applicable, add screenshots to help explain your problem.\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/242/comments",
    "author": "DankoZhang",
    "comments": [
      {
        "user": "mowentian",
        "created_at": "2025-01-14T06:23:30Z",
        "body": "It depends..."
      },
      {
        "user": "sannyii",
        "created_at": "2025-02-14T10:28:05Z",
        "body": "您好，请问HAI-LLM 和 HAI-Platform 有什么区别呢？"
      }
    ]
  },
  {
    "number": 229,
    "title": "refactor(inference): Modularize model architecture for improved maintainability and scalability",
    "created_at": "2025-01-05T11:00:20Z",
    "closed_at": "2025-01-09T02:42:53Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/pull/229",
    "body": "## Overview\r\nThis PR refactors the monolithic model architecture into modular components, improving code organization, maintainability and extensibility. The changes follow SOLID principles and industry best practices for large-scale ML systems.\r\n\r\n## Key Changes\r\n- Split `model.py` into focused modules under `inference/models/`:\r\n  - `config.py`: Model configuration and hyperparameters\r\n  - `attention.py`: Multi-head Latent Attention (MLA) implementation\r\n  - `moe.py`: Mixture of Experts components (Gate, Expert, MoE)\r\n  - `linear.py`: Linear layer variants with parallel processing support\r\n  - `__init__.py`: Clean public API exports\r\n\r\n## Benefits\r\n- **Improved Maintainability**: Each module has a single, well-defined responsibility\r\n- **Better Testing**: Components can be tested in isolation\r\n- **Enhanced Readability**: Clear separation of concerns makes code easier to understand\r\n- **Easier Extensions**: New components can be added without modifying existing code\r\n- **Simplified Dependencies**: Clear module boundaries and dependency management\r\n- **Type Safety**: Proper type hints and dataclass configuration\r\n\r\n## Testing\r\n- All existing functionality preserved\r\n- Unit tests pass\r\n- Integration tests pass\r\n- No performance regression\r\n\r\n## Documentation\r\n- Added docstrings and type hints\r\n- Updated README with new module structure\r\n- Added architecture documentation\r\n\r\n## Migration Guide\r\nNo breaking changes - imports updated to use new module structure:\r\n```python\r\nfrom inference.models import MLA, MoE, ModelArgs\r\n",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/229/comments",
    "author": "twlhitesh",
    "comments": [
      {
        "user": "twlhitesh",
        "created_at": "2025-01-05T11:37:29Z",
        "body": "This pull request introduces several new classes and configurations to the `inference/models` module, enhancing its functionality and modularity. The main changes include the addition of the `ModelArgs` configuration class, new attention, linear, and mixture of experts (MoE) models, and the initialization of these components in the `__init__.py` file.\r\n\r\nNew configurations and models:\r\n\r\n* [`inference/models/config.py`](diffhunk://#diff-afcca900ca9d2cea30d3990a799ca8ae064c80fb8f706e096671c176ccf3f339R1-R36): Added the `ModelArgs` class to define model configuration parameters.\r\n\r\nNew attention model:\r\n\r\n* [`inference/models/attention.py`](diffhunk://#diff-94d85dacb5450cd2b0367c4f6172088994d02a41e094ca5e923f223918c47e30R1-R25): Introduced the `MLA` class, a new attention mechanism, with its initialization and forward methods.\r\n\r\nNew linear models:\r\n\r\n* [`inference/models/linear.py`](diffhunk://#diff-e85ed7f1c01d29a8a58bed78cb2cfbaf7ac89b5dbf5ace6419ba7833f6f2eda6R1-R28): Added the `Linear`, `ColumnParallelLinear`, and `RowParallelLinear` classes, each with their respective initializations and forward methods.\r\n\r\nNew mixture of experts (MoE) models:\r\n\r\n* [`inference/models/moe.py`](diffhunk://#diff-cc11aa16f0f100c303b149c0f0cbd80b522b54bcdc66ecb9831ec11a4e5d6abdR1-R30): Introduced the `Gate`, `Expert`, and `MoE` classes, each with their respective initializations and forward methods.\r\n\r\nInitialization of new components:\r\n\r\n* [`inference/models/__init__.py`](diffhunk://#diff-e7537a16ce544cab200cf27ad0b9fd046e06b0bbf19f59b64853bdb76506b895R1-R15): Updated the `__init__.py` file to import and expose the newly added classes (`ModelArgs`, `MLA`, `Gate`, `Expert`, `MoE`, `Linear`, `ColumnParallelLinear`, `RowParallelLinear`)."
      },
      {
        "user": "mowentian",
        "created_at": "2025-01-07T10:12:26Z",
        "body": "Thank you for your interest in the DeepSeek-V3 repository! The primary goal of this repo is to showcase our research findings and provide a minimal example to illustrate the model's architecture. It is not intended to serve as a fully-fledged, production-ready deployment solution, as excellent tools like sglang and other community-driven projects already excel in that area.\r\n\r\nHere are a few points to consider:\r\n\r\n1. DeepSeek_V3.pdf contains our research paper, and the figures directory demonstrates the model's performance. Removing these would detract from the repo's purpose.\r\n\r\n2. A single-machine deployment is not designed to deliver usable throughput for practical applications. Adding a web server would not significantly enhance usability and could distract users from focusing on the core model.py implementation.\r\n\r\nMost importantly, building a robust deployment pipeline is a highly complex process. We are grateful for the efforts of the broader community in this area. Instead of optimizing the code here, we recommend contributing to other community-driven projects that specialize in deployment. Simply refactoring or splitting our example code would not achieve the necessary scalability, usability, or maintainability required for production use.\r\n\r\nThank you for your understanding and support!"
      }
    ]
  },
  {
    "number": 225,
    "title": "Create azure-webapps-python.yml",
    "created_at": "2025-01-04T15:11:24Z",
    "closed_at": "2025-01-07T06:03:25Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/pull/225",
    "body": "hi ",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/225/comments",
    "author": "shhmfa",
    "comments": [
      {
        "user": "mowentian",
        "created_at": "2025-01-07T06:03:25Z",
        "body": "thanks, but no need for [Deploy to Azure Web App]"
      }
    ]
  },
  {
    "number": 210,
    "title": "[BUG]convert后运行错误",
    "created_at": "2025-01-03T02:32:23Z",
    "closed_at": "2025-01-17T06:38:56Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/issues/210",
    "body": "**Describe the bug**\r\n[rank0]: ValueError: Unrecognized model in ../DV3-hf-32/. Should have a `model_type` key in its config.json, or contain one of the following strings in its name: albert, align, altclip, audio-spectrogram-transformer, autoformer, bark, bart, beit, bert, bert-generation, big_bird, bigbird_pegasus, biogpt, bit, blenderbot, blenderbot-small, blip, blip-2, bloom, bridgetower, bros, camembert, canine, chameleon, chinese_clip, chinese_clip_vision_model, clap, clip, clip_text_model, clip_vision_model, clipseg, clvp, code_llama, codegen, cohere, conditional_detr, convbert, convnext, convnextv2, cpmant, ctrl, cvt, dac, data2vec-audio, data2vec-text, data2vec-vision, dbrx, deberta, deberta-v2, decision_transformer, deformable_detr, deit, depth_anything, deta, detr, dinat, dinov2, distilbert, donut-swin, dpr, dpt, efficientformer, efficientnet, electra, encodec, encoder-decoder, ernie, ernie_m, esm, falcon, falcon_mamba, fastspeech2_conformer, flaubert, flava, fnet, focalnet, fsmt, funnel, fuyu, gemma, gemma2, git, glm, glpn, gpt-sw3, gpt2, gpt_bigcode, gpt_neo, gpt_neox, gpt_neox_japanese, gptj, gptsan-japanese, granite, granitemoe, graphormer, grounding-dino, groupvit, hiera, hubert, ibert, idefics, idefics2, idefics3, imagegpt, informer, instructblip, instructblipvideo, jamba, jetmoe, jukebox, kosmos-2, layoutlm, layoutlmv2, layoutlmv3, led, levit, lilt, llama, llava, llava_next, llava_next_video, llava_onevision, longformer, longt5, luke, lxmert, m2m_100, mamba, mamba2, marian, markuplm, mask2former, maskformer, maskformer-swin, mbart, mctct, mega, megatron-bert, mgp-str, mimi, mistral, mixtral, mllama, mobilebert, mobilenet_v1, mobilenet_v2, mobilevit, mobilevitv2, moshi, mpnet, mpt, mra, mt5, musicgen, musicgen_melody, mvp, nat, nemotron, nezha, nllb-moe, nougat, nystromformer, olmo, olmoe, omdet-turbo, oneformer, open-llama, openai-gpt, opt, owlv2, owlvit, paligemma, patchtsmixer, patchtst, pegasus, pegasus_x, perceiver, persimmon, phi, phi3, phimoe, pix2struct, pixtral, plbart, poolformer, pop2piano, prophetnet, pvt, pvt_v2, qdqbert, qwen2, qwen2_audio, qwen2_audio_encoder, qwen2_moe, qwen2_vl, rag, realm, recurrent_gemma, reformer, regnet, rembert, resnet, retribert, roberta, roberta-prelayernorm, roc_bert, roformer, rt_detr, rt_detr_resnet, rwkv, sam, seamless_m4t, seamless_m4t_v2, segformer, seggpt, sew, sew-d, siglip, siglip_vision_model, speech-encoder-decoder, speech_to_text, speech_to_text_2, speecht5, splinter, squeezebert, stablelm, starcoder2, superpoint, swiftformer, swin, swin2sr, swinv2, switch_transformers, t5, table-transformer, tapas, time_series_transformer, timesformer, timm_backbone, trajectory_transformer, transfo-xl, trocr, tvlt, tvp, udop, umt5, unispeech, unispeech-sat, univnet, upernet, van, video_llava, videomae, vilt, vipllava, vision-encoder-decoder, vision-text-dual-encoder, visual_bert, vit, vit_hybrid, vit_mae, vit_msn, vitdet, vitmatte, vits, vivit, wav2vec2, wav2vec2-bert, wav2vec2-conformer, wavlm, whisper, xclip, xglm, xlm, xlm-prophetnet, xlm-roberta, xlm-roberta-xl, xlnet, xmod, yolos, yoso, zamba, zoedepth\r\n\r\n**To Reproduce**\r\nSteps to reproduce the behavior.\r\n\r\n**Expected behavior**\r\nA clear and concise description of what you expected to happen.\r\n\r\n**Screenshots**\r\nIf applicable, add screenshots to help explain your problem.\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/210/comments",
    "author": "catsled",
    "comments": [
      {
        "user": "GeeeekExplorer",
        "created_at": "2025-01-03T07:27:48Z",
        "body": "It seems that there is no `tokenizer.json` and `tokenizer_config.json` in your original huggingface directory. `convert.py` will copy them to the new directory if exists."
      },
      {
        "user": "catsled",
        "created_at": "2025-01-03T07:33:54Z",
        "body": "firstly, i converted the fp8 to bf16 and then converted the bf16 to hf format. \r\ni think copy them from the original will be ok, does it?"
      },
      {
        "user": "GeeeekExplorer",
        "created_at": "2025-01-03T10:19:02Z",
        "body": "> firstly, i converted the fp8 to bf16 and then converted the bf16 to hf format. i think copy them from the original will be ok, does it?\r\n\r\nYeah, the directory specified for `transformers` should contain `tokenizer.json`, `config.json`, etc."
      }
    ]
  },
  {
    "number": 207,
    "title": "[BUG]is:issue is:a typo :\"vLLM: Support DeekSeek-V3 .....\", DeekSeek-V3 to DeepSeek-V3",
    "created_at": "2025-01-02T14:21:37Z",
    "closed_at": "2025-01-03T07:31:34Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/issues/207",
    "body": "**Describe the bug**\r\n\r\nTypo in \"vLLM: Support DeepSeek-V3 .....\"\r\nChanged \"DeekSeek-V3\" to \"DeepSeek-V3\".\r\n\r\n",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/207/comments",
    "author": "Raostu",
    "comments": [
      {
        "user": "GeeeekExplorer",
        "created_at": "2025-01-03T07:31:34Z",
        "body": "It's fixed. Thank you!"
      }
    ]
  },
  {
    "number": 193,
    "title": "Add docstrings to functions in inference modules for better clarity",
    "created_at": "2025-01-01T23:30:47Z",
    "closed_at": "2025-01-07T06:02:11Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/pull/193",
    "body": "Closes #192. \r\n\r\nGoogle-style docstrings. \r\n\r\nFeedbacks are welcome.",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/193/comments",
    "author": "enochkan",
    "comments": [
      {
        "user": "enochkan",
        "created_at": "2025-01-03T21:20:01Z",
        "body": "thoughts?"
      },
      {
        "user": "enochkan",
        "created_at": "2025-01-05T18:19:05Z",
        "body": "@mowentian @GeeeekExplorer accidentally closed PR when syncing fork, re-opening PR.  "
      },
      {
        "user": "mowentian",
        "created_at": "2025-01-07T06:02:29Z",
        "body": "thanks~"
      }
    ]
  },
  {
    "number": 189,
    "title": "Mediatek NPU support",
    "created_at": "2025-01-01T15:01:09Z",
    "closed_at": "2025-02-12T07:53:32Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/issues/189",
    "body": "What's the possibility of running this model with mobile devices that have mediatek dimensity chips that supports neuropilot, in the future?",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/189/comments",
    "author": "syhmsztrk",
    "comments": [
      {
        "user": "EscaticZheng",
        "created_at": "2025-01-09T01:05:39Z",
        "body": "671B in mobile device? 14B is possible"
      },
      {
        "user": "github-actions[bot]",
        "created_at": "2025-02-09T00:17:32Z",
        "body": "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. If you believe this issue is still relevant, please leave a comment to keep it open. Thank you for your contributions!"
      },
      {
        "user": "dinithaw",
        "created_at": "2025-02-09T16:46:04Z",
        "body": "> What's the possibility of running this model with mobile devices that have mediatek dimensity chips that supports neuropilot, in the future?\n\nIf you're using github. You're probably a developer. Why don't you fork the model and try to develop it to run on those mobile chip rather than putting useless issues 🤔 "
      }
    ]
  },
  {
    "number": 171,
    "title": "Where can I find the source code?",
    "created_at": "2024-12-31T19:23:34Z",
    "closed_at": "2025-02-08T03:00:01Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/issues/171",
    "body": "And how does the community (people like me) contribute to the LLM",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/171/comments",
    "author": "ruidazeng",
    "comments": [
      {
        "user": "sarkarbikram90",
        "created_at": "2025-01-29T09:21:25Z",
        "body": "Hey @ruidazeng Users can provide feedback on the model's performance, report bugs, or suggest improvements."
      }
    ]
  },
  {
    "number": 153,
    "title": "不是哥们你这issue栏目怎么回事？",
    "created_at": "2024-12-31T05:32:54Z",
    "closed_at": "2024-12-31T06:37:55Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/issues/153",
    "body": "### 那我问你，为什么 README 没有中文的呢？\r\n\r\n那我问你，你是README吗？如果你是README的这样说的话，啊，那我问你，你你你是README，那我问你，那那你那README是不是不是MARKDOWN的？那我那我问你，你README是金子做的呢？还是银的，啊，还是，啊，异世界转生的，那我问你，啊，还是生成的，如果是如果你是MARKDOWN那我问你，啊，你说README是README，是，那我问你，那README是什么？那你要不要？啊？你是MARKDOWN还是README的，啊？那我问你，README加中文行不行？",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/153/comments",
    "author": "Po252",
    "comments": [
      {
        "user": "prife",
        "created_at": "2024-12-31T06:02:00Z",
        "body": "LZSB"
      },
      {
        "user": "jasonfish568",
        "created_at": "2025-01-03T10:31:43Z",
        "body": "> LZSB\r\n\r\n4字顶千金"
      },
      {
        "user": "Po252",
        "created_at": "2025-01-03T14:08:44Z",
        "body": "想在issue皮一下的，抱歉看来并不好笑。但是请问有中文介绍么？"
      }
    ]
  },
  {
    "number": 117,
    "title": "maybe feat: looking forward to an app version",
    "created_at": "2024-12-31T02:15:21Z",
    "closed_at": "2024-12-31T02:19:57Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/issues/117",
    "body": null,
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/117/comments",
    "author": "heygsc",
    "comments": [
      {
        "user": "mowentian",
        "created_at": "2025-01-17T06:23:03Z",
        "body": "已经发布了 app"
      },
      {
        "user": "heygsc",
        "created_at": "2025-01-17T06:29:46Z",
        "body": "嗯前几天刚上线小米商店我就下了，虽然有很多细节可以优化，整体还可以"
      }
    ]
  },
  {
    "number": 28,
    "title": "[Question] On NVLink bandwidth of H800",
    "created_at": "2024-12-30T01:08:56Z",
    "closed_at": "2024-12-31T09:19:32Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/issues/28",
    "body": "> NVLink offers a bandwidth of 160 GB/s, roughly 3.2 times that of IB (50 GB/s).\r\n\r\nMay I know why the bandwidth of NVLink on H800 is 160GB/s, instead of 400GB/s?\r\n\r\nThanks.",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/28/comments",
    "author": "GHGmc2",
    "comments": [
      {
        "user": "shenkele2016",
        "created_at": "2024-12-31T03:07:50Z",
        "body": "same question\r\n"
      },
      {
        "user": "mowentian",
        "created_at": "2024-12-31T09:19:32Z",
        "body": "400GB/s 是双向理论值，160GB/s 是我们的单向实测"
      },
      {
        "user": "GHGmc2",
        "created_at": "2025-01-01T04:10:14Z",
        "body": "> 400GB/s 是双向理论值，160GB/s 是我们的单向实测\r\n\r\n谢谢。那IB带宽50GB/s也是单向实测值吗？"
      },
      {
        "user": "yiakwy-xpu-ml-framework-team",
        "created_at": "2025-01-01T15:00:40Z",
        "body": "> 400GB/s 是双向理论值，160GB/s 是我们的单向实测\r\n\r\nCould I get the nccl test snapshot (both algorithm and bus bandwidth) of all to all test with multiple nodes ? If the bandwidth data (160 GB/s) is from nccl-test, it hardly to be true. H800 should have the same IB/NCCL performance with H100 (450-490 GB/s) (NV SHARP)"
      },
      {
        "user": "shenh10",
        "created_at": "2025-02-06T11:49:25Z",
        "body": "> > 400GB/s 是双向理论值，160GB/s 是我们的单向实测\n> \n> 谢谢。那IB带宽50GB/s也是单向实测值吗？\n\n同问。IB connect X-8 单向 400Gb/s （50GB/s）像是用的理论值。 @mowentian "
      }
    ]
  },
  {
    "number": 23,
    "title": "why need convert.py?",
    "created_at": "2024-12-29T08:53:55Z",
    "closed_at": "2025-02-08T03:00:14Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/issues/23",
    "body": null,
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/23/comments",
    "author": "CSEEduanyu",
    "comments": [
      {
        "user": "GeeeekExplorer",
        "created_at": "2024-12-31T08:09:44Z",
        "body": "`convert.py` is used to convert huggingface checkpoints into model parallel checkpoints required by the demo, so that each rank only needs to load the corresponding checkpoint when running the demo"
      },
      {
        "user": "KKwanhee",
        "created_at": "2025-02-03T08:14:40Z",
        "body": "Why was layer61 (corresponding to `nextn_predict_layers`) excluded in `convert.py` when generating the safetensor? Doesn't that mean `layer61` won't be used during inference?"
      },
      {
        "user": "GeeeekExplorer",
        "created_at": "2025-02-05T01:58:36Z",
        "body": "> Why was layer61 (corresponding to `nextn_predict_layers`) excluded in `convert.py` when generating the safetensor? Doesn't that mean `layer61` won't be used during inference?\n\nYes, The infer demo currently does not support MTP which uses layer 61."
      }
    ]
  },
  {
    "number": 5,
    "title": "add gradio app",
    "created_at": "2024-12-26T16:27:05Z",
    "closed_at": "2024-12-30T07:02:18Z",
    "labels": [],
    "url": "https://github.com/deepseek-ai/DeepSeek-V3/pull/5",
    "body": "added a gradio app that uses ai-gradio python package to easily deploy a chat app in a few lines of code",
    "comments_url": "https://api.github.com/repos/deepseek-ai/DeepSeek-V3/issues/5/comments",
    "author": "AK391",
    "comments": [
      {
        "user": "mowentian",
        "created_at": "2024-12-30T07:02:18Z",
        "body": "Thank you for your contribution. Gradio is a highly popular component, and its deployment process is well-understood by the community. To maintain the brevity and clarity of our documentation, as is common with other open-source frameworks, we have opted not to include detailed deployment or usage code here. Therefore, we will respectfully decline this merge request. We truly appreciate your effort and understanding!"
      }
    ]
  }
]