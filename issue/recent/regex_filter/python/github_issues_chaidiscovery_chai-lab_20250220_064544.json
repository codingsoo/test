[
  {
    "number": 314,
    "title": "Error on installing chai_lab==0.6.0",
    "created_at": "2025-02-19T15:57:36Z",
    "closed_at": "2025-02-19T21:26:30Z",
    "labels": [],
    "url": "https://github.com/chaidiscovery/chai-lab/issues/314",
    "body": "Hi, I tried to install version 0.6.0 as suggested in the README. Unfortunately, no matching version found. \n\nHere is the error msg:\n\nERROR: Could not find a version that satisfies the requirement chai_lab==0.6.0 (from versions: none)\nERROR: No matching distribution found for chai_lab==0.6.0 \n\nCould you help me to fix it?\n\nThank you.",
    "comments_url": "https://api.github.com/repos/chaidiscovery/chai-lab/issues/314/comments",
    "author": "cissizhang",
    "comments": [
      {
        "user": "wukevin",
        "created_at": "2025-02-19T20:09:26Z",
        "body": "The command works for me - can you post a little more about your current OS + python environment?"
      },
      {
        "user": "arogozhnikov",
        "created_at": "2025-02-19T20:12:32Z",
        "body": "```\npip install chai_lab==9999nonexistentversion\nERROR: Could not find a version that satisfies the requirement chai_lab==9999nonexistentversion (from versions: 0.0.1, 0.1.0, 0.2.0, 0.2.1, 0.3.0, 0.3.1, 0.4.1, 0.4.2, 0.5.0, 0.5.1, 0.5.2, 0.6.0)\nERROR: No matching distribution found for chai_lab==9999nonexistentversion\n```\n\npackage is available on pypi \n\n> chai_lab==0.6.0 (from versions: none)\n\nyou likely use custom pypi registry, potentially internal - in this case that's up to your company's infra team"
      },
      {
        "user": "cissizhang",
        "created_at": "2025-02-19T20:23:05Z",
        "body": "> The command works for me - can you post a little more about your current OS + python environment?\n\nThanks for the response. The following is the information: \n\npython environment\nPython 3.9.5\nbackports.entry-points-selectable 1.1.0\nbiopython                         1.81\nbrotlipy                          0.7.0\ncertifi                           2023.5.7\ncffi                              1.14.6\nchardet                           4.0.0\nconda                             4.10.3\nconda-package-handling            1.7.3\ncryptography                      3.4.7\ndistlib                           0.3.3\net-xmlfile                        1.1.0\nfilelock                          3.3.2\nh5py                              3.7.0\nidna                              2.10\nlxml                              4.9.1\nmamba                             0.15.3\nnumpy                             1.22.3\nopenpyxl                          3.0.9\npandas                            1.2.3\npip                               21.1.3\npycosat                           0.6.3\npycparser                         2.20\npyOpenSSL                         20.0.1\nPySocks                           1.7.1\npython-dateutil                   2.8.2\npytz                              2021.3\nrequests                          2.25.1\nruamel-yaml-conda                 0.15.100\nsetuptools                        52.0.0.post20210125\nsix                               1.16.0\ntqdm                              4.61.2\nurllib3                           1.26.6\nvirtualenv                        20.10.0\nwheel                             0.36.2\nXlsxWriter                        3.1.0\n\n\nOS infor: \nNAME=\"Ubuntu\"\nVERSION=\"20.04.2 LTS (Focal Fossa)\"\nID=ubuntu\nID_LIKE=debian\nPRETTY_NAME=\"Ubuntu 20.04.2 LTS\"\nVERSION_ID=\"20.04\"\n"
      },
      {
        "user": "arogozhnikov",
        "created_at": "2025-02-19T20:25:29Z",
        "body": "ok, then it makes sense - we support python>=3.10"
      },
      {
        "user": "cissizhang",
        "created_at": "2025-02-19T20:26:56Z",
        "body": "> ok, then it makes sense - we support python>=3.10\n\nI see. Thanks for the help!"
      }
    ]
  },
  {
    "number": 313,
    "title": "kalign issue when I am using --use-templates-server option",
    "created_at": "2025-02-19T02:29:58Z",
    "closed_at": "2025-02-19T04:44:15Z",
    "labels": [],
    "url": "https://github.com/chaidiscovery/chai-lab/issues/313",
    "body": "Thank you for your great job! I am quite impressive your works! \n\nI have some issues in using '--use-templates-server' option.\n\nwhen I am using this code to predict my protein.\n\n`chai-lab fold --use-msa-server --use-templates-server --num-trunk-recycles 3 --num-diffn-timesteps 200 --num-diffn-samples 5 --seed 42 6ZT2.fasta result`\n\nthen, I got this error messages\n\n```\n│ │                 seq = 'GTRYAGKVVVVTGGGRGIGAGIVRAFVNSGARVVICDKDESGGRALEQELPGAVFILCDVTQEDDVKTLVSETIRRFGRL'+177                                                                                           │ │\n│ │        seq_matching = 'TRYAGKVVVVTGGGRGIGAGIVRAFVNSGARVVICDKDESGGRALEQELPGAVFILCDVTQEDDVKTLVSETIRRFGRLD'+172                                                                                           │ │\n│ │           structure = <gemmi.Structure 6HNO with 1 model(s)>                                                                                                                                           │ │\n│ │               table = │   │   │   │   │   │   │   │   │   │   │     query_id subject_id  pident  length  mismatch  gapopen  ...  query_end  subject_start  subject_end        evalue  bitscore         │ │\n│ │                       comment                                                                                                                                                                          │ │\n│ │                       0    fd7582191b4e9444350b4c34993365a78d6e5f9ffcc616...     6hno_A   0.996     252         1        0  ...        252              1          253  4.243000e-89       293         │ │\n│ │                       252M                                                                                                                                                                             │ │\n│ │                       1    fd7582191b4e9444350b4c34993365a78d6e5f9ffcc616...     5jsf_A   1.000     252         0        0  ...        252              1          253  4.243000e-89       293         │ │\n│ │                       252M                                                                                                                                                                             │ │\n│ │                       2    fd7582191b4e9444350b4c34993365a78d6e5f9ffcc616...     5o6z_A   0.996     252         1        0  ...        252              1          253  5.812000e-89       293         │ │\n│ │                       252M                                                                                                                                                                             │ │\n│ │                       3    fd7582191b4e9444350b4c34993365a78d6e5f9ffcc616...     5js6_A   0.996     252         1        0  ...        252              1          253  5.812000e-89       293         │ │\n│ │                       252M                                                                                                                                                                             │ │\n│ │                       4    fd7582191b4e9444350b4c34993365a78d6e5f9ffcc616...     6h0m_A   0.996     252         1        0  ...        252              0          252  1.353000e-87       289         │ │\n│ │                       252M                                                                                                                                                                             │ │\n│ │                       ..                                                 ...        ...     ...     ...       ...      ...  ...        ...            ...          ...           ...       ...         │ │\n│ │                       ...                                                                                                                                                                              │ │\n│ │                       295  fd7582191b4e9444350b4c34993365a78d6e5f9ffcc616...     2bd0_D   0.213     229       152        5  ...        225              4          217  1.281000e-34       136         │ │\n│ │                       23M7D20M4D37M1I40M1D69M15I12M                                                                                                                                                    │ │\n│ │                       296  fd7582191b4e9444350b4c34993365a78d6e5f9ffcc616...     5u4s_B   0.274     186       129        2  ...        187              1          181  8.275000e-34       133         │ │\n│ │                       37M2I34M4I109M                                                                                                                                                                   │ │\n│ │                       297  fd7582191b4e9444350b4c34993365a78d6e5f9ffcc616...     5u4s_A   0.268     186       124        2  ...        187              1          175  3.914000e-33       131         │ │\n│ │                       35M8I30M4I109M                                                                                                                                                                   │ │\n│ │                       298  fd7582191b4e9444350b4c34993365a78d6e5f9ffcc616...     3kzv_A   0.274     186       130        3  ...        187              0          184  1.625000e-31       126         │ │\n│ │                       21M2D25M1D117M2I18M                                                                                                                                                              │ │\n│ │                       299  fd7582191b4e9444350b4c34993365a78d6e5f9ffcc616...     6uhx_A   0.274     186       130        3  ...        187              0          184  1.625000e-31       126         │ │\n│ │                       21M2D25M1D117M2I18M                                                                                                                                                              │ │\n│ │                                                                                                                                                                                                        │ │\n│ │                       [300 rows x 13 columns]                                                                                                                                                          │ │\n│ │ template_cif_folder = PosixPath('result/templates')                                                                                                                                                    │ │\n│ │              tmpdir = '/tmp/tmpbfj8ds1o'                                                                                                                                                               │ │\n│ ╰────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯ │\n│                                                                                                                                                                                                            │\n│ /data/hwkang/anaconda3/envs/chai0.6/lib/python3.12/site-packages/chai_lab/tools/kalign.py:73 in kalign_query_to_reference                                                                                  │\n│                                                                                                                                                                                                            │\n│    70 │   Returns KalignAlignment object that encapsulates the aligned query w.r.t. reference  ╭───────────────────────────────────────────── locals ─────────────────────────────────────────────╮        │\n│    71 │   \"\"\"                                                                                  │   query = 'TRYAGKVVVVTGGGRGIGAGIVRAFVNSGARVVICDKDESGGRALEQELPGAVFILCDVTQEDDVKTLVSETIRRFGRLD'+172 │        │\n│    72 │   assert (                                                                             │     ref = 'TRYAGKVVVVTGGGRGIGAGIVRAFVNSGARVVICDKDESGGRALEQELPGAVFILCDVTQEDDVKTLVSETIRRFGRLD'+172 │        │\n│ ❱  73 │   │   shutil.which(\"kalign\") is not None                                               │ threads = 1                                                                                      │        │\n│    74 │   ), \"Could not find kalign in your PATH; kalign is required for templates\"            ╰──────────────────────────────────────────────────────────────────────────────────────────────────╯        │\n│    75 │                                                                                                                                                                                                    │\n│    76 │   query = query.upper().replace(\"-\", \"\")                                                                                                                                                           │\n╰────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\nAssertionError: Could not find kalign in your PATH; kalign is required for templates\n\n```\n\nand this is my fasta file\n\n```\n>protein|name=6ZT2_QPK_P\nTRYAGKVVVVTGGGRGIGAGIVRAFVNSGARVVICDKDESGGRALEQELPGAVFILCDVTQEDDVKTLVSETIRRFGRLDCVVNNAGHHPPPQRPEETSAQGFRQLLELNLLGTYTLTKLALPYLRKSQGNVINISSLVGAIGQAQAVPYVATKGAVTAMTKALALDESPYGVRVNCISPGNIWTPLWEELAALMPDPRASIREGMLAQPLGRMGQPAEVGAAAVFLASEANFCTGIELLVTGGAELGYGCK\n>ligand|name=6ZT2_QPK_L\nOc1c(F)ccc(Cl)c1F\n\n```\n\nIs there anything wrong with my code or fasta file?",
    "comments_url": "https://api.github.com/repos/chaidiscovery/chai-lab/issues/313/comments",
    "author": "kanghw0325",
    "comments": [
      {
        "user": "kanghw0325",
        "created_at": "2025-02-19T02:39:53Z",
        "body": "also, I am using your examples but, it does not work\n\n```\nimport logging\nfrom pathlib import Path\n\nfrom chai_lab.chai1 import run_inference\n\nlogging.basicConfig(level=logging.INFO)\n\n# See RCSB identifier 7WCU\nexample_fasta = \"\"\"\n>protein|101\nTNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFSTFKCYGVSPTKLNDLCFTNVYADSFVIRGDEVRQIAPGQTGKIADYNYKLPDDFTGCVIAWNSNNLDSKVGGNYNYRYRLFRKSNLKPFERDISTEIYQAGSKPCNGVEGFNCYFPLQSYGFQPTNGVGYQPYRVVVLSFELLHAPATVCGPKKST\n>protein|102\nEVQLVESGGGLIQPGGSLRLSCAASEFIVSRNYMSWVRQAPGTGLEWVSVIYPGGSTFYADSVKGRFTISRDNSKNTLYLQMDSLRVEDTAVYYCARDYGDFYFDYWGQGTLVTVSSASTKGPSVFPLAPSSKSTSGGTAALGCLVKDYFPEPVTVSWNSGALTSGVHTFPAVLQSSGLYSLSSVVTVPSSSLGTQTYICNVNHKPSNTKVDKKVEPKSCDK\n>protein|103\nEIVMTQSPVSLSVSPGERATLSCRASQGVASNLAWYQQKAGQAPRLLIYGASTRATGIPARFSGSGSGTEFTLTISTLQSEDSAVYYCQQYNDRPRTFGQGTKLEIKRT\n\"\"\".strip()\n\nfasta_path = Path(\"/tmp/example.fasta\")\nfasta_path.write_text(example_fasta)\n\noutput_dir = Path(\"outputs\")\n\ncandidates = run_inference(\n    fasta_file=fasta_path,\n    output_dir=output_dir,\n    use_msa_server=True,\n    use_templates_server=True,\n    seed=1234,\n    device=\"cuda:0\",\n\n```\n\nand also I got this error.\n```\nTraceback (most recent call last):\n  File \"/data/hwkang/Software/installation_files/chai_latest/t.py\", line 23, in <module>\n    candidates = run_inference(\n                 ^^^^^^^^^^^^^^\n  File \"/data/hwkang/anaconda3/envs/chai6/lib/python3.12/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/data/hwkang/anaconda3/envs/chai6/lib/python3.12/site-packages/chai_lab/chai1.py\", line 512, in run_inference\n    feature_context = make_all_atom_feature_context(\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/data/hwkang/anaconda3/envs/chai6/lib/python3.12/site-packages/chai_lab/chai1.py\", line 416, in make_all_atom_feature_context\n    template_context = get_template_context(\n                       ^^^^^^^^^^^^^^^^^^^^^\n  File \"/data/hwkang/anaconda3/envs/chai6/lib/python3.12/site-packages/chai_lab/data/dataset/templates/context.py\", line 378, in get_template_context\n    loaded_templates = get_template_data(\n                       ^^^^^^^^^^^^^^^^^^\n  File \"/data/hwkang/anaconda3/envs/chai6/lib/python3.12/site-packages/jaxtyping/_decorator.py\", line 562, in wrapped_fn\n    return wrapped_fn_impl(args, kwargs, bound, memos)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/data/hwkang/anaconda3/envs/chai6/lib/python3.12/site-packages/jaxtyping/_decorator.py\", line 486, in wrapped_fn_impl\n    out = fn(*args, **kwargs)\n          ^^^^^^^^^^^^^^^^^^^\n  File \"/data/hwkang/anaconda3/envs/chai6/lib/python3.12/site-packages/chai_lab/data/dataset/templates/load.py\", line 290, in get_template_data\n    for template_hit in template_hits:\n                        ^^^^^^^^^^^^^\n  File \"/data/hwkang/anaconda3/envs/chai6/lib/python3.12/site-packages/chai_lab/data/parsing/templates/m8.py\", line 97, in parse_m8_to_template_hits\n    alignment = kalign_query_to_reference(ref=query_sequence, query=seq_matching)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/data/hwkang/anaconda3/envs/chai6/lib/python3.12/site-packages/chai_lab/tools/kalign.py\", line 73, in kalign_query_to_reference\n    shutil.which(\"kalign\") is not None\nAssertionError: Could not find kalign in your PATH; kalign is required for templates\n```\n\n"
      },
      {
        "user": "wukevin",
        "created_at": "2025-02-19T03:46:32Z",
        "body": "There's nothing wrong with your code or fasta file - we require `kalign` to align template hits and the original query sequence. However, since `kalign` is not a Python package, there's no easy way to include it as an automatically installed dependency. We recommend that you install this yourself using something like `sudo apt install kalign`; the example should work once you do that."
      },
      {
        "user": "kanghw0325",
        "created_at": "2025-02-19T04:42:56Z",
        "body": "Thank you for fast response!"
      }
    ]
  },
  {
    "number": 283,
    "title": "Is the inference script repetitively loading download model in sequential inference?",
    "created_at": "2025-01-18T00:14:44Z",
    "closed_at": "2025-01-21T21:19:31Z",
    "labels": [],
    "url": "https://github.com/chaidiscovery/chai-lab/issues/283",
    "body": "Hi Chai team\n\nSuppose I want to predict multiple structures in a python script. Right now I'm using a script with pseudocode:\n```\nfrom chai_lab.chai1 import run_inference\n...\n\nfor path_to_input_file in list_of_path:\n    candidates = run_inference(fasta_file= path_to_input_file, ........)\n    ...\n\n```\n\nSeeing the progress bar from tqdm it seems like the inference process is reasonably fast. But in between inference there is relatively long wait time. Then I realize chai_lab.chai1.run_inference, when calling chai_lab.chai1.run_folding_on_context, always load parts of the model by calling chai_lab.chai1.load_exported. If I understand it right (but correct me if wrong), this re-loads the model that has been already put onto GPU in previous inference, causing wait time in between inferences. Is there anyway to avoid this behavior?\n\nBest",
    "comments_url": "https://api.github.com/repos/chaidiscovery/chai-lab/issues/283/comments",
    "author": "andrew0901",
    "comments": [
      {
        "user": "arogozhnikov",
        "created_at": "2025-01-18T01:51:03Z",
        "body": "Hi @andrew0901 \n\nthat's correct, we move model fragments to/from device to reduce the memory consumption, largest is ESM2 model. Loading/unloading should be fast compared to inference, though. How long is gap between predictions vs how long the prediction takes in your case?\n\n"
      },
      {
        "user": "arogozhnikov",
        "created_at": "2025-01-18T11:15:58Z",
        "body": "(also, line-profiling can be a better answer to your question than any guesses)"
      },
      {
        "user": "arogozhnikov",
        "created_at": "2025-01-21T21:19:31Z",
        "body": "no answer -> closing"
      }
    ]
  },
  {
    "number": 278,
    "title": "DNA-Protein",
    "created_at": "2025-01-11T04:25:56Z",
    "closed_at": "2025-01-14T01:28:13Z",
    "labels": [],
    "url": "https://github.com/chaidiscovery/chai-lab/issues/278",
    "body": "Dear Developer,\r\n\r\nThank you for your assistance. My research focuses on proteins that interact with specialized DNA structures, such as G-quadruplex (G4) DNA. I am particularly interested in whether Chai currently accounts for the binding of such distinct DNA structures with proteins.\r\n\r\nThank you for your time and guidance on this matter. I look forward to your response.",
    "comments_url": "https://api.github.com/repos/chaidiscovery/chai-lab/issues/278/comments",
    "author": "ZhuLvs",
    "comments": [
      {
        "user": "arogozhnikov",
        "created_at": "2025-01-14T01:28:06Z",
        "body": "I don't see any obstacles with this. \r\n\r\nIf G4 structure does not appear per se, use restrains to force this."
      }
    ]
  },
  {
    "number": 276,
    "title": "Help with MSA",
    "created_at": "2025-01-11T04:06:18Z",
    "closed_at": "2025-01-11T04:10:27Z",
    "labels": [],
    "url": "https://github.com/chaidiscovery/chai-lab/issues/276",
    "body": "When using Chai (including the web version), I encountered an issue where the pTM score of a protein predicted using MSA is lower than that without using MSA. For example, the pTM score with MSA is only 0.72, but the prediction score without selecting the MSA option is 0.90.\r\nCould you please explain why this is happening? Thank you for your help!",
    "comments_url": "https://api.github.com/repos/chaidiscovery/chai-lab/issues/276/comments",
    "author": "ZhuLvs",
    "comments": [
      {
        "user": "arogozhnikov",
        "created_at": "2025-01-11T04:10:08Z",
        "body": "MSAs do not provide convincing/consistent information with model's expectations. \r\nCheck that found MSAs are relevant for your example. Specifically, for newly designed proteins, MSAs can be irrelevant as they are not evolutionary connected to the protein you try to fold"
      }
    ]
  },
  {
    "number": 267,
    "title": "Using CCD vs covalent bond with smiles",
    "created_at": "2024-12-30T16:25:35Z",
    "closed_at": "2024-12-31T03:12:07Z",
    "labels": [],
    "url": "https://github.com/chaidiscovery/chai-lab/issues/267",
    "body": "Hello! Thank you for the great work.\r\n\r\nI am recently working on your covalent bond system.\r\nand I see one small issues in here.\r\n\r\nIn my opinion, using SMILES seems to yield better results than using CCD when forming covalent bonds. I’m not sure why.\r\nDo you have any informations of this kind of issues?",
    "comments_url": "https://api.github.com/repos/chaidiscovery/chai-lab/issues/267/comments",
    "author": "kanghw0325",
    "comments": [
      {
        "user": "arogozhnikov",
        "created_at": "2024-12-31T03:10:08Z",
        "body": "I'd check if it tries to match reference conformer for CCD when you use CCD. "
      }
    ]
  },
  {
    "number": 260,
    "title": "arbitrary num_diffn_samples + use ds to enumerate diffusion samples",
    "created_at": "2024-12-23T20:09:40Z",
    "closed_at": "2024-12-24T00:38:24Z",
    "labels": [],
    "url": "https://github.com/chaidiscovery/chai-lab/pull/260",
    "body": "## Description/motivation\r\n\r\nallow generating more diffusion samples from single trunk.\r\n\r\nfix #257 \r\n\r\nalternative pr is #259 \r\n\r\n## Test plan\r\n\r\n- manually verified that exported diffusion module can handle arbitrary number of samples.\r\n\r\n- tested default predict_samples with 9 samples\r\n",
    "comments_url": "https://api.github.com/repos/chaidiscovery/chai-lab/issues/260/comments",
    "author": "arogozhnikov",
    "comments": [
      {
        "user": "wukevin",
        "created_at": "2024-12-24T00:01:19Z",
        "body": "Looks like the number of diffusion samples isn't exposed as an argument in the function signature for `run_inference`. Should we expose this similar to #259 ?"
      },
      {
        "user": "arogozhnikov",
        "created_at": "2024-12-24T00:11:13Z",
        "body": "yup, didn't push one commit. Mind looking again?"
      }
    ]
  },
  {
    "number": 255,
    "title": "chai_lab version 0.5.1 is not available in pip as of 2024.12.20",
    "created_at": "2024-12-20T15:10:16Z",
    "closed_at": "2024-12-20T19:18:08Z",
    "labels": [],
    "url": "https://github.com/chaidiscovery/chai-lab/issues/255",
    "body": "Hi, thanks for the great tool!\r\n\r\nI tried to install the tool via pip as suggested in README with:\r\n`pip install chai_lab==0.5.1 `\r\n\r\nReturns:\r\n```\r\nDefaulting to user installation because normal site-packages is not writeable\r\nERROR: Could not find a version that satisfies the requirement chai_lab==0.5.1 (from versions: 0.0.1, 0.1.0, 0.2.0, 0.2.1, 0.3.0, 0.3.1, 0.4.1, 0.4.2, 0.5.0)\r\nERROR: No matching distribution found for chai_lab==0.5.1\r\n```\r\n\r\nThen I checked pip website to see whether it is about my pip version. I wasn't able to find the version 0.5.1 in pip. It is only up to 0.5.0. Could you please update the pip version? Thanks a lot!",
    "comments_url": "https://api.github.com/repos/chaidiscovery/chai-lab/issues/255/comments",
    "author": "resulelgin",
    "comments": [
      {
        "user": "arogozhnikov",
        "created_at": "2024-12-20T19:18:08Z",
        "body": "Hi Resul,\r\n\r\nthanks for reporting, it should be fixed now"
      }
    ]
  },
  {
    "number": 252,
    "title": "Were all of AFDB sequences used to generate MSA?",
    "created_at": "2024-12-16T09:27:54Z",
    "closed_at": "2024-12-16T17:15:42Z",
    "labels": [],
    "url": "https://github.com/chaidiscovery/chai-lab/issues/252",
    "body": "I am curious for whether all of AFDB sequences have to generate MSA. Notice that there are more than 290 million monomer sequences in AFDB. Generating all MSA will cost long time if so. Is there any difference if `jackhmmer` and `hhblits` are replaced with `mmseqs/colabfold` ?",
    "comments_url": "https://api.github.com/repos/chaidiscovery/chai-lab/issues/252/comments",
    "author": "TheChosenOneJG",
    "comments": [
      {
        "user": "arogozhnikov",
        "created_at": "2024-12-16T17:15:42Z",
        "body": "> Is there any difference if jackhmmer and hhblits are replaced with mmseqs/colabfold ?\r\n\r\ntry and see! I'm curious about this question too.\r\n\r\n> I am curious for whether all of AFDB sequences have to generate MSA. Notice that there are more than 290 million monomer sequences in AFDB.\r\n\r\nthat's something to you can ask AF team; there are multiple possible directions to optimize. \r\n\r\n"
      }
    ]
  },
  {
    "number": 243,
    "title": "Bump version 0.5.1 > 0.5.2",
    "created_at": "2024-12-12T01:37:32Z",
    "closed_at": "2024-12-24T22:59:33Z",
    "labels": [],
    "url": "https://github.com/chaidiscovery/chai-lab/pull/243",
    "body": "## Description\r\nNew version with fixes for glycans.\r\n\r\n",
    "comments_url": "https://api.github.com/repos/chaidiscovery/chai-lab/issues/243/comments",
    "author": "wukevin",
    "comments": [
      {
        "user": "jackdent",
        "created_at": "2024-12-16T18:35:37Z",
        "body": "@wukevin should we merge this?"
      },
      {
        "user": "wukevin",
        "created_at": "2024-12-16T18:36:50Z",
        "body": "> @wukevin should we merge this?\r\n\r\nYeah aiming to merge this today - there were a lot of changes to cif writing so I want to check a couple more things first."
      }
    ]
  },
  {
    "number": 231,
    "title": "How to calculate ptm scores of an existing protein 3D complex structure ?",
    "created_at": "2024-12-09T12:45:26Z",
    "closed_at": "2024-12-09T17:23:54Z",
    "labels": [],
    "url": "https://github.com/chaidiscovery/chai-lab/issues/231",
    "body": "I would be interested in calculating the ptm/iptm/chain_ptm etc scores for a 3D protein complex structure that I have. \r\n\r\nI could of course run Chai-1r with a very large number of restraints for the interacting interface residues so that the generated model matches almost exactly with my structure, but I was wondering if it's possible to skip the whole modelling part and just calculate the scores ? Would this be doable, and if yes, what would be the steps to do it ?\r\n\r\nThanks !",
    "comments_url": "https://api.github.com/repos/chaidiscovery/chai-lab/issues/231/comments",
    "author": "gciaberi",
    "comments": [
      {
        "user": "arogozhnikov",
        "created_at": "2024-12-09T17:23:41Z",
        "body": "Hi @gciaberi \r\n\r\nconfidence estimate (like pTM) were trained only on model predictions and they *require* model predictions besides just atom positions. So you can't skip modelling."
      }
    ]
  },
  {
    "number": 225,
    "title": "Extra OH group on N linked NAG",
    "created_at": "2024-12-09T00:02:54Z",
    "closed_at": "2024-12-10T00:38:57Z",
    "labels": [],
    "url": "https://github.com/chaidiscovery/chai-lab/issues/225",
    "body": "Thanks for adding glycan support! I noticed an error where N linked glycans starting with NAG retain the OH group off of carbon 1. Which should not be there in the context of N-linked glycosylation. ",
    "comments_url": "https://api.github.com/repos/chaidiscovery/chai-lab/issues/225/comments",
    "author": "fabgonzal",
    "comments": [
      {
        "user": "arogozhnikov",
        "created_at": "2024-12-09T05:40:27Z",
        "body": "Hi @fabgonzal, \r\ncan you post small FASTA example for debugging? "
      },
      {
        "user": "fabgonzal",
        "created_at": "2024-12-09T07:06:45Z",
        "body": "Sure thing. Below is the fasta and accompanying restraints.\r\nFASTA\r\n\\>protein|motif\r\nMGRAMVARLGLGLLLLALLLPTQIYSSETTTGTSSNSSQSTSNSGLAPNPTNATTKAAGGALQSTASLFVVSLSLLHLYS\r\n\\>glycan|n_1\r\nNAG(1-4 NAG)\r\n\\>glycan|n_2\r\nNAG(1-4 NAG)\r\n\r\nRESTRAINTS\r\nrestraint_id,chainA,res_idxA,chainB,res_idxB,connection_type,confidence,min_distance_angstrom,max_distance_angstrom,comment\r\nnag1,A,N36@ND2,B,@C1,covalent,1.0,0.0,0.0,toy\r\nnag2,A,N52@ND2,C,@C1,covalent,1.0,0.0,0.0,toy"
      },
      {
        "user": "wukevin",
        "created_at": "2024-12-09T23:34:21Z",
        "body": "Thanks for flagging this issue @fabgonzal  - turns out this was a mixture of (1) a bug in how we were defining glycosidic bonds, and (2) a lack of logic for removing leaving atoms upon bond formation. Both issues have been addressed in the linked PR; let us know if there's anything else that seems off!"
      },
      {
        "user": "fabgonzal",
        "created_at": "2024-12-10T00:38:57Z",
        "body": "Great thank you! "
      }
    ]
  },
  {
    "number": 203,
    "title": "diffusion model for design",
    "created_at": "2024-12-03T00:05:13Z",
    "closed_at": "2024-12-03T03:01:58Z",
    "labels": [],
    "url": "https://github.com/chaidiscovery/chai-lab/issues/203",
    "body": "I was wondering if you have any plans to make diffusion models as a design tool.\r\n\r\nHope to use your version of diffusion design tools someday!\r\n",
    "comments_url": "https://api.github.com/repos/chaidiscovery/chai-lab/issues/203/comments",
    "author": "simonkim1347",
    "comments": [
      {
        "user": "joshim5",
        "created_at": "2024-12-03T03:01:58Z",
        "body": "We will keep you posted if we release something for this in the future!"
      }
    ]
  },
  {
    "number": 200,
    "title": "Query about the evaluation of restraints feature",
    "created_at": "2024-12-02T08:17:06Z",
    "closed_at": "2024-12-18T01:43:39Z",
    "labels": [],
    "url": "https://github.com/chaidiscovery/chai-lab/issues/200",
    "body": "Hi, thanks for your wonderful open-source work!  I have a question about the evaluation of constraint feature when read the technical report.\r\n\r\nIn Figure 4, how do you add the contact/pocket feature to a complex when multiple antibody-antigen interfaces exist? Do you separately add contacts to each interface and run the evaluation on the complex (one complex would be inferred multiple times)? Or do you add contacts to each interface together at once and run the evaluation one time (one complex would be inferred only once)?\r\n\r\nThank you!",
    "comments_url": "https://api.github.com/repos/chaidiscovery/chai-lab/issues/200/comments",
    "author": "Anfankus",
    "comments": [
      {
        "user": "MattMcPartlon",
        "created_at": "2024-12-09T01:49:45Z",
        "body": "Hi @Anfankus, \r\n\r\nthe process was actually quite simplistic: \r\n\r\n1. Identify all pairs of residues `(a,b)` where `a` and `b` come from different chains and `dist(a,b)<theta`\r\n2. filter these down to pairs where (WLOG) `a` comes from an antigen chain and `b` comes from an antibody chain.\r\n3. Randomly sample `k` of these pairs (where`k=1` for the \"one-contact/ one-epitope\" result and `k=4` for the \"four epitope\" result).\r\n4. Provide these as a pocket or contact restraint and run inference\r\n5. evaluate output of (4) on *every* Ab-Ag interface\r\n\r\nWhat you're suggesting should yield better results than this approach."
      }
    ]
  },
  {
    "number": 194,
    "title": "UFFTYPER: Unrecognized atom type: Ca+2 (0)",
    "created_at": "2024-11-29T06:37:50Z",
    "closed_at": "2024-12-05T13:45:53Z",
    "labels": [],
    "url": "https://github.com/chaidiscovery/chai-lab/issues/194",
    "body": "I am trying to put ions to fold together with protein chains. Here is how I did it:\r\n```\r\n>ligand|name=ca_1\r\n[Ca+2]\r\n```\r\nbut I got the error `UFFTYPER: Unrecognized atom type: Ca+2 (0)`. For Mg2+, the error is different but just\r\n`UFFTYPER: Unrecognized charge state for atom: 0`\r\n\r\nWhat is the corrent way?",
    "comments_url": "https://api.github.com/repos/chaidiscovery/chai-lab/issues/194/comments",
    "author": "Ruibin-Liu",
    "comments": [
      {
        "user": "wukevin",
        "created_at": "2024-11-29T19:42:53Z",
        "body": "I believe this error shouldn't affect the correct generation and placement of the Ca ion in the predicted structure. Can you confirm?"
      },
      {
        "user": "Ruibin-Liu",
        "created_at": "2024-12-02T01:38:41Z",
        "body": "Yes, I have more than 1 Ca2+ ions and they are in the correct places for my system. \r\nA side question, did you test the MMFF14s force field instead of UFF in generating small molecule 3D conformers? Do you think it matters to use a different FF?"
      },
      {
        "user": "wukevin",
        "created_at": "2024-12-04T23:29:06Z",
        "body": "I wouldn't expect that using a difference force field for 3D conformers would make a large difference in predictions, though we have not tested this empirically.\r\n\r\nWe've also added a bit of testing around the error you observed, making sure that the actual charge is and atomic element are passed through correctly."
      },
      {
        "user": "Ruibin-Liu",
        "created_at": "2024-12-05T13:45:53Z",
        "body": "Thanks!"
      }
    ]
  },
  {
    "number": 174,
    "title": "Inconsistent predictions",
    "created_at": "2024-11-25T12:29:36Z",
    "closed_at": "2024-12-09T03:02:23Z",
    "labels": [],
    "url": "https://github.com/chaidiscovery/chai-lab/issues/174",
    "body": "Why is the IPTM value for the structures predicted on the server 0.45, while the IPTM value for the structures predicted on the local machine is only 0.12, despite using the same input?",
    "comments_url": "https://api.github.com/repos/chaidiscovery/chai-lab/issues/174/comments",
    "author": "YidongSong",
    "comments": [
      {
        "user": "wukevin",
        "created_at": "2024-11-27T00:05:00Z",
        "body": "> Why is the IPTM value for the structures predicted on the server 0.45, while the IPTM value for the structures predicted on the local machine is only 0.12, despite using the same input?\r\n\r\nAre you using MSAs or single sequence modes consistently in this comparison? "
      },
      {
        "user": "arogozhnikov",
        "created_at": "2024-12-09T03:02:23Z",
        "body": "sounds like double-post of #173, where @YidongSong got good results with A100, but not 3090, this has nothing to do with server/local"
      }
    ]
  },
  {
    "number": 173,
    "title": "low iptm",
    "created_at": "2024-11-25T12:01:32Z",
    "closed_at": "2025-01-11T04:20:29Z",
    "labels": [],
    "url": "https://github.com/chaidiscovery/chai-lab/issues/173",
    "body": "Why are the IPTM values for the locally predicted structures consistently low, with 90% being below 0.2? Is this due to insufficient accuracy of chai in antibody-antigen complexes?",
    "comments_url": "https://api.github.com/repos/chaidiscovery/chai-lab/issues/173/comments",
    "author": "YidongSong",
    "comments": [
      {
        "user": "YidongSong",
        "created_at": "2024-11-26T02:27:23Z",
        "body": "The IPTM value is 0.17 when calculated on the 3090, whereas it is 0.65 when calculated on the A100. What is the reason for this?"
      },
      {
        "user": "arogozhnikov",
        "created_at": "2024-12-09T07:43:05Z",
        "body": "Nothing depends on GPU model, and graph should be evaluated in the same way.\r\n\r\nSteps to debug\r\n\r\n1. Check that you use identical environments and identical input scripts\r\n2. run with 3 seeds on each machine\r\n\r\nIf there is still significant difference, that's something to report to torch team."
      }
    ]
  },
  {
    "number": 168,
    "title": "Fix Dockerfile for devcontainer",
    "created_at": "2024-11-22T03:30:10Z",
    "closed_at": "2024-11-22T06:00:11Z",
    "labels": [],
    "url": "https://github.com/chaidiscovery/chai-lab/pull/168",
    "body": "## Test plan\r\nRebuilt container from scratch. Previously, this resulted in an error.\r\n",
    "comments_url": "https://api.github.com/repos/chaidiscovery/chai-lab/issues/168/comments",
    "author": "jackdent",
    "comments": [
      {
        "user": "arogozhnikov",
        "created_at": "2024-11-22T06:00:11Z",
        "body": "closed in favor of #169 "
      }
    ]
  },
  {
    "number": 152,
    "title": "Why there is a limit of 2048 tokens hardcoded in Chai-1?",
    "created_at": "2024-11-15T17:03:55Z",
    "closed_at": "2024-11-16T11:13:47Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/chaidiscovery/chai-lab/issues/152",
    "body": "Initially, I thought the limit of 2048 tokens you have on the webserver was related to the machine/GPUs you are using at the backend, but it seems it is the same is also for the local installation:\r\n\r\nI tried to run chai-1 for a longer sequence and I got:\r\n**chai_lab.chai1.UnsupportedInputError: Too many tokens in input: 2789 > 2048. Please limit the length of the input sequence**\r\n\r\nIs there any particular reason why you hardcoded to 2048? \r\n\r\nInitially, I guessed that maybe vRAM skyrocketing for longer sequences, and it is partly the case as for A100 40GB I was able to run chai for ~1000aa sequence (used initially 10GB, then 37GB for a short time, and most of the time during diffusion 27GB). Chai failed for 2048 on A100 40GB  (most likely the A100 80GB limit you set; the longest seq I could run on 40GB was 1550aa, 1625aa was already too much). Yet, today/tomorrow one can have better GPUs thus hardcoding this to 80GB aka 2048 tokens seems weird.\r\n\r\nAdditional question: maybe the model decays above 2048 (which is still reasonable as not so many such proteins in the training)?",
    "comments_url": "https://api.github.com/repos/chaidiscovery/chai-lab/issues/152/comments",
    "author": "lukasz-kozlowski",
    "comments": [
      {
        "user": "arogozhnikov",
        "created_at": "2024-11-15T20:33:58Z",
        "body": "Hi Lucasz,\r\n\r\n> 1550aa, 1625aa was already too much\r\n\r\nthresholds for exported model are  1024, 1536, 2048 (+ smaller ones), so if 1550 worked, 2048 is very likely to work too. Each size has its dedicated inference graph, which almost completely defines memory footprint for specific input size.\r\n\r\n2048 fits well onto current hardware with a nice memory gap + covers most use-cases + we provide restraints, they can be used to handle smaller parts of complex.\r\n\r\n> Additional question: maybe the model decays above 2048?\r\n\r\nThat's not what we observe. If you have some examples of (comparable) larger complexes that work worse, I'd be curious to look at such examples.\r\n"
      },
      {
        "user": "lukasz-kozlowski",
        "created_at": "2024-11-15T21:50:58Z",
        "body": "1) On A100 40GB: 1000aa worked, 1500aa worked, 1550aa worked, 1625aa crashed, 1750aa crashed, 2048 crashed, 2789 crushed (maybe this depends also on sequence, but this is the outcome on a single sequence trimmed from C-terminus to meet the memory requirements)\r\n\r\n2) going back to the main question: why to hardcode the 2048 limit? \r\n\r\n3) do you have any plot for the memory footprint? "
      },
      {
        "user": "arogozhnikov",
        "created_at": "2024-11-15T22:10:14Z",
        "body": "> do you have any plot for the memory footprint?\r\n\r\nI can't provide sufficient guarantees about memory allocations in torch to say \"this is the memory allocation that you'll have\", so I won't put those out (but you can if you want). I, for one, did not expect anything above 1536 to work on 40GB.\r\n\r\n"
      },
      {
        "user": "lukasz-kozlowski",
        "created_at": "2024-11-16T11:01:20Z",
        "body": "the main question: why to hardcode the 2048 limit? \r\n\r\nps. I want to test chai on H100 for longer seqs"
      },
      {
        "user": "arogozhnikov",
        "created_at": "2024-11-16T11:13:47Z",
        "body": "requires engineering investment, and not a priority for now. See #77 \r\n\r\n\r\n\r\n"
      },
      {
        "user": "lukasz-kozlowski",
        "created_at": "2024-11-16T13:22:31Z",
        "body": "simply remove the hardcoding from the code and people will have a possibility to check it on the other GPUs even if you do not have such (this is as easy as commenting ~2 lines of code), in the worst scenario it will crush even on H100 for longer than 2048, but I guess that on H100 one will be able to run inference for 2500-3000aa"
      },
      {
        "user": "jackdent",
        "created_at": "2024-11-17T04:38:33Z",
        "body": "@lukasz-kozlowski that's not how the code works, we can't simply comment out the 2 lines and make the model work for sequences longer than 2048. We need to create an entirely new version of the computational graph, which is a much larger investment."
      }
    ]
  },
  {
    "number": 140,
    "title": "Output files from the v0.2.0 version",
    "created_at": "2024-10-31T13:13:10Z",
    "closed_at": "2024-10-31T15:30:02Z",
    "labels": [],
    "url": "https://github.com/chaidiscovery/chai-lab/issues/140",
    "body": "Hi,\r\nThanks a lot for the great work! \r\nI have tested the v0.2.0 and I tried to run the prediction on a bunch of protein sequences. In contrary to the v0.1.0 I only got the cif and npz files, and not the pdb and the json files. \r\nIs it the normal new behavior? In that case, what is the command to get the pdb files?\r\n\r\nThanks a lot,\r\nBest.",
    "comments_url": "https://api.github.com/repos/chaidiscovery/chai-lab/issues/140/comments",
    "author": "qhelleu",
    "comments": [
      {
        "user": "arogozhnikov",
        "created_at": "2024-10-31T15:30:02Z",
        "body": "Hi @qhelleu,\r\n\r\ncif is the new pdb, see #49 for why, and npz now takes role of json."
      }
    ]
  },
  {
    "number": 123,
    "title": "Batch inference？",
    "created_at": "2024-10-22T06:30:09Z",
    "closed_at": "2024-10-22T06:37:17Z",
    "labels": [],
    "url": "https://github.com/chaidiscovery/chai-lab/issues/123",
    "body": "Is it possible to perform inference in batches?\r\n\r\nI have observed that the inference time for a single instance often requires at least 60 seconds. If the dataset is large, the cumulative waiting time becomes significantly prolonged.",
    "comments_url": "https://api.github.com/repos/chaidiscovery/chai-lab/issues/123/comments",
    "author": "mengmeng233",
    "comments": [
      {
        "user": "arogozhnikov",
        "created_at": "2024-10-22T06:37:00Z",
        "body": "Hi @mengmeng233 \r\n\r\nno, that's not practically feasible - typical bottleneck is memory.\r\n\r\nIn case you have only small proteins, you can just start several processes in parallel, don't expect significant speed up - GPU utilization is quite ok."
      }
    ]
  },
  {
    "number": 118,
    "title": "Token length extension",
    "created_at": "2024-10-20T14:44:50Z",
    "closed_at": "2024-10-28T14:32:38Z",
    "labels": [],
    "url": "https://github.com/chaidiscovery/chai-lab/issues/118",
    "body": "Hi dear Team, \r\nFirst of all thanks for this amazing resource! This is super cool and helpful in many ways! \r\nI am working with a protein complex that only is marginally longer than 2048AA -> 2400AA and have access to H100/A100 80GB GPUS so I think I would be able to run it. I already read #77 -> Cubic scaling, I know.\r\n\r\nSo I skimmed the code a little. There is only a checking function I saw so far, if I disable that will the model run or did you guys hardcode anything more that would make this unfeasible? If not I would just fork the repo and run my version with longer context :)\r\n\r\nLove your work and again thanks so much!",
    "comments_url": "https://api.github.com/repos/chaidiscovery/chai-lab/issues/118/comments",
    "author": "JustABiologist",
    "comments": [
      {
        "user": "arogozhnikov",
        "created_at": "2024-10-21T23:01:59Z",
        "body": "Thanks for kind words, \r\n\r\n> if I disable that will the model run or did you guys hardcode anything more that would make this unfeasible?\r\n\r\nThere is no _our_ hard-coded constraint, but AFAICT models won't work for size that is _different_ from what was exported, and largest exported was 2048 (previously I tried and it didn't work).\r\n\r\n\r\n"
      },
      {
        "user": "JustABiologist",
        "created_at": "2024-10-22T13:29:16Z",
        "body": "Okay thank you I will give it a shot and report back!"
      },
      {
        "user": "JustABiologist",
        "created_at": "2024-10-28T14:32:39Z",
        "body": "Hey gave it a shot. Guess the diffusion size is fixed. At least it did not work for me and makes sense that it would not work. \r\n"
      }
    ]
  },
  {
    "number": 114,
    "title": "fix race conditions during downloads",
    "created_at": "2024-10-19T06:30:21Z",
    "closed_at": "2024-10-19T06:31:26Z",
    "labels": [],
    "url": "https://github.com/chaidiscovery/chai-lab/pull/114",
    "body": "## Description\r\n\r\nFixed race conditons when multiple processes started independently, see issue reported in #81 \r\n\r\n## Test plan\r\n\r\nonly tested that artifacts are re-downloaded when deleted; \r\n",
    "comments_url": "https://api.github.com/repos/chaidiscovery/chai-lab/issues/114/comments",
    "author": "arogozhnikov",
    "comments": [
      {
        "user": "jackdent",
        "created_at": "2024-10-19T06:59:09Z",
        "body": "LGTM"
      }
    ]
  },
  {
    "number": 104,
    "title": "AssertionError",
    "created_at": "2024-10-13T10:29:13Z",
    "closed_at": "2024-10-14T05:26:42Z",
    "labels": [],
    "url": "https://github.com/chaidiscovery/chai-lab/issues/104",
    "body": "assert serialized_example_inputs is not None\r\nWhy I encontered this problem",
    "comments_url": "https://api.github.com/repos/chaidiscovery/chai-lab/issues/104/comments",
    "author": "Overignited",
    "comments": [
      {
        "user": "jackdent",
        "created_at": "2024-10-13T15:41:26Z",
        "body": "Please provide more details on your inputs and provide a minimal reproduction"
      },
      {
        "user": "Overignited",
        "created_at": "2024-10-14T04:49:21Z",
        "body": "sor, is my env problem. i redownload the env and solve the problem"
      }
    ]
  },
  {
    "number": 96,
    "title": "antipickle issue when running predict_structure.py example",
    "created_at": "2024-09-30T20:55:51Z",
    "closed_at": "2024-10-04T13:38:28Z",
    "labels": [
      "user support"
    ],
    "url": "https://github.com/chaidiscovery/chai-lab/issues/96",
    "body": "Python 3.10.15\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/projects/mayhem/predict_structure.py\", line 25, in <module>\r\n    candidates = run_inference(\r\n  File \"/home/jimendi1/mambaforge/envs/chai1/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\r\n    return func(*args, **kwargs)\r\n  File \"/home/jimendi1/mambaforge/envs/chai1/lib/python3.10/site-packages/chai_lab/chai1.py\", line 271, in run_inference\r\n    chains = load_chains_from_raw(fasta_inputs)\r\n  File \"/home/jimendi1/mambaforge/envs/chai1/lib/python3.10/site-packages/chai_lab/data/dataset/inference_dataset.py\", line 164, in load_chains_from_raw\r\n    conformer_generator = RefConformerGenerator()\r\n  File \"/home/jimendi1/mambaforge/envs/chai1/lib/python3.10/site-packages/chai_lab/data/sources/rdkit.py\", line 61, in __init__\r\n    self.cached_conformers = self._load_apkl_conformers(conformers_cache_file)\r\n  File \"/home/jimendi1/mambaforge/envs/chai1/lib/python3.10/site-packages/chai_lab/data/sources/rdkit.py\", line 71, in _load_apkl_conformers\r\n    return antipickle.load(path, adapters=_get_adapters())\r\n  File \"/home/jimendi1/mambaforge/envs/chai1/lib/python3.10/site-packages/antipickle/__init__.py\", line 129, in load\r\n    loaded = list(load_sequence(f, adapters=adapters))\r\n  File \"/home/jimendi1/mambaforge/envs/chai1/lib/python3.10/site-packages/antipickle/__init__.py\", line 75, in load_sequence\r\n    raise AntipickleDeserializationError(\"Wrong format or corrupted file\")\r\nantipickle.AntipickleDeserializationError: Wrong format or corrupted file\r\n```",
    "comments_url": "https://api.github.com/repos/chaidiscovery/chai-lab/issues/96/comments",
    "author": "dannyoo",
    "comments": [
      {
        "user": "arogozhnikov",
        "created_at": "2024-09-30T20:58:00Z",
        "body": "\"Wrong format or corrupted file\" says it all - your downloaded conformers file is corrupted, delete and re-download"
      },
      {
        "user": "arogozhnikov",
        "created_at": "2024-10-02T17:52:15Z",
        "body": "This fragment shows the path: \r\n\r\n```python\r\nfrom chai_lab.utils import paths\r\nprint(paths.cached_conformers.get_path())\r\n```\r\n\r\nIf you delete file, it should be automatically redownloaded"
      }
    ]
  },
  {
    "number": 94,
    "title": "Is that possible for chai to support float32?",
    "created_at": "2024-09-30T02:45:06Z",
    "closed_at": "2024-09-30T18:18:23Z",
    "labels": [],
    "url": "https://github.com/chaidiscovery/chai-lab/issues/94",
    "body": null,
    "comments_url": "https://api.github.com/repos/chaidiscovery/chai-lab/issues/94/comments",
    "author": "JinyuanSun",
    "comments": [
      {
        "user": "arogozhnikov",
        "created_at": "2024-09-30T18:18:16Z",
        "body": "Hi Jinyuan,\r\n\r\ntechnically it is possible to support float32, but doesn't make any practical sense - you'll not get good speed and will be bottlenecked by memory anyway"
      }
    ]
  },
  {
    "number": 85,
    "title": "CPU version for structure inference?",
    "created_at": "2024-09-27T17:36:21Z",
    "closed_at": "2024-09-27T17:44:17Z",
    "labels": [],
    "url": "https://github.com/chaidiscovery/chai-lab/issues/85",
    "body": "Dear team, \r\n\r\nWe have few protein targets that are longer than 1000 AAs. These targets caused the out-of-memory issues on both A100 40GB and A40 48GB GPUs in the University's cluster. The cluster does not have A100 80GB GPUs. Could your team provide a version that can use CPUs for structure inference?\r\n\r\nThanks,\r\nTommy",
    "comments_url": "https://api.github.com/repos/chaidiscovery/chai-lab/issues/85/comments",
    "author": "tommyhuangthu",
    "comments": [
      {
        "user": "arogozhnikov",
        "created_at": "2024-09-27T17:44:17Z",
        "body": "Hi Tommy, \r\n\r\nthere is already discussion #19 about CPU. \r\nTLDR: that's not a priority for now. Compute time scales as N^3, so for big complexes you really want GPU. \r\n\r\nAlso see #69 , maybe some option will work for you"
      }
    ]
  },
  {
    "number": 81,
    "title": "Race condition in downloads when running multiple jobs (manifests as 'file not found')",
    "created_at": "2024-09-27T00:51:33Z",
    "closed_at": "2024-10-19T06:33:15Z",
    "labels": [
      "bug"
    ],
    "url": "https://github.com/chaidiscovery/chai-lab/issues/81",
    "body": "Hi! Truly truly amazing release. Congratulations!\r\n\r\nI've been running into some issues when running multiple folds in parallel some of them fail with this error. Any ideas what I might try? it seems to not do this when running multipel \r\n```\r\nTraceback (most recent call last):\r\n  File \"/aian/scripts/Chai/run_chai.py\", line 25, in <module>\r\n    output_paths = run_inference(\r\n                   ^^^^^^^^^^^^^^\r\n  File \"/software/envs/chai/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\r\n    return func(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/software/envs/chai/lib/python3.11/site-packages/chai_lab/chai1.py\", line 271, in run_inference\r\n    chains = load_chains_from_raw(fasta_inputs)\r\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/software/envs/chai/lib/python3.11/site-packages/chai_lab/data/dataset/inference_dataset.py\", line 164, in load_chains_from_raw\r\n    conformer_generator = RefConformerGenerator()\r\n                          ^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/software/envs/chai/lib/python3.11/site-packages/chai_lab/data/sources/rdkit.py\", line 58, in __init__\r\n    conformers_cache_file = paths.cached_conformers.get_path().as_posix()\r\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/software/envs/chai/lib/python3.11/site-packages/chai_lab/utils/paths.py\", line 51, in get_path\r\n    download(self.url, path=self.path)\r\n  File \"/software/envs/chai/lib/python3.11/site-packages/chai_lab/utils/paths.py\", line 39, in download\r\n    tmp_path.rename(path)\r\n  File \"/software/envs/chai/lib/python3.11/pathlib.py\", line 1175, in rename\r\n    os.rename(self, target)\r\nFileNotFoundError: [Errno 2] No such file or directory: '/software/envs/chai/lib/python3.11/site-packages/downloads/conformers_v1.download_tmp' -> '/software/envs/chai/lib/python3.11/site-packages/downloads/conformers_v1.apkl'\r\n```",
    "comments_url": "https://api.github.com/repos/chaidiscovery/chai-lab/issues/81/comments",
    "author": "ianandersonlol",
    "comments": [
      {
        "user": "arogozhnikov",
        "created_at": "2024-09-27T01:25:04Z",
        "body": "hi Ian,\r\n\r\nthx for reporting, this part of code is not protected from race conditions, will fix"
      },
      {
        "user": "arogozhnikov",
        "created_at": "2024-10-19T06:33:16Z",
        "body": "fixed in #114  (install new version from github!)"
      }
    ]
  },
  {
    "number": 79,
    "title": "How to disable MSA?",
    "created_at": "2024-09-25T23:47:33Z",
    "closed_at": "2024-09-26T01:25:16Z",
    "labels": [],
    "url": "https://github.com/chaidiscovery/chai-lab/issues/79",
    "body": "Hi,\r\n\r\n\r\nThis is a great model and I'm excited to work with it. I wish to run it on some computing cluster nodes without internet access so I'd like to run in single-sequence mode without MSA (it seems to me that your code is accessing a remote database for MSA, correct me if I'm wrong). I'm wondering if there is a flag somewhere to disable MSA sampling? Appreciate your help!",
    "comments_url": "https://api.github.com/repos/chaidiscovery/chai-lab/issues/79/comments",
    "author": "andrew0901",
    "comments": [
      {
        "user": "arogozhnikov",
        "created_at": "2024-09-26T01:25:17Z",
        "body": "Hi @andrew0901, model does not pull MSA from internet, it relies on ESM embeddings instead.\r\n\r\nWhen you start the model, model auto-downloads necessary weights for itself (for several sizes) and for the ESM. By default everything is stored in <package root>/downloads, but can be changed with envvar, see #51 for details."
      }
    ]
  },
  {
    "number": 77,
    "title": "Chai-1 for proteins >2048 AAs",
    "created_at": "2024-09-25T13:26:03Z",
    "closed_at": "2024-09-27T01:26:22Z",
    "labels": [],
    "url": "https://github.com/chaidiscovery/chai-lab/issues/77",
    "body": "Dear Chai Team,\r\n\r\nThank you very much for releasing the powerful Chai-1 platform. Our lab is very interested in a few very large proteins that are much longer than 2048 AAs. One example is the human Usherin (UniProt ID: O75445) that has 5202 AAs. I wonder if your team plans to release a version for modeling such ultra-large proteins. And if so, any suggestions on the required resources for launching the program in a HPC cluster?\r\n\r\nBest regards,",
    "comments_url": "https://api.github.com/repos/chaidiscovery/chai-lab/issues/77/comments",
    "author": "tommyhuangthu",
    "comments": [
      {
        "user": "MattMcPartlon",
        "created_at": "2024-09-26T18:38:00Z",
        "body": "Hi Tommy,\r\n\r\nThis isn't something we're actively working on now but it is something we hope to support in future releases. There are some engineering tricks that could get us to support ~5k length range but inference would require multiple GPUs and would still be extremely slow.\r\n\r\nTLDR: hoping to support at some point in the future but no current plans.\r\n\r\n"
      },
      {
        "user": "tommyhuangthu",
        "created_at": "2024-09-26T20:52:02Z",
        "body": "> Hi Tommy,\r\n> \r\n> This isn't something we're actively working on now but it is something we hope to support in future releases. Unfortunately memory/time scaling in the current architecture is essentially cubic in sequence length 😞 . There are some engineering tricks that could get us to support ~5k length range but inference would require multiple GPUs and would still be extremely slow.\r\n> \r\n> TLDR: hoping to support at some point in the future but no current plans.\r\n\r\nThank you for this information."
      }
    ]
  },
  {
    "number": 75,
    "title": "Web-Server Parameters",
    "created_at": "2024-09-23T23:38:11Z",
    "closed_at": "2024-09-28T01:22:47Z",
    "labels": [],
    "url": "https://github.com/chaidiscovery/chai-lab/issues/75",
    "body": "Hi, \r\n\r\nI've been noticing some differences in the confidence metrics ran locally versus on the web server (No MSA). \r\n\r\nI was wondering what parameters (if any) were different in regards to the # of diffusions and # trunk recycles. ",
    "comments_url": "https://api.github.com/repos/chaidiscovery/chai-lab/issues/75/comments",
    "author": "sbpkyle",
    "comments": [
      {
        "user": "arogozhnikov",
        "created_at": "2024-09-24T00:45:23Z",
        "body": "AFAIK we use same settings: 5 samples are generated and ranked.\r\nNB: there were recent changes in metrics #60 , not yet deployed to web server"
      }
    ]
  },
  {
    "number": 73,
    "title": "How to construct MSA features",
    "created_at": "2024-09-22T03:20:14Z",
    "closed_at": "2024-10-21T04:53:29Z",
    "labels": [],
    "url": "https://github.com/chaidiscovery/chai-lab/issues/73",
    "body": "Has the code released in the current version been updated to support MSA input? If I have stored MSA result files (a3m) locally, can I generate MSA features by specifying the file path?  I haven't found an example of how to manually create an AllAtomFeatureContext.",
    "comments_url": "https://api.github.com/repos/chaidiscovery/chai-lab/issues/73/comments",
    "author": "cloverzizi",
    "comments": [
      {
        "user": "jackdent",
        "created_at": "2024-09-22T15:26:52Z",
        "body": "Hi @cloverzizi, we don't have an example right now, but will be releasing one soon."
      },
      {
        "user": "stianale",
        "created_at": "2024-10-03T21:28:02Z",
        "body": "This seems rather important. I observed big differences in ipTM when using the MSA module in the web server compared to my local predictions. "
      },
      {
        "user": "jackdent",
        "created_at": "2024-10-03T23:33:49Z",
        "body": "Hi @stianale — I agree. We have a good sense for what this involves and will prioritize getting this out. "
      },
      {
        "user": "stianale",
        "created_at": "2024-10-10T14:15:40Z",
        "body": "Maybe I'm misunderstanding something, but you already have the code to run MSA on the server, I presume, since the option is there, so why not just implement that version of Chai1 here?"
      },
      {
        "user": "jackdent",
        "created_at": "2024-10-18T16:55:14Z",
        "body": "You are correct that we already have working logic. We have been improving the interface to make it easier to use MSA feature, before we release it. "
      }
    ]
  },
  {
    "number": 65,
    "title": "Query about adding pocket and contact constraints in chi-1",
    "created_at": "2024-09-20T01:07:00Z",
    "closed_at": "2024-09-20T13:05:21Z",
    "labels": [],
    "url": "https://github.com/chaidiscovery/chai-lab/issues/65",
    "body": "Dear chi-1 Development Team,\r\n\r\nI am a researcher who is very interested in chi-1. I recently read the technical report for chi-1 and I'm particularly intrigued by the use of **pocket constraints and contact constraints** in antigen-antibody complex structure prediction, as shown in Figure 4.\r\n\r\nI would like to inquire about how to add these constraints in the input for general protein-protein complex structure prediction. Could you provide a specific example demonstrating how to specify these constraints in the input file?\r\n\r\nYour assistance would be greatly appreciated. ",
    "comments_url": "https://api.github.com/repos/chaidiscovery/chai-lab/issues/65/comments",
    "author": "tianflame",
    "comments": [
      {
        "user": "arogozhnikov",
        "created_at": "2024-09-20T13:05:21Z",
        "body": "Hi @tianflame \r\n\r\nSee #27 , we will add more user-friendly interface for contact constraints soon"
      }
    ]
  },
  {
    "number": 58,
    "title": "chai_lab.chai1.UnsupportedInputError: Too many tokens in input: 4775 > 2048. ",
    "created_at": "2024-09-18T07:40:08Z",
    "closed_at": "2024-09-18T14:07:23Z",
    "labels": [],
    "url": "https://github.com/chaidiscovery/chai-lab/issues/58",
    "body": "When I enter my  sequence on my  server, the following error is reported :\r\n\"chai_lab.chai1.UnsupportedInputError: Too many tokens in input: 4775 > 2048. Please limit the length of the input sequence.\"\r\nIs there any way to solve this problem?\r\n\r\nAll the best！\r\nWenbin cheng\r\n",
    "comments_url": "https://api.github.com/repos/chaidiscovery/chai-lab/issues/58/comments",
    "author": "chengwbTOT",
    "comments": [
      {
        "user": "arogozhnikov",
        "created_at": "2024-09-18T14:07:23Z",
        "body": "hi @chengwbTOT \r\n\r\nExample of counting tokens - each canonical AA is one token; for ligands and non-canonical AAs every atom is a token.\r\n\r\nmodels allow inference on up to 2048 tokens, that's what reported, and recommendation is also there:\r\n\r\n> Please limit the length of the input sequence."
      }
    ]
  },
  {
    "number": 57,
    "title": "Protein function prediction",
    "created_at": "2024-09-18T02:36:54Z",
    "closed_at": "2024-10-02T06:47:20Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/chaidiscovery/chai-lab/issues/57",
    "body": "Hi, I have a question about the code. After predicting the interaction between a protein and its substrate, can it determine whether the protein catalyzes the substrate? Thanks!",
    "comments_url": "https://api.github.com/repos/chaidiscovery/chai-lab/issues/57/comments",
    "author": "Jiajie-Zzz",
    "comments": [
      {
        "user": "arogozhnikov",
        "created_at": "2024-09-18T02:39:26Z",
        "body": "that's on open question for research 😄  "
      }
    ]
  },
  {
    "number": 51,
    "title": "How do I control where downloaded weights are saved?",
    "created_at": "2024-09-16T02:56:41Z",
    "closed_at": "2024-10-19T06:54:01Z",
    "labels": [
      "documentation",
      "enhancement"
    ],
    "url": "https://github.com/chaidiscovery/chai-lab/issues/51",
    "body": "Currently we store model weights in two places (one is <pkg_root>/downloads, second esm location defined by huggingface). \r\n\r\nIt would be nice to provide some envvar (or some other mean) so that users could explicitly set where the model is saved.\r\n\r\nMotivating example was provided by @dionjwa in #21 where weights are re-downloaded in docker container on every container restart.\r\n\r\nIt could also help with cases like #29 ",
    "comments_url": "https://api.github.com/repos/chaidiscovery/chai-lab/issues/51/comments",
    "author": "arogozhnikov",
    "comments": [
      {
        "user": "dionjwa",
        "created_at": "2024-09-16T05:19:09Z",
        "body": "👍 agree being able to set an env var where the models are saved would be ideal\r\n"
      },
      {
        "user": "arogozhnikov",
        "created_at": "2024-09-18T17:59:53Z",
        "body": "Hey @dionjwa I've just merged #61, so you could control path by setting envvar `CHAI_DOWNLOADS_DIR`\r\n\r\nExamples:\r\n\r\n```bash\r\nCHAI_DOWNLOADS_DIR=/downloads python ./examples/predict_structure.py \r\n```\r\n\r\nFor docker, one can set envvar in dockerfile (using `ENV`), or with `-e` flag in `docker run -e ... `\r\n\r\n"
      },
      {
        "user": "arogozhnikov",
        "created_at": "2024-10-19T06:54:01Z",
        "body": "Documented CHAI_DOWNLOADS_DIR in repo readme, closing"
      },
      {
        "user": "dionjwa",
        "created_at": "2024-10-21T22:31:12Z",
        "body": "Thank you! "
      }
    ]
  },
  {
    "number": 50,
    "title": "Differences between the GitHub Open Version and the Page Server Version",
    "created_at": "2024-09-14T10:06:33Z",
    "closed_at": "2024-09-14T16:17:20Z",
    "labels": [],
    "url": "https://github.com/chaidiscovery/chai-lab/issues/50",
    "body": "I would like to ask about the differences between the version you have open on GitHub and the current server version on your page. I noticed that the page seems to be using MSA, while the GitHub version deployed locally uses the ESM model weights.",
    "comments_url": "https://api.github.com/repos/chaidiscovery/chai-lab/issues/50/comments",
    "author": "gibhdyw",
    "comments": [
      {
        "user": "arogozhnikov",
        "created_at": "2024-09-14T16:17:20Z",
        "body": "Hi duyouwei, \r\n\r\nyes, server additionally collects MSAs for user and selects the best result by score."
      },
      {
        "user": "gibhdyw",
        "created_at": "2024-09-14T16:28:25Z",
        "body": "Can I also use MSA after local deployment? Since I find that the results are different on the local deployment and on the server page, obviously the effect on the server looks more reliable, could there be a section on readme on how to add the msa search function on the local deploy。"
      },
      {
        "user": "arogozhnikov",
        "created_at": "2024-09-14T16:30:55Z",
        "body": "yes, that's in plans "
      }
    ]
  },
  {
    "number": 46,
    "title": "Another CUDA-related question: CutlassF error",
    "created_at": "2024-09-13T20:42:23Z",
    "closed_at": "2024-09-13T20:46:02Z",
    "labels": [],
    "url": "https://github.com/chaidiscovery/chai-lab/issues/46",
    "body": "Hello! I have two GPUs: an NVIDIA L40S and an NVIDIA V100, both of which are running CUDA 12.2 (I have tried with CUDA 11.8/Pytorch 2.3.1, and the following error does not change). \r\n\r\nOn the L40S, I can run the code with no problems. However, on the V100, I get the following error when using the size-256 model upon running folding:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/project2/andrewferguson/berlaga/drugdiscovery/run_chai.py\", line 60, in <module>\r\n    output_pdb_paths = run_inference(\r\n                       ^^^^^^^^^^^^^^\r\n  File \"/scratch/midway3/berlaga/miniconda3/envs/chai/lib/python3.12/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\r\n    return func(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/scratch/midway3/berlaga/miniconda3/envs/chai/lib/python3.12/site-packages/chai_lab/chai1.py\", line 293, in run_inference\r\n    output_paths, scores, ranking_data = run_folding_on_context(\r\n                                         ^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/scratch/midway3/berlaga/miniconda3/envs/chai/lib/python3.12/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\r\n    return func(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/scratch/midway3/berlaga/miniconda3/envs/chai/lib/python3.12/site-packages/chai_lab/chai1.py\", line 421, in run_folding_on_context\r\n    token_input_embedder_outputs: tuple[Tensor, ...] = token_input_embedder.forward(\r\n                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"<eval_with_key>.9\", line 202, in forward\r\n  File \"/scratch/midway3/berlaga/miniconda3/envs/chai/lib/python3.12/site-packages/torch/_ops.py\", line 594, in __call__\r\n    return self_._op(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nRuntimeError: cutlassF: no kernel found to launch!\r\n```\r\nIs the code not supported on V100s? Otherwise, what could be causing this issue?",
    "comments_url": "https://api.github.com/repos/chaidiscovery/chai-lab/issues/46/comments",
    "author": "alexberlaga",
    "comments": [
      {
        "user": "arogozhnikov",
        "created_at": "2024-09-13T20:46:02Z",
        "body": "Hi Alex, this is same issue as #26 \r\n\r\nI've updated readme to reflect supported GPUs. Both V100 and L40s don't support bfloat16."
      },
      {
        "user": "alexberlaga",
        "created_at": "2024-09-13T20:55:12Z",
        "body": "Thanks!"
      }
    ]
  },
  {
    "number": 40,
    "title": "Adding experimental constraints or restraints during structure prediction",
    "created_at": "2024-09-13T01:51:47Z",
    "closed_at": "2024-09-13T20:15:07Z",
    "labels": [],
    "url": "https://github.com/chaidiscovery/chai-lab/issues/40",
    "body": "Hi,\r\n\r\n  How to specify experimental constraints or restraints during prediction?\r\n\r\nRegards\r\nRakesh",
    "comments_url": "https://api.github.com/repos/chaidiscovery/chai-lab/issues/40/comments",
    "author": "rakeshr10",
    "comments": [
      {
        "user": "arogozhnikov",
        "created_at": "2024-09-13T20:15:07Z",
        "body": "Hi Rakesh, there is already issue #27 , let's track it there (you can subscribe to issue to get notifications about updates)"
      }
    ]
  },
  {
    "number": 33,
    "title": "Inference on Apple Silicon",
    "created_at": "2024-09-12T14:07:49Z",
    "closed_at": "2024-11-05T06:43:03Z",
    "labels": [],
    "url": "https://github.com/chaidiscovery/chai-lab/issues/33",
    "body": "Would it be possible to run chai on apple silicon devices ?\r\nI replaced cuda:0 with mps:0, however I still have the AssertionError: Torch not compiled with CUDA enabled error.\r\nI believe it come from the feature_embedding.pt2 file, but I'm not sure and Idk how to solve the issue.\r\nBest,\r\nDominique MIAS.",
    "comments_url": "https://api.github.com/repos/chaidiscovery/chai-lab/issues/33/comments",
    "author": "DomML",
    "comments": [
      {
        "user": "popfido",
        "created_at": "2024-09-26T08:56:44Z",
        "body": "It's because every module of the model, as you can see from the source code published, is a jit compiled version by `Torch Dynamo` . Since you have `mps` device that probably not support the compiled module which was compiled by the default backend inductor of torch jit, you will receive this `AssertionError`. \r\n\r\nI think currently there is no way for `mps` device to run current compiled module. \r\n\r\nMaybe they should release another version of compiled checkpoint with `Triton`."
      }
    ]
  },
  {
    "number": 12,
    "title": "Write confidence scores with model outputs",
    "created_at": "2024-09-10T23:22:52Z",
    "closed_at": "2024-09-11T01:53:11Z",
    "labels": [],
    "url": "https://github.com/chaidiscovery/chai-lab/pull/12",
    "body": "## Description\r\n\r\nWrite model confidence scores for each prediction in `run_inference()`\r\n",
    "comments_url": "https://api.github.com/repos/chaidiscovery/chai-lab/issues/12/comments",
    "author": "jacquesboitreaud",
    "comments": [
      {
        "user": "GXcells",
        "created_at": "2024-09-11T08:18:00Z",
        "body": "The commit is not yet in the pip package, when I upgrade the pip package chai_lab the changes are not done.\r\nShould I do pip install  git+git://github.com/chaidiscovery/chai-lab instead of pip install chai_lab\r\n??"
      }
    ]
  },
  {
    "number": 8,
    "title": "Add pLDDT to pdb files",
    "created_at": "2024-09-10T17:47:29Z",
    "closed_at": "2024-09-10T18:10:32Z",
    "labels": [],
    "url": "https://github.com/chaidiscovery/chai-lab/pull/8",
    "body": "## Description\r\n\r\nThis PR adds per-atom pLDDT scores to B-factor column in output PDB files.\r\npLDDT scores are in [0,100] range, with 100 indicating perfect predicted LDDT (high model confidence).\r\n",
    "comments_url": "https://api.github.com/repos/chaidiscovery/chai-lab/issues/8/comments",
    "author": "jacquesboitreaud",
    "comments": [
      {
        "user": "arogozhnikov",
        "created_at": "2024-09-10T18:10:37Z",
        "body": "looks great, thx @jacquesboitreaud "
      }
    ]
  },
  {
    "number": 6,
    "title": "VRAM management",
    "created_at": "2024-09-10T16:04:32Z",
    "closed_at": "2024-12-09T18:46:27Z",
    "labels": [
      "enhancement"
    ],
    "url": "https://github.com/chaidiscovery/chai-lab/issues/6",
    "body": "Is there a way to reduce memory usage or at least to distribute part in RAM or something like this so that we can run on smaller VRAM machines?\r\nSomething similar than what is used in image diffusion models by UI such as ComfyUI whzn they use LOW_VRAM.\r\n",
    "comments_url": "https://api.github.com/repos/chaidiscovery/chai-lab/issues/6/comments",
    "author": "GXcells",
    "comments": [
      {
        "user": "arogozhnikov",
        "created_at": "2024-09-10T17:33:12Z",
        "body": "(I had to look up to confirm that VRAM is GPU memory)\r\n\r\nI need to look up again if torch has tools for optimizing provided graph for peak memory usage.\r\n\r\nTricks from ComfyUI won't work in our case - balance of memory spent on activations vs weights is very different."
      },
      {
        "user": "phbradley",
        "created_at": "2024-09-21T17:24:14Z",
        "body": "Thank you for looking into it, this would be wonderful! It looks to me like the memory drops during the main part of the run, but there is an early peak which is topping out over the ~12G we have on our (sadly, old) GPUs. Please do let us know if there is anything that could be done!"
      }
    ]
  },
  {
    "number": 4,
    "title": "How to get the metrics about predictions?",
    "created_at": "2024-09-10T15:10:18Z",
    "closed_at": "2024-09-11T08:56:38Z",
    "labels": [],
    "url": "https://github.com/chaidiscovery/chai-lab/issues/4",
    "body": "Hi,\r\n\r\nThanks a lot for open sourcing the model.\r\n\r\nIs there a way to output the metrics similar to alpha fold/alphafold multimer and get also coloring of residues based on prediction confidence?\r\n\r\nThanks a lot.\r\n",
    "comments_url": "https://api.github.com/repos/chaidiscovery/chai-lab/issues/4/comments",
    "author": "GXcells",
    "comments": [
      {
        "user": "arogozhnikov",
        "created_at": "2024-09-10T15:53:06Z",
        "body": "Hi @GXcells \r\n\r\n> get also coloring of residues based on prediction confidence?\r\n\r\nI guess that's pLDDT coloring of residues? Sure, we can add this.\r\n\r\n> to output the metrics similar to alpha fold/alphafold multimer \r\n\r\nYou want to see PDE / PAE matrices or something else?\r\n\r\n\r\n"
      },
      {
        "user": "GXcells",
        "created_at": "2024-09-10T15:58:40Z",
        "body": "Yes pLDDT coloring.\r\nFor scores, pTM ad ipTM would also be good for multimers.\r\nAlso a  PAE plot would be really useful.\r\n\r\nThanks a lot."
      },
      {
        "user": "arogozhnikov",
        "created_at": "2024-09-10T18:12:28Z",
        "body": "pLDDT coloring was just merged in #8 , not yet exposed in web server"
      },
      {
        "user": "jackdent",
        "created_at": "2024-09-10T21:38:08Z",
        "body": "This has now been deployed to the web server"
      },
      {
        "user": "jacquesboitreaud",
        "created_at": "2024-09-11T01:59:50Z",
        "body": "@GXcells we now write a scores file alongside the pdbs ( #12), you can get ptm and iptm as follows: \r\n\r\n```python\r\nimport numpy as np\r\n# Load pTM, ipTM, pLDDTs and clash scores for sample 2\r\nscores = np.load(output_dir.joinpath(\"scores.model_idx_2.npz\"))\r\n\r\nptm = scores[\"ptm\"]\r\niptm = scores[\"iptm\"]\r\n\r\nall_available_scores = list(scores.keys())\r\n```\r\nthe scores also contain per-chain pTM and per-chain-pair ipTM if you need more detailed metrics."
      },
      {
        "user": "GXcells",
        "created_at": "2024-09-11T08:56:38Z",
        "body": "Great Thank you all. I close the issue."
      }
    ]
  },
  {
    "number": 1,
    "title": "chore: update utils.py",
    "created_at": "2024-09-09T18:43:20Z",
    "closed_at": "2024-09-09T19:02:16Z",
    "labels": [],
    "url": "https://github.com/chaidiscovery/chai-lab/pull/1",
    "body": "\r\n\r\n## Description\r\nallways -> always\r\n\r\n",
    "comments_url": "https://api.github.com/repos/chaidiscovery/chai-lab/issues/1/comments",
    "author": "eltociear",
    "comments": [
      {
        "user": "arogozhnikov",
        "created_at": "2024-09-09T19:02:29Z",
        "body": "thx for catching!"
      }
    ]
  }
]