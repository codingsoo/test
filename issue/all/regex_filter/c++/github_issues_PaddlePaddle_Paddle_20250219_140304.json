[
  {
    "number": 25288,
    "title": "How to skip to validate selected output tensors in python unit tests?",
    "created_at": "2020-06-30T15:20:42Z",
    "closed_at": "2020-07-01T14:44:00Z",
    "labels": [
      "question",
      "Intel"
    ],
    "url": "https://github.com/PaddlePaddle/Paddle/issues/25288",
    "body": "Hi,\r\n\r\nThere are operators like LRN which are having one of an outputs (MidOut) that is no use for user , but it contains intermediate data\r\nthat are speeding computation of LRN grad operator. In unit tests, (test_check_output) this MidOut is also verified if it contains valid / expected data. Problem is that what is inside MidOut is implementation specific. oneDNN LRN will produce MidOut with diffrent kind of data, because LRN oneDNN grad op is diffrent in implementation to Paddle CPU LRN grad. So unit test may fail\r\ndue to diffrent kind of data being put into MidOut. So my question is : is it possible to skip comparing MidOut tensor in Unit tests of LRN oneDNN ? If positive then how can I do that? ",
    "comments_url": "https://api.github.com/repos/PaddlePaddle/Paddle/issues/25288/comments",
    "author": "jczaja",
    "comments": [
      {
        "user": "zhiqiu",
        "created_at": "2020-07-01T05:46:28Z",
        "body": "Hi, you can call `self.check_output(no_check_set=['MidOut'])` , so `MidOut` will not be checked."
      },
      {
        "user": "jczaja",
        "created_at": "2020-07-01T14:44:00Z",
        "body": "@zhiqiu  Thanks for suggestion! To actually have it working I also needed to add *lrn* to *no_check_set_whitelist*."
      }
    ]
  },
  {
    "number": 23021,
    "title": "动态图使用fluid.dygraph.Layer.create_parameter报告缺少参数错误",
    "created_at": "2020-03-16T02:27:37Z",
    "closed_at": "2020-03-16T03:46:01Z",
    "labels": [
      "question",
      "dygraph"
    ],
    "url": "https://github.com/PaddlePaddle/Paddle/issues/23021",
    "body": " 1）PaddlePaddle版本：1.7.0\r\n动态图使用create_parameter出现缺少参数self错误,可是官方文档里并没有这个参数。\r\n下面是一个简单的示例，如果是我使用有问题还希望能够给一个例子，如何使用。\r\nimport paddle.fluid as fluid\r\nwith fluid.dygraph.guard():\r\n   w=fluid.dygraph.Layer.create_parameter(dtype='float64',shape=[2,2])\r\n报错：\r\nTraceback (most recent call last):\r\n  File \"14.py\", line 3, in <module>\r\n    w=fluid.dygraph.Layer.create_parameter(dtype='float64',shape=[2,2])\r\nTypeError: create_parameter() missing 1 required positional argument: 'self'\r\n",
    "comments_url": "https://api.github.com/repos/PaddlePaddle/Paddle/issues/23021/comments",
    "author": "zhangylch",
    "comments": [
      {
        "user": "qingqing01",
        "created_at": "2020-03-16T03:42:22Z",
        "body": "@zylustc \r\n\r\n此函数需要在继承 fluid.Layer的sub-class中用，而不是当做普通的function调用。正确的用法是:\r\n\r\n```\r\n\r\nclass MyModel(fluid.Layer):\r\n    def __init__(self):\r\n        super(MyModel, self).__init__()\r\n        self.w = self.create_parameter(\r\n            dtype='float64',\r\n            shape=[2, 2])\r\n\r\nwith fluid.dygraph.guard():\r\n    model = MyModel()\r\n    print(model.w)\r\n```"
      },
      {
        "user": "zhangylch",
        "created_at": "2020-03-16T03:45:51Z",
        "body": "> @zylustc\r\n> \r\n> 此函数需要在继承 fluid.Layer的sub-class中用，而不是当做普通的function调用。正确的用法是:\r\n> \r\n> ```\r\n> \r\n> class MyModel(fluid.Layer):\r\n>     def __init__(self):\r\n>         super(MyModel, self).__init__()\r\n>         self.w = self.create_parameter(\r\n>             dtype='float64',\r\n>             shape=[2, 2])\r\n> \r\n> with fluid.dygraph.guard():\r\n>     model = MyModel()\r\n>     print(model.w)\r\n> ```\r\n\r\n非常感谢"
      },
      {
        "user": "zhangylch",
        "created_at": "2020-03-16T04:36:02Z",
        "body": "非常感谢发自我的华为手机-------- 原始邮件 --------发件人： qingqing01 <notifications@github.com>日期： 2020年3月16日周一 11:42收件人： PaddlePaddle/Paddle <Paddle@noreply.github.com>抄送： zyl12138 <ylzustc@mail.ustc.edu.cn>, Mention <mention@noreply.github.com>主    题： Re: [PaddlePaddle/Paddle] 动态图使用fluid.dygraph.Layer.create_parameter报告缺少参数错误 (#23021)\r\r\n@zylustc\r\r\n次函数需要在继承 fluid.Layer的sub-class中用，而不是当做普通的function调用。正确的用法是:\r\r\n\r\r\nclass MyModel(fluid.Layer):\r\r\n    def __init__(self):\r\r\n        super(MyModel, self).__init__()\r\r\n        self.w = self.create_parameter(\r\r\n            dtype='float32',\r\r\n            shape=[2, 2])\r\r\n\r\r\nwith fluid.dygraph.guard():\r\r\n    model = MyModel()\r\r\n    print(model.w)\r\r\n\r\r\n\r\r\n—You are receiving this because you were mentioned.Reply to this email directly, view it on GitHub, or unsubscribe."
      }
    ]
  },
  {
    "number": 20778,
    "title": "BERT use case",
    "created_at": "2019-10-22T12:04:45Z",
    "closed_at": "2019-12-09T06:13:37Z",
    "labels": [
      "question",
      "Intel"
    ],
    "url": "https://github.com/PaddlePaddle/Paddle/issues/20778",
    "body": "Hi,\r\nWe'd like to ask you for your BERT use case (in other words: how to test it to better suite your needs).\r\nHow do you use BERT? What batch size? How many threads? In Unit Test by default it is BS=8. Do you confirm that?",
    "comments_url": "https://api.github.com/repos/PaddlePaddle/Paddle/issues/20778/comments",
    "author": "ddokupil",
    "comments": [
      {
        "user": "bingyanghuang",
        "created_at": "2019-10-28T01:34:59Z",
        "body": "@luotao1 Could you help provide us some information about this?"
      },
      {
        "user": "bingyanghuang",
        "created_at": "2019-12-09T06:13:37Z",
        "body": "Bert configuration we can use default one in the UT. Since we are working on ERNIE, will suspect ERNIE in our CE system. And Baidu will give us their CE script when it's ready."
      }
    ]
  },
  {
    "number": 19592,
    "title": "是否有办法取得一个scope下面的所有variables or functions as tensorflow",
    "created_at": "2019-09-02T21:25:08Z",
    "closed_at": "2020-09-07T09:44:53Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/PaddlePaddle/Paddle/issues/19592",
    "body": "在tensorflow中，我们可以使用下面这个方法取得scope为generator下面的所有变量。\r\ng_vars = get_collection(fluid.layers.GraphKeys.TRAINABLE_VARIABLES, scope='generator')。\r\n我发现我们可以用\r\ng_vars = fluid.name_scope('generator')\r\n得到一个contextlib._GeneratorContextManager，但是好像我们并不能利用它做进一步有用的操作。\r\n多谢",
    "comments_url": "https://api.github.com/repos/PaddlePaddle/Paddle/issues/19592/comments",
    "author": "leonleeldc",
    "comments": [
      {
        "user": "gongweibao",
        "created_at": "2019-09-03T02:33:03Z",
        "body": "先在只能用scope.find(var_name),暂时没有iterator 遍历。"
      },
      {
        "user": "sneaxiy",
        "created_at": "2019-09-03T05:34:08Z",
        "body": "目前paddle没有这个接口，抱歉。paddle的name_scope和tf的概念不同，paddle的name_scope用于内部处理，对用户不可见，亦不会在变量名前加上特殊前缀。"
      },
      {
        "user": "paddle-bot-old[bot]",
        "created_at": "2020-09-07T09:45:04Z",
        "body": "Since you haven\\'t replied for more than a year, we have closed this issue/pr.\nIf the problem is not solved or there is a follow-up one, please reopen it at any time and we will continue to follow up.\n由于您超过一年未回复，我们将关闭这个issue/pr。\n若问题未解决或有后续问题，请随时重新打开，我们会继续跟进。"
      }
    ]
  },
  {
    "number": 17072,
    "title": "1.4版本还不支持CUDA 10？",
    "created_at": "2019-04-24T07:22:12Z",
    "closed_at": "2019-04-25T06:57:51Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/PaddlePaddle/Paddle/issues/17072",
    "body": "# 环境\r\n - PaddlePaddle 1.4\r\n - Ubuntu 16.04\r\n - Python 3.5\r\n\r\n# 问题\r\n都 1.4 版本了，还不支持CUDA 10，虽然我自行编译可以支持CUDA 10，但是每次都要编译其实很麻烦的。\r\n\r\n对于1.4版本的发布，值得高兴的是，paddlePaddle终于支持动态图了。",
    "comments_url": "https://api.github.com/repos/PaddlePaddle/Paddle/issues/17072/comments",
    "author": "yeyupiaoling",
    "comments": [
      {
        "user": "hjchen2",
        "created_at": "2019-04-24T07:30:49Z",
        "body": "@yeyupiaoling 确实目前还没提供cuda 10的预编译二进制包"
      },
      {
        "user": "yeyupiaoling",
        "created_at": "2019-04-24T11:42:38Z",
        "body": "@hjchen2 这我就不懂了，明明是可以在cuda 10正常编译得到的。为什么不顺便提供呢？"
      }
    ]
  },
  {
    "number": 16037,
    "title": "paddle-gpu的训练过程，是所有迭代过程间的计算并行，还是一次迭代内部计算的并行？",
    "created_at": "2019-03-04T06:33:52Z",
    "closed_at": "2023-01-11T12:21:52Z",
    "labels": [
      "question",
      "User",
      "status/close"
    ],
    "url": "https://github.com/PaddlePaddle/Paddle/issues/16037",
    "body": "请问paddle-gpu的训练过程，是所有迭代过程间的并行，还是一次迭代过程内部的并行？",
    "comments_url": "https://api.github.com/repos/PaddlePaddle/Paddle/issues/16037/comments",
    "author": "yxnal",
    "comments": [
      {
        "user": "Superjomn",
        "created_at": "2019-03-05T09:44:30Z",
        "body": "看不太懂问题。\r\n\r\n目前是一个 batch, all reduce 的方式更新的"
      },
      {
        "user": "yxnal",
        "created_at": "2019-03-06T02:00:50Z",
        "body": "感谢解答！\r\npaddle gpu版本，训练阶段在gpu并行时，是batch间并行（多个batch同时计算loss、梯度、更新等），还是只是一个batch内部运算时并行（loss、梯度等运算本身并行）？"
      }
    ]
  },
  {
    "number": 15422,
    "title": "模型压缩",
    "created_at": "2019-01-18T10:00:23Z",
    "closed_at": "2019-11-28T08:28:46Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/PaddlePaddle/Paddle/issues/15422",
    "body": "使用paddlepaddle训练的模型怎么进行模型压缩\r\n",
    "comments_url": "https://api.github.com/repos/PaddlePaddle/Paddle/issues/15422/comments",
    "author": "xueshang-liulp",
    "comments": [
      {
        "user": "qingqing01",
        "created_at": "2019-01-18T10:06:12Z",
        "body": "@llp123 感谢关注，我们正在做模型压缩系列工作，请问您具体需要那种压缩方法？"
      },
      {
        "user": "xueshang-liulp",
        "created_at": "2019-01-18T10:59:40Z",
        "body": "@qingqing01 现在遇到的问题就是模型过大，推理耗费时间长，进行例如降低精度，模型裁剪等方面的压缩方法，另外DeepBench不知道能否应用上？\r\n"
      },
      {
        "user": "qingqing01",
        "created_at": "2019-01-20T15:47:08Z",
        "body": "请问您是什么模型？是在端上预测还是Server上预测？是CPU预测还是GPU预测？推理较耗时，也需要依据您的模型和C++预测API的使用情况。\r\n\r\n关于Paddle对于模型压缩的情况： \r\n1. 8bit预测，如果是端上，Paddle-Mobile支持若干CNN模型的预测，Paddle CPU正在支持8bit的预测。 GPU可以使用TensorRT的8bit加速CNN模型。 需要知道您的具体模型和硬件。8bit预测Paddle也正在优化支持。\r\n2. 其他裁剪模型、蒸馏等方法属于算法级别，这些后续会支持，但需要知道您的模型类型。\r\n\r\nDeepBench我理解是来针对不同操作、硬件、模型做benchmark，评估性能，不是用来加速的。"
      }
    ]
  },
  {
    "number": 15400,
    "title": "reshape_op can not match size",
    "created_at": "2019-01-17T12:47:14Z",
    "closed_at": "2020-05-22T10:16:53Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/PaddlePaddle/Paddle/issues/15400",
    "body": "预测的时候发现input_shape改变会在reshape层导致size不匹配的问题\r\n问题应该是reshape_op中的output_shape[unk_dim_idx] 没有取float所导致，具体表现为：\r\nin_dim=[-1, 260, 35, 63]\r\nshape = [-1, 2, 1820, 14]\r\nCapacity = -1*2*1820*14 = - 35840\r\nin_size=-1*260*35*63=-573300\r\n不取float\r\noutput_shape[unk_dim_idx] = -in_size / capacity = 15\r\noutput_shape[unk_dim_idx] * capacity = 15*35840 = 537600 != in_size \r\n取float\r\noutput_shape[unk_dim_idx] = -in_size / capacity = 15.9960938\r\noutput_shape[unk_dim_idx] * capacity = 15.9960938*35840 = 573300 == in_size ",
    "comments_url": "https://api.github.com/repos/PaddlePaddle/Paddle/issues/15400/comments",
    "author": "liyingying05",
    "comments": [
      {
        "user": "hjchen2",
        "created_at": "2019-01-17T13:01:42Z",
        "body": "@liyingying05 output_shape只能是取整数，因此in_size必须是capacity的整数倍，否则reshape前后的数据大小就不一样了。请看看是不是输入数据的shape本身有问题呢？"
      },
      {
        "user": "paddle-bot-old[bot]",
        "created_at": "2020-05-22T10:17:19Z",
        "body": "Since you haven\\'t replied for more than a year, we have closed this issue/pr.\nIf the problem is not solved or there is a follow-up one, please reopen it at any time and we will continue to follow up.\n由于您超过一年未回复，我们将关闭这个issue/pr。\n若问题未解决或有后续问题，请随时重新打开，我们会继续跟进。"
      }
    ]
  },
  {
    "number": 15378,
    "title": "如何查看模型的参数",
    "created_at": "2019-01-17T03:01:18Z",
    "closed_at": "2020-05-22T10:16:50Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/PaddlePaddle/Paddle/issues/15378",
    "body": "在fluid.io.load_vars后，希望看看模型的各个参数值，不知道如何debug。\r\n```\r\n##============= net =============##\r\n\r\n    with fluid.program_guard(tp, sp):\r\n        img = fluid.layers.data(\r\n            name='img', shape=[3, input_size[1],  input_size[0]], dtype='float32')\r\n        label = fluid.layers.data(name='label', shape=[1], dtype='int32')\r\n\r\n        predict = net(img, args.num_classes)\r\n\r\n    ##=========== exe   ===================##\r\n    place = fluid.CPUPlace()\r\n    if args.gpu != '-1':\r\n        place = fluid.CUDAPlace(0)\r\n    exe = fluid.Executor(place)\r\n    exe.run(sp)\r\n\r\n    ##========== load model ===============##\r\n    if args.init_weights_path:\r\n        logging.info(\"load from:\" + args.init_weights_path)\r\n        assert (os.path.isdir(args.init_weights_path))\r\n\r\n        def if_exist(var):\r\n            return os.path.exists(os.path.join(args.init_weights_path, var.name))\r\n\r\n        fluid.io.load_vars(exe, dirname=args.init_weights_path, main_program=tp, predicate=if_exist)\r\n```",
    "comments_url": "https://api.github.com/repos/PaddlePaddle/Paddle/issues/15378/comments",
    "author": "sguuaa",
    "comments": [
      {
        "user": "hjchen2",
        "created_at": "2019-01-17T04:59:18Z",
        "body": "@sguuaa 可以试一下下面的代码，从scope中取出你需要打印的tensor。\r\n```python\r\nimport numpy as np\r\n...\r\n# load params\r\n# print var named `name`\r\nscope = global_scope()\r\nprint np.array(scope.find_var(name).get_tensor())\r\n```"
      },
      {
        "user": "paddle-bot-old[bot]",
        "created_at": "2020-05-22T10:17:17Z",
        "body": "Since you haven\\'t replied for more than a year, we have closed this issue/pr.\nIf the problem is not solved or there is a follow-up one, please reopen it at any time and we will continue to follow up.\n由于您超过一年未回复，我们将关闭这个issue/pr。\n若问题未解决或有后续问题，请随时重新打开，我们会继续跟进。"
      }
    ]
  },
  {
    "number": 15369,
    "title": "PaddlePaddle中是否有对应Tensorflow中的一些rnn api实现？",
    "created_at": "2019-01-16T09:41:45Z",
    "closed_at": "2019-02-28T03:26:15Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/PaddlePaddle/Paddle/issues/15369",
    "body": "主要是下面四个api\r\ntf.contrib.rnn.BasicLSTMCell\r\ntf.contrib.rnn.DropoutWrapper\r\ntf.contrib.rnn.MultiRNNCell\r\ntf.nn.static_bidirectional_rnn",
    "comments_url": "https://api.github.com/repos/PaddlePaddle/Paddle/issues/15369/comments",
    "author": "jjjkaixin",
    "comments": [
      {
        "user": "heavengate",
        "created_at": "2019-01-16T11:19:55Z",
        "body": "没有上面这些直接对应的接口，lstm与tf的rnn_cell/LSTMCell一致，不知道与你要求是否一致"
      }
    ]
  },
  {
    "number": 14370,
    "title": "确定DecayRegularizer 用于 SelectedRow数据的实际效果？",
    "created_at": "2018-11-12T12:56:11Z",
    "closed_at": "2018-12-11T13:53:21Z",
    "labels": [
      "question",
      "User"
    ],
    "url": "https://github.com/PaddlePaddle/Paddle/issues/14370",
    "body": "将L1DecayRegularizer用于大规模稀疏表，是否能自动去掉作用较小的id特征，更确切的说是在id对应embedding的每个维度做L1正则还是在整个id对应的embedding向量上作分组L1正则？\r\n\r\n另外，求简要介绍大规模稀疏表的正则化实现策略。",
    "comments_url": "https://api.github.com/repos/PaddlePaddle/Paddle/issues/14370/comments",
    "author": "colin1988",
    "comments": [
      {
        "user": "chengduoZH",
        "created_at": "2018-11-13T02:59:49Z",
        "body": "> 是否能自动去掉作用较小的id特征\r\n\r\n目前Paddle是不支持在L1中指定id的。\r\n\r\n您是要做分布式吗？"
      },
      {
        "user": "colin1988",
        "created_at": "2018-11-13T03:32:24Z",
        "body": "@chengduoZH 对。大规模稀疏特征的embedding，期望能通过正则化过滤掉某些低频id特征对应的整个embedding。或者说对pserver支持weight decay。develop分支两天前对SelectedRow是有特化的，刚刚去掉吧\r\n\r\n        if grad.type == core.VarDesc.VarType.SELECTED_ROWS:\r\n            idx = block.create_var(\r\n                dtype=\"int64\",\r\n                shape=param.shape,\r\n                type=core.VarDesc.VarType.LOD_TENSOR)\r\n            decay = block.create_var(\r\n                dtype=\"float32\",\r\n                shape=param.shape,\r\n                type=core.VarDesc.VarType.LOD_TENSOR)\r\n            block.append_op(\r\n                type='extract_rows', inputs={'X': grad}, outputs={'Out': idx})\r\n            block.append_op(\r\n                type='lookup_table',\r\n                inputs={'W': param,\r\n                        'Ids': idx},\r\n                outputs={'Out': decay},\r\n                attrs={'is_sparse': True})\r\n            param = decay\r\npython/paddle/fluid/regularizer.py"
      },
      {
        "user": "chengduoZH",
        "created_at": "2018-11-13T03:40:21Z",
        "body": "> develop分支两天前对SelectedRow是有特化的，刚刚去掉吧\r\n\r\n是的，之前的实现方式是有问题的，~~正确的正则化方法应该是对整个参数，这是符合数学表达的。~~ 根据正则化的数学公式，正确的正则化方法应该是对整个参数做正则。"
      },
      {
        "user": "colin1988",
        "created_at": "2018-11-13T04:05:35Z",
        "body": "@chengduoZH 最新的develop分支里正则化针对pserver是什么效果啊？另外，\"正确的正则化方法\"预计什么时候可用啊"
      },
      {
        "user": "chengduoZH",
        "created_at": "2018-11-13T04:53:04Z",
        "body": "> \"正确的正则化方法\"预计什么时候可用 \r\n\r\n根据数学公式，正确的正则化方法应该是对整个参数，现在的develop分支就是这么做的。"
      },
      {
        "user": "wangguibao",
        "created_at": "2018-12-11T13:53:21Z",
        "body": "先关闭了。后续相关需求可以随时重新打开"
      }
    ]
  },
  {
    "number": 14253,
    "title": "单机单卡可以使用ParallelExecutor加速训练吗 ",
    "created_at": "2018-11-06T01:50:51Z",
    "closed_at": "2019-01-18T07:35:33Z",
    "labels": [
      "question",
      "User"
    ],
    "url": "https://github.com/PaddlePaddle/Paddle/issues/14253",
    "body": "在GPU环境下，只有单机单卡的话可以使用ParallelExecutor加速训练模型吗？例如设置num_trainers = 4之类的",
    "comments_url": "https://api.github.com/repos/PaddlePaddle/Paddle/issues/14253/comments",
    "author": "zzhzz",
    "comments": [
      {
        "user": "chengduoZH",
        "created_at": "2018-11-06T02:05:22Z",
        "body": "> 只有单机单卡的话可以使用ParallelExecutor加速训练模型吗？\r\n\r\n相比于Executor，ParallelExecutor在执行策略上做一些改动，比如operator是乱序执行，即如果多个Op的输入互不依赖，这些op在ParallelExecutor里面可以并发执行，所以单机单卡下ParallelExecutor是否能够加速模型训练与模型的结构相关。\r\n\r\nParallelExecutor是为多卡设计的，所以如果只有一个卡，那么num_trainers就只能是1."
      },
      {
        "user": "333caowei",
        "created_at": "2018-11-06T11:53:02Z",
        "body": "```ParallelExecutor是为多卡设计的```\r\n请问如果是mpi cpu训练的的话，ParallelExecutor有意义吗？\r\n@chengduoZH \r\n"
      },
      {
        "user": "chengduoZH",
        "created_at": "2018-12-26T03:08:47Z",
        "body": "@333caowei 目前分布式用ParallelExecutor执行时，通过MPI进行通信的情况还没有正式测试，后续会有相关测试和发布。"
      }
    ]
  },
  {
    "number": 13746,
    "title": "nn.py里面dynamic_gru判读h_0 != None出错",
    "created_at": "2018-10-08T04:21:54Z",
    "closed_at": "2018-10-31T12:59:19Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/PaddlePaddle/Paddle/issues/13746",
    "body": "如题，改为if h_0:能正常运行。\r\n查看1.0代码，dynamic_lstm已经从if h_0 != None:改为if h_0:,但dynamic_gru还没有修改。",
    "comments_url": "https://api.github.com/repos/PaddlePaddle/Paddle/issues/13746/comments",
    "author": "xiaoyao4573",
    "comments": [
      {
        "user": "sneaxiy",
        "created_at": "2018-10-30T05:12:04Z",
        "body": "非常感谢您的问题，这个bug已修复完毕。"
      }
    ]
  },
  {
    "number": 13471,
    "title": "评价指标问题",
    "created_at": "2018-09-19T03:02:24Z",
    "closed_at": "2018-11-15T12:42:06Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/PaddlePaddle/Paddle/issues/13471",
    "body": "你好，我在使用nce做多分类损失函数时，想在训练过程中打印出训练集和验证集的P值或AUC等评价指标。\r\n我的做法是取出nce层的参数，然后得到输出向量，用该向量和label做evaluator的参数。\r\n问题是在训练过程中，event.metrics都是空的，请问这是什么原因呢？",
    "comments_url": "https://api.github.com/repos/PaddlePaddle/Paddle/issues/13471/comments",
    "author": "mengyiliu22",
    "comments": [
      {
        "user": "seiriosPlus",
        "created_at": "2018-09-25T03:20:42Z",
        "body": "你好，您用的是trainer.py来训练的么？"
      },
      {
        "user": "mengyiliu22",
        "created_at": "2018-09-28T09:14:24Z",
        "body": "> 你好，您用的是trainer.py来训练的么？\r\n\r\n是的，用trainer.train()来训练的。"
      },
      {
        "user": "lucywsq",
        "created_at": "2018-10-26T06:58:54Z",
        "body": "您好，请您截图详细的报错代码，以便定位和解决问题~\r\n此issue若已经解决，我们将于三天内关闭。若在关闭后您仍需跟进 提问，可重新开启此问题，\r\n我们将在24小时内回复您。因关闭带来的不便我们深表歉意，请您谅解~感谢您对PaddlePaddle的支持!"
      }
    ]
  },
  {
    "number": 6676,
    "title": "Some question about the inheritance relationship of `DeviceContext`.",
    "created_at": "2017-12-16T08:55:26Z",
    "closed_at": "2018-08-15T10:43:00Z",
    "labels": [
      "question",
      "need be discussed"
    ],
    "url": "https://github.com/PaddlePaddle/Paddle/issues/6676",
    "body": "We assume each computational library is a place and has its own `DeviceContext`. So the inheritance relationship of `CUDADevCtx`, `CUDNNDevCtx`, and `NCCLDevCtx` is:\r\n\r\n```\r\n                 /- CUDNNDeviceContext\r\nCUDADeviceContext\r\n                 `- NCCLDeviceContext\r\n```\r\n\r\nQuestion 1: How about an operator will need both `NCCL` context and `CUDNN` context? Should we provide an `NCCLAndCUDNNDeviceContext`? Or we just let this operator get two `DeviceContext` instances?\r\n\r\nQuestion 2: Should we implement a decoration pattern for `CUDNNDevCtx` and `NCCLDevCtx`? i.e.\r\nThe sample code is as below:\r\n\r\n```cpp\r\nclass CUDADevCtx;\r\nclass CUDNNDevCtx : public CUDADevCtx {\r\npublic:\r\n  CUDNNDevCtx(CUDADevCtx* cuda_dev_ctx): cuda_dev_ctx_(cuda_dev_ctx) {}\r\nprivate:\r\n  CUDADevCtx* cuda_dev_ctx_;\r\n};\r\n```\r\n\r\nQuestion 3: If we make DeviceContext as global variables, how do we use different streams for copying data and computation in the same GPU?\r\n\r\n\r\nQuestion 4: If we make DeviceContext as global variables, why we need `DeviceContext` class? Why not just some global functions?",
    "comments_url": "https://api.github.com/repos/PaddlePaddle/Paddle/issues/6676/comments",
    "author": "reyoung",
    "comments": [
      {
        "user": "QiJune",
        "created_at": "2017-12-17T03:17:53Z",
        "body": "> Question 1: How about an operator will need both `NCCL` context and `CUDNN` context? Should we provide an `NCCLAndCUDNNDeviceContext`? Or we just let this operator get two `DeviceContext` instances?\r\n\r\nCUDNN is used to do computation, NCCL is used to do communication. I could not find an operator that both need these two temporarily. If so, we may split this operator into two operators.\r\n\r\n> Question 2: Should we implement a decoration pattern for `CUDNNDevCtx` and `NCCLDevCtx`? \r\n\r\nIt's great If we can reduce codes without losing readability.\r\n\r\n> Question 3: If we make DeviceContext as global variables, how do we use different streams for copying data and computation in the same GPU?\r\n\r\nThere will be at least two streams in a GPU, one for copying, one for computing. So, there will be at least two corresponding DeviecContext.\r\n\r\n> Question 4: If we make DeviceContext as global variables, why we need `DeviceContext` class? Why not just some global functions?\r\n\r\nI think the code lines between `DeviceContext` class and `global functions` are almost the same. If we remove `DeviceConext` class, we will have some global CUDA streams/cublas handles/cudnn handles/mkl handles created first. And we will have some global functions to manipulate these global variables. That's the way which former version paddle does.\r\n\r\n\r\n\r\n"
      },
      {
        "user": "reyoung",
        "created_at": "2017-12-18T02:46:18Z",
        "body": "> There will be at least two streams in a GPU, one for copying, one for computing. So, there will be at least two corresponding DeviceContext.\r\n\r\nSo how do we design this two global DeviceContext?\r\n\r\nShould the global device context be\r\n\r\n```cpp\r\nenum Role {\r\n  kComputation,\r\n  kCommunication\r\n};\r\nstd::map<Place, std::map<enum Role, DeviceContext>> g_dev_ctx;\r\n```"
      },
      {
        "user": "QiJune",
        "created_at": "2017-12-18T03:09:25Z",
        "body": "> Should the global device context be\r\n\r\n```cpp\r\nenum Role {\r\n  kComputation,\r\n  kCommunication\r\n};\r\nstd::map<Place, std::map<enum Role, DeviceContext>> g_dev_ctx;\r\n```\r\n\r\nIn CUDA, we need at least two CUDADeviceContext, one is io, one is computation. I am not sure what will other device/library do, Maybe we can focus on CUDA first and consider to make an abstraction later."
      }
    ]
  },
  {
    "number": 6511,
    "title": "How to optimize data layer in Paddle",
    "created_at": "2017-12-12T07:13:58Z",
    "closed_at": "2018-08-15T11:11:25Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/PaddlePaddle/Paddle/issues/6511",
    "body": "This question is originally asked by a Baidu user. He wants to cheat the pre-trained neural network by just optimizing data layer.\r\n\r\nIn the previous Paddle, the gradient of the data layer is not calculated since it is not necessary for optimizing parameters.\r\n\r\nIn the PaddlePaddle Fuild, we are not separate data/parameter/activation at all. Every variable in a neural network can be optimized.\r\n\r\nI will give an example of cheating a pre-trained neural network.",
    "comments_url": "https://api.github.com/repos/PaddlePaddle/Paddle/issues/6511/comments",
    "author": "reyoung",
    "comments": [
      {
        "user": "shanyi15",
        "created_at": "2018-08-15T11:11:23Z",
        "body": "您好，此issue在近一个月内暂无更新，我们将于今天内关闭。若在关闭后您仍需跟进提问，可重新开启此问题，我们将在24小时内回复您。因关闭带来的不便我们深表歉意，请您谅解~感谢您对PaddlePaddle的支持! \n Hello, this issue has not been updated in the past month. We will close it today for the sake of other user‘s experience. If you still need to follow up on this question after closing, please feel free to reopen it. In that case, we will get back to you within 24 hours. We apologize for the inconvenience caused by the closure and thank you so much for your support of PaddlePaddle Group!"
      }
    ]
  },
  {
    "number": 5879,
    "title": "paddle有支持实时流训练的计划吗？",
    "created_at": "2017-11-23T07:02:28Z",
    "closed_at": "2018-04-17T08:11:29Z",
    "labels": [
      "question",
      "User"
    ],
    "url": "https://github.com/PaddlePaddle/Paddle/issues/5879",
    "body": "目前了解到只能离线训练了，拿到模型，再infer。模型无法做到根据实时流数据更新",
    "comments_url": "https://api.github.com/repos/PaddlePaddle/Paddle/issues/5879/comments",
    "author": "windy444",
    "comments": [
      {
        "user": "reyoung",
        "created_at": "2017-11-23T07:04:02Z",
        "body": "Paddle使用Python作为数据提供器。如果提供数据的时候是流式的提供，譬如一个用Python读消息队列，那么Paddle就可以根据实时流数据更新"
      },
      {
        "user": "lcy-seso",
        "created_at": "2017-11-23T07:06:33Z",
        "body": "@reyoung 我觉得这个问题有两个层面，一个是功能层面，比如从功能层面整个训练是如何在线上进运作的；另一个是算法层面，有一些专门的online学习算法，是否有这方面的要求也需要用户来提供信息。\r\n\r\n如果希望支持请具体的列出一些功能需求。比如：\r\n\r\n1. 期待的训练过程是如何运作；\r\n2. 如何接入实时数据流；\r\n3. 有没有性能要求；\r\n4. 有没有特定算法和模型要求；\r\n……\r\n\r\nPaddle即使支持，也请清晰地描述需求，无法只根据一句话去支持一类功能。\r\n\r\n信息未必需要详尽到列出一个完美需求报告，但也请提供必要且足够的信息，让大家了解需要的功能是什么样子。"
      }
    ]
  },
  {
    "number": 5737,
    "title": "sparse update的原理是什么？开启sparse update虽然会加速，模型的效果会下降吗？",
    "created_at": "2017-11-17T08:45:48Z",
    "closed_at": "2017-11-20T14:39:47Z",
    "labels": [
      "question",
      "User"
    ],
    "url": "https://github.com/PaddlePaddle/Paddle/issues/5737",
    "body": "PaddlePaddle实现的sparse update有没有参考的paper？",
    "comments_url": "https://api.github.com/repos/PaddlePaddle/Paddle/issues/5737/comments",
    "author": "hikkinight",
    "comments": [
      {
        "user": "typhoonzero",
        "created_at": "2017-11-17T10:11:08Z",
        "body": "sparse update是在每一个layer的参数（parameters）optimize时，只更新非0的参数，或者在分布式处理时，只把非0参数发送到parameter server参数更新。在参数足够稀疏时增加optimize速度而不影响效果。"
      }
    ]
  },
  {
    "number": 3508,
    "title": "paddle android  capi加载模型预测结果与v1 api demo的预测结果不一致",
    "created_at": "2017-08-15T15:37:46Z",
    "closed_at": "2017-08-16T09:05:00Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/PaddlePaddle/Paddle/issues/3508",
    "body": "在android平台用capi的预测结果和服务端不一致\r\n\r\n服务端预测相关代码：\r\n    def get_data(self, img_path):\r\n        \"\"\"\r\n        1. load image from img_path.\r\n        2. resize or oversampling.\r\n        3. transformer data: transpose, sub mean.\r\n        return K x H x W ndarray.\r\n        img_path: image path.\r\n        \"\"\"\r\n        image = image_util.load_image(img_path, self.is_color)\r\n        if self.oversample:\r\n            # image_util.resize_image: short side is self.resize_dim\r\n            image = image_util.resize_image(image, self.resize_dim)\r\n            image = np.array(image)\r\n            input = np.zeros(\r\n                (1, image.shape[0], image.shape[1], 3), dtype=np.float32)\r\n            input[0] = image.astype(np.float32)\r\n            input = image_util.oversample(input, self.crop_dims)\r\n        else:\r\n            image = image.resize(self.crop_dims, Image.ANTIALIAS)\r\n            input = np.zeros(\r\n                (1, self.crop_dims[0], self.crop_dims[1], 3), dtype=np.float32)\r\n            input[0] = np.array(image).astype(np.float32)\r\n\r\n        data_in = []\r\n        for img in input:\r\n            img = self.transformer.transformer(img).flatten()\r\n            data_in.append([img.tolist()])\r\n        return data_in\r\n\r\n    def forward(self, input_data):\r\n        in_arg = self.converter(input_data)\r\n        return self.network.forwardTest(in_arg)\r\n\r\n    def forward(self, data, output_layer):\r\n        \"\"\"\r\n        input_data: py_paddle input data.\r\n        output_layer: specify the name of probability, namely the layer with\r\n                      softmax activation.\r\n        return: the predicting probability of each label.\r\n        \"\"\"\r\n        input = self.converter(data)\r\n        self.network.forwardTest(input)\r\n        output = self.network.getLayerOutputs(output_layer)\r\n        # For oversampling, average predictions across crops.\r\n        # If not, the shape of output[name]: (1, class_number),\r\n        # the mean is also applicable.\r\n        return output[output_layer]['value'].mean(0)\r\n    def predict(self, image=None, output_layer=None):\r\n        assert isinstance(image, basestring)\r\n        assert isinstance(output_layer, basestring)\r\n        data = self.get_data(image)\r\n        prob = self.forward(data, output_layer)\r\n        lab = np.argsort(-prob)\r\n        # logging.info(\"Label of %s is: %d\", image, lab[0])\r\n        return lab[0], prob[lab[0]]\r\nandroid paddle capi：我把输入设置贴出来看，其他的就是demo里的，模型加载用paddle_gradient_machine_create_for_inference_with_parameters：\r\n\tfor (int i = 0; i < height; ++i)\r\n\t{\r\n\t\tfor (int j = 0; j < width; ++j)\r\n\t\t{\r\n\t\t\t//opencv brg->rgb\r\n\t\t\tarray[index++] = (paddle_real)frame.at<Vec3b>(i, j)[2]; // R\r\n\t\t\tarray[index++] = (paddle_real)frame.at<Vec3b>(i, j)[1]; // G\r\n\t\t\tarray[index++] = (paddle_real)frame.at<Vec3b>(i, j)[0]; // B\r\n                 }\r\n       }\r\nPS: 模型加载没有日志，没法知道是不是这个模型加载有问题。。",
    "comments_url": "https://api.github.com/repos/PaddlePaddle/Paddle/issues/3508/comments",
    "author": "bushidonggua",
    "comments": [
      {
        "user": "dzhwinter",
        "created_at": "2017-08-15T16:01:25Z",
        "body": "对你用的模型不了解。在图像里mean file常用来做均值减法，把图像里的每个值都减去一个该通道的 mean value(在数据集上对应通道像素值的平均值)。目的是让模型更加稳健，和normalize 是同一个思路。meta_path就不清楚了。mean file这个会影响预测结果，如果训练时候有减去，预测时候也必须减去 mean value.   如果是Android相关问题请问一下 @Xreki "
      }
    ]
  },
  {
    "number": 3407,
    "title": "有关模型存储的问题",
    "created_at": "2017-08-11T03:07:25Z",
    "closed_at": "2018-01-08T03:41:57Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/PaddlePaddle/Paddle/issues/3407",
    "body": "\r\n各位老师好，我最近刚刚开始学习paddlepaddle，对于模型存储方面有一些疑惑。\r\n1. 请问在模型存储时新一轮pass的参数值会不会覆盖上一次存储的值？\r\n2. 如果新的参数值不会覆盖之前的值，那在加载模型时是自动选择cost最小的模型还是选择最近一次存储的模型？\r\n3. 如何保证存储的模型一定是当前效果最好的模型（或者说cost最小的），又或者如何保证加载的模型一定是效果最好的模型？",
    "comments_url": "https://api.github.com/repos/PaddlePaddle/Paddle/issues/3407/comments",
    "author": "dockiHan",
    "comments": [
      {
        "user": "reyoung",
        "created_at": "2017-08-11T05:15:35Z",
        "body": "> 请问在模型存储时新一轮pass的参数值会不会覆盖上一次存储的值？\r\n\r\n使用Python驱动Paddle训练，用户保存模型的时候，可以选择保存的文件名。用户可以配置是否覆盖。\r\n使用paddle train二进制训练Paddle，每一次保存都是新的文件\r\n\r\n> 如果新的参数值不会覆盖之前的值，那在加载模型时是自动选择cost最小的模型还是选择最近一次存储的模型？\r\n\r\n如果使用Python驱动Paddle训练，用户可以在写程序时，记录下一个cost最小的模型队列。进而选择cost最小的模型\r\n如果使用paddle train二进制训练Paddle，需要用户自己解析配置文件，选择cost最小的模型。\r\n\r\n> 如何保证存储的模型一定是当前效果最好的模型（或者说cost最小的），又或者如何保证加载的模型一定是效果最好的模型？\r\n\r\n和问题2一致。"
      }
    ]
  },
  {
    "number": 3362,
    "title": "ubuntu 16.04  docker 安装失败",
    "created_at": "2017-08-09T12:49:07Z",
    "closed_at": "2017-08-10T00:05:35Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/PaddlePaddle/Paddle/issues/3362",
    "body": "###执行如下命令\r\nsudo docker run -d -p 3333:22 -p 11111:8888 docker.paddlepaddle.org/paddle:0.10.0-dev\r\nUnable to find image 'docker.paddlepaddle.org/paddle:0.10.0-dev' locally\r\n0.10.0-dev: Pulling from paddle\r\n8f229c550c2e: Pull complete\r\n8e1fb71e8df6: Pull complete\r\nf75a34586856: Pull complete\r\n8744e322b832: Pull complete\r\nd5165bfce78f: Pull complete\r\nc350e060f1db: Pull complete\r\nccabcb470eb7: Pull complete\r\n8324d9bfba85: Pull complete\r\n6c1fd41d1688: Pull complete\r\naf86b8b1415a: Pull complete\r\n533ede042dd1: Pull complete\r\naa427fe59157: Pull complete\r\nc31a1fcce111: Pull complete\r\n58adae1ed11f: Pull complete\r\nafb366c49a8c: Pull complete\r\n5d37668cede0: Pull complete\r\n5b695de39932: Pull complete\r\n7f0ab2bc4560: Pull complete\r\ncbf3e74d759c: Pull complete\r\n530f1fcaf731: Pull complete\r\n0d1f487575a3: Pull complete\r\nc682a22f9118: Pull complete\r\n5e98db544738: Pull complete\r\nDigest: sha256:0a0620e6896906701c1fe120637337aecaf8fc3fbae86250dccc19d0d8051b2c\r\nStatus: Downloaded newer image for docker.paddlepaddle.org/paddle:0.10.0-dev\r\nf2e33cc6003f823f8aec95654ed95518758fdee16bf4ac3d5337a1b3fb49e46d\r\n\r\n###执行 docker logs 命令，给出如下提示\r\nbash: /paddle/paddle/scripts/docker/build.sh: No such file or directory",
    "comments_url": "https://api.github.com/repos/PaddlePaddle/Paddle/issues/3362/comments",
    "author": "xmuyong",
    "comments": [
      {
        "user": "xmuyong",
        "created_at": "2017-08-09T13:34:07Z",
        "body": "用  docker run -d -p 3333:22 -p 11111:8888 paddlepaddle/paddle:0.10.0-dev /usr/sbin/sshd -D  可以"
      },
      {
        "user": "xmuyong",
        "created_at": "2017-08-09T13:34:29Z",
        "body": "ssh -p 3333 root@localhost"
      },
      {
        "user": "xmuyong",
        "created_at": "2017-08-09T13:34:35Z",
        "body": "密码 root"
      },
      {
        "user": "helinwang",
        "created_at": "2017-08-10T00:05:35Z",
        "body": "您好，用\r\n```\r\n$ sudo docker run -it docker.paddlepaddle.org/paddle:0.10.0-dev bash\r\n``` \r\n或者像您说的\r\n```\r\n$ sudo docker run -d -p 3333:22 -p 11111:8888 docker.paddlepaddle.org/paddle:0.10.0-dev /usr/sbin/sshd -D\r\n```\r\n都可以。"
      }
    ]
  },
  {
    "number": 1987,
    "title": "通过python接口预估多类型instance问题",
    "created_at": "2017-05-03T12:35:29Z",
    "closed_at": "2017-08-03T12:30:08Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/PaddlePaddle/Paddle/issues/1987",
    "body": "请教一下，在预估阶段，paddle如何实现封装 读取包含sequence和dense slot类型的raw data并进行预估？\r\nDataProviderWrapperConverter方法好像需要通过初始化use_seq来校验instance中的数据类型，无法识别一条instance内的sequence/non-sequence类型？",
    "comments_url": "https://api.github.com/repos/PaddlePaddle/Paddle/issues/1987/comments",
    "author": "RainyZh",
    "comments": [
      {
        "user": "reyoung",
        "created_at": "2017-05-03T13:43:50Z",
        "body": "@luotao1 看起来这个问题也和我们如何使用Python预测的文档相关。不知该文档目前谁在优化？"
      },
      {
        "user": "lcy-seso",
        "created_at": "2017-05-03T13:58:26Z",
        "body": "我们是不是可以帮用户先快速地解决一下这个问题呢 ？"
      },
      {
        "user": "luotao1",
        "created_at": "2017-05-04T03:14:41Z",
        "body": "@reyoung 目前没有Python预测的相关文档。"
      },
      {
        "user": "wanghaoshuang",
        "created_at": "2017-08-03T12:30:08Z",
        "body": "Closing this issue due to inactivity, feel free to reopen it."
      },
      {
        "user": "everal",
        "created_at": "2018-02-09T08:44:21Z",
        "body": "现在有相应的例子或者文档说明这部分Python接口的使用了么？V2版本的看看Python代码还能搞明白infer的使用，但是V1版本真的完全摸不着怎么写"
      }
    ]
  },
  {
    "number": 1629,
    "title": "TrainerConfigHelpers会停止支持吗",
    "created_at": "2017-03-17T03:22:08Z",
    "closed_at": "2017-08-04T09:47:25Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/PaddlePaddle/Paddle/issues/1629",
    "body": "API V2推出后，trainer_config_helpers还会继续支持吗？",
    "comments_url": "https://api.github.com/repos/PaddlePaddle/Paddle/issues/1629/comments",
    "author": "wondervictor",
    "comments": [
      {
        "user": "reyoung",
        "created_at": "2017-03-17T06:01:54Z",
        "body": "@wondervictor 会的。\r\n\r\n这两个API在网络配置上形式基本一致，用的也是一套代码。\r\n\r\n事实上，我们下周、下下周的工作之一，是将二者完全依赖同一套代码。这样，我们就可以同步更新两套API了。"
      },
      {
        "user": "jacquesqiao",
        "created_at": "2017-07-26T12:40:22Z",
        "body": "question answered"
      }
    ]
  },
  {
    "number": 1448,
    "title": "Dataprovider",
    "created_at": "2017-02-24T07:31:38Z",
    "closed_at": "2017-10-23T10:23:15Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/PaddlePaddle/Paddle/issues/1448",
    "body": "请问PaddlePaddle在在输入二维数组时，init_hook中的input_type应该怎么设置？？？？data_Layer中的size应该怎么写？？\r\n",
    "comments_url": "https://api.github.com/repos/PaddlePaddle/Paddle/issues/1448/comments",
    "author": "studyPaddle",
    "comments": [
      {
        "user": "reyoung",
        "created_at": "2017-02-24T07:59:28Z",
        "body": "@studyPaddle 有一个基本的问题，为什么输入数据是二维的呢？是图像么？如果是图像的话，请参考Paddle的图像识别demo。\r\n\r\nPaddle对图像的处理，是将二维数据变成一维数据，然后在卷积层里面处理图像的长和宽的。\r\n\r\n如果是其他需求，请说明输入数据是什么。"
      },
      {
        "user": "swords123",
        "created_at": "2017-02-26T13:30:48Z",
        "body": "文档中：\r\nPaddlePaddle的数据包括四种主要类型，和三种序列模式。其中，四种数据类型是\r\ndense_vector 表示稠密的浮点数向量。\r\nsparse_binary_vector 表示稀疏的零一向量，即大部分值为0，有值的位置只能取1\r\nsparse_vector 表示稀疏的向量，即大部分值为0，有值的部分可以是任何浮点数\r\ninteger 表示整数标签。\r\n而三种序列模式为\r\n\r\nSequenceType.NO_SEQUENCE 即不是一条序列\r\nSequenceType.SEQUENCE 即是一条时间序列\r\nSequenceType.SUB_SEQUENCE 即是一条时间序列，且序列的每一个元素还是一个时间序列。\r\n不同的数据类型和序列模式返回的格式不同，列表如下\r\n\r\n \tNO_SEQUENCE\tSEQUENCE\tSUB_SEQUENCE\r\ndense_vector\t[f, f, ...]\t[[f, ...], [f, ...], ...]\t[[[f, ...], ...], [[f, ...], ...],...]\r\nsparse_binary_vector\t[i, i, ...]\t[[i, ...], [i, ...], ...]\t[[[i, ...], ...], [[i, ...], ...],...]\r\nsparse_vector\t[(i,f), (i,f), ...]\t[[(i,f), ...], [(i,f), ...], ...]\t[[[(i,f), ...], ...], [[(i,f), ...], ...],...]\r\ninteger_value\ti\t[i, i, ...]\t[[i, ...], [i, ...], ...]\r\n其中，f代表一个浮点数，i代表一个整数。\r\n\r\n\r\n其中\tSEQUENC和SUB_SEQUENCE两种数据类型，输入时如何配置？？都要转换成1维数组吗？我如果需要保留二维的信息怎么办？？"
      },
      {
        "user": "swords123",
        "created_at": "2017-02-26T13:31:17Z",
        "body": "@reyoung "
      },
      {
        "user": "lcy-seso",
        "created_at": "2017-10-23T10:23:15Z",
        "body": "读取数据格式相关的信息，可以在Paddle的文档区查找信息。\r\n由于长时间没有信息更新，我先close掉此issue。如果有进一步的信息，可以reopen后继续交流。"
      }
    ]
  },
  {
    "number": 1437,
    "title": "训练RNN在K80上为什么还没有CPU跑得快？",
    "created_at": "2017-02-23T10:03:08Z",
    "closed_at": "2017-11-07T11:49:33Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/PaddlePaddle/Paddle/issues/1437",
    "body": "我的机器CPU配置是24核，cpu型号是 Intel(R) Xeon(R) CPU E5-2680 v3 @ 2.50GH \r\n最近在用paddle写rnn的应用，本来在K80上做，以为是本身计算慢\r\n但偶然间发现，在CPU上直接运行反而更快\r\n运行是k80上显存一直在200M，但内存的利用率却很高，系统是centos-7.2\r\n而我在我的另一台服务器用的GTX1070表现的却比较正常，显存也可以达到2GB左右的占用，而那个系统是ubuntu16.04的\r\n所以是在centos上用的源码安装，而paddle源码安装只支持ubuntu的系统差异造成的？\r\n还是GPU的原因？\r\n又或者是我没加什么运行或者编译的参数造成的？\r\n但我记得GTX1070的GFLOPS没有K80的高\r\n望解答\r\n@reyoung @luotao1 ",
    "comments_url": "https://api.github.com/repos/PaddlePaddle/Paddle/issues/1437/comments",
    "author": "lcxaiw",
    "comments": [
      {
        "user": "ZhangXinNan",
        "created_at": "2017-08-08T01:47:35Z",
        "body": "同问？"
      }
    ]
  },
  {
    "number": 1430,
    "title": "How to set a 2-dimensional vector to input_types?",
    "created_at": "2017-02-23T04:26:31Z",
    "closed_at": "2017-08-21T18:20:57Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/PaddlePaddle/Paddle/issues/1430",
    "body": "I want to input a 30*50 matrix to data_layer like [[......],[......],[......],......] , but after I set settings.input_type as below , there occurs an error.\r\n\r\n`\r\nsettings.input_types = [dense_vector(30,seq_type=SequenceType.SEQUENCE),dense_vector(50,seq_type=SequenceType.SEQUENCE)]`\r\n\r\nI'd be very grateful if anyone can help.\r\n",
    "comments_url": "https://api.github.com/repos/PaddlePaddle/Paddle/issues/1430/comments",
    "author": "17Skye17",
    "comments": [
      {
        "user": "JiayiFeng",
        "created_at": "2017-08-21T18:20:57Z",
        "body": "Close this issue due to inactivity. please feel free to reopen it if more information is available"
      }
    ]
  },
  {
    "number": 1404,
    "title": "关于sparse update和test问题",
    "created_at": "2017-02-21T10:43:33Z",
    "closed_at": "2017-08-08T17:01:34Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/PaddlePaddle/Paddle/issues/1404",
    "body": "有两个问题有些不解：\r\n1. 看之前的issue提到sparse update和test不能共存。将define_by_data_sources2()中的test_list设置成none即可。现在有没有更好的解决方案？\r\n\r\n2. 如果train和test分离，那如何提交一个只有test的任务给集群？ 比如加载几个指定PASS的model，在测试集上做evaluation？ \r\n\r\n",
    "comments_url": "https://api.github.com/repos/PaddlePaddle/Paddle/issues/1404/comments",
    "author": "fishfly3384",
    "comments": [
      {
        "user": "Yancey1989",
        "created_at": "2017-08-08T17:01:34Z",
        "body": "Close this inactivate issue, please feel free to reopen."
      }
    ]
  },
  {
    "number": 1359,
    "title": "【discuss】分布式paddle性能问题，cpu集群",
    "created_at": "2017-02-17T06:51:49Z",
    "closed_at": "2017-08-02T07:08:30Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/PaddlePaddle/Paddle/issues/1359",
    "body": "具体场景如下：\r\n1. 使用一个单元的simple_gru2网络，在cpu集群上运行\r\n2.输入数据为序列（长度为2个词），然后预测第3个词，词表大小为200万\r\n3.训练节点采用100，单个节点batch_size为2000，trainer_count为32，优化方法为momentum sync\r\n4.每个节点cpu利用率比较低\r\n现在训练速度为 9.3s训练1万样本，非常慢，请问这个性能是否符合预期，有没有优化的建议？",
    "comments_url": "https://api.github.com/repos/PaddlePaddle/Paddle/issues/1359/comments",
    "author": "pkuyym",
    "comments": [
      {
        "user": "hedaoyuan",
        "created_at": "2017-02-20T02:43:22Z",
        "body": "1. 如果集群的CPU是支持AVX的，可以使用一个AVX版本的paddle，会快一些。\r\n```\r\n# paddle version\r\n    with_avx: ON\r\n\r\n```\r\n2. 试试减少trainer_count，增大batch_size；应该能提升训练速度。\r\n3. `训练速度为 9.3s训练1万样本`  这个没法判断，这个是怎么测试出来的？总样本是多少？"
      },
      {
        "user": "pkuyym",
        "created_at": "2017-02-20T05:10:36Z",
        "body": "@hedaoyuan \r\n1. 是avx版本\r\n2.batch_size已经是最大量级，减少trainer_count，我理解应该是减少线程竞争，增大cpu利用率，感觉不能带来量级上的提升\r\n3.一共5万个样本，迭代6轮取平均的结果，平均每轮46.7s\r\n现在想看一下性能是否正常，以及是否存在配置上的优化，可以大幅提升性能（几十倍）"
      },
      {
        "user": "hedaoyuan",
        "created_at": "2017-02-20T05:21:27Z",
        "body": "5万个样本为什么要用100个节点跑？另外，减少trainer_count，不会带来数量级上的性能提升，不过能够对`每个节点cpu利用率比较低`这个问题有帮助。"
      },
      {
        "user": "pkuyym",
        "created_at": "2017-02-20T05:53:36Z",
        "body": "@hedaoyuan 现在是做性能测试，对比单机、多机的性能，所以用的比较小的数据集"
      }
    ]
  },
  {
    "number": 1348,
    "title": "集群无法提交，关于receiver配置",
    "created_at": "2017-02-16T07:17:16Z",
    "closed_at": "2017-02-20T03:43:04Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/PaddlePaddle/Paddle/issues/1348",
    "body": "内网用户更换了多个receiver仍然无法提交，麻烦能整理下集群支持的receiver嘛？\r\n",
    "comments_url": "https://api.github.com/repos/PaddlePaddle/Paddle/issues/1348/comments",
    "author": "zhangyong15",
    "comments": [
      {
        "user": "reyoung",
        "created_at": "2017-02-20T03:43:04Z",
        "body": "Recievers的列表请在内网与Paddle开发人员联系查阅。github上不太适宜公开。"
      }
    ]
  },
  {
    "number": 1340,
    "title": "paddle支持batch normalztion 双向rnn吗？并且带有clip relu的功能？",
    "created_at": "2017-02-15T07:39:15Z",
    "closed_at": "2017-07-23T02:05:54Z",
    "labels": [
      "question",
      "User"
    ],
    "url": "https://github.com/PaddlePaddle/Paddle/issues/1340",
    "body": "paddle支持batch normalztion 双向rnn吗？并且带有clip relu的功能？",
    "comments_url": "https://api.github.com/repos/PaddlePaddle/Paddle/issues/1340/comments",
    "author": "ghost",
    "comments": [
      {
        "user": "qingqing01",
        "created_at": "2017-02-16T11:21:24Z",
        "body": "不是特别理解 \"batch normalization 双向rnn\" 是如何操作的，您可以再详细描述下嘛？ 或者给个参考也可以。 \"带有clip relu\" 指的是什么呢？ 对ReLU激活后做clip吗？"
      },
      {
        "user": "luotao1",
        "created_at": "2017-02-20T07:07:01Z",
        "body": "@guoying1030 请问您说的是“Batch Renormalization: Towards Reducing Minibatch Dependence in Batch-Normalized Models”么？"
      },
      {
        "user": "QiJune",
        "created_at": "2017-07-23T02:05:54Z",
        "body": "长时间没有更新，暂时close；如有进一步更新，欢迎reopen"
      }
    ]
  },
  {
    "number": 1299,
    "title": "mac 安装错误",
    "created_at": "2017-02-09T06:06:21Z",
    "closed_at": "2017-02-10T10:01:03Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/PaddlePaddle/Paddle/issues/1299",
    "body": "[Paddle] Python Executable: /usr/bin/python2.7\r\n[Paddle] Python Include: /usr/include/python2.7\r\n[Paddle] Python Libraries: /usr/lib/libpython2.7.dylib\r\nCMake Error at cmake/external/openblas.cmake:36 (MESSAGE):\r\n  To build lapack in libopenblas, you need to set gfortran compiler: cmake ..\r\n  -DCMAKE_Fortran_COMPILER=...\r\nCall Stack (most recent call first):\r\n  CMakeLists.txt:64 (include)\r\n\r\n需要自主安装一个？还是配置错了.\r\n",
    "comments_url": "https://api.github.com/repos/PaddlePaddle/Paddle/issues/1299/comments",
    "author": "VamWolf",
    "comments": [
      {
        "user": "gangliao",
        "created_at": "2017-02-09T06:08:40Z",
        "body": "@VamWolf \r\n有两种方法解决这个问题：\r\n\r\n因为如果系统不存在blas库，paddle会自行去下载编译openblas, openblas编译依赖于gfortran.\r\n\r\n第一种方法：brew install openblas\r\n第二种方法：brew install gcc"
      },
      {
        "user": "gangliao",
        "created_at": "2017-02-09T06:38:09Z",
        "body": "@VamWolf  any update？\r\n"
      },
      {
        "user": "VamWolf",
        "created_at": "2017-02-09T09:23:50Z",
        "body": "blas 的问题搞定了。\b\r\n新问题是\r\nCMake Error at cmake/configure.cmake:48 (message):\r\n  Paddle need cudnn to compile\r\nCall Stack (most recent call first):\r\n  CMakeLists.txt:78 (include)"
      },
      {
        "user": "VamWolf",
        "created_at": "2017-02-09T09:24:26Z",
        "body": "求解决方案"
      },
      {
        "user": "VamWolf",
        "created_at": "2017-02-09T09:26:03Z",
        "body": "这个库我下载下来安装了"
      },
      {
        "user": "gangliao",
        "created_at": "2017-02-09T09:27:55Z",
        "body": "```\r\ncmake -DCUDNN_ROOT=xxx  ..\r\n```\r\n@VamWolf \r\n\r\n你Mac有gpu?"
      },
      {
        "user": "gangliao",
        "created_at": "2017-02-10T10:00:37Z",
        "body": "@VamWolf misunderstand his Mac OS X equipped with GPU when compiling paddle.\r\n\r\nI closed this issue.\r\n\r\n"
      }
    ]
  },
  {
    "number": 1294,
    "title": "paddle源码编译遇到问题",
    "created_at": "2017-02-08T10:09:59Z",
    "closed_at": "2017-02-09T03:17:58Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/PaddlePaddle/Paddle/issues/1294",
    "body": "内部用户，使用提供的build.sh进行编译，提示\r\nfatal error: TrainerConfig.pb.h: No such file or directory，编译失败，下载的是最新的开发分支，请问是什么问题呢",
    "comments_url": "https://api.github.com/repos/PaddlePaddle/Paddle/issues/1294/comments",
    "author": "leanna62",
    "comments": [
      {
        "user": "gangliao",
        "created_at": "2017-02-08T11:14:24Z",
        "body": "你好，之前维护的一键编译并不支持Paddle的最新代码，可以考虑使用最新的一键编译脚本编译Paddle最新代码.\r\n@leanna62 \r\n脚本在icode上面, 具体地址请参考 #1283 icode: baidu/idl/paddle_internal_release_tools\r\n"
      },
      {
        "user": "leanna62",
        "created_at": "2017-02-08T11:17:53Z",
        "body": "用的就是icode上面的这个脚本，编译的github上的最新分支出现的这个问题 @gangliao "
      },
      {
        "user": "gangliao",
        "created_at": "2017-02-08T11:19:51Z",
        "body": "@leanna62  你提供的信息好少，重新 rm -rf Paddle, 重新 sh build.sh试一试， 请贴一下错误详情。"
      },
      {
        "user": "leanna62",
        "created_at": "2017-02-08T12:13:18Z",
        "body": "好的，详细信息如下：\r\n`make[2]: *** [paddle/function/CMakeFiles/paddle_function.dir/ContextProjectionOp.cpp.o] Error 1\r\nIn file included from /home/work/paddle_new/paddle_internal_release_tools/idl/paddle/Paddle/paddle/utils/ThreadLocal.h:25:0,\r\n                 from /home/work/paddle_new/paddle_internal_release_tools/idl/paddle/Paddle/paddle/math/Matrix.h:22,\r\n                 from /home/work/paddle_new/paddle_internal_release_tools/idl/paddle/Paddle/paddle/function/TensorType.h:17,\r\n                 from /home/work/paddle_new/paddle_internal_release_tools/idl/paddle/Paddle/paddle/function/BufferArg.h:20,\r\n                 from /home/work/paddle_new/paddle_internal_release_tools/idl/paddle/Paddle/paddle/function/Function.h:19,\r\n                 from /home/work/paddle_new/paddle_internal_release_tools/idl/paddle/Paddle/paddle/function/CrossMapNormalOp.h:17,\r\n                 from /home/work/paddle_new/paddle_internal_release_tools/idl/paddle/Paddle/paddle/function/CrossMapNormalOp.cpp:15:\r\n/home/work/paddle_new/paddle_internal_release_tools/idl/paddle/Paddle/paddle/utils/Util.h:31:30: fatal error: TrainerConfig.pb.h: No such file or directory\r\n #include \"TrainerConfig.pb.h\"\r\n                              ^\r\ncompilation terminated.\r\nmake[2]: *** [paddle/function/CMakeFiles/paddle_function.dir/CrossMapNormalOp.cpp.o] Error 1\r\nIn file included from /home/work/paddle_new/paddle_internal_release_tools/idl/paddle/Paddle/paddle/utils/ThreadLocal.h:25:0,\r\n                 from /home/work/paddle_new/paddle_internal_release_tools/idl/paddle/Paddle/paddle/math/Matrix.h:22,\r\n                 from /home/work/paddle_new/paddle_internal_release_tools/idl/paddle/Paddle/paddle/function/TensorType.h:17,\r\n                 from /home/work/paddle_new/paddle_internal_release_tools/idl/paddle/Paddle/paddle/function/BufferArg.h:20,\r\n                 from /home/work/paddle_new/paddle_internal_release_tools/idl/paddle/Paddle/paddle/function/Function.h:19,\r\n                 from /home/work/paddle_new/paddle_internal_release_tools/idl/paddle/Paddle/paddle/function/Function.cpp:15:\r\n/home/work/paddle_new/paddle_internal_release_tools/idl/paddle/Paddle/paddle/utils/Util.h:31:30: fatal error: TrainerConfig.pb.h: No such file or directory\r\n #include \"TrainerConfig.pb.h\"\r\n                              ^\r\ncompilation terminated.\r\nmake[2]: *** [paddle/function/CMakeFiles/paddle_function.dir/Function.cpp.o] Error 1\r\nmake[1]: *** [paddle/function/CMakeFiles/paddle_function.dir/all] Error 2`"
      },
      {
        "user": "gangliao",
        "created_at": "2017-02-09T02:10:44Z",
        "body": "能否hi下我"
      },
      {
        "user": "leanna62",
        "created_at": "2017-02-09T02:23:17Z",
        "body": "好的"
      },
      {
        "user": "leanna62",
        "created_at": "2017-02-09T03:17:52Z",
        "body": "感谢 @gangliao  提供最新的工具，已经解决编译问题了～"
      }
    ]
  },
  {
    "number": 1274,
    "title": "在编译paddle时，with_metric_learning和with_predict_sdk分别是什么含义？",
    "created_at": "2017-02-07T03:35:25Z",
    "closed_at": "2017-03-14T11:35:11Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/PaddlePaddle/Paddle/issues/1274",
    "body": "",
    "comments_url": "https://api.github.com/repos/PaddlePaddle/Paddle/issues/1274/comments",
    "author": "dingjie1234",
    "comments": [
      {
        "user": "luotao1",
        "created_at": "2017-02-08T07:21:58Z",
        "body": "with_metric_learning是之前metric_learning目录编译的控制开关，现在这个目录已经没有了，所以 @reyoung @gangliao 要不要把这个编译选项给去掉？"
      },
      {
        "user": "gangliao",
        "created_at": "2017-03-14T06:56:56Z",
        "body": "可以去掉了吧。 @reyoung "
      }
    ]
  },
  {
    "number": 1190,
    "title": "train启动的时候提示\u000bCUDNN_STATUS_NOT_INITIALIZED ",
    "created_at": "2017-01-19T05:35:12Z",
    "closed_at": "2017-02-01T17:05:11Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/PaddlePaddle/Paddle/issues/1190",
    "body": "F0119 13:28:50.834202  2944 hl_cuda_cudnn.cc:186] Check failed: CUDNN_STATUS_SUCCESS == cudnnStat (0 vs. 1) Cudnn Error: CUDNN_STATUS_NOT_INITIALIZED\r\n*** Check failure stack trace: ***\r\n    @          0x147b738  google::LogMessage::Fail()\r\n    @          0x147b690  google::LogMessage::SendToLog()\r\n    @          0x147b125  google::LogMessage::Flush()\r\n    @          0x147dee6  google::LogMessageFatal::~LogMessageFatal()\r\n    @           0x935a3a  hl_cudnn_init()\r\n    @           0x93f791  hl_create_global_resources()\r\n    @           0x93ffa9  hl_specify_devices_start()\r\n    @           0x9403cd  hl_start()\r\n    @           0x8aeb7b  paddle::initMain()\r\n    @           0x5b833f  main\r\n    @     0x7f7fd6775bd5  __libc_start_main\r\n    @           0x5cdfa5  (unknown)\r\n/home/aducz/paddle/paddle_internal_release_tools/idl/paddle/output/bin/paddle_local: line 109:  2944 Aborted                 (core dumped) ${DEBUGGER} $MYDIR/../opt/paddle/bin/paddle_trainer ${@:2} ",
    "comments_url": "https://api.github.com/repos/PaddlePaddle/Paddle/issues/1190/comments",
    "author": "colin1988",
    "comments": [
      {
        "user": "gangliao",
        "created_at": "2017-01-19T05:41:09Z",
        "body": "@colin1988  This error seems that you need to upgrade CUDA Driver. @hedaoyuan "
      },
      {
        "user": "helinwang",
        "created_at": "2017-02-01T17:05:11Z",
        "body": "Closing this issue for now. @colin1988 If updating CUDA driver does not solve your problem. Please reopen this issue."
      }
    ]
  },
  {
    "number": 1052,
    "title": "cluster加载init_model_path报错，但查看hdfs上是有该文件",
    "created_at": "2017-01-03T03:21:36Z",
    "closed_at": "2017-01-03T06:42:09Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/PaddlePaddle/Paddle/issues/1052",
    "body": "训练AlexNetmodel，几百个pass后错误率不下降。因此使用--init_model_path加载已有模型。\r\n--init_model_path /app/msbu/dpp/qubingxin/paddle/skin_disease/disease_subpic_5/output_20161230112232/model_output/pass-00366\r\n\r\n报错如下：\r\nI0103 10:54:17.418300 19798 GradientMachine.cpp:142] Loading parameters from /app/msbu/dpp/qubingxin/paddle/skin_disease/disease_subpic_5/output_20161230112232/model_output/pass-00366\r\nI0103 10:54:17.418331 19798 Parameter.cpp:339] missing parameters [/app/msbu/dpp/qubingxin/paddle/skin_disease/disease_subpic_5/output_20161230112232/model_output/pass-00366/___conv_0__.w0] while loading model.\r\nF0103 10:54:17.418344 19798 Parameter.cpp:345] ___conv_0__.w0 missing, not allowed. \r\n\r\n用hadoop fs -ls 查看该目录下，___conv_0__.w0是存在的，请问怎么解决？",
    "comments_url": "https://api.github.com/repos/PaddlePaddle/Paddle/issues/1052/comments",
    "author": "qubingxin",
    "comments": [
      {
        "user": "qubingxin",
        "created_at": "2017-01-03T03:42:31Z",
        "body": "此外，能否提供针对paddle_platform平台的alexnet模型提供pyDataProvider2的demo？ 目前的不是"
      },
      {
        "user": "reyoung",
        "created_at": "2017-01-03T05:53:41Z",
        "body": "Hadoop的HDFS上面有不代表同时传递到MPI节点上了，也就是运行那个Paddle进程的机器里面没有这些参数。解决办法是\r\n\r\n* 将对应参数和Paddle的二进制一起打包传到MPI上。然后修改`--init_model_path `到MPI下的某个路径。\r\n* 或者，直接修改paddle的训练脚本，在mpi上从HDFS下下载这些参数。"
      },
      {
        "user": "qubingxin",
        "created_at": "2017-01-03T06:01:40Z",
        "body": "直接修改paddle的训练脚本，在mpi上从HDFS下下载这些参数。这个方法能否提供一个demo？目前是在cluster_config里添加model_path参数，不起作用"
      },
      {
        "user": "qubingxin",
        "created_at": "2017-01-03T06:42:09Z",
        "body": "在cluster_config中添加init_model_path，可解决，之前问题是添加了model_path"
      }
    ]
  },
  {
    "number": 923,
    "title": "paddle训练使用多cpu不如单cpu速度快",
    "created_at": "2016-12-16T05:42:40Z",
    "closed_at": "2016-12-21T03:47:49Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/PaddlePaddle/Paddle/issues/923",
    "body": "在服务器上建立了1,2,4,8个cpu的镜像，当trainner_counter分别设置为1,2,4,8时发现速度逐渐变慢，全部设置为1时，速度相当。说明paddle并没有利用多cpu啊",
    "comments_url": "https://api.github.com/repos/PaddlePaddle/Paddle/issues/923/comments",
    "author": "janelu9",
    "comments": [
      {
        "user": "janelu9",
        "created_at": "2016-12-16T05:52:12Z",
        "body": "版本是0.9.0a0\r\nwith_avx: ON\r\n    with_gpu: OFF\r\n    with_double: OFF\r\n    with_python: ON\r\n    with_rdma: OFF\r\n    with_glog: ON\r\n    with_gflags: ON\r\n    with_metric_learning:\r\n    with_timer: OFF"
      },
      {
        "user": "reyoung",
        "created_at": "2016-12-16T05:54:14Z",
        "body": "@janelu9 最可能的原因是batch_size设置的过小，导致计算线程大量空闲。\r\n\r\n同时，读数据的DataProvider可能写的太慢，导致时间占用都在读数据上。"
      },
      {
        "user": "backyes",
        "created_at": "2016-12-16T09:59:45Z",
        "body": "@janelu9 \r\n\r\n* 比较快速做一些排除分析，比如可以加大batch size，排除是否是mini-batch很小的原因。 \r\n\r\n* 另外如果有兴趣深入分析原因， 也可以从源码编译Paddle， 并使能WITH_TIMER， 可以获取更加量化的分析。\r\n\r\n"
      },
      {
        "user": "backyes",
        "created_at": "2016-12-16T10:00:27Z",
        "body": "@janelu9 \r\n\r\n> 在服务器上建立了1,2,4,8个cpu的镜像\r\n\r\n另外，不知道这些是否都是物理核个数"
      },
      {
        "user": "janelu9",
        "created_at": "2016-12-20T08:29:25Z",
        "body": "@backyes  物理核心有2个 逻辑48个 256G内存 suse12系统"
      },
      {
        "user": "janelu9",
        "created_at": "2016-12-21T00:30:26Z",
        "body": "加大batch_size等于成倍减少训练次数 肯定训练的时间会缩短了 但是精度会下降 "
      },
      {
        "user": "reyoung",
        "created_at": "2016-12-21T03:47:49Z",
        "body": "duplicated #957  不过这里很多想法是错的。。比如加大batch_size不一定成比例增加训练次数。\r\n\r\n到issue #957 讨论吧"
      },
      {
        "user": "janelu9",
        "created_at": "2016-12-21T06:51:31Z",
        "body": "@reyoung 额 不是训练次数 那是迭代次数了 不过每次迭代的计算量不一样了"
      }
    ]
  },
  {
    "number": 902,
    "title": "单层softmax训练报错NotImplementedError",
    "created_at": "2016-12-15T03:23:54Z",
    "closed_at": "2017-09-10T09:01:36Z",
    "labels": [
      "Bug",
      "question"
    ],
    "url": "https://github.com/PaddlePaddle/Paddle/issues/902",
    "body": "Traceback (most recent call last):\r\nThu Dec 15 11:16:14 2016[1,37]<stderr>:  File \"workspace/python27-gcc482/lib/python2.7/site-packages/paddle/trainer/config_parser.py\", line 3408, in parse_config_and_serialize\r\nThu Dec 15 11:16:14 2016[1,37]<stderr>:    config = parse_config(config_file, config_arg_str)\r\nThu Dec 15 11:16:14 2016[1,37]<stderr>:  File \"workspace/python27-gcc482/lib/python2.7/site-packages/paddle/trainer/config_parser.py\", line 3384, in parse_config\r\nThu Dec 15 11:16:14 2016[1,37]<stderr>:    execfile(config_file, make_config_environment(config_file, config_args))\r\nThu Dec 15 11:16:14 2016[1,37]<stderr>:  File \"conf/trainer_config.conf\", line 63, in <module>\r\nThu Dec 15 11:16:14 2016[1,37]<stderr>:    regularization=L2Regularization(8e-4)\r\nThu Dec 15 11:16:14 2016[1,37]<stderr>:  File \"workspace/python27-gcc482/lib/python2.7/site-packages/paddle/trainer_config_helpers/default_decorators.py\", line 53, in __wrapper__\r\nThu Dec 15 11:16:14 2016[1,37]<stderr>:    return func(*args, **kwargs)\r\nThu Dec 15 11:16:14 2016[1,37]<stderr>:  File \"workspace/python27-gcc482/lib/python2.7/site-packages/paddle/trainer_config_helpers/default_decorators.py\", line 53, in __wrapper__\r\nThu Dec 15 11:16:14 2016[1,37]<stderr>:    return func(*args, **kwargs)\r\nThu Dec 15 11:16:14 2016[1,37]<stderr>:  File \"workspace/python27-gcc482/lib/python2.7/site-packages/paddle/trainer_config_helpers/optimizers.py\", line 422, in settings\r\nThu Dec 15 11:16:14 2016[1,37]<stderr>:    kwargs = __extends__(kwargs, learning_method.to_setting_kwargs())\r\nThu Dec 15 11:16:14 2016[1,37]<stderr>:  File \"workspace/python27-gcc482/lib/python2.7/site-packages/paddle/trainer_config_helpers/optimizers.py\", line 71, in to_setting_kwargs\r\nThu Dec 15 11:16:14 2016[1,37]<stderr>:    raise NotImplementedError()\r\nThu Dec 15 11:16:14 2016[1,37]<stderr>:NotImplementedError",
    "comments_url": "https://api.github.com/repos/PaddlePaddle/Paddle/issues/902/comments",
    "author": "wchange",
    "comments": [
      {
        "user": "luotao1",
        "created_at": "2016-12-15T03:28:37Z",
        "body": "请贴上你的网络配置"
      },
      {
        "user": "wchange",
        "created_at": "2016-12-15T04:49:51Z",
        "body": "```\r\ndefine_py_data_sources2(train_list=trn,\r\n                        test_list=tst,\r\n                        module=\"user_image_provider\",\r\n                        obj=process,\r\n                        args={})\r\n\r\nbatch_size = 16 if not is_predict else 1\r\nsettings(\r\n    batch_size=batch_size,\r\n    learning_rate=2e-4,\r\n    learning_method=BaseSGDOptimizer(),\r\n    regularization=L2Regularization(8e-4)\r\n)\r\n\r\ndata = data_layer(name=\"input\", size=40135)\r\noutput = fc_layer(input=data, size=2, act=SoftmaxActivation())\r\n\r\nif not is_predict:\r\n    label = data_layer(name=\"label\", size=2)\r\n\r\n    classification_cost(input=output, label=label)\r\n    cls = classification_cost(input=output, label=label)\r\n    outputs(cls)\r\n```"
      },
      {
        "user": "luotao1",
        "created_at": "2016-12-15T05:20:05Z",
        "body": "learning_method=BaseSGDOptimizer()这行可以去掉，默认就是SGD"
      },
      {
        "user": "wchange",
        "created_at": "2016-12-15T05:24:03Z",
        "body": "不好使啊，之前是下面的配置\r\n```\r\nsettings(\r\n    batch_size=batch_size,\r\n    learning_rate=2e-4,\r\n    learning_method=AdamOptimizer(),\r\n    regularization=L2Regularization(8e-4),\r\n    gradient_clipping_threshold=25\r\n)\r\n```\r\n报Floating point exception\r\n"
      },
      {
        "user": "backyes",
        "created_at": "2016-12-15T05:24:20Z",
        "body": "@luotao1 \r\n\r\nBaseSGDOptimizer这个基类不应该被暴露的吧， 感觉要发个pr，用__all__避免这个基类的导出。"
      },
      {
        "user": "wchange",
        "created_at": "2016-12-15T05:29:08Z",
        "body": "现在其实就想做个ctr预估，训练一个lr模型，请问能否提供一个比较通用的配置？"
      },
      {
        "user": "luotao1",
        "created_at": "2016-12-15T05:30:49Z",
        "body": "@backyes @reyoung 在__all__中把BaseSGDOptimizer直接去掉可以么？"
      },
      {
        "user": "wchange",
        "created_at": "2016-12-16T09:32:08Z",
        "body": "sparse_vector有什么使用限制吗？定义域之类的？"
      },
      {
        "user": "NHZlX",
        "created_at": "2017-09-10T09:01:36Z",
        "body": "I close this issue due to inactivity. please feel free to reopen it.\r\n"
      }
    ]
  },
  {
    "number": 878,
    "title": "Gflags for glog do not have effect.",
    "created_at": "2016-12-14T05:30:13Z",
    "closed_at": "2018-05-16T02:57:47Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/PaddlePaddle/Paddle/issues/878",
    "body": "For some unknown reason, the gflags (e.g. --v, --vmodel) for glog does not have any effect although \"paddle trainer --help\" can show those flags. However, using environment variable GLOV_v, GLOG_vmodule can take effect.",
    "comments_url": "https://api.github.com/repos/PaddlePaddle/Paddle/issues/878/comments",
    "author": "emailweixu",
    "comments": [
      {
        "user": "gongweibao",
        "created_at": "2018-05-16T02:46:25Z",
        "body": "Close it since no activity.\r\nFeel free to reopen it."
      }
    ]
  },
  {
    "number": 827,
    "title": "句子 extraction training",
    "created_at": "2016-12-12T07:03:30Z",
    "closed_at": "2017-07-19T07:49:47Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/PaddlePaddle/Paddle/issues/827",
    "body": "How do I use paddle to extract sentences from 第三人称句 to 第一人称句?",
    "comments_url": "https://api.github.com/repos/PaddlePaddle/Paddle/issues/827/comments",
    "author": "jjhesk",
    "comments": [
      {
        "user": "luotao1",
        "created_at": "2016-12-15T03:48:43Z",
        "body": "能否详细描述下您的问题？句子extracting，是不是一个sed脚本就可以完成了。"
      },
      {
        "user": "luotao1",
        "created_at": "2017-07-19T07:49:47Z",
        "body": "Too old to close this issue."
      }
    ]
  },
  {
    "number": 769,
    "title": "pyDataProvider报错，单机CPU运行",
    "created_at": "2016-12-08T05:20:34Z",
    "closed_at": "2016-12-08T05:40:56Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/PaddlePaddle/Paddle/issues/769",
    "body": "重载了pyDataProviderBase.py，单机CPU运行报错误，log为：\r\n> F1208 12:13:47.471302 25426 ClassRegistrar.h:63] Check failed: mapGet(type, creatorMap_, &creator) Unknown class type: py",
    "comments_url": "https://api.github.com/repos/PaddlePaddle/Paddle/issues/769/comments",
    "author": "pkuyym",
    "comments": [
      {
        "user": "backyes",
        "created_at": "2016-12-08T05:27:18Z",
        "body": "@pkuyym \r\n\r\n请尽可能提供多的配置信息。 "
      },
      {
        "user": "pkuyym",
        "created_at": "2016-12-08T05:28:32Z",
        "body": "################################### Data Configuration ###################################\r\nTrainData(PyData(files = \"train.list\", load_data_module = \"pyDataProvider\", load_data_object = \"GeneralDataProvider\"))\r\n\r\n################################### Algorithm Configuration ###################################\r\nSettings(learning_rate=0.4, learning_rate_decay_a=1e-05, learning_rate_decay_b=0.0, batch_size=400, algorithm='sgd')\r\n\r\n################################### Network Configuration ###################################\r\nLayer(type = \"data\", name = \"input1\", size = 153)\r\nLayer(type = \"data\", name = \"input2\", size = 1)\r\nLayer(inputs = [Input(\"input1\", parameter_name = \"_layer1.w\")], name = \"layer1\", bias = Bias(parameter_name = \"_layer1.bias\"), active_type = \"tanh\", type = \"fc\", size = 128)\r\nLayer(inputs = [Input(\"layer1\", parameter_name = \"_layer2.w\")], name = \"layer2\", bias = Bias(parameter_name = \"_layer2.bias\"), active_type = \"tanh\", type = \"fc\", size = 128)\r\nLayer(inputs = [Input(\"layer2\", parameter_name = \"_output.w\")], name = \"output\", bias = Bias(parameter_name = \"_output.bias\"), active_type = \"softmax\", type = \"fc\", size = 2)\r\nLayer(type = \"data\", name = \"label\", size = 1)\r\nLayer(inputs = [Input(\"output\"), Input(\"label\"), Input(\"input2\")], type = \"multi-class-cross-entropy\", name = \"cost\")\r\nLayer(inputs = [Input(\"output\"), Input(\"label\"), Input(\"input2\")], type = \"auc-validation\", name = \"auc\")\r\nInputs(\"input1\", \"input2\", \"label\")\r\nOutputs(\"cost\")"
      },
      {
        "user": "reyoung",
        "created_at": "2016-12-08T05:29:45Z",
        "body": "1、PyDataProvider 已经被废弃了，请使用PyDataProvider2。\r\n2、这个原因似乎是编译时没有enable python解释器。使用cmake的时候，请开启`-DWITH_PYTHON=ON`"
      },
      {
        "user": "pkuyym",
        "created_at": "2016-12-08T05:31:07Z",
        "body": "我使用的是paddle_api_cmd_1_0_0_7环境，请问能否自己编译paddle，然后替换其中的paddle_trainer？"
      },
      {
        "user": "reyoung",
        "created_at": "2016-12-08T05:31:46Z",
        "body": "> 我使用的是paddle_api_cmd_1_0_0_7环境，请问能否自己编译paddle，然后替换其中的paddle_trainer？\r\n\r\n直接升级一下二进制就好了。"
      },
      {
        "user": "pkuyym",
        "created_at": "2016-12-08T05:32:55Z",
        "body": "还有一个问题，paddle_api_cmd_1_0_0_7这个应该仅仅是一个提交mpi任务的环境吧，应该不会过时吧，有需要就直接替换二进制？"
      },
      {
        "user": "reyoung",
        "created_at": "2016-12-08T05:40:56Z",
        "body": "> 还有一个问题，paddle_api_cmd_1_0_0_7这个应该仅仅是一个提交mpi任务的环境吧，应该不会过时吧，有需要就直接替换二进制？\r\n\r\n1、不全是。这个软件包会把这个软件包里的二进制放到mpi上执行。所以二进制会老的。\r\n2、直接替换也不太行。因为公司内的mpi集群用的linux版本非常老。导致本地编译的不一定能直接放上去运行。请联系 王燕飞 @backyes 查询现在百度集群训练的软件包"
      },
      {
        "user": "backyes",
        "created_at": "2016-12-08T05:59:16Z",
        "body": "@pkuyym  \r\n\r\ndeeplearning.baidu.com/doc"
      }
    ]
  },
  {
    "number": 689,
    "title": "稀疏更新方式，训练出错",
    "created_at": "2016-12-01T07:25:20Z",
    "closed_at": "2016-12-01T08:26:20Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/PaddlePaddle/Paddle/issues/689",
    "body": "paddle1103版本，使用sparse_update加速，train.log报错\r\n\r\n\r\n16[1,29]<stderr>:TypeError: __init__() got an unexpected keyword argument 'sparse_remote_update'\r\nThu Dec  1 11:54:24 2016[1,29]<stderr>:Traceback (most recent call last):\r\nThu Dec  1 11:54:24 2016[1,29]<stderr>:  File \"<string>\", line 2, in <module>\r\nThu Dec  1 11:54:24 2016[1,29]<stderr>:  File \"trainer/config_parser.py\", line 3036, in parse_config_and_serialize\r\nThu Dec  1 11:54:24 2016[1,29]<stderr>:    \r\nThu Dec  1 11:54:24 2016[1,29]<stderr>:config = parse_config(config_file, config_arg_str)\r\nThu Dec  1 11:54:24 2016[1,29]<stderr>:  File \"trainer/config_parser.py\", line 3012, in parse_config\r\nThu Dec  1 11:54:24 2016[1,29]<stderr>:    \r\nThu Dec  1 11:54:24 2016[1,29]<stderr>:execfile(config_file, make_config_environment(config_file, config_args))\r\nThu Dec  1 11:54:24 2016[1,29]<stderr>:  File \"conf/trainer_config.conf\", line 51, in <module>\r\nThu Dec  1 11:54:24 2016[1,29]<stderr>:    \r\nThu Dec  1 11:54:24 2016[1,29]<stderr>:Layer(inputs = [Input(\"input1\", parameter_name = \"_layer1_1.w\")], name = \"layer1_1\", bias = Bias(parameter_name = \"_layer1_1.bias\"), active_type = \"tanh\", type = \"fc\", size = 40, drop_rate = 0.5, sparse_remote_update = True)\r\nThu Dec  1 11:54:24 2016[1,29]<stderr>:  File \"trainer/config_parser.py\", line 2736, in Layer\r\nThu Dec  1 11:54:24 2016[1,29]<stderr>:    \r\nThu Dec  1 11:54:24 2016[1,29]<stderr>:layer_func(name, **xargs)\r\nThu Dec  1 11:54:24 2016[1,29]<stderr>:  File \"trainer/config_parser.py\", line 1430, in __init__\r\nThu Dec  1 11:54:24 2016[1,29]<stderr>:    \r\nThu Dec  1 11:54:24 2016[1,29]<stderr>:super(FCLayer, self).__init__(name, 'fc', size, inputs=inputs, **xargs)\r\nThu Dec  1 11:54:24 2016[1,29]<stderr>:TypeError\r\nThu Dec  1 11:54:24 2016[1,29]<stderr>:: \r\nThu Dec  1 11:54:24 2016[1,29]<stderr>:__init__() got an unexpected keyword argument 'sparse_remote_update'\r\nThu Dec  1 11:54:24 2016[1,29]<stderr>:\r\n",
    "comments_url": "https://api.github.com/repos/PaddlePaddle/Paddle/issues/689/comments",
    "author": "PseudoProgrammer",
    "comments": [
      {
        "user": "backyes",
        "created_at": "2016-12-01T07:43:48Z",
        "body": "@PseudoProgrammer \r\n请重新提问，确保问题能被精确理解。"
      },
      {
        "user": "PseudoProgrammer",
        "created_at": "2016-12-01T07:49:42Z",
        "body": "@backyes 已更新"
      },
      {
        "user": "reyoung",
        "created_at": "2016-12-01T08:26:20Z",
        "body": "版本太老了。之前Sparse设置机制和现在的不一样。请更新版本。"
      },
      {
        "user": "backyes",
        "created_at": "2016-12-01T08:26:52Z",
        "body": "@PseudoProgrammer 是不是使用了新版本的模型api，跑在老的二进制程序上？ "
      },
      {
        "user": "PseudoProgrammer",
        "created_at": "2016-12-01T08:49:50Z",
        "body": "@backyes 没用新版本的api哈，全套都是用的paddle1103，bash submit.sh cpu提交方式"
      }
    ]
  },
  {
    "number": 665,
    "title": "集群训练报错Check failed: height_ == a.height_ (256 vs. 1390) ",
    "created_at": "2016-11-30T06:25:11Z",
    "closed_at": "2016-11-30T08:02:29Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/PaddlePaddle/Paddle/issues/665",
    "body": "以下是网络和 slot 类型的配置\r\n\r\n```\r\ndef lstm_dnn_net(seq_dim,\r\n                feat_dim,\r\n                class_dim,\r\n                emb_dim=128,\r\n                hid_dim=512,\r\n                lstm_dim=128,\r\n                is_predict=False):\r\n    \"\"\" \r\n    lstm 和 DNN 网络\r\n    \"\"\"\r\n    bias_attr = ParameterAttribute(initial_std=0., l2_rate=0.0001)\r\n    fc_para_attr = ParameterAttribute(learning_rate=2e-3)\r\n    lstm_para_attr = ParameterAttribute(initial_std=0., learning_rate=2e-3)#, sparse_update=True)\r\n    sparse_up = ParameterAttribute(sparse_update=True)\r\n    layer_attr = ExtraLayerAttribute(drop_rate=0.5)\r\n    para_attr = [lstm_para_attr, fc_para_attr]\r\n    relu = ReluActivation()\r\n    linear = LinearActivation()\r\n \r\n \r\n    seq_data = data_layer(\"seq\", seq_dim)\r\n    emb = embedding_layer(input=seq_data, size=emb_dim)\r\n    \r\n    bi_lstm = bidirectional_lstm(input=emb, size=lstm_dim, concat_act=relu)\r\n    #dropout = dropout_layer(input=bi_lstm, dropout_rate=0.5)\r\n    lstm_out = fc_layer(input=bi_lstm, size=lstm_dim, act=TanhActivation(),\r\n            bias_attr=bias_attr)\r\n    \r\n    feat_data = data_layer(\"feat\", feat_dim)\r\n    emb2 = embedding_layer(input=feat_data, size=emb_dim)\r\n    feat_layer_1 = fc_layer(input=emb2, size=hid_dim/4, act=relu,\r\n                   bias_attr=bias_attr)#, param_attr=sparse_up)\r\n    feat_layer_2 = fc_layer(input=feat_layer_1, size=hid_dim/4, act=relu, bias_attr=bias_attr)\r\n    output = fc_layer(name='fc_ly_4', input=[lstm_out, feat_layer_2], size=class_dim,\r\n                      act=SoftmaxActivation(),\r\n                      bias_attr=bias_attr, param_attr=para_attr)\r\n    \r\n    if is_predict:\r\n        outputs(output)\r\n    else:\r\n        outputs(\r\n            classification_cost(input=output, label=data_layer('label', 1), \r\n                evaluator=[precision_recall_evaluator, classification_error_evaluator]))\r\n```\r\n\r\n```\r\ndef hook(obj, dictionary, **kwargs):\r\n    obj.input_types = [integer_value_sequence(len(dictionary)), integer_value_sequence(6121), integer_value(888)]\r\n```\r\n\r\n训练时报错：\r\nF1130 14:12:50.641754 18718 Matrix.cpp:378] Check failed: height_ == a.height_ (256 vs. 1390) \r\nF1130 14:12:50.643165 18726 Matrix.cpp:378] Check failed: height_ == a.height_ (256 vs. 1327) \r\nF1130 14:12:50.643165 18726 Matrix.cpp:378] Check failed: height_ == a.height_ (256 vs. 1327) F1130 14:12:50.644318 18714 Matrix.cpp:378] Check failed: height_ == a.height_ (256 vs. 1408) \r\nF1130 14:12:50.643165 18726 Matrix.cpp:378] Check failed: height_ == a.height_ (256 vs. 1327) F1130 14:12:50.644318 18714 Matrix.cpp:378] Check failed: height_ == a.height_ (256 vs. 1408) F1130 14:12:50.645272 18722 Matrix.cpp:378] Check failed: height_ == a.height_ (256 vs. 1387) \r\n\r\n请问可能是什么原因？",
    "comments_url": "https://api.github.com/repos/PaddlePaddle/Paddle/issues/665/comments",
    "author": "20092136",
    "comments": [
      {
        "user": "backyes",
        "created_at": "2016-11-30T06:49:17Z",
        "body": "@20092136 尝试梳理出一个完整的线程堆栈出来，否则看起来比较盲目。 我估计应该是数据问题导致的。\r\n\r\n@luotao1 @hedaoyuan "
      },
      {
        "user": "luotao1",
        "created_at": "2016-11-30T06:52:06Z",
        "body": "@20092136 matrix.cpp 378是哪个函数，试试看是哪层出的问题"
      },
      {
        "user": "20092136",
        "created_at": "2016-11-30T07:03:54Z",
        "body": "F1130 14:06:40.257648 1228 Matrix.cpp:378] Check failed: height_ == a.height_ (256 vs. 1376) \r\n*** Check failure stack trace: *** \r\n@ 0xfb8b4c google::LogMessage::Fail() \r\n@ 0xfb8aa4 google::LogMessage::SendToLog() \r\n@ 0xfb8539 google::LogMessage::Flush() \r\nF1130 14:06:40.260176 1224 Matrix.cpp:378] Check failed: height_ == a.height_ (256 vs. 1357) \r\n*** Check failure stack trace: *** \r\n@ 0xfb8b4c google::LogMessage::Fail() \r\n@ 0xfbb2fa google::LogMessageFatal::~LogMessageFatal() \r\n@ 0x7a33a0 paddle::GpuMatrix::mul() \r\n@ 0xfb8aa4 google::LogMessage::SendToLog() \r\n@ 0x7a3b0b paddle::GpuMatrix::mul() \r\n@ 0xfb8539 google::LogMessage::Flush() \r\n@ 0x6dcb67 paddle::FullyConnectedLayer::forward() \r\n@ 0xfbb2fa google::LogMessageFatal::~LogMessageFatal() \r\nF1130 14:06:40.260176 1224 Matrix.cpp:378] Check failed: height_ == a.height_ (256 vs. 1357) F1130 14:06:40.263499 1232 Matrix.cpp:378] Check failed: height_ == a.height_ (256 vs. 1382) \r\n*** Check failure stack trace: *** \r\n@ 0x7a33a0 paddle::GpuMatrix::mul() \r\n@ 0xfb8b4c google::LogMessage::Fail() \r\n@ 0x73b8b4 paddle::NeuralNetwork::forward() \r\n@ 0x7a3b0b paddle::GpuMatrix::mul() \r\n@ 0xfb8aa4 google::LogMessage::SendToLog() \r\n@ 0x732991 paddle::TrainerThread::forward() \r\n@ 0xfb8539 google::LogMessage::Flush() \r\n@ 0x6dcb67 paddle::FullyConnectedLayer::forward() \r\n@ 0x73394c paddle::TrainerThread::computeThread() \r\n@ 0xfbb2fa google::LogMessageFatal::~LogMessageFatal() \r\n@ 0x73b8b4 paddle::NeuralNetwork::forward() \r\n@ 0x7a33a0 paddle::GpuMatrix::mul() \r\n@ 0x7fc351e038a0 execute_native_thread_routine \r\n@ 0x7a3b0b paddle::GpuMatrix::mul() \r\n@ 0x732991 paddle::TrainerThread::forward() \r\n@ 0x7fc352aa11c3 start_thread \r\n@ 0x73394c paddle::TrainerThread::computeThread() \r\n@ 0x6dcb67 paddle::FullyConnectedLayer::forward() \r\n@ 0x7fc35157412d __clone \r\n\r\n@luotao1 "
      }
    ]
  },
  {
    "number": 662,
    "title": "训练model从GPU集群移到CPU集群报错",
    "created_at": "2016-11-30T02:52:44Z",
    "closed_at": "2016-12-13T06:44:30Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/PaddlePaddle/Paddle/issues/662",
    "body": "之前用GPU训练CNNmodel，移到CPU集群训练报错。local_config和receiver已改，--where参数已改。\r\n具体错误如下，未找到libpython2.6.so.1.0：\r\nI1130 10:44:17.482218  3086 PyDataProvider.cpp:43] module:pyDataProviderImage class:GeneralJpegDataProvider\r\nI1130 10:44:17.868773  3086 PythonUtil.cpp:149] createPythonClass moduleName.c_str:pyDataProviderImage\r\nI1130 10:44:17.868809  3086 PythonUtil.cpp:154] createPythonClass className.c_str():GeneralJpegDataProvider\r\nI1130 10:44:17.888891  3086 PythonUtil.cpp:83] Python Error: <type 'exceptions.ImportError'> : libpython2.6.so.1.0: cannot open shared object file: No such file or directory\r\nI1130 10:44:17.888914  3086 PythonUtil.cpp:87] Python Callstack: \r\nI1130 10:44:17.888922  3086 PythonUtil.cpp:92]             /home/normandy/maybach/204635/workspace/thirdparty/thirdparty/pyDataProviderImage.py : 127\r\nF1130 10:44:17.889091  3086 PythonUtil.cpp:108] Create class GeneralJpegDataProvider failed.\r\n\r\npyDataProviderImage.py的第126-127行是：\r\nself.lib_name = \"decodeJPEG._DeJPEG\"\r\nself.libmodel = __import__(self.lib_name,fromlist=['_DeJPEG'])",
    "comments_url": "https://api.github.com/repos/PaddlePaddle/Paddle/issues/662/comments",
    "author": "qubingxin",
    "comments": [
      {
        "user": "backyes",
        "created_at": "2016-11-30T03:03:47Z",
        "body": "集群环境的python运行时环境为2.7版本，错误提示没有2.6版本。请更新到2.7版本依赖。\r\n"
      },
      {
        "user": "qubingxin",
        "created_at": "2016-11-30T03:21:34Z",
        "body": "请问这个更新依赖是更新哪里的依赖？是指的receiver？"
      },
      {
        "user": "backyes",
        "created_at": "2016-11-30T03:46:48Z",
        "body": "可能是你的thirdparty部分应该有依赖python2.6动态库模块，确保它们依赖python2.7，而不是2.6（集群环境没有2.6环境）。"
      },
      {
        "user": "reyoung",
        "created_at": "2016-12-13T06:44:30Z",
        "body": "Closed due not response for long time. Reopen it if necessary."
      },
      {
        "user": "Skyeyue",
        "created_at": "2019-07-24T05:46:45Z",
        "body": "请问问题解决了吗？我遇到的问题是sqlite依赖于py2.6，但是我折腾了很久一直无法升级到2.7"
      }
    ]
  },
  {
    "number": 660,
    "title": "sparse training cluster时在pass0后失败",
    "created_at": "2016-11-29T16:59:52Z",
    "closed_at": "2016-12-16T01:53:38Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/PaddlePaddle/Paddle/issues/660",
    "body": "集群配置问题，转到内网",
    "comments_url": "https://api.github.com/repos/PaddlePaddle/Paddle/issues/660/comments",
    "author": "CDDB",
    "comments": [
      {
        "user": "backyes",
        "created_at": "2016-11-30T07:01:00Z",
        "body": "@tianbingsz 也知晓下。sparse相关模型重构后，用户反馈若干问题，需要深入分析问题。"
      },
      {
        "user": "CDDB",
        "created_at": "2016-11-30T07:42:50Z",
        "body": "我现在用的是icode的版本，最近一次ci是10月8日（* master 7c60b90 Merge \"remove PserverForPython.h which is not used\"）。 不知道是否已经被重构了。\r\n\r\n另外。我们尝试过sparse-binary-vec的cluster版本的sparse-train，遇到同样p-server启动失败的问题。"
      },
      {
        "user": "backyes",
        "created_at": "2016-11-30T07:46:48Z",
        "body": "icode版本不再维护，且后续github 主干有若干关于sparse训练的bugfix，故请更新到新代码，内部有新版本receiver（通过内部渠道沟通），您只要更换下receiver配置即可使能最新版本。"
      },
      {
        "user": "backyes",
        "created_at": "2016-11-30T07:48:55Z",
        "body": "@CDDB  请关注deeplearning.baidu.com，面向百度同学的使用文档介绍，获取有关集群信息。"
      },
      {
        "user": "CDDB",
        "created_at": "2016-11-30T08:29:35Z",
        "body": "收到， 能确认我遇到的问题是已知问题，并且已经fix了么？"
      },
      {
        "user": "backyes",
        "created_at": "2016-11-30T08:34:35Z",
        "body": "暂时不能确定"
      },
      {
        "user": "CDDB",
        "created_at": "2016-11-30T09:09:09Z",
        "body": "好的， 我转到内网询问。 这个issue我删掉"
      },
      {
        "user": "CDDB",
        "created_at": "2016-12-01T08:00:59Z",
        "body": "成功跑了一轮Pass，但是在Eval结果还没有出现前挂了。 似乎有几个关联问题？ \r\n采用公司最新receiver\r\nI1201 14:22:15.860833 24546 ThreadLocal.cpp:37] thread use undeterministic rand seed:24547\r\nI1201 14:43:17.116703 21909 TrainerInternal.cpp:182]  Pass=0 Batch=711 samples=35526 AvgCost=0.245079 Eval: \r\nF1201 14:43:17.771586 21981 SparseRowMatrix.h:63] Check failed: globalIndices_[row] != kUnusedId_ (4294967295 vs. 4294967295) \r\nF1201 14:43:17.771664 21983 SparseRowMatrix.h:63] Check failed: globalIndices_[row] != kUnusedId_ (4294967295 vs. 4294967295) F1201  14:43::1717..771920 21980 SparseRowMatrix.hSparseRowMatrix.h::63] Check failed: globalIndices_[row] != kUnusedId_ (4294967295 vs. 4294967295)\r\n'''\r\n更多错误日志\r\n'''\r\nu Dec  1 14:43:17 2016[1,3]<stderr>:F1201 14:43:17.139876 11101 SparseRowMatrix.h:63] Check failed: globalIndices_[row] != kUnusedId_ (4294967295 vs. 4294967295) \r\nThu Dec  1 14:43:17 2016[1,3]<stderr>:*** Check failure stack trace: ***\r\nThu Dec  1 14:43:17 2016[1,3]<stderr>:F1201 14:43:17.139876 11103 S0:63] 12Check failed: globalIndices_[row] != kUnusedId_ (4294967295 vs. 4294967295) \r\nThu Dec  1 14:43:17 2016[1,3]<stderr>:1 14:43:17.139876 11104 SparseRowMatrix.h:63] Check failed: globalIndices_[row] != kUnusedId_ (4294967295 vs. 4294967295) F1201 14:43:17.140319 11102 SparseRowMatrix.h:63] Check failed: globalIndices_[row] != kUnusedId_ (4294967295 vs. 4294967295) \r\nThu Dec  1 14:43:17 2016[1,3]<stderr>:*** Check failure stack trace: ***\r\nThu Dec  1 14:43:17 2016[1,3]<stderr>:F1201 14:43:17.139876 11103 S0:63] 12Check failed: globalIndices_[row] != kUnusedId_ (4294967295 vs. 4294967295) \r\nThu Dec  1 14:43:17 2016[1,3]<stderr>:1 14:43:17.139876 11104 SparseRowMatrix.h:63] Check failed: globalIndices_[row] != kUnusedId_ (4294967295 vs. 4294967295) F1201 14:43:17.140319 11102 SparseRowMatrix.h:63] Check failed: globalIndices_[row] != kUnusedId_ (4294967295 vs. 4294967295) \r\nThu Dec  1 14:43:17 2016[1,3]<stderr>:*** Check failure stack trace: ***\r\nThu Dec  1 14:43:17 2016[1,3]<stderr>:F1201 14:43:17.139876 11103 S0:63] 12Check failed: globalIndices_[row] != kUnusedId_ (4294967295 vs. 4294967295) \r\nThu Dec  1 14:43:17 2016[1,3]<stderr>:1 14:43:17.139876 11104 SparseRowMatrix.h:63] Check failed: globalIndices_[row] != kUnusedId_ (4294967295 vs. 4294967295) F1201 14:43:17.140319 11102 SparseRowMatrix.h:63] Check failed: globalIndices_[row] != kUnusedId_ (4294967295 vs. 4294967295) \r\nThu Dec  1 14:43:17 2016[1,3]<stderr>:*** Check failure stack trace: ***\r\nThu Dec  1 14:43:17 2016[1,3]<stderr>:    @          0x13aeb38  google::LogMessage::Fail()\r\nThu Dec  1 14:43:17 2016[1,3]<stderr>:    @          0x13aeb38  google::LogMessage::Fail()\r\nThu Dec  1 14:43:17 2016[1,3]<stderr>:    @          0x13aeb38  google::LogMessage::Fail()\r\nThu Dec  1 14:43:17 2016[1,3]<stderr>:    @          0x13aeb38  google::LogMessage::Fail()\r\nThu Dec  1 14:43:17 2016[1,3]<stderr>:    @          0x13aea90  google::LogMessage::SendToLog()\r\nThu Dec  1 14:43:17 2016[1,3]<stderr>:    @          0x13aea90  google::LogMessage::SendToLog()\r\nThu Dec  1 14:43:17 2016[1,3]<stderr>:    @          0x13aea90  google::LogMessage::SendToLog()\r\nThu Dec  1 14:43:17 2016[1,3]<stderr>:    @          0x13aea90  google::LogMessage::SendToLog()\r\nThu Dec  1 14:43:17 2016[1,3]<stderr>:    @          0x13ae525  google::LogMessage::Flush()\r\nThu Dec  1 14:43:17 2016[1,3]<stderr>:    @          0x13ae525  google::LogMessage::Flush()\r\nThu Dec  1 14:43:17 2016[1,3]<stderr>:    @          0x13ae525  google::LogMessage::Flush()\r\nThu Dec  1 14:43:17 2016[1,3]<stderr>:    @          0x13ae525  google::LogMessage::Flush()\r\nThu Dec  1 14:43:17 2016[1,3]<stderr>:    @          0x13b12e6  google::LogMessageFatal::~LogMessageFatal()\r\nThu Dec  1 14:43:17 2016[1,3]<stderr>:    @          0x13b12e6  google::LogMessageFatal::~LogMessageFatal()\r\nThu Dec  1 14:43:17 2016[1,3]<stderr>:    @          0x13b12e6  google::LogMessageFatal::~LogMessageFatal()\r\nThu Dec  1 14:43:17 2016[1,3]<stderr>:    @          0x13b12e6  google::LogMessageFatal::~LogMessageFatal()\r\nThu Dec  1 14:43:17 2016[1,3]<stderr>:    @           0x7e5bec  paddle::CpuMatrix::mul<>()\r\nThu Dec  1 14:43:17 2016[1,3]<stderr>:    @           0x7e5bec  paddle::CpuMatrix::mul<>()\r\nThu Dec  1 14:43:17 2016[1,3]<stderr>:    @           0x7e5bec  paddle::CpuMatrix::mul<>()\r\nThu Dec  1 14:43:17 2016[1,3]<stderr>:    @           0x7e5bec  paddle::CpuMatrix::mul<>()\r\nThu Dec  1 14:43:17 2016[1,3]<stderr>:    @           0x7d5b77  paddle::CpuMatrix::mul()\r\nThu Dec  1 14:43:17 2016[1,3]<stderr>:    @           0x7d5b77  paddle::CpuMatrix::mul()\r\nThu Dec  1 14:43:17 2016[1,3]<stderr>:    @           0x7d5b77  paddle::CpuMatrix::mul()\r\nThu Dec  1 14:43:17 2016[1,3]<stderr>:    @           0x7d5b77  paddle::CpuMatrix::mul()\r\nThu Dec  1 14:43:17 2016[1,3]<stderr>:    @           0x675f1e  paddle::FullyConnectedLayer::forward()\r\nThu Dec  1 14:43:17 2016[1,3]<stderr>:    @           0x675f1e  paddle::FullyConnectedLayer::forward()\r\nThu Dec  1 14:43:17 2016[1,3]<stderr>:    @           0x675f1e  paddle::FullyConnectedLayer::forward()\r\nThu Dec  1 14:43:17 2016[1,3]<stderr>:    @           0x675f1e  paddle::FullyConnectedLayer::forward()\r\nThu Dec  1 14:43:17 2016[1,3]<stderr>:    @           0x6d36a4  paddle::NeuralNetwork::forward()\r\nThu Dec  1 14:43:17 2016[1,3]<stderr>:    @           0x6d36a4  paddle::NeuralNetwork::forward()\r\nThu Dec  1 14:43:17 2016[1,3]<stderr>:    @           0x6d36a4  paddle::NeuralNetwork::forward()\r\nThu Dec  1 14:43:17 2016[1,3]<stderr>:    @           0x6d36a4  paddle::NeuralNetwork::forward()\r\nThu Dec  1 14:43:17 2016[1,3]<stderr>:    @           0x6c9ae6  paddle::TrainerThread::forward()\r\nThu Dec  1 14:43:17 2016[1,3]<stderr>:    @           0x6c9ae6  paddle::TrainerThread::forward()\r\nThu Dec  1 14:43:17 2016[1,3]<stderr>:    @           0x6c9ae6  paddle::TrainerThread::forward()\r\nThu Dec  1 14:43:17 2016[1,3]<stderr>:    @           0x6c9ae6  paddle::TrainerThread::forward()\r\nThu Dec  1 14:43:17 2016[1,3]<stderr>:    @           0x6cac28  paddle::TrainerThread::computeThread()\r\nThu Dec  1 14:43:17 2016[1,3]<stderr>:    @           0x6cac28  paddle::TrainerThread::computeThread()\r\nThu Dec  1 14:43:17 2016[1,3]<stderr>:    @           0x6cac28  paddle::TrainerThread::computeThread()\r\nThu Dec  1 14:43:17 2016[1,3]<stderr>:    @           0x6cac28  paddle::TrainerThread::computeThread()\r\nThu Dec  1 14:43:17 2016[1,3]<stderr>:    @     0x7f36b565f8a0  execute_native_thread_routine\r\nThu Dec  1 14:43:17 2016[1,3]<stderr>:    @     0x7f36b565f8a0  execute_native_thread_routine\r\nThu Dec  1 14:43:17 2016[1,3]<stderr>:    @     0x7f36b565f8a0  execute_native_thread_routine\r\nThu Dec  1 14:43:17 2016[1,3]<stderr>:    @     0x7f36b565f8a0  execute_native_thread_routine\r\nThu Dec  1 14:43:17 2016[1,3]<stderr>:    @     0x7f36b5edd1c3  start_thread\r\nThu Dec  1 14:43:17 2016[1,3]<stderr>:    @     0x7f36b5edd1c3  start_thread\r\nThu Dec  1 14:43:17 2016[1,3]<stderr>:    @     0x7f36b5edd1c3  start_thread\r\nThu Dec  1 14:43:17 2016[1,3]<stderr>:    @     0x7f36b5edd1c3  start_thread\r\nThu Dec  1 14:43:17 2016[1,3]<stderr>:    @     0x7f36b4dd012d  __clone\r\nThu Dec  1 14:43:17 2016[1,3]<stderr>:    @     0x7f36b4dd012d  __clone\r\nThu Dec  1 14:43:17 2016[1,3]<stderr>:    @     0x7f36b4dd012d  __clone\r\nThu Dec  1 14:43:17 2016[1,3]<stderr>:    @     0x7f36b4dd012d  __clone\r\n'''"
      },
      {
        "user": "CDDB",
        "created_at": "2016-12-01T09:05:02Z",
        "body": "@backyes "
      },
      {
        "user": "CDDB",
        "created_at": "2016-12-01T10:07:14Z",
        "body": "确认如果取消Test就可以跑通"
      }
    ]
  },
  {
    "number": 638,
    "title": "怎样使用paddle里面的 auc_evaluator等函数 就是如何导出测试的分类错误率 ",
    "created_at": "2016-11-28T07:16:35Z",
    "closed_at": "2016-12-15T09:59:19Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/PaddlePaddle/Paddle/issues/638",
    "body": "想通过导出每次训练 的分类test错误率 这样在预测时就可以实现 自动选择最优参数了 可是只在文档里找到了求错误率的函数 但不知道如何进行调用 并将其赋值给变量",
    "comments_url": "https://api.github.com/repos/PaddlePaddle/Paddle/issues/638/comments",
    "author": "janelu9",
    "comments": [
      {
        "user": "qingqing01",
        "created_at": "2016-11-28T08:42:59Z",
        "body": "如果设置了 evaluator， 评估结果会打印到log文件里面，可以通过log文件正则匹配出需要的结果(比如分类错误率)。"
      }
    ]
  },
  {
    "number": 634,
    "title": "regression_cost使用求助：如何使用百分误差",
    "created_at": "2016-11-26T17:25:35Z",
    "closed_at": "2016-12-15T10:00:17Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/PaddlePaddle/Paddle/issues/634",
    "body": "我看了源码中regression_cost layer的默认实现是采用square_error（均方误差）作为回归测试的默认的方法，现在问题是如果我希望使用相对误差（也叫百分误差）MAPE，如何实现呢？非常感谢！\r\n\r\n",
    "comments_url": "https://api.github.com/repos/PaddlePaddle/Paddle/issues/634/comments",
    "author": "liuzongquan",
    "comments": [
      {
        "user": "qingqing01",
        "created_at": "2016-11-28T07:08:09Z",
        "body": "目前不支持MAPE，如果想实现，可以在 `Paddle/paddle/gserver/layers/CostLayer.*` 中增加实现。"
      }
    ]
  },
  {
    "number": 563,
    "title": "float point exception",
    "created_at": "2016-11-22T09:47:17Z",
    "closed_at": "2017-03-15T03:22:04Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/PaddlePaddle/Paddle/issues/563",
    "body": "训练过程中经过多个pass之后会出现float point exception错误。\r\n\r\n#46   #53  有提到可以通过更换模型，降低batcisize、降低学习速率或者优化算法可以解决这个问题。\r\n\r\n经过实验发现降低batcisize（128变为50）、降低学习速率（adam由1e-3变为1e-4）并没有解决这个问题。\r\n更换优化算法（由adam变为MomentumOptimizer(0.9)）也还是会出现同样问题。\r\n\r\n\r\n不知有没有什么别的办法可以解决这个float point exception问题\r\n\r\n（注：训练样本大约50w条数据做序列分类，label大约8w个，90%数据序列长度小于10，集群版本paddle，训练了大约80个pass）\r\n\r\n",
    "comments_url": "https://api.github.com/repos/PaddlePaddle/Paddle/issues/563/comments",
    "author": "333caowei",
    "comments": [
      {
        "user": "liuyuuan",
        "created_at": "2016-11-23T03:29:22Z",
        "body": "已经训练了80个pass，是否前80个pass中已经出现了较好的结果？建议观察一下训练集和测试集的cost和其他指标变化，判断一下是否在出现这个错误之前就已经过拟合可以停止训练了。如果确认还需要继续优化，可以尝试逐渐加大数据量或者逐渐减小网络规模。"
      },
      {
        "user": "333caowei",
        "created_at": "2016-11-23T05:56:19Z",
        "body": "@comeonfox 请问paddle如何进行early stop停止训练呢，搜了一下文档没发现，目前只能在在启动paddle时候配置num pass"
      },
      {
        "user": "liuyuuan",
        "created_at": "2016-11-23T13:33:35Z",
        "body": "主要通过 $num_passes 控制，在到达 $num_passes 之前，如果需要停止训练，可以直接kill掉任务，不会影响模型产出。被kill 之前的模型都保存在$save_dir 下， 每$saving_period个pass保存一次。"
      },
      {
        "user": "333caowei",
        "created_at": "2016-11-24T02:21:17Z",
        "body": "@comeonfox 也就是说early stop没办法动过代码逻辑中检测valid data的loss变化来停掉任务（类似于for循环break的逻辑），需要人工去kill任务吗"
      },
      {
        "user": "backyes",
        "created_at": "2016-11-25T03:41:28Z",
        "body": "@pengli09 @lcy-seso \r\n两位看看能不给出一些意见。"
      },
      {
        "user": "pengli09",
        "created_at": "2016-11-25T04:53:18Z",
        "body": "\"label大约8w个\"，直觉label应该会非常脏（各种标注不一致等等），算出来的梯度应该也会有非常大的噪声，训练过程肯定会不稳定。所以建议是不是再重新审视一个问题建模本身，如：\r\n- 真的需要8w个类吗？\r\n- 确实需要8w个类的话，数据标注质量够吗？数据质量不够，模型不可能训好的"
      },
      {
        "user": "zhuantouer",
        "created_at": "2017-07-17T03:16:57Z",
        "body": "hi， 请问“float point exception”问题出现的原因找到了么，解决了么？"
      },
      {
        "user": "lcy-seso",
        "created_at": "2017-07-17T03:21:37Z",
        "body": "@zishuaiz 请问具体是哪个任务呢？ FPE 的原因可能是多种的，（1）训练数据处理不当，或是异常数据；（2）梯度计算溢出等等，通常都是针对具体的训练任务分析。\r\n\r\n如果您遇到什么问题，可以在新的issue中具体描述一下任务以及配置参数。"
      },
      {
        "user": "zhuantouer",
        "created_at": "2017-07-17T04:34:58Z",
        "body": "@lcy-seso 任务在训练第9个pass时报错，应该不是数据处理不当或数据异常原因；\r\n模型是双向lstm+crf作ner，lr=1e-3,batch_size=150"
      }
    ]
  },
  {
    "number": 542,
    "title": "How to sample from a normal (Gaussian) distribution as input",
    "created_at": "2016-11-21T02:50:10Z",
    "closed_at": "2016-11-23T10:47:31Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/PaddlePaddle/Paddle/issues/542",
    "body": "",
    "comments_url": "https://api.github.com/repos/PaddlePaddle/Paddle/issues/542/comments",
    "author": "zuowang",
    "comments": [
      {
        "user": "pengli09",
        "created_at": "2016-11-21T13:23:35Z",
        "body": "You can do it in your data provider. Currently PaddlePaddle does not have corresponding layer to do this."
      },
      {
        "user": "zuowang",
        "created_at": "2016-11-23T10:47:31Z",
        "body": "Thanks!"
      }
    ]
  },
  {
    "number": 535,
    "title": "多机训练场景下, 加载已有模型的重训练（--init_model_path参数）过程中，各个节点模型参数如何初始化？",
    "created_at": "2016-11-19T05:21:44Z",
    "closed_at": "2016-11-21T05:00:38Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/PaddlePaddle/Paddle/issues/535",
    "body": "RT， 重点关注：\r\n\r\n*  各个节点的参数加载方法？\r\n*  如何支持is_static参数的？\r\n",
    "comments_url": "https://api.github.com/repos/PaddlePaddle/Paddle/issues/535/comments",
    "author": "backyes",
    "comments": [
      {
        "user": "backyes",
        "created_at": "2016-11-19T05:38:07Z",
        "body": "早期部分版本对多机的**加载已有模型的重训练** 有部分bug，主要体现在：\n- 非0节点会在pserver完成被主节点初始化之前试图从pserver获取模型，此处逻辑有误\n- 集群并未对所有节点下载已有模型到本地磁盘\n\n最新主干代码对相关逻辑实现比较清晰：\n- 集群外围脚本负责为所有节点准备已有模型文件，并存储到本地磁盘\n- 所有节点paddle trainer会负责从本地磁盘加载模型，完成初始化。\n- 从上面两条可确定，该场景下的模型初始化逻辑基本是共享单机的逻辑，因此 is_static的参数初始化可以理解为等同于单机策略。\n\n@reyoung @qingqing01 @emailweixu @luotao1 各位修改意见的，请comments，这个feature将会有很多同学逐渐使用。\n"
      },
      {
        "user": "qingqing01",
        "created_at": "2016-11-20T07:59:08Z",
        "body": "代码逻辑是：\n- 集群训练提交环境脚本，改过让**所有**节点均下载初始化模型到本地, 然后各个节点均加载模型。这个最新的集群提交环境的脚本里这样做的。\n- 加载完毕之后，主节点还会将非static参数(包括随机初始化参数)发送给其他节点 。这点不使用init_model_path也会走这个流程。\n\n很早之前我们发布的paddle_api_cmd_1_1_0_3就是这个逻辑。\n\n我觉得这个逻辑是没有问题的，比如：部分参数load初始化模型、部分参数随机初始化，这样主节点广播一次非static参数到其他节点，我觉得是没有问题，这样保证了每个节点起始的参数是相同的。\n\n这个逻辑很早之前就是这样的，只是部分同学一直只更新paddle代码，并没有更新提交集群环境的外围脚本，导致出错，代码之前也是check的：\n\n```\nif (!testing &&\n      (trainerInternal_.getGradientMachine()->hasStaticParameters())) {\n    CHECK(!FLAGS_init_model_path.empty())\n        << \"Static parameters should be initialized by --init_model_path\";\n}\n```\n\n@backyes 你指的是要更改这个逻辑吗？\n"
      },
      {
        "user": "backyes",
        "created_at": "2016-11-20T08:24:44Z",
        "body": "从目前github版本来看，处理命令行init_model_path参数和parameter选项is _staticc参数的逻辑，并没有任何问题。\n\n@qingqing01 新版本代码中，init_model_path使能的时候，所有节点应该是各自主动从本地磁盘读取模型完成trainer端参数初始化。\n"
      },
      {
        "user": "backyes",
        "created_at": "2016-11-20T11:00:40Z",
        "body": "经过跟 @qingqing01 讨论，总结如下，以便参考（所有以最新代码为准commit SHA1 77ddce0f0be883bc60d3949bf18dee96dd118e64）： \n- 多机下，每个节点均会从本地节点试图加载参数（第一阶段）\n\n``` c++\n 227   if (testing) {\n  228     // will load per pass for tester\n  229   } else if (paramUtil_->tryLoadParametersFromConfig()) {\n  230     // load from config already.\n  231   } else {\n  232     trainerInternal_.getGradientMachine()->randParameters();\n  233   }\n```\n\nTrainer.cpp init函数调用开始尝试加载本地参数。如果本地没有相关参数，本阶段加载参数会失败（下一个阶段仍然有一个次加载参数过程，发生在pserver启动之后）\n注意： is_static 参数初始化只能发生在该阶段，如果该阶段没有成功加载，那么程序逻辑将不符合预期。（这是一个潜在可能出现风险的坑，最好能加一个check，比如发生is_static配置，必须从本地磁盘完成部分参数的加载）\n\n```\n  102   /**\n  103    * Try to load parameter from config.\n  104    * @return true if can load from trainer config.\n  105    */\n  106   inline bool tryLoadParametersFromConfig() {\n  107     auto& c = config_->getConfig();\n  108     if (!c.init_model_path().empty()) {\n  109       loadParametersWithPath(c.init_model_path());\n  110       return true;\n  111     } else if (c.start_pass() > 0) {\n  112       CHECK(loadParameters(c.start_pass() - 1));\n  113       return true;\n  114     } else {\n  115       return false;\n  116     }\n  117   }\n```\n\n尝试加载函数实现。\n- pserver启动后，会进行第二阶段参数加载（主要进行non static参数初始化）\n  \n  ``` c++\n  83   parameterClient_.reset(new ParameterClient2(separateSendAndRecv_));\n  84   parameterClient_->init(cpuParameters_);\n  85   parameterClient_->setTrainerId(FLAGS_trainer_id);\n  86\n  87   if (FLAGS_trainer_id == 0) {\n  88     parameterClient_->setConfig(config_);\n  89     copyParametersFromDevice(PARAMETER_VALUE);\n  90     parameterClient_->setParameter();\n  91     parameterClient_->setStatus(PSERVER_STATUS_PARAMETER_READY);\n  92   } else {\n  93     parameterClient_->waitForStatus(PSERVER_STATUS_PARAMETER_READY);\n  94    ** parameterClient_->getParameter(); **\n  95     copyParametersToDevice(PARAMETER_VALUE);\n  96   }\n  ```\n\nparameter启动后，主节点完成对所有pserver节点的参数初始化， 然后从节点等待\n\n```\nparameterClient_->waitForStatus(PSERVER_STATUS_PARAMETER_READY);\n```\n\n信号，完成自己trainer参数的初始化。\n\n所以，如果从节点也准备了本地参数的话，从节点部分参数会被初始化两次，但是不影响结果。 \n\n由于历史原因，上述逻辑将通信逻辑和参数初始化逻辑揉和到一起了，理解起来略困难。\n\n整体的根本需求汇总如下（以后重构需要考虑到一下几点）： \n- 达到所有节点初始化参数一致。 因此不能所有节点随意初始化自己的参数，由于随机种子问题，会导致参数不一致，所以需要某种手段来达到多节点一致的模型参数。（从上面的分析来看，主要运用master + 参数分发机制来实现）\n- 要达到对static参数的支持。因此逻辑上要确保所有节点设置了is_static的参数必须在全部节点上使能，不能仅仅在master节点上使能。\n- 为了优化通信效率，要求做到对is_static参数梯度不进行合并，不进行参数更新，不传输任何is_static参数。\n\n@qingqing01  请review下，逻辑。 方便以后同学熟悉。\n"
      },
      {
        "user": "backyes",
        "created_at": "2016-11-21T05:00:38Z",
        "body": "此issue由内部用户使用集群训练带有is_static参数配置选项的场景下延伸出来，相关问题已经解决，同时对上述问题已做清晰阐述， 故close此issue"
      }
    ]
  },
  {
    "number": 469,
    "title": "Whether forwardTest is thread safe or not while using python predict module?",
    "created_at": "2016-11-15T04:00:47Z",
    "closed_at": "2016-11-15T05:02:33Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/PaddlePaddle/Paddle/issues/469",
    "body": "",
    "comments_url": "https://api.github.com/repos/PaddlePaddle/Paddle/issues/469/comments",
    "author": "20092136",
    "comments": [
      {
        "user": "backyes",
        "created_at": "2016-11-15T04:14:50Z",
        "body": "这个 @reyoung 解释下吧，涉及到py_paddle实现细节。\n"
      },
      {
        "user": "reyoung",
        "created_at": "2016-11-15T04:36:36Z",
        "body": "No, it is not thread safe. And to use multithread in Python is a very bad practice because of GIL.\n"
      },
      {
        "user": "backyes",
        "created_at": "2016-11-15T05:07:04Z",
        "body": "@20092136 既然不是线程安全的，如果必须考虑多核加速的话，其实可以考虑多进程。\n\n@reyoung py_paddle 支持MulitiGradientMachine驾驭多核多gpu么？ \n"
      }
    ]
  },
  {
    "number": 467,
    "title": "CMake Error shows the version wrong",
    "created_at": "2016-11-15T02:10:05Z",
    "closed_at": "2016-11-15T12:49:48Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/PaddlePaddle/Paddle/issues/467",
    "body": "I installed gflags from source code. And gflags was built in /home/local/. Then when I compiled Paddle, I was meeting the following errors.  I have verified the CMake version on my machine is 3.6 above 2.8,  however it always shows \"This file relies on consumers using CMake 2.8.12 or greater.\", What's the reason ? Could you help me please ? Thanks\r\n\r\n\r\n/////////////////////////////////////////////////////////////////////////////////////////////////////////\r\ncmake  .. -DWITH_GPU=OFF -DWITH_DOC=OFF\r\n\r\n-- No preference for use of exported gflags CMake configuration set, and no hints for include/library directories provided. Defaulting to preferring an installed/exported gflags CMake configuration if available.\r\nCMake Error at /home/local/lib/cmake/gflags/gflags-targets.cmake:66 (message):\r\n  This file relies on consumers using CMake 2.8.12 or greater.\r\nCall Stack (most recent call first):\r\n  /home/local/lib/cmake/gflags/gflags-config.cmake:10 (include)\r\n  cmake/FindGflags.cmake:318 (find_package)\r\n  CMakeLists.txt:27 (find_package)\r\n////////////////////////////////////////////////////////////////////////////////////////////////////////////",
    "comments_url": "https://api.github.com/repos/PaddlePaddle/Paddle/issues/467/comments",
    "author": "gaoshan2006",
    "comments": [
      {
        "user": "hedaoyuan",
        "created_at": "2016-11-15T02:49:12Z",
        "body": "Have not encountered such a problem. \nTry modify the first line of the `CMakeLists.txt` file to `cmake_minimum_required (VERSION 2.8.12)`.\nBy the way, what version of `gflags` you use?\n"
      },
      {
        "user": "gaoshan2006",
        "created_at": "2016-11-15T03:35:29Z",
        "body": "The version of  gflags source code I got from github  is 1.8.3.1\nI modified CMakeLists.txt file, by changing  \"cmake_minimum_required (VERSION 2.8) \" to \"cmake_minimum_required (VERSION 2.8.12) \"\n\nThen the error shows: \ncmake .. -DWITH_GPU=OFF -DWITH_DOC=OFF\nCMake Error at CMakeLists.txt:1 (cmake_minimum_required):\n  CMake 2.8.12 or higher is required.  You are running version 2.8.11\n\nBut actually, when I check cmake version (\"cmake -version\"), the result is :\ncmake version 3.6.20160704-g75232\n"
      },
      {
        "user": "hedaoyuan",
        "created_at": "2016-11-15T04:48:28Z",
        "body": "I think the problem may be in your cmake environment.\nIn my environment, `cmake -version` show `cmake version 3.2.2`.\nIf set `cmake_minimum_required(VERSION 3.3)`,  the following error will be reported.\n\n> CMake Error at CMakeLists.txt:1 (cmake_minimum_required):\n>  CMake 3.3 or higher is required.  You are running version 3.2.2\n\nIf set the VERSION less than 3.2, no error reported.\n"
      },
      {
        "user": "gaoshan2006",
        "created_at": "2016-11-15T12:49:48Z",
        "body": "Make sense.  It looks the problem is from my cmake.  Thanks a lot !\n"
      }
    ]
  },
  {
    "number": 418,
    "title": "\"Double requirement given\" problem",
    "created_at": "2016-11-10T03:34:13Z",
    "closed_at": "2016-11-11T03:20:08Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/PaddlePaddle/Paddle/issues/418",
    "body": "I got below errors. Currently, I resolved this problem by remove one of them. I am working with the latest code. So I guess the problem is due to my docker image is outdated. But I don't want to download the latest docker image and have a try. Could you tell me how to solve this problem?\r\n```\r\nFirst time run paddle, need to install some python dependencies.\r\nUnpacking /usr/local/opt/paddle/share/wheels/paddle-0.8.0b-py2-none-any.whl\r\nUnpacking /usr/local/opt/paddle/share/wheels/paddle-0.8.0b1-py2-none-any.whl\r\nCleaning up...\r\nDouble requirement given: paddle==0.8.0b1 from file:///usr/local/opt/paddle/share/wheels/paddle-0.8.0b1-py2-none-any.whl (already in paddle==0.8.0b from file:///usr/local/opt/paddle/share/wheels/paddle-0.8.0b-py2-none-any.whl, name='paddle')\r\nStoring debug log for failure in /root/.pip/pip.log\r\npip install wheels failed. \r\nPlease use 'sudo paddle' at the first time you use PaddlePaddle\r\nPaddlePaddle will install some python dependencies automatically.\r\n```\r\n\r\n```\r\n\r\nFirst time run paddle, need to install some python dependencies.\r\nUnpacking /usr/local/opt/paddle/share/wheels/paddle-0.8.0b2-py2-none-any.whl\r\nUnpacking /usr/local/opt/paddle/share/wheels/py_paddle-0.8.0b-cp27-none-linux_x86_64.whl\r\nUnpacking /usr/local/opt/paddle/share/wheels/py_paddle-0.8.0b1-cp27-none-linux_x86_64.whl\r\nCleaning up...\r\nDouble requirement given: py-paddle==0.8.0b1 from file:///usr/local/opt/paddle/share/wheels/py_paddle-0.8.0b1-cp27-none-linux_x86_64.whl (already in py-paddle==0.8.0b from file:///usr/local/opt/paddle/share/wheels/py_paddle-0.8.0b-cp27-none-linux_x86_64.whl, name='py-paddle')\r\nStoring debug log for failure in /root/.pip/pip.log\r\npip install wheels failed. \r\nPlease use 'sudo paddle' at the first time you use PaddlePaddle\r\nPaddlePaddle will install some python dependencies automatically\r\n```\r\n",
    "comments_url": "https://api.github.com/repos/PaddlePaddle/Paddle/issues/418/comments",
    "author": "zuowang",
    "comments": [
      {
        "user": "luotao1",
        "created_at": "2016-11-10T03:44:32Z",
        "body": "‘ I am working with the latest code’：请问你是用源码编译develop分支出现上述问题的么\n"
      },
      {
        "user": "zuowang",
        "created_at": "2016-11-10T03:54:19Z",
        "body": "When I ran command `paddle version`.\n"
      },
      {
        "user": "reyoung",
        "created_at": "2016-11-10T04:06:46Z",
        "body": "@zuowang \nPlease uninstall Paddle before install a new version.\n\n``` bash\npip uninstall -u paddle py_paddle\nrm -rf /usr/local/bin/paddle /usr/local/opt/paddle\n```\n"
      },
      {
        "user": "zuowang",
        "created_at": "2016-11-10T04:58:51Z",
        "body": "@reyoung sorry, it doesn't work.\n"
      },
      {
        "user": "reyoung",
        "created_at": "2016-11-10T04:59:56Z",
        "body": "@zuowang \nAnd clean your git checkout directory by\n\n``` bash\ngit clean -fxd  # note it is danger, please commit your local change before\n```\n"
      },
      {
        "user": "zuowang",
        "created_at": "2016-11-10T06:00:58Z",
        "body": "@reyoung sorry, it doesn't work.\n"
      },
      {
        "user": "qingqing01",
        "created_at": "2016-11-10T12:20:18Z",
        "body": "@zuowang Maybe you need to remove the package in `Paddle/paddle/dist/` path by  `rm -rf Paddle/paddle/dist/*`. Then make install again.\n"
      },
      {
        "user": "zuowang",
        "created_at": "2016-11-11T03:20:08Z",
        "body": "It works, Thank you!\n"
      }
    ]
  },
  {
    "number": 352,
    "title": "Build errors with Mac OS X",
    "created_at": "2016-11-04T06:22:28Z",
    "closed_at": "2016-11-08T03:01:50Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/PaddlePaddle/Paddle/issues/352",
    "body": "When I run `make` after `cmake`  succeeded, it complains that\r\n\r\n```\r\n[  5%] Built target gen_proto_py\r\n[  9%] Built target paddle_proto\r\n[ 11%] Built target paddle_cuda\r\n[ 11%] Building CXX object paddle/utils/CMakeFiles/paddle_utils.dir/Util.cpp.o\r\nIn file included from /Users/yi/work/paddle/paddle/utils/Util.cpp:16:\r\nIn file included from /Users/yi/work/paddle/paddle/utils/Util.h:31:\r\nIn file included from /Users/yi/work/paddle/paddle/utils/Logging.h:183:\r\n/usr/local/include/glog/logging.h:695:32: error: comparison of integers of different signs:\r\n      'const unsigned long long' and 'const int' [-Werror,-Wsign-compare]\r\nDEFINE_CHECK_OP_IMPL(Check_NE, !=)  // Use CHECK(x == NULL) instead.\r\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~\r\n/usr/local/include/glog/logging.h:683:32: note: expanded from macro 'DEFINE_CHECK_OP_IMPL'\r\n    if (GOOGLE_PREDICT_TRUE(v1 op v2)) return NULL; \\\r\n                               ^\r\n/usr/local/include/glog/logging.h:133:53: note: expanded from macro 'GOOGLE_PREDICT_TRUE'\r\n#define GOOGLE_PREDICT_TRUE(x) (__builtin_expect(!!(x), 1))\r\n                                                    ^\r\n/Users/yi/work/paddle/paddle/utils/Util.cpp:109:3: note: in instantiation of function template specialization\r\n      'google::Check_NEImpl<unsigned long long, int>' requested here\r\n  CHECK_NE(tid, -1);\r\n  ^\r\n/usr/local/include/glog/logging.h:766:30: note: expanded from macro 'CHECK_NE'\r\n#define CHECK_NE(val1, val2) CHECK_OP(_NE, !=, val1, val2)\r\n                             ^\r\n/usr/local/include/glog/logging.h:741:3: note: expanded from macro 'CHECK_OP'\r\n  CHECK_OP_LOG(name, op, val1, val2, google::LogMessageFatal)\r\n  ^\r\n/usr/local/include/glog/logging.h:732:18: note: expanded from macro 'CHECK_OP_LOG'\r\n         google::Check##name##Impl(                      \\\r\n                 ^\r\n<scratch space>:165:1: note: expanded from here\r\nCheck_NEImpl\r\n^\r\n1 error generated.\r\nmake[2]: *** [paddle/utils/CMakeFiles/paddle_utils.dir/Util.cpp.o] Error 1\r\nmake[1]: *** [paddle/utils/CMakeFiles/paddle_utils.dir/all] Error 2\r\nmake: *** [all] Error 2\r\n```\r\n\r\nI am running Mac OS X 10.10.5 and Xcode 7.2.1.\r\n\r\n```\r\n$ clang --version\r\nApple LLVM version 7.0.2 (clang-700.1.81)\r\nTarget: x86_64-apple-darwin14.5.0\r\nThread model: posix\r\n```",
    "comments_url": "https://api.github.com/repos/PaddlePaddle/Paddle/issues/352/comments",
    "author": "wangkuiyi",
    "comments": [
      {
        "user": "backyes",
        "created_at": "2016-11-04T06:45:26Z",
        "body": "We need to address installation issues before next milestone. @gangliao \n"
      },
      {
        "user": "gangliao",
        "created_at": "2016-11-04T07:10:27Z",
        "body": "@wangkuiyi  This bug might be triggered when the different version of compiler is used. I have met same problem many times across different source files in Paddle. I guess the similar problem still exists somewhere.  @reyoung \n"
      }
    ]
  },
  {
    "number": 345,
    "title": "Mac上paddle安装成功后执行时报段错误",
    "created_at": "2016-11-04T02:44:26Z",
    "closed_at": "2016-11-08T03:01:49Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/PaddlePaddle/Paddle/issues/345",
    "body": "运行demo中sentiment的例子，报一下错误：\r\n```\r\nI1104 10:38:17.781116 2008993792 Util.cpp:130] Calling runInitFunctions\r\nI1104 10:38:17.781256 2008993792 Util.cpp:143] Call runInitFunctions done.\r\n[INFO 2016-11-04 10:38:17,889 networks.py:1282] The input order is [word, label]\r\n[INFO 2016-11-04 10:38:17,889 networks.py:1289] The output order is [__cost_0__]\r\nI1104 10:38:17.891353 2008993792 Trainer.cpp:170] trainer mode: Normal\r\n*** Aborted at 1478227097 (unix time) try \"date -d @1478227097\" if you are using GNU date ***\r\nPC: @        0x10edc27f8 paddle::Weight::Weight()\r\n*** SIGSEGV (@0xa0) received by PID 9930 (TID 0x7fff77bed000) stack trace: ***\r\n    @     0x7fff856ffeaa _sigtramp\r\n    @                0x0 (unknown)\r\n    @        0x10eb9bbcd paddle::TableProjection::TableProjection()\r\n    @        0x10eb9c29e _ZNSt3__128__invoke_void_return_wrapperIPN6paddle10ProjectionEE6__callIJRZNS1_14ClassRegistrarIS2_JNS1_16ProjectionConfigENS_10shared_ptrINS1_9ParameterEEEbEE13registerClassINS1_15TableProjectionEEEvRKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEEUlS7_SA_bE_S7_SA_bEEES3_DpOT_\r\n    @        0x10eb9c20d _ZNSt3__110__function6__funcIZN6paddle14ClassRegistrarINS2_10ProjectionEJNS2_16ProjectionConfigENS_10shared_ptrINS2_9ParameterEEEbEE13registerClassINS2_15TableProjectionEEEvRKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEEUlS5_S8_bE_NSF_ISK_EEFPS4_S5_S8_bEEclEOS5_OS8_Ob\r\n    @        0x10ebac7ef _ZN6paddle14ClassRegistrarINS_10ProjectionEJNS_16ProjectionConfigENSt3__110shared_ptrINS_9ParameterEEEbEE12createByTypeERKNS3_12basic_stringIcNS3_11char_traitsIcEENS3_9allocatorIcEEEES2_S6_b\r\n    @        0x10ebac66d paddle::Projection::create()\r\n    @        0x10ebb60d8 paddle::MixedLayer::init()\r\n    @        0x10ec12242 paddle::NeuralNetwork::init()\r\n    @        0x10ec18a83 paddle::MultiGradientMachine::MultiGradientMachine()\r\n    @        0x10ec2017e paddle::GradientMachine::create()\r\n    @        0x10ec9ae46 paddle::TrainerInternal::init()\r\n    @        0x10ec96be7 paddle::Trainer::init()\r\n    @        0x10eb93d1b main\r\n    @     0x7fff940e95ad start\r\n    @                0xb (unknown)\r\n/Users/baidu/local/bin/paddle: line 81:  9930 Segmentation fault: 11  ${DEBUGGER} $MYDIR/../opt/paddle/bin/paddle_trainer ${@:2}\r\n```\r\n\r\n利用gdb调试得到的信息：\r\n```\r\nI1104 10:37:35.910127 2008993792 Util.cpp:155] commandline: /Users/baidu/local/opt/paddle/bin/paddle_trainer --config=trainer_config.py --save_dir=./model_output --job=train --use_gpu=false --trainer_count=4 --num_passes=10 --log_period=10 --dot_period=20 --show_parameter_stats_period=100 --test_all_data_in_one_period=1\r\nI1104 10:37:35.910747 2008993792 Util.cpp:130] Calling runInitFunctions\r\nI1104 10:37:35.910902 2008993792 Util.cpp:143] Call runInitFunctions done.\r\n[New Thread 0x1913 of process 9904]\r\n[INFO 2016-11-04 10:37:36,410 networks.py:1282] The input order is [word, label]\r\n[INFO 2016-11-04 10:37:36,410 networks.py:1289] The output order is [__cost_0__]\r\nI1104 10:37:36.412492 2008993792 Trainer.cpp:170] trainer mode: Normal\r\n\r\nThread 1 received signal SIGSEGV, Segmentation fault.\r\npaddle::Weight::Weight (this=0x107a6af70, height=0, width=128, param=...) at /Users/baidu/codehub/Paddle/paddle/parameter/Weight.cpp:21\r\n21\t  VectorPtr vPtr = param->getBuf(PARAMETER_VALUE);\r\n```\r\n\r\nmake test 发现一些单测过不了：\r\n```\r\nThe following tests FAILED:\r\n\t 22 - test_PyDataProvider (Failed)\r\n\t 24 - test_RecurrentGradientMachine (Failed)\r\n\t 25 - test_NetworkCompare (Failed)\r\n\t 26 - test_PyDataProvider2 (Failed)\r\n\t 30 - test_Prediction (Failed)\r\n\t 31 - test_Compare (Failed)\r\n\t 32 - test_Trainer (Failed)\r\n\t 33 - test_TrainerOnePass (Failed)\r\n\t 34 - test_CompareTwoNets (Failed)\r\n\t 35 - test_CompareTwoOpts (Failed)\r\n\t 36 - test_CompareSparse (Failed)\r\n\t 37 - test_recurrent_machine_generation (Failed)\r\n\t 38 - test_PyDataProviderWrapper (Failed)\r\n\t 39 - test_config_parser (Failed)\r\n\t 40 - test_swig_api (Failed)\r\n\t 41 - layers_test (Failed)\r\n\t 42 - test_layerHelpers (Failed)\r\nErrors while running CTest\r\nmake: *** [test] Error 8\r\n```",
    "comments_url": "https://api.github.com/repos/PaddlePaddle/Paddle/issues/345/comments",
    "author": "5idaidai",
    "comments": [
      {
        "user": "gangliao",
        "created_at": "2016-11-04T03:00:51Z",
        "body": "@5idaidai  请给我看一下单测的详细信息：\n 你可以在你mac上输入：`make test ARGS=\"-V -R test_PyDataProvider\"`\n\n粘贴详细信息到这里\n"
      },
      {
        "user": "5idaidai",
        "created_at": "2016-11-04T03:31:59Z",
        "body": "按`make test ARGS=\"-V -R test_PyDataProvider\"`执行后发现`test_PyDataProvider`等单测错误是由于先安装了python库导致的，目前还有两个单测过不了：`test_swig_api`和`test_layerHelpers`，\n其中`test_swig_api`报错的详细信息：\n\n```\n    Start 40: test_swig_api\n\n40: Test command: /bin/bash \"/Users/baidu/codehub/Paddle/paddle/api/test/run_tests.sh\"\n40: Test timeout computed to be: 9.99988e+06\n40: /Users/baidu/codehub/Paddle/paddle/api/test/run_tests.sh: line 23: [: ../../dist/py_paddle-0.8.0b3-cp27-cp27m-macosx_10_11_intel.whl: binary operator expected\n40: rm: .test_env: No such file or directory\n40: rm: -rf: No such file or directory\n40: /Users/baidu/codehub/Paddle/paddle/api/test/run_tests.sh: line 28: virtualenv: command not found\n40: /Users/baidu/codehub/Paddle/paddle/api/test/run_tests.sh: line 29: .test_env/bin/activate: No such file or directory\n40: Requirement already satisfied: py-paddle==0.8.0b3 from file:///Users/baidu/codehub/Paddle/paddle/dist/py_paddle-0.8.0b3-cp27-cp27m-macosx_10_11_intel.whl in /Library/Python/2.7/site-packages\n40: Requirement already satisfied: numpy>=1.8.0 in /Library/Python/2.7/site-packages (from py-paddle==0.8.0b3)\n40: Requirement already satisfied: protobuf>=2.4.1 in /Library/Python/2.7/site-packages (from py-paddle==0.8.0b3)\n40: Requirement already satisfied: six>=1.9 in /Library/Python/2.7/site-packages (from protobuf>=2.4.1->py-paddle==0.8.0b3)\n40: Requirement already satisfied: setuptools in /System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python (from protobuf>=2.4.1->py-paddle==0.8.0b3)\n40: test testArguments.py\n40: Traceback (most recent call last):\n40:   File \"testArguments.py\", line 15, in <module>\n40:     from py_paddle import swig_paddle\n40:   File \"/Library/Python/2.7/site-packages/py_paddle/__init__.py\", line 15, in <module>\n40:     from util import DataProviderWrapperConverter\n40:   File \"/Library/Python/2.7/site-packages/py_paddle/util.py\", line 19, in <module>\n40:     import swig_paddle\n40:   File \"/Library/Python/2.7/site-packages/py_paddle/swig_paddle.py\", line 28, in <module>\n40:     _swig_paddle = swig_import_helper()\n40:   File \"/Library/Python/2.7/site-packages/py_paddle/swig_paddle.py\", line 24, in swig_import_helper\n40:     _mod = imp.load_module('_swig_paddle', fp, pathname, description)\n40: ImportError: dlopen(/Library/Python/2.7/site-packages/py_paddle/_swig_paddle.so, 2): Library not loaded: /usr/local/opt/openblas/lib/libopenblas_haswellp-r0.2.18.dylib\n40:   Referenced from: /Library/Python/2.7/site-packages/py_paddle/_swig_paddle.so\n40:   Reason: image not found\n1/1 Test #40: test_swig_api ....................***Failed    0.40 sec\n```\n\n`test_layerHelpers`具体报错：是由于md5校验的问题，已解决。\n\n但是执行paddle进行训练时依然报上面错误。\n"
      },
      {
        "user": "5idaidai",
        "created_at": "2016-11-04T03:59:42Z",
        "body": "目前`test_swig_api`的单测也可能跑通，问题主要是加载_swig_paddle.so的时候去寻找libopenblas_haswellp-r0.2.18.dylib链接库，而openblas安装的名字是libopenblasp-r0.2.18.dylib，建了一个软链可以跑通，而且发现：测试swig_api的时候是可以正常训练的：\n\n```\n40: test testTrainer.py\n40: I1104 11:51:40.863245 2008993792 Util.cpp:155] commandline:  --use_gpu=0 --trainer_count=1\n40: I1104 11:51:40.863308 2008993792 Util.cpp:130] Calling runInitFunctions\n40: I1104 11:51:40.863461 2008993792 Util.cpp:143] Call runInitFunctions done.\n40: [INFO 2016-11-04 11:51:40,872 networks.py:1282] The input order is [input, lbl]\n40: [INFO 2016-11-04 11:51:40,872 networks.py:1289] The output order is [__cost_0__]\n40: I1104 11:51:40.876513 2008993792 Trainer.cpp:170] trainer mode: Normal\n40: I1104 11:51:40.876585 2008993792 GradientMachine.cpp:134] Initing parameters..\n40: I1104 11:51:40.876593 2008993792 ThreadLocal.cpp:37] thread use undeterministic rand seed:134790\n40: I1104 11:51:40.880947 2008993792 GradientMachine.cpp:141] Init parameters done.\n40: ..........I1104 11:51:42.899732 2008993792 TrainerInternal.cpp:182]  Pass=0 Batch=10 samples=10000 AvgCost=2.34816 Eval: classification_error_evaluator=0.904\n40: I1104 11:51:42.900073 2008993792 GradientMachine.cpp:112] Saving parameters to ./output/model/pass-00000\n40: [INFO 2016-11-04 11:51:42,903 testTrainer.py:41] train cost=2.348161\n40: I1104 11:51:44.894619 2008993792 Tester.cpp:127]  Test samples=10000 cost=2.31819 Eval: classification_error_evaluator=0.9004\n40: [INFO 2016-11-04 11:51:44,894 testTrainer.py:56] test cost=2.318192\n40: ..........I1104 11:51:46.906138 2008993792 TrainerInternal.cpp:182]  Pass=1 Batch=10 samples=10000 AvgCost=2.31541 Eval: classification_error_evaluator=0.9\n40: I1104 11:51:46.906260 2008993792 GradientMachine.cpp:112] Saving parameters to ./output/model/pass-00001\n40: [INFO 2016-11-04 11:51:46,908 testTrainer.py:41] train cost=2.315411\n40: I1104 11:51:48.853003 2008993792 Tester.cpp:127]  Test samples=10000 cost=2.31046 Eval: classification_error_evaluator=0.8995\n40: [INFO 2016-11-04 11:51:48,853 testTrainer.py:56] test cost=2.310463\n1/1 Test #40: test_swig_api ....................   Passed   12.40 sec\n```\n\n但是执行paddle binary——paddle_trainer进行训练时依然报错：\n\n```\n sh train.sh\nI1104 11:56:00.007506 2008993792 Util.cpp:155] commandline: /Users/baidu/local/bin/../opt/paddle/bin/paddle_trainer --config=trainer_config.py --save_dir=./model_output --job=train --use_gpu=false --trainer_count=4 --num_passes=10 --log_period=10 --dot_period=20 --show_parameter_stats_period=100 --test_all_data_in_one_period=1\nI1104 11:56:00.008182 2008993792 Util.cpp:130] Calling runInitFunctions\nI1104 11:56:00.008308 2008993792 Util.cpp:143] Call runInitFunctions done.\n[INFO 2016-11-04 11:56:00,121 networks.py:1282] The input order is [word, label]\n[INFO 2016-11-04 11:56:00,121 networks.py:1289] The output order is [__cost_0__]\nI1104 11:56:00.123587 2008993792 Trainer.cpp:170] trainer mode: Normal\n*** Aborted at 1478231760 (unix time) try \"date -d @1478231760\" if you are using GNU date ***\nPC: @        0x1017807f8 paddle::Weight::Weight()\n*** SIGSEGV (@0xa0) received by PID 11703 (TID 0x7fff77bed000) stack trace: ***\n    @     0x7fff856ffeaa _sigtramp\n    @                0x0 (unknown)\n    @        0x101559bcd paddle::TableProjection::TableProjection()\n    @        0x10155a29e _ZNSt3__128__invoke_void_return_wrapperIPN6paddle10ProjectionEE6__callIJRZNS1_14ClassRegistrarIS2_JNS1_16ProjectionConfigENS_10shared_ptrINS1_9ParameterEEEbEE13registerClassINS1_15TableProjectionEEEvRKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEEUlS7_SA_bE_S7_SA_bEEES3_DpOT_\n    @        0x10155a20d _ZNSt3__110__function6__funcIZN6paddle14ClassRegistrarINS2_10ProjectionEJNS2_16ProjectionConfigENS_10shared_ptrINS2_9ParameterEEEbEE13registerClassINS2_15TableProjectionEEEvRKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEEUlS5_S8_bE_NSF_ISK_EEFPS4_S5_S8_bEEclEOS5_OS8_Ob\n    @        0x10156a7ef _ZN6paddle14ClassRegistrarINS_10ProjectionEJNS_16ProjectionConfigENSt3__110shared_ptrINS_9ParameterEEEbEE12createByTypeERKNS3_12basic_stringIcNS3_11char_traitsIcEENS3_9allocatorIcEEEES2_S6_b\n    @        0x10156a66d paddle::Projection::create()\n    @        0x1015740d8 paddle::MixedLayer::init()\n    @        0x1015d0242 paddle::NeuralNetwork::init()\n    @        0x1015d6a83 paddle::MultiGradientMachine::MultiGradientMachine()\n    @        0x1015de17e paddle::GradientMachine::create()\n    @        0x101658e46 paddle::TrainerInternal::init()\n    @        0x101654be7 paddle::Trainer::init()\n    @        0x101551d1b main\n    @     0x7fff940e95ad start\n    @                0xb (unknown)\n/Users/baidu/local/bin/paddle: line 81: 11703 Segmentation fault: 11  ${DEBUGGER} $MYDIR/../opt/paddle/bin/paddle_trainer ${@:2}\n```\n"
      },
      {
        "user": "gangliao",
        "created_at": "2016-11-04T04:31:34Z",
        "body": "@5idaidai  我在尝试复现  \n"
      },
      {
        "user": "5idaidai",
        "created_at": "2016-11-04T05:39:00Z",
        "body": "用lldb看了下core，日志如下：\n\n```\nCore file '/cores/core.11939' (x86_64) was loaded.\n(lldb) bt\n* thread #1: tid = 0x0000, 0x0000000101c7a7f8 paddle_trainer`paddle::Weight::Weight(unsigned long, unsigned long, std::__1::shared_ptr<paddle::Parameter>) [inlined] std::__1::shared_ptr<paddle::VectorT<float> >::shared_ptr(std::__1::shared_ptr<paddle::VectorT<float> > const&) at memory:4250, stop reason = signal SIGSTOP\n  * frame #0: 0x0000000101c7a7f8 paddle_trainer`paddle::Weight::Weight(unsigned long, unsigned long, std::__1::shared_ptr<paddle::Parameter>) [inlined] std::__1::shared_ptr<paddle::VectorT<float> >::shared_ptr(std::__1::shared_ptr<paddle::VectorT<float> > const&) at memory:4250\n    frame #1: 0x0000000101c7a7f8 paddle_trainer`paddle::Weight::Weight(unsigned long, unsigned long, std::__1::shared_ptr<paddle::Parameter>) [inlined] std::__1::shared_ptr<paddle::VectorT<float> >::shared_ptr(std::__1::shared_ptr<paddle::VectorT<float> > const&) at memory:4252\n    frame #2: 0x0000000101c7a7f8 paddle_trainer`paddle::Weight::Weight(this=0x00007fa619d7dee0, height=0, width=128, param=nullptr) + 56 at Weight.cpp:21\n    frame #3: 0x0000000101a53bcd paddle_trainer`paddle::TableProjection::TableProjection(this=0x00007fa619d7de40, config=<unavailable>, parameter=<unavailable>, useGpu=false) + 221 at TableProjection.cpp:26\n    frame #4: 0x0000000101a5429e paddle_trainer`paddle::Projection* std::__1::__invoke_void_return_wrapper<paddle::Projection*>::__call<void paddle::ClassRegistrar<paddle::Projection, paddle::ProjectionConfig, std::__1::shared_ptr<paddle::Parameter>, bool>::registerClass<paddle::TableProjection>(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)::'lambda'(paddle::ProjectionConfig, std::__1::shared_ptr<paddle::Parameter>, bool)&, paddle::ProjectionConfig, std::__1::shared_ptr<paddle::Parameter>, bool>(void paddle::ClassRegistrar<paddle::Projection, paddle::ProjectionConfig, std::__1::shared_ptr<paddle::Parameter>, bool>::registerClass<paddle::TableProjection>(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)::'lambda'(paddle::ProjectionConfig, std::__1::shared_ptr<paddle::Parameter>, bool)&&&, paddle::ProjectionConfig&&, std::__1::shared_ptr<paddle::Parameter>&&, bool&&) [inlined] paddle::TableProjection::TableProjection(this=<unavailable>, config=<unavailable>, parameter=<unavailable>) + 94 at TableProjection.cpp:24\n    frame #5: 0x0000000101a54288 paddle_trainer`paddle::Projection* std::__1::__invoke_void_return_wrapper<paddle::Projection*>::__call<void paddle::ClassRegistrar<paddle::Projection, paddle::ProjectionConfig, std::__1::shared_ptr<paddle::Parameter>, bool>::registerClass<paddle::TableProjection>(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)::'lambda'(paddle::ProjectionConfig, std::__1::shared_ptr<paddle::Parameter>, bool)&, paddle::ProjectionConfig, std::__1::shared_ptr<paddle::Parameter>, bool>(void paddle::ClassRegistrar<paddle::Projection, paddle::ProjectionConfig, std::__1::shared_ptr<paddle::Parameter>, bool>::registerClass<paddle::TableProjection>(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)::'lambda'(paddle::ProjectionConfig, std::__1::shared_ptr<paddle::Parameter>, bool)&&&, paddle::ProjectionConfig&&, std::__1::shared_ptr<paddle::Parameter>&&, bool&&) [inlined] void paddle::ClassRegistrar<paddle::Projection, paddle::ProjectionConfig, std::__1::shared_ptr<paddle::Parameter>, bool>::registerClass<paddle::TableProjection>(args=<unavailable>)::'lambda'(paddle::ProjectionConfig, std::__1::shared_ptr<paddle::Parameter>, bool)::operator()(paddle::ProjectionConfig, std::__1::shared_ptr<paddle::Parameter>, bool) const + 13 at ClassRegistrar.h:60\n    frame #6: 0x0000000101a5427b paddle_trainer`paddle::Projection* std::__1::__invoke_void_return_wrapper<paddle::Projection*>::__call<void paddle::ClassRegistrar<paddle::Projection, paddle::ProjectionConfig, std::__1::shared_ptr<paddle::Parameter>, bool>::registerClass<paddle::TableProjection>(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)::'lambda'(paddle::ProjectionConfig, std::__1::shared_ptr<paddle::Parameter>, bool)&, paddle::ProjectionConfig, std::__1::shared_ptr<paddle::Parameter>, bool>(void paddle::ClassRegistrar<paddle::Projection, paddle::ProjectionConfig, std::__1::shared_ptr<paddle::Parameter>, bool>::registerClass<paddle::TableProjection>(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)::'lambda'(paddle::ProjectionConfig, std::__1::shared_ptr<paddle::Parameter>, bool)&&&, paddle::ProjectionConfig&&, std::__1::shared_ptr<paddle::Parameter>&&, bool&&) [inlined] decltype(__args=<unavailable>, __args=<unavailable>, __args=<unavailable>)::'lambda'(paddle::ProjectionConfig, std::__1::shared_ptr<paddle::Parameter>, bool)&>(fp)(std::__1::forward<paddle::ProjectionConfig, std::__1::shared_ptr<paddle::Parameter>, bool>(fp0))) std::__1::__invoke<void paddle::ClassRegistrar<paddle::Projection, paddle::ProjectionConfig, std::__1::shared_ptr<paddle::Parameter>, bool>::registerClass<paddle::TableProjection>(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)::'lambda'(paddle::ProjectionConfig, std::__1::shared_ptr<paddle::Parameter>, bool)&, paddle::ProjectionConfig, std::__1::shared_ptr<paddle::Parameter>, bool>(void paddle::ClassRegistrar<paddle::Projection, paddle::ProjectionConfig, std::__1::shared_ptr<paddle::Parameter>, bool>::registerClass<paddle::TableProjection>(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)::'lambda'(paddle::ProjectionConfig, std::__1::shared_ptr<paddle::Parameter>, bool)&&&, paddle::ProjectionConfig&&, std::__1::shared_ptr<paddle::Parameter>&&, bool&&) + 34 at __functional_base:416\n    frame #7: 0x0000000101a54259 paddle_trainer`paddle::Projection* std::__1::__invoke_void_return_wrapper<paddle::Projection*>::__call<void paddle::ClassRegistrar<paddle::Projection, paddle::ProjectionConfig, std::__1::shared_ptr<paddle::Parameter>, bool>::registerClass<paddle::TableProjection>(__args=<unavailable>, __args=<unavailable>, __args=<unavailable>, __args=<unavailable>)::'lambda'(paddle::ProjectionConfig, std::__1::shared_ptr<paddle::Parameter>, bool)&, paddle::ProjectionConfig, std::__1::shared_ptr<paddle::Parameter>, bool>(void paddle::ClassRegistrar<paddle::Projection, paddle::ProjectionConfig, std::__1::shared_ptr<paddle::Parameter>, bool>::registerClass<paddle::TableProjection>(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)::'lambda'(paddle::ProjectionConfig, std::__1::shared_ptr<paddle::Parameter>, bool)&&&, paddle::ProjectionConfig&&, std::__1::shared_ptr<paddle::Parameter>&&, bool&&) + 25 at __functional_base:437\n    frame #8: 0x0000000101a5420d paddle_trainer`std::__1::__function::__func<void paddle::ClassRegistrar<paddle::Projection, paddle::ProjectionConfig, std::__1::shared_ptr<paddle::Parameter>, bool>::registerClass<paddle::TableProjection>(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)::'lambda'(paddle::ProjectionConfig, std::__1::shared_ptr<paddle::Parameter>, bool), std::__1::allocator<void paddle::ClassRegistrar<paddle::Projection, paddle::ProjectionConfig, std::__1::shared_ptr<paddle::Parameter>, bool>::registerClass<paddle::TableProjection>(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)::'lambda'(paddle::ProjectionConfig, std::__1::shared_ptr<paddle::Parameter>, bool)>, paddle::Projection* (paddle::ProjectionConfig, std::__1::shared_ptr<paddle::Parameter>, bool)>::operator(this=<unavailable>, __arg=<unavailable>, __arg=<unavailable>, __arg=<unavailable>)(paddle::ProjectionConfig&&, std::__1::shared_ptr<paddle::Parameter>&&, bool&&) + 13 at functional:1437\n    frame #9: 0x0000000101a647ef paddle_trainer`paddle::ClassRegistrar<paddle::Projection, paddle::ProjectionConfig, std::__1::shared_ptr<paddle::Parameter>, bool>::createByType(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, paddle::ProjectionConfig, std::__1::shared_ptr<paddle::Parameter>, bool) [inlined] std::__1::function<paddle::Projection* (paddle::ProjectionConfig, std::__1::shared_ptr<paddle::Parameter>, bool)>::operator(__arg=<unavailable>)(paddle::ProjectionConfig, std::__1::shared_ptr<paddle::Parameter>, bool) const + 43 at functional:1817\n    frame #10: 0x0000000101a647c4 paddle_trainer`paddle::ClassRegistrar<paddle::Projection, paddle::ProjectionConfig, std::__1::shared_ptr<paddle::Parameter>, bool>::createByType(this=<unavailable>, type=<unavailable>, args=<unavailable>, args=<unavailable>, args=<unavailable>) + 244 at ClassRegistrar.h:68\n    frame #11: 0x0000000101a6466d paddle_trainer`paddle::Projection::create(config=<unavailable>, parameter=<unavailable>, useGpu=false) + 93 at Projection.cpp:29\n    frame #12: 0x0000000101a6e0d8 paddle_trainer`paddle::MixedLayer::init(this=0x00007fa61a8aea00, layerMap=<unavailable>, parameterMap=<unavailable>) + 424 at MixedLayer.cpp:32\n    frame #13: 0x0000000101aca242 paddle_trainer`paddle::NeuralNetwork::init(this=0x00007fa619c96c20, config=0x00007fa619c93ce0, callback=paddle::ParamInitCallback @ 0x00007fa619c92848, parameterTypes=0x00007fff5e1b6ea0, useGpu=false)>, std::__1::vector<paddle::enumeration_wrapper::ParameterType, std::__1::allocator<paddle::enumeration_wrapper::ParameterType> > const&, bool) + 2514 at NeuralNetwork.cpp:158\n    frame #14: 0x0000000101ad0a83 paddle_trainer`paddle::MultiGradientMachine::MultiGradientMachine(this=0x00007fa619c96a10, config=0x00007fa619c93ce0, useGpu=<unavailable>) + 627 at MultiGradientMachine.cpp:95\n    frame #15: 0x0000000101ad817e paddle_trainer`paddle::GradientMachine::create(config=0x00007fa619c93ce0, mode=<unavailable>, parameterTypes=<unavailable>) + 270 at GradientMachine.cpp:38\n    frame #16: 0x0000000101b52e46 paddle_trainer`paddle::TrainerInternal::init(this=0x00007fff5e1b7440, config=<unavailable>, gradientMachine=<unavailable>, intconfig=<unavailable>, stats=<unavailable>, testing=<unavailable>) + 326 at TrainerInternal.cpp:60\n    frame #17: 0x0000000101b4ebe7 paddle_trainer`paddle::Trainer::init(this=0x00007fff5e1b7358, config=<unavailable>, testing=false, gradientMachine=0x00007fff5e1b7320, dataProvider=0x00007fff5e1b7310, testDataProvider=0x00007fff5e1b7300) + 2439 at Trainer.cpp:174\n    frame #18: 0x0000000101a4bd1b paddle_trainer`main(argc=<unavailable>, argv=<unavailable>) + 1723 at TrainerMain.cpp:98\n    frame #19: 0x00007fff940e95ad libdyld.dylib`start + 1\n```\n\n看着像是`paddle_trainer`paddle::Weight::Weight(this=0x00007fa619d7dee0, height=0, width=128, param=nullptr) + 56 at Weight.cpp:21`这里传过去了空指针？不知道为什么会出现这种情况。\n"
      },
      {
        "user": "gangliao",
        "created_at": "2016-11-04T06:17:10Z",
        "body": "@5idaidai \nThat's awesome!!! Maybe you use CMake to build a debug version to figure out what's wrong there. Thanks.\n"
      },
      {
        "user": "5idaidai",
        "created_at": "2016-11-04T06:21:31Z",
        "body": "cmake的时候添加-DCMAKE_BUILD_TYPE=Debug？还需要其他操作吗？编译完成后直接执行paddle_trainer就可以么\n"
      },
      {
        "user": "gangliao",
        "created_at": "2016-11-04T06:26:34Z",
        "body": "@5idaidai  `-DCMAKE_BUILD_TYPE=Debug`就可以了。 我不确实直接执行paddle_trainer能否复现。\n"
      },
      {
        "user": "5idaidai",
        "created_at": "2016-11-04T06:47:29Z",
        "body": "加上debug参数重新编译后，执行paddle_trainer还是会出现那个问题，不过我发现一个现象就是，mac下编译出来的binary明显小很多，我怀疑是不是编译后链接出了问题？\n\nmac上编译出来的binary大小：\n\n```\n-rwxr-xr-x  1 baidu  staff    14M Nov  4 14:34 paddle_merge_model\n-rwxr-xr-x  1 baidu  staff    14M Nov  4 14:34 paddle_pserver_main\n-rwxr-xr-x  1 baidu  staff    15M Nov  4 14:34 paddle_trainer\n```\n\nlinux下编译出来的binary大小：\n\n```\n-rwxr-xr-x  1 work work 106M Nov  3 16:07 paddle_merge_model\n-rwxr-xr-x  1 work work 100M Nov  3 16:07 paddle_pserver_main\n-rwxr-xr-x  1 work work 110M Nov  3 16:07 paddle_trainer\n```\n"
      },
      {
        "user": "gangliao",
        "created_at": "2016-11-04T07:24:46Z",
        "body": "@5idaidai  或者你用了mkl\n"
      },
      {
        "user": "5idaidai",
        "created_at": "2016-11-04T08:27:41Z",
        "body": "查看paddle_trainer链接的结果：\n\n```\n$ otool -L /Users/baidu/local/bin/../opt/paddle/bin/paddle_trainer\n/Users/baidu/local/bin/../opt/paddle/bin/paddle_trainer:\n    /usr/local/opt/protobuf/lib/libprotobuf.9.dylib (compatibility version 10.0.0, current version 10.1.0)\n    /usr/local/opt/openblas/lib/libopenblasp-r0.2.18.dylib (compatibility version 0.0.0, current version 0.0.0)\n    /usr/lib/libz.1.dylib (compatibility version 1.0.0, current version 1.2.5)\n    /System/Library/Frameworks/Python.framework/Versions/2.7/Python (compatibility version 2.7.0, current version 2.7.10)\n    /usr/local/opt/glog/lib/libglog.0.dylib (compatibility version 1.0.0, current version 1.0.0)\n    /usr/local/opt/gflags/lib/libgflags.2.dylib (compatibility version 2.0.0, current version 2.1.2)\n    /usr/lib/libc++.1.dylib (compatibility version 1.0.0, current version 120.1.0)\n    /usr/lib/libSystem.B.dylib (compatibility version 1.0.0, current version 1226.10.1)\n```\n\n其中`libopenblasp-r0.2.18.dylib`的version是0.0.0，会是这个原因造成的吗？\n"
      },
      {
        "user": "gangliao",
        "created_at": "2016-11-04T08:29:33Z",
        "body": "我周末跟一下这个问题 @5idaidai \n你刚刚linux paddle那么大是因为你用mkl吗\n"
      },
      {
        "user": "5idaidai",
        "created_at": "2016-11-04T08:41:55Z",
        "body": "linux下我确实是用的公司的mkl库\n"
      },
      {
        "user": "gangliao",
        "created_at": "2016-11-04T09:10:47Z",
        "body": "@5idaidai  我的理解是mkl本身就很大 所以不是编译链接的问题。 我之后再认真follow吧。\n"
      },
      {
        "user": "5idaidai",
        "created_at": "2016-11-05T14:13:00Z",
        "body": "昨天仔细check了一下每步执行的数据，确实是在`Weight.cpp:21`中传入的参数为空指针，这主要是在生成网络配置的时候最开始哪层emebding层的iput size是根据词典的大小设置的，而在我mac上执行sentiment中的`preprocess.sh`进行数据预处理的时候生成的词典和训练、测试数据为空，（不知道是我电脑环境原因还是在mac上该脚本执行都不成功，具体还没check）从而导致网络配置参数的iput size为0，而使得出现空指针。\n"
      },
      {
        "user": "gangliao",
        "created_at": "2016-11-08T02:55:13Z",
        "body": "Remove mac build docs #386  经过讨论， 大家认为Mac OS X还没有经过完整的测试，先删掉了mac build 文档，等一切稳定了，会重新放开，近期我们的工作会主要集中在Docker和K8s上面。\n\n@5idaidai  如果你能继续跟进这个bug, 提交PR，我们万分感谢。\n"
      },
      {
        "user": "jacquesqiao",
        "created_at": "2016-12-10T06:13:06Z",
        "body": "这个问题的原因是get_imdb.sh 在生成数据的时候\r\ncp -r aclImdb/train/pos/ imdb/train/\r\ncp -r aclImdb/train/neg/ imdb/train/\r\n把pos和neg下的文件拷贝到了train下而不是train/pos和train/neg下，看到最新的develop分支中已经修复了"
      }
    ]
  },
  {
    "number": 338,
    "title": " Error sparse matrix mul ",
    "created_at": "2016-11-03T14:10:35Z",
    "closed_at": "2017-07-23T05:49:05Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/PaddlePaddle/Paddle/issues/338",
    "body": "F1103 21:54:53.385020 12754 Matrix.cpp:466] Check failed: ret == 0 (-1 vs. 0) Error sparse matrix mul \r\nF1103 21:54:53.385568 12748 Matrix.cpp:466] Check failed: ret == 0 (-1 vs. 0) Error sparse matrix mul \r\nF1103 21:54:53.385568 12748 Matrix.cpp:466] Check failed: ret == 0 (-1 vs. 0) Error sparse matrix mulF1103 21:54:53.386371 12751 Matrix.cpp:466] Check failed: ret == 0 (-1 vs. 0) Error sparse matrix mul \r\n\r\n什么情况下会触发 Error sparse matrix mul ？",
    "comments_url": "https://api.github.com/repos/PaddlePaddle/Paddle/issues/338/comments",
    "author": "20092136",
    "comments": [
      {
        "user": "backyes",
        "created_at": "2016-11-03T14:13:26Z",
        "body": "Paste you model if you feel free.  \n- Model file\n- PaddlePaddle version\n- command line\n- reproduce method.\n"
      },
      {
        "user": "20092136",
        "created_at": "2016-11-03T14:33:24Z",
        "body": "```\ndef lstm_dnn_net(seq_dim,              \n                feat_dim,              \n                class_dim,             \n                emb_dim=128,           \n                hid_dim=512,           \n                lstm_dim=128,          \n                is_predict=False):  \n    \"\"\"                                \n    lstm 和 DNN 网络                   \n    \"\"\"                                \n    bias_attr = ParameterAttribute(initial_std=0., l2_rate=0.0001)\n    fc_para_attr = ParameterAttribute(learning_rate=2e-3)\n    lstm_para_attr = ParameterAttribute(initial_std=0., learning_rate=2e-3)#, sparse_update=True)\n    sparse_up = ParameterAttribute(sparse_update=True, learning_rate=2e-3)\n    para_attr = [lstm_para_attr, fc_para_attr]\n    relu = ReluActivation()            \n\n    #seq_data = data_layer(\"seq\", seq_dim)\n    #emb = embedding_layer(input=seq_data, size=emb_dim)\n    #context_layer = text_conv_pool(input=emb, context_len=5, hidden_size=lstm_dim,\n    #        context_start=-1, fc_act=TanhActivation(), fc_bias_attr=bias_attr)\n\n    #bi_lstm = simple_lstm(input=emb, size=lstm_dim, concat_act=TanhActivation())\n\n    #bi_lstm = bidirectional_lstm(input=emb, size=lstm_dim, concat_act=relu)\n    #lstm_out = fc_layer(input=bi_lstm, size=lstm_dim, act=SoftmaxActivation(),\n    #        bias_attr=bias_attr)   \n\n    feat_data = data_layer(\"feat\", feat_dim)\n    feat_layer_1 = fc_layer(input=feat_data, size=hid_dim, act=relu,\n                   bias_attr=bias_attr, param_attr=sparse_up)\n    feat_layer_2 = fc_layer(input=feat_layer_1, size=hid_dim, bias_attr=bias_attr,\n            param_attr=fc_para_attr)\n    feat_layer_3 = fc_layer(input=feat_layer_2, size=hid_dim, bias_attr=bias_attr,\n            param_attr=fc_para_attr)\n    feat_layer_4 = fc_layer(input=feat_layer_3, size=hid_dim, bias_attr=bias_attr,\n            param_attr=fc_para_attr)\n    feat_layer_5 = fc_layer(input=feat_layer_4, size=hid_dim, bias_attr=bias_attr,\n            param_attr=fc_para_attr)\n\n    #output = fc_layer(name='fc_ly_4', input=[lstm_out, feat_layer_2], size=class_dim,\n    #                  act=SoftmaxActivation(),\n    #                  bias_attr=bias_attr, param_attr=para_attr)\n\n    output = fc_layer(name='fc_ly_4', input=feat_layer_5, size=class_dim, act=SoftmaxActivation(),\n                    bias_attr=bias_attr, param_attr=fc_para_attr)\n\n    if is_predict:                  \n        outputs(output)             \n    else:                           \n        #outputs(                   \n        #    classification_cost(input=output, label=data_layer('label', 1),\n        #        evaluator=[precision_recall_evaluator, classification_error_evaluator]))\n        outputs(                    \n            classification_cost(input=output, label=data_layer('label', 1)))\n```\n\n```\n@init_hook_wrapper                                                                                                                                   \ndef hook(obj, dictionary, **kwargs):\n    obj.slots = [SparseNonValueSlot(6121), IndexSlot(888)]\n    obj.dictionary = dictionary\n    obj.sym_dict = kwargs['tag_dict']\n    obj.pop_dict = kwargs['pop_dict']\n    obj.dis_dict = kwargs['dis_dict']\n    obj.logger.info('dict len : %d' % (len(obj.dictionary)))\n\n@provider(init_hook=hook)\ndef process(obj, file_name):\n    with open(file_name, 'r') as fdata:\n        for line in fdata:\n\n            arr = line.strip().split('\\t')\n            if len(arr) != 4:\n                continue\n            label, seq, sym, pop = arr \n\n            if obj.dis_dict.get(label) is None:\n                continue\n            label = int(obj.dis_dict[label])\n\n            if len(seq.strip()) == 0:\n                continue\n\n            feat_slot = [obj.sym_dict[s] for s in sym.split() if obj.sym_dict.get(s) is not None]\n            if len(feat_slot) <= 0:\n                continue\n            feat_slot.extend([obj.pop_dict[p] for p in pop.split() if obj.pop_dict.get(p) is not None])\n            if len(feat_slot) <= 0:\n                continue\n\n            obj.logger.info('feat_slot: %s' % feat_slot)\n            obj.logger.info('label: %s %s' % (arr[0], label))\n            yield feat_slot, label\n```\n\n```\npaddle cluster_train \\\n  --config=test/sentiment_p1/cluster_job_config/job_config.py \\\n  --use_gpu=gpu \\\n  --num_nodes=4 \\\n  --num_passes=20 \\\n  --log_period=100 \\\n  --dot_period=10 \\\n  --trainer_count=16 \\\n  --saving_period=1 \\\n  --thirdparty=./test/sentiment_p1/thirdparty \\\n  --job_name=test \\\n  --time_limit=700:00:00 \\\n  --submitter=angelababy \\\n  --config_args=is_local=0 \\\n  --where=test_cluster \\   \n```\n\nFor\npaddle_platform-v5.10.alpha\n"
      },
      {
        "user": "backyes",
        "created_at": "2016-11-03T14:59:46Z",
        "body": "@reyoung Can you help to check dataprovider?  It seems that SparseNonValueSlot(6121) had been deprecated.\n\n@20092136 please try latest PaddlePaddle bin\n"
      },
      {
        "user": "luotao1",
        "created_at": "2016-11-04T02:30:02Z",
        "body": "#330 这个issue也有sparse \\* sparse出错的问题。目前gpu下不支持sparse \\* sparse。能贴出Matrix.cpp的466行是什么吗\n"
      },
      {
        "user": "typhoonzero",
        "created_at": "2017-07-23T05:49:05Z",
        "body": "Closing this issue due to inactivity, feel free to reopen it."
      }
    ]
  },
  {
    "number": 316,
    "title": "旧版的网络配置能自动转换为新版的PY配置吗？",
    "created_at": "2016-11-02T09:16:05Z",
    "closed_at": "2016-11-02T09:30:17Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/PaddlePaddle/Paddle/issues/316",
    "body": "旧版的网络配置能自动转换为新版的PY配置吗？\r\nPS：旧版的网络配置写法感觉更加直接明了",
    "comments_url": "https://api.github.com/repos/PaddlePaddle/Paddle/issues/316/comments",
    "author": "buptzzl",
    "comments": [
      {
        "user": "gangliao",
        "created_at": "2016-11-02T09:28:26Z",
        "body": "@buptzzl \n\n这个需求刚好与 #304  相反。 \n\n请在#304 提问，我close掉了。\n"
      }
    ]
  },
  {
    "number": 221,
    "title": "questions about  CpuMatrix::mul(CpuSparseMatrix* a, MatBType* b, MatCType* c, real scaleAB, real scaleT)",
    "created_at": "2016-10-18T09:00:52Z",
    "closed_at": "2016-10-24T13:48:17Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/PaddlePaddle/Paddle/issues/221",
    "body": "1、我现在想用paddle给的方法执行两个矩阵相乘，C = A_B。 A是稀疏矩阵，B是稠密矩阵。我在Matrix.cpp中找到这个函数：\nvoid  CpuMatrix::mul(CpuSparseMatrix_ a, CpuMatrix\\* b, real scaleAB,  real scaleT) {\n  if (dynamic_cast<CacheRowCpuMatrix*>(b)) {\n    return mul(a, dynamic_cast<CacheRowCpuMatrix*>(b), this, scaleAB, scaleT);\n  } else if (dynamic_cast<SparseRowCpuMatrix*>(b)) {\n    return mul(a, dynamic_cast<SparseRowCpuMatrix*>(b), this, scaleAB, scaleT);\n  } else {\n    return mul(a, b, this, scaleAB, scaleT);\n  }\n我的情况应该是最后一个return，但是我不确定mul(a, b, this, scaleAB, scaleT)的实现，我只找到了这个函数：\nvoid CpuMatrix::mul(CpuSparseMatrix\\* a, MatBType\\* b, MatCType\\* c, real scaleAB, real scaleT)，此处我的理解是否正确？\n在void CpuMatrix::mul(CpuSparseMatrix\\* a, MatBType\\* b, MatCType\\* c, real scaleAB, real scaleT)这个函数里面，代码中提到了不支持A是SPARSE_CSR存储格式（CHECK_EQ(a->getFormat(), SPARSE_CSR) << \"Not supported\" ），且还不支持好几种情况：例如scaleAB=1 等等，现在针对A是SPARSE_CSR存储格式的情况，以及代码中提到的另外几种不支持的情况，paddle给出实现了吗？\n2、基于我之前的理解是正确的，那么在这个函数里CpuMatrix::mul(CpuSparseMatrix\\* a, MatBType\\* b, MatCType\\* c, real scaleAB, real scaleT)\n我的A设置成 是 [0, 1, 0, 2, 0;1, 0, 0, 0, 0;0, 0, 0, 2, 5];  按照SPARSE_CSC存储，col   [0, 1, 2, 2, 4, 5]; row   [1, 0, 0, 2, 2];  value [1, 1, 2, 2, 5];\n 函数里面，第一次的start = a->getRowStartIdx(1);  end = a->getRowStartIdx(1 + 1); 这样的话对应上述row 的值，start=1，而end = 0? 我无法理解矩阵按照SPARSE_CSC存储下，getRowStartIdx的取值，请指正，谢谢。\n",
    "comments_url": "https://api.github.com/repos/PaddlePaddle/Paddle/issues/221/comments",
    "author": "shenhuinuist",
    "comments": [
      {
        "user": "hedaoyuan",
        "created_at": "2016-10-20T07:39:01Z",
        "body": "1. if do C = A_B(A is sparse matrix), use `void CpuMatrix::mul(CpuSparseMatrix_ a, MatBType\\* b, MatCType\\* c, real scaleAB, real scaleT)` is right.\n2. this api only support A is CSR format. See `CHECK_EQ(a->getFormat(), SPARSE_CSR) << \"Not supported\";`\n"
      },
      {
        "user": "shenhuinuist",
        "created_at": "2016-10-20T09:09:28Z",
        "body": "Thank you very much , I will try again.\n"
      }
    ]
  },
  {
    "number": 209,
    "title": "No data to plot after run image_classification demo",
    "created_at": "2016-10-15T05:18:43Z",
    "closed_at": "2016-10-17T11:10:11Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/PaddlePaddle/Paddle/issues/209",
    "body": "larry@L~eBook:~/Documents/Paddle/Paddle-master/demo/image_classification$ sh train.sh \nI1015 11:51:56.208109  7998 Util.cpp:151] commandline: /usr/bin/../opt/paddle/bin/paddle_trainer --config=vgg_16_cifar.py --dot_period=10 --log_period=100 --test_all_data_in_one_period=1 --use_gpu=0 --trainer_count=1 --num_passes=200 --save_dir=./cifar_vgg_model \nI1015 11:51:56.208637  7998 Util.cpp:126] Calling runInitFunctions\nI1015 11:51:56.209271  7998 Util.cpp:139] Call runInitFunctions done.\n[INFO 2016-10-15 11:51:56,626 layers.py:1620] channels=3 size=3072\n[INFO 2016-10-15 11:51:56,627 layers.py:1620] output size for **conv_0** is 32 \n[INFO 2016-10-15 11:51:56,632 layers.py:1620] channels=64 size=65536\n[INFO 2016-10-15 11:51:56,633 layers.py:1620] output size for **conv_1** is 32 \n[INFO 2016-10-15 11:51:56,638 layers.py:1681] output size for **pool_0** is 16_16 \n[INFO 2016-10-15 11:51:56,641 layers.py:1620] channels=64 size=16384\n[INFO 2016-10-15 11:51:56,641 layers.py:1620] output size for **conv_2** is 16 \n[INFO 2016-10-15 11:51:56,646 layers.py:1620] channels=128 size=32768\n[INFO 2016-10-15 11:51:56,647 layers.py:1620] output size for **conv_3** is 16 \n[INFO 2016-10-15 11:51:56,651 layers.py:1681] output size for **pool_1** is 8_8 \n[INFO 2016-10-15 11:51:56,653 layers.py:1620] channels=128 size=8192\n[INFO 2016-10-15 11:51:56,654 layers.py:1620] output size for **conv_4** is 8 \n[INFO 2016-10-15 11:51:56,659 layers.py:1620] channels=256 size=16384\n[INFO 2016-10-15 11:51:56,660 layers.py:1620] output size for **conv_5** is 8 \n[INFO 2016-10-15 11:51:56,663 layers.py:1620] channels=256 size=16384\n[INFO 2016-10-15 11:51:56,664 layers.py:1620] output size for **conv_6** is 8 \n[INFO 2016-10-15 11:51:56,667 layers.py:1681] output size for **pool_2** is 4_4 \n[INFO 2016-10-15 11:51:56,668 layers.py:1620] channels=256 size=4096\n[INFO 2016-10-15 11:51:56,669 layers.py:1620] output size for **conv_7** is 4 \n[INFO 2016-10-15 11:51:56,672 layers.py:1620] channels=512 size=8192\n[INFO 2016-10-15 11:51:56,672 layers.py:1620] output size for **conv_8** is 4 \n[INFO 2016-10-15 11:51:56,675 layers.py:1620] channels=512 size=8192\n[INFO 2016-10-15 11:51:56,676 layers.py:1620] output size for **conv_9** is 4 \n[INFO 2016-10-15 11:51:56,678 layers.py:1681] output size for **pool_3** is 2_2 \n[INFO 2016-10-15 11:51:56,679 layers.py:1681] output size for **pool_4** is 1*1 \n[INFO 2016-10-15 11:51:56,685 networks.py:1125] The input order is [image, label]\n[INFO 2016-10-15 11:51:56,685 networks.py:1132] The output order is [**cost_0**]\nI1015 11:51:56.701963  7998 Trainer.cpp:170] trainer mode: Normal\nI1015 11:51:56.746357  7998 PyDataProvider2.cpp:247] loading dataprovider image_provider::processData\n[INFO 2016-10-15 11:51:56,946 image_provider.py:52] Image size: 32\n[INFO 2016-10-15 11:51:56,946 image_provider.py:53] Meta path: data/cifar-out/batches/batches.meta\n[INFO 2016-10-15 11:51:56,946 image_provider.py:58] DataProvider Initialization finished\nI1015 11:51:56.947093  7998 PyDataProvider2.cpp:247] loading dataprovider image_provider::processData\n[INFO 2016-10-15 11:51:56,968 image_provider.py:52] Image size: 32\n[INFO 2016-10-15 11:51:56,969 image_provider.py:53] Meta path: data/cifar-out/batches/batches.meta\n[INFO 2016-10-15 11:51:56,969 image_provider.py:58] DataProvider Initialization finished\nI1015 11:51:57.007619  7998 GradientMachine.cpp:134] Initing parameters..\nI1015 11:51:57.599355  7998 GradientMachine.cpp:141] Init parameters done.\n/usr/bin/paddle: line 81:  7998 Killed                  ${DEBUGGER} $MYDIR/../opt/paddle/bin/paddle_trainer ${@:2}\nNo data to plot. Exiting!\n\nDoes process 7998 killed normally?\n",
    "comments_url": "https://api.github.com/repos/PaddlePaddle/Paddle/issues/209/comments",
    "author": "ghost",
    "comments": [
      {
        "user": "backyes",
        "created_at": "2016-10-15T06:49:03Z",
        "body": "Maybe PaddlePaddle exhaust too many memories and your laptop system just kill this process... Generally, linux system will kill process eating too many memories... \n"
      },
      {
        "user": "ghost",
        "created_at": "2016-10-15T07:23:05Z",
        "body": "@backyes 4GB memory on this laptop. Too less for it?\n"
      },
      {
        "user": "backyes",
        "created_at": "2016-10-15T07:40:37Z",
        "body": "Observe the memory available while starting PaddlePaddle using cat /proc/meminfo.\n"
      },
      {
        "user": "ghost",
        "created_at": "2016-10-15T08:24:36Z",
        "body": "@backyes  It eats too many memories, almost no free memory to use for system. And even screen become black.\n"
      },
      {
        "user": "backyes",
        "created_at": "2016-10-15T09:27:44Z",
        "body": "If you just want to use this demo to help to understand how it works, try hacking default parameter layer size to reduce model size.. \n"
      }
    ]
  },
  {
    "number": 196,
    "title": "is support centos",
    "created_at": "2016-10-13T03:08:27Z",
    "closed_at": "2016-10-13T06:26:40Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/PaddlePaddle/Paddle/issues/196",
    "body": "I see install from source, support ubuntu and MacOS, so is support centos or not?\n",
    "comments_url": "https://api.github.com/repos/PaddlePaddle/Paddle/issues/196/comments",
    "author": "morganw",
    "comments": [
      {
        "user": "QiJune",
        "created_at": "2016-10-13T06:23:47Z",
        "body": "Yes, we are making suppot to centos now.\nIn next week, centos building doc, rpm and docker image will all be released.\n"
      },
      {
        "user": "morganw",
        "created_at": "2016-10-13T06:26:36Z",
        "body": "Thanks, I now try to use Docker to install Paddle.\n"
      }
    ]
  },
  {
    "number": 159,
    "title": "libprotobuf ERROR while running sentiment demo",
    "created_at": "2016-10-04T23:22:09Z",
    "closed_at": "2016-10-06T04:29:57Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/PaddlePaddle/Paddle/issues/159",
    "body": "1. paddle version\n   git version: commit 29c16e22420b8b69d17572accd2f6fc0239c8c7e\n   paddle compiled from source, with the options: cmake .. -DWITH_GPU=ON -DWITH_DOC=ON -DWITH_SWIG_PY=ON -DCMAKE_INSTALL_PREFIX=/data/user/program/pddl_build/\n   make and make install success.\n2. protoc --version\n   libprotoc 2.5.0\n3. run the sentiment demo:\n   cd /demo/sentiment/data/\n   ./get_imdb.sh\n   cd ..\n   ./preprocess.sh\n   the above steps are good.\n   However, run ./train.sh, I get the following error msg:\n# \n\nI1004 16:22:13.414708 12100 Util.cpp:144] commandline: /usr/local/bin/../opt/paddle/bin/paddle_trainer --config=trainer_config.py --save_dir=./model_output --job=train --use_gpu=false --trainer_count=4 --num_passes=10 --log_period=10 --dot_period=20 --show_parameter_stats_period=100 --test_all_data_in_one_period=1 \nI1004 16:22:13.414949 12100 Util.cpp:113] Calling runInitFunctions\nI1004 16:22:13.415261 12100 Util.cpp:126] Call runInitFunctions done.\n[INFO 2016-10-04 16:22:13,802 networks.py:1125] The input order is [word, label]\n[INFO 2016-10-04 16:22:13,802 networks.py:1132] The output order is [**cost_0**]\n[libprotobuf ERROR google/protobuf/message_lite.cc:123] Can't parse message of type \"paddle.TrainerConfig\" because it is missing required fields: model_config.parameters[0].learning_rate, model_config.parameters[0].momentum, model_config.parameters[1].learning_rate, model_config.parameters[1].momentum, model_config.parameters[2].learning_rate, model_config.parameters[2].momentum, model_config.parameters[3].learning_rate, model_config.parameters[3].momentum, model_config.parameters[4].learning_rate, model_config.parameters[4].momentum, model_config.parameters[5].momentum, model_config.parameters[6].momentum, model_config.parameters[7].learning_rate, model_config.parameters[7].momentum, model_config.parameters[8].learning_rate, model_config.parameters[8].momentum, model_config.parameters[9].learning_rate, model_config.parameters[9].momentum, model_config.parameters[10].momentum, model_config.parameters[11].momentum, model_config.parameters[12].learning_rate, model_config.parameters[12].momentum, model_config.parameters[13].learning_rate, model_config.parameters[13].momentum, model_config.parameters[14].learning_rate, model_config.parameters[14].momentum, model_config.parameters[15].momentum, model_config.parameters[16].momentum, model_config.parameters[17].learning_rate, model_config.parameters[17].momentum\nF1004 16:22:13.825393 12100 TrainerConfigHelper.cpp:59] Check failed: m->conf.ParseFromString(configProtoStr) \n**\\* Check failure stack trace: ***\n    @     0x7fc3d0879daa  (unknown)\n    @     0x7fc3d0879ce4  (unknown)\n    @     0x7fc3d08796e6  (unknown)\n    @     0x7fc3d087c687  (unknown)\n    @           0x6aa559  paddle::TrainerConfigHelper::TrainerConfigHelper()\n    @           0x6aa924  paddle::TrainerConfigHelper::createFromFlags()\n    @           0x53af53  main\n    @     0x7fc3cfa85ec5  (unknown)\n    @           0x546695  (unknown)\n    @              (nil)  (unknown)\n# /usr/local/bin/paddle: line 46: 12100 Aborted                 (core dumped) ${DEBUGGER} $MYDIR/../opt/paddle/bin/paddle_trainer ${@:2}\n\nCould you please help to check what is this about?\n",
    "comments_url": "https://api.github.com/repos/PaddlePaddle/Paddle/issues/159/comments",
    "author": "cactiball",
    "comments": [
      {
        "user": "emailweixu",
        "created_at": "2016-10-05T03:49:54Z",
        "body": "It looks like your conflict version of paddle c++ binary and python interface. Your install prefix is different from the path shown in the above log\n"
      },
      {
        "user": "cactiball",
        "created_at": "2016-10-05T06:42:51Z",
        "body": "Thank you very much! Append the install prefix to PATH in ~/.bashrc solved this issue.\n"
      }
    ]
  },
  {
    "number": 152,
    "title": "questions about sparse multiplication",
    "created_at": "2016-09-30T09:56:02Z",
    "closed_at": "2016-10-09T02:15:53Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/PaddlePaddle/Paddle/issues/152",
    "body": "I verified  sparse multiplication according to your codes.  I designed my demo  which is as follows:\n# include<iostream>\n# include<stdlib.h>\n\nusing namespace std;\nint main()\n{\n    void colVecAddTo(int\\* a, int\\* b, int c, int len, int aWidth, int bWidth);\n    int a[3] = {1, 1, 1};\n\n```\n                                                    //b=[0, 1, 0, 2, 0; 1, 0, 0, 0, 0; 0, 0, 0, 2, 5]  SPARSE_CSR\nint b_value[5] = {1, 2, 1, 2, 5};\nint b_col[5] = {1, 3, 0, 3, 4};\nint b_row[4] = {0, 2, 3, 5};\nint f[5] = {0, 0, 0, 0, 0};\n\nint *A = a;\nint *B = b_value;\nint *C = f;\n\nint *rows = b_row;\nint *cols = b_col;\n\nint m = 3;                    //a->getWidth()   \nint width_ = 5;               //b->getWidth()\nint height_ = 1;              //a->getHeight()\n\nfor (int j = 0 ;j < 3; ++j )   //3 is b->getHeight()\n{\n    int start = b_row[j];             //start = b->getRowStartIdx(j)\n    int end = b_row[j + 1];           //end = b->getRowStartIdx(j + 1)\n    for (int i = start; i < end; ++i)\n    {\n        colVecAddTo(C + cols[i], A + j, B[i], height_, width_, 3);\n        //cout<<*(C + cols[i])<<endl;\n    }\n}\n\nsystem(\"pause\");\nreturn 0;\n```\n\n}\n\n void colVecAddTo(int\\* aa, int\\* bb, int cc, int len, int aWidth, int bWidth) \n{\n      for ( int ii = 0; ii < len; ++ii)\n     {\n         aa[ii \\* aWidth] += bb[ii \\* bWidth] \\* cc;\n     cout<<aa[ii \\* aWidth]<<endl;\n     }\n}\nThe correct result should be 1 1 0 4 5,   but the rusult of my demo is  1 2 1 4 5  . Could you help me ?\n\nWhat's more , could you show me more details or reference materials about sparse multiplication? Thank you very much.\n",
    "comments_url": "https://api.github.com/repos/PaddlePaddle/Paddle/issues/152/comments",
    "author": "shenhuinuist",
    "comments": [
      {
        "user": "hedaoyuan",
        "created_at": "2016-10-01T14:31:47Z",
        "body": "What you print is not the value of C[i](i = 0/1/2/3/4), but the value of C + cols[i](cols[i] = .......).\nPrint outside the loop, and the result is 1 1 0 4 5.\n"
      },
      {
        "user": "shenhuinuist",
        "created_at": "2016-10-08T01:12:55Z",
        "body": "Thank you very much !\n"
      }
    ]
  },
  {
    "number": 94,
    "title": "Install whl failed",
    "created_at": "2016-09-19T15:22:45Z",
    "closed_at": "2016-09-21T12:44:05Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/PaddlePaddle/Paddle/issues/94",
    "body": "I can successfully build out the paddle but while I install \"py_paddle-0.8.0b0-cp27-cp27mu-linux_x86_64.whl\", it failed and promt:\n~/workspace/Paddle/build$ sudo pip install /opt/paddle/share/wheels/*.whl\npy_paddle-0.8.0b0-cp27-cp27mu-linux_x86_64.whl is not a supported wheel on this platform.\nStoring debug log for failure in /home/yu/.pip/pip.log\n\nHow shall I fix it or work around it?\n\nMy configuration:\ncmake -DWITH_GPU=ON -DWITH_DOC=OFF -DMKL_ROOT=/opt/intel/compilers_and_libraries_2016.3.210/linux/mkl/ -DCUDNN_ROOT=/usr/local/cuda -DWITH_SWIG_PY=ON -DCMAKE_INSTALL_PREFIX=/ ..\n\npaddle version\nPaddlePaddle 0.8.0b0, compiled with\n    with_avx: ON\n    with_gpu: ON\n    with_double: OFF\n    with_python: ON\n    with_rdma: OFF\n    with_glog: ON\n    with_gflags: ON\n    with_metric_learning: \n    with_timer: OFF\n    with_predict_sdk: \n",
    "comments_url": "https://api.github.com/repos/PaddlePaddle/Paddle/issues/94/comments",
    "author": "apollos",
    "comments": [
      {
        "user": "F0REacH",
        "created_at": "2016-09-19T15:30:03Z",
        "body": "Hi, @apollos . I've had similar issue: python/pip was installed with multiple versions 2.7 and 3.5\n\n```\nforeach@linux-PC:~> pip2.7 --version\npip 8.1.2 from /usr/lib/python2.7/site-packages (python 2.7)\nforeach@linux-PC:~> pip --version\npip 8.1.1 from /usr/lib/python3.5/site-packages (python 3.5)\n```\n\nHad to run \n\n> foreach@linux-PC:~> sudo update-alternatives --config pip \n> to set pip version to 2.7 manually\n"
      },
      {
        "user": "apollos",
        "created_at": "2016-09-20T10:56:56Z",
        "body": "Thanks for your help. But it seems not my issue\n\n:~$ pip --version\npip 1.5.4 from /usr/lib/python2.7/dist-packages (python 2.7)\n\nMy pip is from python2.7.\n\nAnd I do try pip2 but same issue\n\nsudo pip2 install py_paddle-0.8.0b0-cp27-cp27mu-linux_x86_64.whl \npy_paddle-0.8.0b0-cp27-cp27mu-linux_x86_64.whl is not a supported wheel on this platform.\nStoring debug log for failure in /home/yu/.pip/pip.log\n\n 1 ------------------------------------------------------------\n  2 /usr/bin/pip2 run on Tue Sep 20 18:54:32 2016\n  3 py_paddle-0.8.0b0-cp27-cp27mu-linux_x86_64.whl is not a supported wheel on this platform.\n  4 Exception information:\n  5 Traceback (most recent call last):\n  6   File \"/usr/lib/python2.7/dist-packages/pip/basecommand.py\", line 122, in main\n  7     status = self.run(options, args)\n  8   File \"/usr/lib/python2.7/dist-packages/pip/commands/install.py\", line 257, in run\n  9     InstallRequirement.from_line(name, None))\n 10   File \"/usr/lib/python2.7/dist-packages/pip/req.py\", line 168, in from_line\n 11     raise UnsupportedWheel(\"%s is not a supported wheel on this platform.\" % wheel.filename)\n 12 UnsupportedWheel: py_paddle-0.8.0b0-cp27-cp27mu-linux_x86_64.whl is not a supported wheel on this platform.\n"
      },
      {
        "user": "reyoung",
        "created_at": "2016-09-21T02:07:30Z",
        "body": "This because the pip version is too old, but wheel package is latest.\n\nPlease update your pip by `pip install pip --upgrade`\n"
      },
      {
        "user": "apollos",
        "created_at": "2016-09-21T12:44:05Z",
        "body": "Thanks a lot. \n"
      }
    ]
  },
  {
    "number": 88,
    "title": "Does it support AMD/OpenCL? Thanks",
    "created_at": "2016-09-18T04:00:52Z",
    "closed_at": "2016-09-21T02:44:13Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/PaddlePaddle/Paddle/issues/88",
    "body": "",
    "comments_url": "https://api.github.com/repos/PaddlePaddle/Paddle/issues/88/comments",
    "author": "xyang2013",
    "comments": [
      {
        "user": "reyoung",
        "created_at": "2016-09-18T05:49:39Z",
        "body": "Currently, OpenCL is not supported. Thanks for your attention\n"
      },
      {
        "user": "xyang2013",
        "created_at": "2016-09-18T09:56:11Z",
        "body": "Will it be supported as with CUDA, it is locked to Nvidia hardware?\n"
      },
      {
        "user": "reyoung",
        "created_at": "2016-09-21T02:10:26Z",
        "body": "Supporting OpenCL is not in our plan now.\n"
      }
    ]
  },
  {
    "number": 37,
    "title": "Russian language",
    "created_at": "2016-09-04T05:40:26Z",
    "closed_at": "2016-09-07T10:00:51Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/PaddlePaddle/Paddle/issues/37",
    "body": "Russian language is supported ?\n",
    "comments_url": "https://api.github.com/repos/PaddlePaddle/Paddle/issues/37/comments",
    "author": "alexosv",
    "comments": [
      {
        "user": "qingqing01",
        "created_at": "2016-09-04T08:15:55Z",
        "body": "Do you mean the document? We don't have Russian document now.\n"
      },
      {
        "user": "alexosv",
        "created_at": "2016-09-05T05:50:00Z",
        "body": "To create a neural network in Russian language\n"
      },
      {
        "user": "reyoung",
        "created_at": "2016-09-07T10:00:51Z",
        "body": "We currently won't support Russian in documentation and interface.\n"
      }
    ]
  },
  {
    "number": 29,
    "title": "Is this OK to install requirements from source ?",
    "created_at": "2016-09-02T16:37:36Z",
    "closed_at": "2016-09-08T14:33:37Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/PaddlePaddle/Paddle/issues/29",
    "body": "When build on Ubuntu, paddle's requirements(cmake, protobuf, blas, etc.) can be installed using following way: \n# sudo apt-get install -y g++ make cmake build-essential libatlas-base-dev python python-pip libpython-dev m4 libprotobuf-dev protobuf-compiler python-protobuf python-numpy git\n\nBut if i want to build paddle on other platform which can not connect to internet, the only way is to build these requirements(cmake, g++, blas, protobuf, python) from downloaded source code. \n\nSo i want to confirm is this ok to install these requirements from source.\n\nthanks~\n",
    "comments_url": "https://api.github.com/repos/PaddlePaddle/Paddle/issues/29/comments",
    "author": "lqniunjunlper",
    "comments": [
      {
        "user": "emailweixu",
        "created_at": "2016-09-02T17:43:00Z",
        "body": "It should be ok.\n"
      },
      {
        "user": "reyoung",
        "created_at": "2016-09-03T03:02:51Z",
        "body": "And please note that we use protobuf version 2, not version 3.\n"
      },
      {
        "user": "lqniunjunlper",
        "created_at": "2016-09-03T03:09:23Z",
        "body": "thanks, guys~ \n"
      }
    ]
  },
  {
    "number": 4,
    "title": "Semantic role labeling demo",
    "created_at": "2016-08-31T04:12:18Z",
    "closed_at": "2016-11-21T09:38:58Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/PaddlePaddle/Paddle/issues/4",
    "body": "Is the setup in demo/semantic_role_labeling/train.sh a full replication of the ACL 2015 paper End-to-end Learning of Semantic Role Labeling Using Recurrent Neural Networks? Thanks!\n",
    "comments_url": "https://api.github.com/repos/PaddlePaddle/Paddle/issues/4/comments",
    "author": "luheng",
    "comments": [
      {
        "user": "zhangjcqq",
        "created_at": "2016-08-31T14:43:35Z",
        "body": "Thanks for your attention, the network architecture in demo is consistent with that paper, while the parameters setup  and features are not the optimal. Currently, it's provided to users for study. The experiment code of paper was implemented on the past interface of PaddlePaddle, which is different from this demo.  We will update the setup later, after verified experiment on new code.\n"
      },
      {
        "user": "luheng",
        "created_at": "2016-08-31T18:34:34Z",
        "body": "Thank you so much for your timely reply!\n\nI'm wondering if you happen to have test results from training the current SRL code on the CoNLL2005 training set? And if so, are they close to the numbers reported in the ACL 2015 paper? \n"
      },
      {
        "user": "reyoung",
        "created_at": "2016-11-21T09:38:58Z",
        "body": "@luheng We update SRL demo recently. Now, it is same as 'End-to-end Learning of Semantic Role Labeling Using Recurrent Neural Networks'"
      }
    ]
  },
  {
    "number": 1,
    "title": "read data from hdfs",
    "created_at": "2016-08-31T02:37:58Z",
    "closed_at": "2024-09-24T06:33:15Z",
    "labels": [
      "question",
      "status/developing"
    ],
    "url": "https://github.com/PaddlePaddle/Paddle/issues/1",
    "body": "\"Different node should owns different parts of all Train data. This simple script did not do this job, so you should prepare it at last. \" I saw this in cluster training wiki. So, could paddle read data from hdfs and distribute data to each node automatically?\n",
    "comments_url": "https://api.github.com/repos/PaddlePaddle/Paddle/issues/1/comments",
    "author": "formath",
    "comments": [
      {
        "user": "reyoung",
        "created_at": "2016-08-31T03:27:20Z",
        "body": "Distribute data to cluster is not added in PaddlePaddle now.  You can read data directly from a HDFS file path by PyDataProvider2.\n\nPaddlePaddle not handle how to get data file remotely, just pass the file path into a Python function. It is user's job to OPEN the file (or SQL connection string, or HDFS path), and get each\nsample one by one from it.\n\nIt is welcome to contribute a script to distribute data to cluster. Or we may add it soon if this feature is very necessary.\n"
      },
      {
        "user": "paddle-bot[bot]",
        "created_at": "2024-09-26T08:46:29Z",
        "body": "Since you haven\\'t replied for more than a year, we have closed this issue/pr.\nIf the problem is not solved or there is a follow-up one, please reopen it at any time and we will continue to follow up.\n由于您超过一年未回复，我们将关闭这个issue/pr。\n若问题未解决或有后续问题，请随时重新打开，我们会继续跟进。"
      }
    ]
  }
]