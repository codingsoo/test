[
  {
    "number": 6070,
    "title": "MRTK  support hololens1？ but HoloLens1 can not upgrade to 1809",
    "created_at": "2019-09-25T09:07:18Z",
    "closed_at": "2019-09-25T16:29:20Z",
    "labels": [
      "Question"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/6070",
    "body": "\r\nI use MRTK make a project  ，it need 18962，but my HoloLens can not up to  version 1809， Now，I can not install packdge into HoloLens1",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/6070/comments",
    "author": "zhudaxing",
    "comments": [
      {
        "user": "david-c-kline",
        "created_at": "2019-09-25T16:29:20Z",
        "body": "@zhudaxing\r\n\r\nYou are likely encountering an issue with how MRTK v2.0.0 is specifying the minimum operating system version (the issue will be fixed in v2.1.0). You can work around this, in Visual Studio, by changing the minimum SDK to 10240 and recompiling. This will fix the manifest and allow your application to run on the first generation HoloLens.\r\n\r\nThe Windows SDK requirement is to enable accessing HoloLens 2 features at compile time and does not indicate an operating system version requirement. The MRTK performs the necessary runtime checks to ensure that unsupported APIs are not called.\r\n"
      },
      {
        "user": "zhudaxing",
        "created_at": "2019-09-26T02:48:51Z",
        "body": "sorry， I set min sdk to10240 in VS—Project—Retarget Projects, and  build new package .when install app, it also show \"The package requires OS version 10.0.18362.0 or higher on the Windows.XboxSRA device family. The device is currently running OS version 10.0.17763.737. Failure text: A Prerequisite for an install could not be satisfied. (0x80073cfd)\""
      }
    ]
  },
  {
    "number": 4445,
    "title": "Runtime error when build mixed reality project with unity and visual studio (LOG FILE ATTACHED )",
    "created_at": "2019-05-17T07:12:06Z",
    "closed_at": "2019-05-21T19:27:02Z",
    "labels": [
      "Question",
      "Duplicate"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/4445",
    "body": "Overview\r\n\r\nWhen we have built the solution, a runtime error appears in one eye on a corner. Is imposible to read and we are tested in debug, release, master... and the error persist. In editor mode on Unity, the error dont appear. The experience is the same but is a little annoying. Any solution ?\r\n\r\nExpected Behavior\r\n\r\nNo runtime error\r\n\r\nActual Behavior\r\n\r\nRuntime error\r\n\r\nSteps to reproduce\r\n\r\nCreate project on Unity 2019\r\nBuild for Windows Universal Platform on VR\r\nOpen the solution in Visual Studio 2017\r\nCompile and play or compile and make a appx\r\n\r\nUnity Editor Version\r\n\r\n2019.1.0f2\r\n\r\nMixed Reality Toolkit Release Version\r\n\r\nv2.0.0-RC1\r\n\r\n########### LOG FILE ###############\r\n\r\n```\r\nLogging to C:/Users/MyPC/AppData/Local/Packages/MyProject_vvjrt7vn67k36/TempState/UnityPlayer.log\r\nLoading native plugins\r\n  Loading AudioPluginMsHRTF.dll\r\nModule information:\r\n Built with Compiler Ver '191627012'\r\n Built from '2019.1/staging' branch\r\n Version is '2019.1.0f2 (292b93d75a2c)'\r\n Release build\r\n Application type 'D3D'\r\n OS 'Windows 10 (10.0.17763) 64bit'\r\nPlayerConnection initialized from E:/UNITY_2019_PROJECTS/BUILD VISUAL STUDIO/build/bin/x64/Release/AppX/Data (debug = 0)\r\nPlayerConnection initialized network socket : 0.0.0.0 55050\r\nMulti-casting \"[IP] 172.30.13.181 [Port] 55050 [Flags] 2 [Guid] 737340049 [EditorId] 0 [Version] 1048832 [Id] UWPPlayerX64(MyPC) [Debug] 0 [PackageName] MyProject_vvjrt7vn67k36\" to [225.0.0.222:54997]...\r\nStarted listening to [0.0.0.0:55050]\r\nPlayerConnection already initialized - listening to [0.0.0.0:55050]\r\nPlugins: Failed to load 'WindowsMRXRSDK' because one or more of its dependencies could not be loaded.\r\n \r\n(Filename: C:\\buildslave\\unity\\build\\Runtime/Misc/Plugins.cpp Line: 223)\r\n\r\nGfxDevice: creating device client; threaded=1\r\nDirect3D:\r\n    Version:  Direct3D 11.0 [level 11.1]\r\n    Renderer: NVIDIA GeForce GTX 1050 Ti (ID=0x1c82)\r\n    Vendor:   \r\n    VRAM:     4018 MB\r\nInitialize engine version: 2019.1.0f2 (292b93d75a2c)\r\nFailed to find spatial stage root, falling back to stationary tracking space type!\r\n \r\n(Filename: C:\\buildslave\\unity\\build\\Modules/VR/HoloLens/HoloLensWorldManager.cpp Line: 591)\r\n\r\nCreated eye textures with a \"texture array\" layout.  The \"single-pass instancing\" stereo mode will be used.\r\n\r\nWindows Mixed Reality spatial locatability state changed to Activating.\r\n \r\n(Filename: C:\\buildslave\\unity\\build\\Modules/VR/HoloLens/HoloLensWorldManager.cpp Line: 374)\r\n\r\nThe referenced script (Unknown) on this Behaviour is missing!\r\n \r\n(Filename: C:\\buildslave\\unity\\build\\Runtime/Scripting/ManagedReference/SerializableManagedRef.cpp Line: 197)\r\n\r\nThe referenced script on this Behaviour (Game Object '<null>') is missing!\r\n \r\n(Filename: C:\\buildslave\\unity\\build\\Runtime/Mono/ManagedMonoBehaviourRef.cpp Line: 333)\r\n\r\nA scripted object (probably Microsoft.MixedReality.Toolkit.Input.MixedRealityInputSimulationProfile?) has a different serialization layout when loading. (Read 76 bytes but expected 288 bytes)\r\nDid you #ifdef UNITY_EDITOR a section of your serialized properties in any of your scripts?\r\n \r\n(Filename: C:\\buildslave\\unity\\build\\Runtime/Serialize/SerializedFile.cpp Line: 2012)\r\n\r\nUnloadTime: 41,373700 ms\r\nWindows Mixed Reality spatial locatability state changed to Inhibited.\r\n \r\n(Filename: C:\\buildslave\\unity\\build\\Modules/VR/HoloLens/HoloLensWorldManager.cpp Line: 374)\r\n\r\nSetting up 3 worker threads for Enlighten.\r\n  Thread -> id: 36ac -> priority: 1 \r\n  Thread -> id: 4944 -> priority: 1 \r\n  Thread -> id: 5280 -> priority: 1 \r\nWindows Mixed Reality spatial locatability state changed to Active.\r\n \r\n(Filename: C:\\buildslave\\unity\\build\\Modules/VR/HoloLens/HoloLensWorldManager.cpp Line: 374)\r\n\r\nWindows Mixed Reality spatial locatability state changed to Inhibited.\r\n \r\n(Filename: C:\\buildslave\\unity\\build\\Modules/VR/HoloLens/HoloLensWorldManager.cpp Line: 374)\r\n\r\nWindows Mixed Reality spatial locatability state changed to Active.\r\n \r\n(Filename: C:\\buildslave\\unity\\build\\Modules/VR/HoloLens/HoloLensWorldManager.cpp Line: 374)\r\n\r\nTrimming D3D resources.\r\n\r\n```\r\n########### LOG FILE ###############\r\n\r\nSame with master version... other way would be disable runtime errors in headset screen... any way to do this ?\r\n\r\nthanks !\r\n\r\n\r\n",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/4445/comments",
    "author": "lionrig",
    "comments": [
      {
        "user": "genereddick",
        "created_at": "2019-05-20T17:37:13Z",
        "body": "This looks like the same issue as in #3971. "
      },
      {
        "user": "lionrig",
        "created_at": "2019-05-21T07:43:12Z",
        "body": "thanks genereddick, i I have read your thread and i understand that @davidkline-ms is looking for a solution (eliminate serialization warning on startup). Any temporal solution ? or... we need to wait for a new release of Mixed Reality Toolkit (MRTK v2 RC2) ?\r\nWe have to deliver a job soon... \r\n\r\nThanks all !"
      },
      {
        "user": "lionrig",
        "created_at": "2019-05-21T07:45:35Z",
        "body": "Or any way to \"hide\" console in headset, our game works well but this runtime error is annoying ( and only visible in one eye )"
      },
      {
        "user": "genereddick",
        "created_at": "2019-05-21T18:59:45Z",
        "body": "I have found no solutions. Happens for me on all WMR deploys in all modes (release, debug). I have tried commenting out every debug statement through all the code but doesn't help. \r\n\r\nI don't understand the pattern but sometimes the debug console only shows when first loaded -- which is good -- then goes away, other times it stays and drops the fps far enough to make the app unusable."
      },
      {
        "user": "keveleigh",
        "created_at": "2019-05-21T19:27:02Z",
        "body": "Thanks for filing! Duplicate of #3971, which we'll use for tracking and discussion going forward."
      },
      {
        "user": "keveleigh",
        "created_at": "2019-05-21T19:27:19Z",
        "body": "Duplicate of #3971"
      }
    ]
  },
  {
    "number": 3715,
    "title": "Question: Status of TouchDeviceManager on Android",
    "created_at": "2019-03-27T19:05:21Z",
    "closed_at": "2019-03-28T16:14:42Z",
    "labels": [
      "Question",
      "Platform - Android"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/3715",
    "body": "## Overview\r\nI tried the Toolkit on my Android phone with Unity Remote in the Editor. I was wondering if that kind of support is still in development as it does not really work:\r\n\r\n- A pointer is spawned and only on the second screen touch, which renders a black line along the surface normal of it objects and stays there after lifting the finger. For touch, you don't really need a pointer at all.\r\n\r\n- The \"controller\" is updated twice during one Update which results in the cursor to jump around in the scene, probably toggling between two position values\r\n\r\n- Clicking on interactables does not work, OnClick does not seem to be implemented\r\n\r\n## Unity Editor Version\r\n2018.3.9f1\r\n\r\n## Mixed Reality Toolkit Release Version\r\nmrtk_development",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/3715/comments",
    "author": "Alexees",
    "comments": [
      {
        "user": "david-c-kline",
        "created_at": "2019-03-28T15:59:51Z",
        "body": "as of today, there isn't formal support for platforms other than Windows Mixed Reality and OpenVR. That said, please continue filing issues you encounter on these platforms as they will help us to identify areas for focused testing and investigation as we add formal support.\r\n\r\nThanks!"
      },
      {
        "user": "Alexees",
        "created_at": "2019-03-28T16:14:42Z",
        "body": "ok, I will do that."
      }
    ]
  },
  {
    "number": 3525,
    "title": "vibration/rumble MR",
    "created_at": "2019-02-26T05:52:04Z",
    "closed_at": "2020-03-21T03:56:40Z",
    "labels": [
      "Question",
      "External",
      "Stale"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/3525",
    "body": "Please help!\r\nHow can i enable vibration/rumble on Motion contronllers with HoloToolkit-Unity-2017.4.3.0.unitypackage?\r\n\"obj.state.source.StartHaptics(0.25f, 0.25f)\" it not found.\r\n\r\nThanks.",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/3525/comments",
    "author": "cuongseo",
    "comments": [
      {
        "user": "stale[bot]",
        "created_at": "2020-02-20T03:38:50Z",
        "body": "This issue has been marked as stale by an automated process because it has not had any recent activity. It will be automatically closed in 30 days if no further activity occurs. If this is still an issue please add a new comment with more recent details and repro steps.\n"
      },
      {
        "user": "stale[bot]",
        "created_at": "2020-03-21T03:56:10Z",
        "body": "This issue has been closed by an automated process because it is stale. If this is still an issue please add a new comment with more recent details and repro steps.\n"
      }
    ]
  },
  {
    "number": 3265,
    "title": "spatial mapping can not detect human body",
    "created_at": "2018-12-13T03:18:22Z",
    "closed_at": "2019-02-20T20:36:32Z",
    "labels": [
      "Question",
      "Spatial Mapping / Awareness"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/3265",
    "body": "## Overview\r\nI'm using spatial mapping to detect my legs, but can not do this.\r\nDoes it have any ideas to detect human body?\r\nOr any other module can do this?\r\n\r\nThanks a lot!\r\n\r\n## Expected Behavior\r\ndetect human body\r\n\r\n## Actual Behavior\r\nno spatial mapping  of my leg.\r\n\r\n## Steps to reproduce\r\n_(Links to sample github project preferred)_\r\n\r\n## Unity Editor Version\r\n2017.4 LTS\r\n## Mixed Reality Toolkit Release Version\r\nHoloToolkit 2017.4.2.0",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/3265/comments",
    "author": "joveth",
    "comments": [
      {
        "user": "ghost",
        "created_at": "2018-12-19T14:41:53Z",
        "body": "Try to map somebody else. It's working for me. Maybe you are too close from your legs :p"
      },
      {
        "user": "david-c-kline",
        "created_at": "2019-02-20T20:36:32Z",
        "body": "Spatial Mapping is designed to detect and map the enviornment. It _will_ detect a human body, however it does not _track_ human bodies (ex: Kinect)"
      }
    ]
  },
  {
    "number": 3250,
    "title": "Two pointers active in scene occasionally",
    "created_at": "2018-12-10T09:20:01Z",
    "closed_at": "2019-01-02T23:20:46Z",
    "labels": [
      "Question",
      "Input System - General"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/3250",
    "body": "## Overview\r\nThis one is a little hard to track. But every now and then I have two cursors / pointers in my scene active. One is the DefaultCursor I assigned to the Gaze provider on the camera and the other one is my mouse basically in 3D space. I can then use the mouse to select UI elements e.g. but the gaze cursor won't do anything.\r\n\r\n## Expected Behavior\r\nNot sure what to expect here to be fair. The least I'd expect is, that the mouse pointer is available always when I hit play and not sometimes because it is handy for selecting things and testing in editor.\r\n\r\n## Actual Behavior\r\nMouse pointer is sometimes not available and only restarting play mode until it appears will help.\r\n\r\n## Unity Editor Version\r\n2018.3.0f1\r\n\r\n## Mixed Reality Toolkit Release Version\r\nmrtk_development",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/3250/comments",
    "author": "FejZa",
    "comments": [
      {
        "user": "StephenHodgson",
        "created_at": "2018-12-10T16:27:34Z",
        "body": "Make sure that if you focus out of the editor to click back into the game window to get your cursor back.\r\n\r\nThere is a time out on the cursor and it will disappear after it's not in use for a few seconds.  If you click during this time it should recenter on the gaze."
      },
      {
        "user": "StephenHodgson",
        "created_at": "2018-12-10T16:29:54Z",
        "body": "Still thinking about how to support customizing the input experience. Ideally I think that having the mouse input by default is the way to go (even in vr, and it works on the HoloLens with Holographic Emulation as well!) but we've got to keep in mind that the MRTK is cross platform and a standalone platform target is valid."
      },
      {
        "user": "FejZa",
        "created_at": "2018-12-11T18:11:48Z",
        "body": "I agree. The mouse input seems pretty handy as a default. "
      },
      {
        "user": "Yoyozilla",
        "created_at": "2018-12-12T07:53:21Z",
        "body": "Looks like we can close this issue as by design? \r\n\r\n"
      }
    ]
  },
  {
    "number": 3194,
    "title": "How should the IP on the NetworkManager be set?",
    "created_at": "2018-11-29T03:40:49Z",
    "closed_at": "2019-07-24T04:13:20Z",
    "labels": [
      "Question"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/3194",
    "body": "## Overview\r\n\r\n## Expected Behavior\r\n\r\n## Actual Behavior\r\n\r\n## Steps to reproduce\r\n_(Links to sample github project preferred)_\r\n\r\n## Unity Editor Version\r\n\r\n## Mixed Reality Toolkit Release Version\r\n",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/3194/comments",
    "author": "renfengyi",
    "comments": [
      {
        "user": "renfengyi",
        "created_at": "2018-11-29T03:42:09Z",
        "body": "How should the IP on the NetworkManager be set?Why did I display the qr code on the iPad after I released it? I used two Hololens to scan the location of only one scene simultaneously?"
      },
      {
        "user": "Yoyozilla",
        "created_at": "2019-07-24T04:13:20Z",
        "body": "Bulk closing older issues.\n\nAlso you can try asking the question on Slack Overflow with the mrtk tag. we have a bunch of active folks there helping :)"
      }
    ]
  },
  {
    "number": 3009,
    "title": "Which branch to use for latest BoundingBox implementation",
    "created_at": "2018-10-29T16:20:32Z",
    "closed_at": "2019-05-23T03:55:34Z",
    "labels": [
      "Question",
      "Input System - General",
      "Utilities"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/3009",
    "body": "## Overview\r\nI have not looked into the MRTK Git Repo for a while and am quite confused about all the Branches without any vNext available and such. I tested the BoundingBox from the Master branch but this can't be right as it's handling is wrong using the MR Motion Controller.\r\n\r\nWhich Branch is the latest with a working BoundingBox in it?\r\n\r\n## Unity Editor Version\r\n2018.2.6f1\r\n",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/3009/comments",
    "author": "Alexees",
    "comments": [
      {
        "user": "StephenHodgson",
        "created_at": "2018-10-29T16:44:48Z",
        "body": "Master is the way to go. We have not finished porting this feature to vNEXT yet."
      },
      {
        "user": "Alexees",
        "created_at": "2018-10-30T08:06:10Z",
        "body": "@StephenHodgson ok who is in charge of the bounding box then? It's still broken when used with MR Headset. Movement is slow and not always the same direction as the motion controller goes. Even holding the controller still and moving the head moves the object. Scaling is the worst as you never get what you want, scaling down when you effectively scale up and the other way around, having a hard time to scale big really.\r\nStarting a drag is based on the NavigationStarted event, which uses a threshold making this feel unnatural as it does not start right away, which I would expect.\r\nThere is no highlight for the corner points when hovering them to indicate you actually managed to aim correctly.\r\nThe box is not good at all. Who can I talk to?"
      },
      {
        "user": "Alexees",
        "created_at": "2018-10-30T11:41:55Z",
        "body": "Ok, I fixed it in my project, but the MRTK there is old and a mess. Nevertheless, the reason why the box is broken is that the code only works for the Hololens hand. The calculations only use the hand position, since there is no beam or cursor. The calculations need to be done differently for the controller, as the relevant position is where the controller is aiming at, the offset from it's position in pointing direction."
      },
      {
        "user": "StephenHodgson",
        "created_at": "2018-10-30T16:02:26Z",
        "body": "I'm unsure as to who owns this feature. But we def want to port it as soon as possible. (There's been one or two attempts made already)\r\n\r\nIf you were able to fix some things, we'd appreciate any contributions back into the HTK dev branch.\r\n\r\nIf you were able to port to MRTK dev branch already, that'd be awesome to see as well."
      },
      {
        "user": "PJBowron",
        "created_at": "2018-11-07T13:31:56Z",
        "body": "BoundingBox and AppBar were originated by @cre8ivepark / @johnppella .\r\nThose guys have begun porting already, see #3044 . I think it might be wise to hold off on attempting to contribute anything to vNext as their work seems to be ongoing and there's not much back and forth going on."
      },
      {
        "user": "chbecker-ms",
        "created_at": "2019-05-23T03:55:34Z",
        "body": "Bounding box is in mrtk_development. Closing out."
      }
    ]
  },
  {
    "number": 2862,
    "title": "Mouse and Keyboard input when \"Simulate in Editor\"",
    "created_at": "2018-10-01T15:12:25Z",
    "closed_at": "2019-04-11T20:12:54Z",
    "labels": [
      "Question"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/2862",
    "body": "Hello, is there any way I can use mouse and keyboard input to move around when \"Simulate in Editor\" is on? not everyone has an XBox Controller.\r\n\r\nI have a HoloLens, but it's very annoying to keep putting it on and off just to test a minor thing that is very easy to test in the Editor, I could use \"none\" in the Holographic Emulator mode settings, but that doesn't generate the room's mesh with spatial mapping which I need for my tests.\r\n\r\nWhat would be a solution here? I don't have a controller.",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/2862/comments",
    "author": "nosmirck",
    "comments": [
      {
        "user": "StephenHodgson",
        "created_at": "2018-10-02T16:48:37Z",
        "body": "Is this for MRTK or HTK?"
      },
      {
        "user": "nosmirck",
        "created_at": "2018-10-02T18:17:18Z",
        "body": "MRTK using HoloLens."
      },
      {
        "user": "wiwei",
        "created_at": "2019-04-11T20:12:53Z",
        "body": "Closing issues older than 180 days. If this is still an issue, please reactivate with recent information."
      }
    ]
  },
  {
    "number": 2766,
    "title": "Is there any guide/readme file to understand UNet Sharing example?",
    "created_at": "2018-09-12T08:42:52Z",
    "closed_at": "2019-04-11T20:12:58Z",
    "labels": [
      "Question",
      "Sharing / Networking",
      "Documentation",
      "Legacy (HoloToolkit)"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/2766",
    "body": "## Overview\r\nCurrently i want to use UNet Sharing to share world anchor between hololens. But i can't what exactly understand if the example shares anchor automatically or any step is required. It would be great to have a read me file for each example. If already such a file exists, please guide me to right place.\r\n## Expected Behavior\r\n\r\n## Actual Behavior\r\n\r\n## Steps to reproduce\r\n_(Links to sample github project preferred)_\r\n\r\n## Unity Editor Version\r\n\r\n## Mixed Reality Toolkit Release Version\r\n",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/2766/comments",
    "author": "Shubham7694",
    "comments": [
      {
        "user": "wiwei",
        "created_at": "2019-04-11T20:12:58Z",
        "body": "Closing issues older than 180 days. If this is still an issue, please reactivate with recent information."
      }
    ]
  },
  {
    "number": 2712,
    "title": "Question: How do we reduce the hold time ?",
    "created_at": "2018-09-06T09:49:16Z",
    "closed_at": "2019-04-11T20:13:03Z",
    "labels": [
      "Question",
      "Platform - HoloLens - First Gen",
      "Legacy (HoloToolkit)",
      "Input System - General"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/2712",
    "body": "## Overview\r\nHold time is too long to get the long tap behavior. I want to reduce it\r\n\r\n",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/2712/comments",
    "author": "Shubham7694",
    "comments": [
      {
        "user": "wiwei",
        "created_at": "2019-04-11T20:13:02Z",
        "body": "Closing issues older than 180 days. If this is still an issue, please reactivate with recent information."
      }
    ]
  },
  {
    "number": 2671,
    "title": "parabolic laser pointer",
    "created_at": "2018-08-30T07:23:03Z",
    "closed_at": "2019-04-11T20:13:13Z",
    "labels": [
      "Question",
      "Legacy (HoloToolkit)",
      "UX Controls - General"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/2671",
    "body": "**Does this affect the legacy HoloToolkit (master) or the Mixed Reality Toolkit (mrtk_release)?**\r\nHoloToolkit \r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nIn the Home screen, when the joy sticked is tilted, the parabolic laser does appear.\r\nI want to implement this.\r\nIt seems that there are no prefabs, components to achive this in the HoloToolKit and HoloToolKit-Example.\r\nAll of the example are using straight laser pointer.\r\nIf the laser pointer is straight, it's hard to point a heigher place.\r\n\r\n**Describe the solution you'd like**\r\nI want to know how to do this.\r\nOffering the sample project is the best.\r\n\r\n**Describe alternatives you've considered**\r\nI'm considering creating original script...but it's little hard.",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/2671/comments",
    "author": "Yoshihide-Nishimoto",
    "comments": [
      {
        "user": "StephenHodgson",
        "created_at": "2018-08-30T13:01:34Z",
        "body": "I'm confused about which version of the mrtk this issue is for."
      },
      {
        "user": "wiwei",
        "created_at": "2019-04-11T20:13:12Z",
        "body": "Closing issues older than 180 days. If this is still an issue, please reactivate with recent information."
      }
    ]
  },
  {
    "number": 2527,
    "title": "Why are Modal and Fallback listeners stacks and not Lists like Global listeners?",
    "created_at": "2018-07-31T16:05:10Z",
    "closed_at": "2019-04-11T20:13:27Z",
    "labels": [
      "Question",
      "Legacy (HoloToolkit)",
      "Input System - General"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/2527",
    "body": "One of my object needs to receive unfocused tap events, but not always. I think modal is the way to go but maybe i'm wrong. With a stack there is no way for me to unregister myself. Is there a reason for choosing stacks that I am not aware of?\r\n",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/2527/comments",
    "author": "Gotcab",
    "comments": [
      {
        "user": "StephenHodgson",
        "created_at": "2018-07-31T16:06:09Z",
        "body": "They're handled differently from global listeners. Althought @maxouellet would know a bit better, considering his team wrote the initial implementation."
      },
      {
        "user": "StephenHodgson",
        "created_at": "2018-07-31T16:08:41Z",
        "body": "> With a stack there is no way for me to unregister myself\r\n\r\nSomeone has proposal #2494 which requests changes to add functionality to unregister from specific stacks."
      },
      {
        "user": "StephenHodgson",
        "created_at": "2018-07-31T16:13:29Z",
        "body": "If we do end up changing this, it'll be in vNEXT to prevent breaking changes."
      },
      {
        "user": "Gotcab",
        "created_at": "2018-07-31T16:16:28Z",
        "body": "So if I register to global listeners will I receive the event even if a focused object consumed it?"
      },
      {
        "user": "maxouellet",
        "created_at": "2018-07-31T16:30:51Z",
        "body": "You will, but I'm not sure that this is what you should use. The original intent of global listeners was to receive all input events, ignoring whoever might consume it. It was mostly built for things like cursors and 6DOF pointing rays that need to react to everything. There are a couple other edge cases where I've had to use it, but usually I try to stay away from it if I can do things in a different way.\r\n\r\nEverything was implemented with stacks to make your app more predictable with regards to how it handle input. The thought was that it's an error if something that is handling input in a modal way try to deregister while it isn't at the top of the stack. Think of it like popup windows: the front popup window should always prevent inputs to other windows it's on top of, and it should always close before anything it's on top of. We could certainly switch the implementation to use lists instead of a stack, but you'd lose the ability to validate that your program is registering / unregistering input handlers in the correct order (which might be acceptable)\r\n\r\nI don't know about what your scenario is exactly, but it sounds like what you want is to register your object as a Fallback input handler. Basically, if nothing else consumed the input (like a UI or something else), you want to receive it and potentially do something with it. "
      },
      {
        "user": "Gotcab",
        "created_at": "2018-07-31T16:43:26Z",
        "body": "Thank you so much, that clarify the intend behind that choice. Here is my scenario:\r\n\r\nMy app is a kind of a promotional virtual space. You walk around and there are interests points and ads that you can interact with. There is a Edit mode and a View mode. Edit mode is where you place objects and view mode you hide editing buttons and you walk around. I have a script CreateObjectOnTap which \"spawn\" the objects incrementaly when tapping in the air (not focused). So I need to receive unfocused tap on Edit mode and unregister when switching to View mode (event based)."
      },
      {
        "user": "maxouellet",
        "created_at": "2018-07-31T16:47:50Z",
        "body": "I see. Assuming that Edit mode contains other UI, I'd say the right solution would be to have your \"CreateObjectOnTap\" script register itself as a fallback input handler when your enter EditMode. This would allow other UI that might be present in Edit mode (maybe a piece of UI to exit EditMode, fo example) to still take priority over creating objects, but any \"taps\" that aren't handled would create an object.\r\n\r\nHope this helps, good luck with your app :)"
      },
      {
        "user": "PJBowron",
        "created_at": "2018-08-04T15:00:38Z",
        "body": "Not a criticism, rather a suggestion - one thing the toolkit input documentation does lack is 'best practices' guide, that encapsulates the kind of things @maxouellet touched on above. I ended up writing one for my team a while ago and I'm happy to see it meshes with the info given here!\r\n\r\nThe only area I would like to see tweaked is the stack nature of the Fallbacks. A stack makes perfect sense for Modalities, but Fallback systems don't necessarily follow symmetrical patterns and may well have overlapping lifetimes, which makes them hard to support in the current model. /ponderings"
      },
      {
        "user": "StephenHodgson",
        "created_at": "2018-08-04T15:21:42Z",
        "body": "Please do"
      },
      {
        "user": "wiwei",
        "created_at": "2019-04-11T20:13:26Z",
        "body": "Closing issues older than 180 days. If this is still an issue, please reactivate with recent information."
      }
    ]
  },
  {
    "number": 2448,
    "title": "How many world anchor can we safely store in world anchor store database?",
    "created_at": "2018-07-16T12:12:52Z",
    "closed_at": "2019-04-11T20:13:37Z",
    "labels": [
      "Question"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/2448",
    "body": "## Overview\r\nI will be placing world anchor for different types of entities. Is it safe to use if world anchors count in api cross say 500. Does this impact store ready time? If so, any pointers.\r\n## Expected Behavior\r\n\r\n## Actual Behavior\r\n\r\n## Steps to reproduce\r\n_(Links to sample github project preferred)_\r\n\r\n## Unity Editor Version\r\n\r\n## Mixed Reality Toolkit Release Version\r\n",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/2448/comments",
    "author": "Shubham7694",
    "comments": [
      {
        "user": "wiwei",
        "created_at": "2019-04-11T20:13:36Z",
        "body": "Closing issues older than 180 days. If this is still an issue, please reactivate with recent information."
      }
    ]
  },
  {
    "number": 2366,
    "title": "Are Unity 2017.1.0f3, Visual Studio 2015 and HoloToolkit-Unity-2017.2.1.0 compatibile for Hololens application developement? I am getting some errors while trying to create a project.  ",
    "created_at": "2018-06-29T16:57:45Z",
    "closed_at": "2018-06-29T18:03:37Z",
    "labels": [
      "Question"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/2366",
    "body": "## Overview\r\n\r\n## Expected Behavior\r\n\r\n## Actual Behavior\r\n\r\n## Steps to reproduce\r\n_(Links to sample github project preferred)_\r\n\r\n## Unity Editor Version\r\n\r\n## Mixed Reality Toolkit Release Version\r\n",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/2366/comments",
    "author": "ISUSupriyaRaul",
    "comments": [
      {
        "user": "ISUSupriyaRaul",
        "created_at": "2018-06-29T17:01:24Z",
        "body": "***\\HoloToolkit\\Utilities\\Scripts\\ApplicationViewManager.cs(52,62,52,64): error CS1003: Syntax error, ',' expected\r\n***\\HoloToolkit\\Utilities\\Scripts\\ApplicationViewManager.cs(88,17,88,21): error CS1547: Keyword 'void' cannot be used in this context\r\n***\\HoloToolkit\\Utilities\\Scripts\\ApplicationViewManager.cs(88,50,95,85): error CS1528: Expected ; or = (cannot specify constructor arguments in declaration)\r\n***\\HoloToolkit\\Utilities\\Scripts\\ApplicationViewManager.cs(88,50,88,51): error CS1003: Syntax error, '[' expected\r\n***\\HoloToolkit\\Utilities\\Scripts\\ApplicationViewManager.cs(88,102,88,102): error CS1003: Syntax error, '=>' expected\r\n***\\HoloToolkit\\Utilities\\Scripts\\ApplicationViewManager.cs(94,18,94,18): error CS1003: Syntax error, ',' expected\r\n***\\HoloToolkit\\Utilities\\Scripts\\ApplicationViewManager.cs(95,85,95,86): error CS1003: Syntax error, ']' expected"
      },
      {
        "user": "StephenHodgson",
        "created_at": "2018-06-29T18:03:37Z",
        "body": "Visual Studio 2017 is required to work with the Holotoolkit."
      },
      {
        "user": "ISUSupriyaRaul",
        "created_at": "2018-06-29T19:21:37Z",
        "body": "@StephenHodgson Thank you for your reply. For some reason, I can not upgrade the Unity and VS versions on my lab's system. Could you please suggest me any alternative version (or any other way) of Holotoolkit to use with them?"
      }
    ]
  },
  {
    "number": 2320,
    "title": "Does world anchor store return anchors from all spaces or the current space of user?",
    "created_at": "2018-06-20T12:30:55Z",
    "closed_at": "2019-04-11T20:14:14Z",
    "labels": [
      "Question"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/2320",
    "body": "## Overview\r\nWe query world anchor store api to get all identifiers. Does it return identifiers only for the space we are in or all identifiers from device? [ seems like the latter option but want to validate.]\r\n\r\n",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/2320/comments",
    "author": "Shubham7694",
    "comments": [
      {
        "user": "Shubham7694",
        "created_at": "2018-07-16T09:17:34Z",
        "body": "@StephenHodgson Can you answer this! Thanks in advance I want to classify anchors based on space. It doesn't make sense to use anchors created in another space."
      },
      {
        "user": "wiwei",
        "created_at": "2019-04-11T20:14:13Z",
        "body": "Closing issues older than 180 days. If this is still an issue, please reactivate with recent information."
      }
    ]
  },
  {
    "number": 2311,
    "title": "Can we restrict the mesh to be used in Plane (floor) finding API?",
    "created_at": "2018-06-17T04:30:37Z",
    "closed_at": "2019-04-11T20:14:18Z",
    "labels": [
      "Question",
      "Spatial Mapping / Awareness"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/2311",
    "body": "## Overview\r\nAs we move around, the Hololens saves meshes from vast areas. This inturn means that if i want to detect floor correctly, a mesh covering huge area is used to detect which offsets floor average height from actual floor. How can we restrict to compute floor based on meshes from near by or restrict it from using previously scanned mesh (which accumulate offset over period of time).\r\n## Expected Behavior\r\n\r\n## Actual Behavior\r\n\r\n## Steps to reproduce\r\n_(Links to sample github project preferred)_\r\n\r\n## Unity Editor Version\r\n\r\n## Mixed Reality Toolkit Release Version\r\n",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/2311/comments",
    "author": "Shubham7694",
    "comments": [
      {
        "user": "wiwei",
        "created_at": "2019-04-11T20:14:17Z",
        "body": "Closing issues older than 180 days. If this is still an issue, please reactivate with recent information."
      }
    ]
  },
  {
    "number": 2291,
    "title": "Share holograms with Android ?",
    "created_at": "2018-06-13T01:15:59Z",
    "closed_at": "2019-04-11T20:14:24Z",
    "labels": [
      "Question",
      "SpectatorView"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/2291",
    "body": "Hi all,\r\n\r\nIs there any plan on share holograms with Android device?\r\n\r\nThanks",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/2291/comments",
    "author": "zhangalex",
    "comments": [
      {
        "user": "david-c-kline",
        "created_at": "2018-06-13T17:25:02Z",
        "body": "Yes, we do plan on supporting SpectatorView on ARCore devices. Unsure of the timing at this point."
      },
      {
        "user": "wiwei",
        "created_at": "2019-04-11T20:14:24Z",
        "body": "Closing issues older than 180 days. If this is still an issue, please reactivate with recent information."
      }
    ]
  },
  {
    "number": 2277,
    "title": "Proposal:We were wondering if you could add property \"Handedness\" in BaseInputEventData class?",
    "created_at": "2018-06-10T04:57:42Z",
    "closed_at": "2018-08-03T14:10:44Z",
    "labels": [
      "Question"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/2277",
    "body": "## Overview\r\nFor example,when if we want to use select button of left Motion Controller with IInputHandler,\r\nwe can't know left or right select button is down,so we must get this information from InteractionSource(following example codes).\r\n\r\n```cSharp\r\nusing System.Collections.Generic;\r\nusing HoloToolkit.Unity;\r\n#if UNITY_2017_2_OR_NEWER\r\nusing UnityEngine.XR.WSA.Input;\r\n#endif\r\n\r\npublic class InteractionSourceStateManager : Singleton<InteractionSourceStateManager>{\r\n\r\n    public Dictionary<uint, InteractionSourceState> InteractionSourceStates;\r\n\r\n    protected override void Awake(){\r\n        base.Awake();\r\n#if UNITY_WSA && UNITY_2017_2_OR_NEWER\r\n        InteractionSourceStates; = new Dictionary<uint, InteractionSourceState>();\r\n        InteractionManager.InteractionSourceDetected += InteractionSourceDetected;\r\n        InteractionManager.InteractionSourceLost += InteractionSourceLost;\r\n#endif\r\n    }\r\n\r\n#if UNITY_WSA && UNITY_2017_2_OR_NEWER\r\n    private void InteractionSourceDetected(InteractionSourceDetectedEventArgs obj)    {\r\n        if (!InteractionSourceStates;.ContainsKey(obj.state.source.id))\r\n            InteractionSourceStates;.Add(obj.state.source.id, obj.state);\r\n    }\r\n\r\n    private void InteractionSourceLost(InteractionSourceLostEventArgs obj)    {\r\n        InteractionSourceStates;.Remove(obj.state.source.id);\r\n    }\r\n\r\n#endif\r\n}\r\n```\r\n\r\n\r\n```cSharp\r\nusing HoloToolkit.Unity.InputModule;\r\nusing UnityEngine;\r\nusing UnityEngine.XR.WSA.Input;\r\n\r\npublic class SampleInput : MonoBehaviour, IInputHandler{\r\n\r\n    public void OnInputDown(InputEventData eventData)    {\r\n        var instanceInteractionSourceState = InteractionSourceStateManager.Instance.InteractionSourceStates[eventData.SourceId];\r\n        if (instanceInteractionSourceState.source.handedness == InteractionSourceHandedness.Left)        {\r\n            // something code...\r\n        }\r\n    }\r\n\r\n    public void OnInputUp(InputEventData eventData){}\r\n}\r\n```\r\n\r\nIn IInputHandler event,OnInputDown(OnInputUp) method has parameter \"InputEventData\",\r\nso,if you could add property \"Handedness(get from  InteractionSource)\" in \"InputEventData\",we can develop more easier the application that uses Input operation more Interactive!\r\n\r\n## Unity Editor Version\r\nUnity 2017.4.3f1\r\n## Mixed Reality Toolkit Release Version\r\n",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/2277/comments",
    "author": "TakahiroMiyaura",
    "comments": [
      {
        "user": "StephenHodgson",
        "created_at": "2018-06-10T13:12:24Z",
        "body": "We did in vNEXT"
      }
    ]
  },
  {
    "number": 2206,
    "title": "How to let the object in iPhone follow in the SpectatorView?",
    "created_at": "2018-05-30T05:47:30Z",
    "closed_at": "2018-05-30T18:22:04Z",
    "labels": [
      "Question",
      "Sharing / Networking",
      "SpectatorView"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/2206",
    "body": "## Overview\r\nI tried the sample scene \"SpectatorViewExample\" and built it both on Hololens and iPhone,and i added a \"Hand Draggable\" component on the object.but when i drag the object,the object in iPhone will not move.\r\nSo how can i let the object in iPhone follow?\r\n\r\n## Unity Editor Version\r\n2017.3.1p4\r\n## Mixed Reality Toolkit Release Version\r\nMRTK4.0RC2",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/2206/comments",
    "author": "mrsniperz",
    "comments": [
      {
        "user": "ghost",
        "created_at": "2018-05-30T10:06:14Z",
        "body": "Hello mrsniperz\r\n\r\nI think there's a bit of a confusion about what SpectatorView should do out of the box. SpectatorView will manage the connection and space sync between the HoloLens and the iPhone, however, it won't sync up every action you do on the HoloLens by default (transform change, color change....) You can do it but it's something you'll have to hook up manually. \r\n\r\nThe reason being is that the iPhone doesn't have to be a \"window\" to what the HoloLens is seeing but a different application with different actions/modes/views that simply shares the same space.\r\n\r\nWhat you're trying to achieve is possible, an easy way to do it so you can get up and running ASAP would be to implement something similar to what `ColorChanger` is doing but sync the transform instead. There are multiple examples around on how to sync a transform using UNET, I'm sure a simple Google search will yield what you're looking for! :) \r\n"
      },
      {
        "user": "mrsniperz",
        "created_at": "2018-05-30T12:39:40Z",
        "body": "@JoseSantano-ms Thanks a lot!"
      }
    ]
  },
  {
    "number": 2041,
    "title": "Minimum Scale for Bounding Box Rig",
    "created_at": "2018-05-03T12:54:51Z",
    "closed_at": "2019-04-11T20:15:02Z",
    "labels": [
      "Question"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/2041",
    "body": "Hello, I'm using Bounding box Rig for rotation, scaling of hologram,\r\nHow can i add Minimum Scale variable to the script so that the hologram can't be scale down below some specified value. \r\n",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/2041/comments",
    "author": "ghost",
    "comments": [
      {
        "user": "wiwei",
        "created_at": "2019-04-11T20:15:01Z",
        "body": "Closing issues older than 180 days. If this is still an issue, please reactivate with recent information."
      }
    ]
  },
  {
    "number": 2034,
    "title": "The frame rate is very low.",
    "created_at": "2018-05-02T17:50:32Z",
    "closed_at": "2018-05-03T19:06:01Z",
    "labels": [
      "Question",
      "No Repro"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/2034",
    "body": "## Overview\r\nFPS is very low even in the basic example scenes on the screen. In UNITY we have the settings for the MIXEDREALITY development environment. What do I need to set more in the example scene to maintain 60 fps?....\r\n\r\n## Expected Behavior\r\n.\r\n## Actual Behavior\r\n.\r\n## Steps to reproduce\r\n_(Links to sample github project preferred)_\r\n.\r\n## Unity Editor Version\r\n2017.2.1P2\r\n## Mixed Reality Toolkit Release Version\r\n2017.2.1.4-RC2",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/2034/comments",
    "author": "lgs777",
    "comments": [
      {
        "user": "pwroff",
        "created_at": "2018-05-03T08:19:12Z",
        "body": "I would reccomend you to check your VS build mode. If it is in Debug it will be extremely low, try to use Release mode for debugging and Master mode for deploy. Hope it helps."
      },
      {
        "user": "lgs777",
        "created_at": "2018-05-03T10:14:17Z",
        "body": "@pwroff  Answer Thank you very much !! You saved my time!"
      }
    ]
  },
  {
    "number": 1961,
    "title": "Duplication of Holotoolkit camera when switching scenes",
    "created_at": "2018-04-16T19:22:19Z",
    "closed_at": "2018-04-17T15:41:50Z",
    "labels": [
      "Question"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/1961",
    "body": "When switching to a scene that already includes a mixed reality camera, the camera is duplicated. Solution included.\r\n\r\n## Expected Behavior- Each scene has only one mixed reality camera\r\n\r\n## Actual Behavior-Mixed Reality camera is duplicated when a new scene that already includes one is loaded\r\n\r\n## Steps to reproduce\r\n-create two scenes, each with a mixed reality camera.\r\n-run the application in the unity editor\r\n-go to second scene\r\n-messages \r\n\r\n## Unity Editor Version- 2017.3\r\n\r\n## Mixed Reality Toolkit Release Version-2017.2.1.3\r\n\r\n## Solution- The code in the Awake() method of the Singleton class destroys the script but not the object to which it is attached. I corrected the problem with the following code.\r\n\r\n```\r\nprotected virtual void Awake()\r\n        {\r\n            if (IsInitialized && instance != this)\r\n            {\r\n                if (Application.isEditor)\r\n                {\r\n                   //DestroyImmediate(this);replaced\r\n                    DestroyImmediate(gameObject);\r\n                }\r\n                else\r\n                {\r\n                   // Destroy(this);replaced\r\n                    Destroy(gameObject);\r\n                }\r\n\r\n                Debug.LogErrorFormat(\"Trying to instantiate a second instance of singleton class {0}. Additional Instance was destroyed\", GetType().Name);\r\n            }\r\n```\r\nIf there is a better solution, let me know.\r\n",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/1961/comments",
    "author": "Mustellinus",
    "comments": [
      {
        "user": "StephenHodgson",
        "created_at": "2018-04-17T13:43:25Z",
        "body": "> create two scenes, each with a mixed reality camera.\r\n\r\nWell there's your problem. The expected workflow requires a main master scene and additive loading of your additional scenes.\r\n\r\nIf you don't like that workflow, then you can _optionally_ disable don't destroy on load, but it's not recommended."
      },
      {
        "user": "Mustellinus",
        "created_at": "2018-04-17T15:41:50Z",
        "body": "Ok, I have a main scene. Additive loading of additional scenes solved the problem"
      }
    ]
  },
  {
    "number": 1925,
    "title": "How to use the Build Window?",
    "created_at": "2018-04-09T14:41:52Z",
    "closed_at": "2019-04-11T20:15:08Z",
    "labels": [
      "Question",
      "Build / Tools"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/1925",
    "body": "This feels sort of like a really dumb question but, for some reason I just can't figure out how to use the build window. I have my device connected to USB, which is how I normally build my projects through VS. Whenever I go to install it I just get the following error.\r\n\r\n**Failed to start deployment. Install failed. Please contact your software vendor.**\r\n\r\nWhy is this error happening?\r\n",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/1925/comments",
    "author": "dtb49",
    "comments": [
      {
        "user": "wiwei",
        "created_at": "2019-04-11T20:15:06Z",
        "body": "Closing issues older than 180 days. If this is still an issue, please reactivate with recent information."
      }
    ]
  },
  {
    "number": 1866,
    "title": "World Anchor Usage",
    "created_at": "2018-03-23T09:04:50Z",
    "closed_at": "2019-04-11T20:15:25Z",
    "labels": [
      "Question"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/1866",
    "body": "Is it okay to call world anchor api to attach or remove anchor frequently ? Does attach & remove anchor has any performance effect?\r\nUse case: User is moving a hologram. I want to attach anchor once user does finger remove gesture. If user again presses finger, to move hologram i should remove world anchor and repeat the same.\r\n\r\nShould world anchor attach & remove be tied to UI like button clicked to remove or to user actions like finger press gesture (while doing some action).",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/1866/comments",
    "author": "Shubham7694",
    "comments": [
      {
        "user": "calebcannon",
        "created_at": "2018-03-23T21:18:57Z",
        "body": "We've been using WorldAnchors pretty extensively with zero problems.  When unlocking an object for positioning (e.g., using HandDraggable), we delete the anchor immediately and recreate it when the drag operation is completed. I've yet to see a single side effect, even in scenes with dozens of anchors.\r\n\r\nThe only time we don't use anchors is when an object is expected to be more active than not: UI elements with Tagalong components, remote user avatars, etc."
      },
      {
        "user": "Shubham7694",
        "created_at": "2018-03-26T05:38:32Z",
        "body": "Thank you @calebcannon "
      },
      {
        "user": "wiwei",
        "created_at": "2019-04-11T20:15:24Z",
        "body": "Closing issues older than 180 days. If this is still an issue, please reactivate with recent information."
      }
    ]
  },
  {
    "number": 1844,
    "title": "Question about VoiceChat",
    "created_at": "2018-03-19T02:22:07Z",
    "closed_at": "2019-04-11T20:15:32Z",
    "labels": [
      "Question"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/1844",
    "body": "\r\n## Overview\r\nI am using VoiceChat scripts(MicrophoneReceiver.cs and MicrophoneTransmitter.cs) from MixedRealityToolkit-Unity, but I am only hearing my own voice..\r\n\r\n## Expected Behavior\r\nI can hear other's voice \r\n\r\n## Actual Behavior\r\nI only can hear my own voice\r\n\r\n## Steps to reproduce\r\n1.Open the SharingTest scene which in the Assets\\HoloToolkit-Examples\\Sharing\\SharingService\\Scenes by unity.\r\n2.Attached both MicrophoneReceiver.cs and MicrophoneTransmitter.cs onto MixedRealityCamera.\r\n3.Publish the Unity Project to the two HOLOLENS.\r\n4.Launch the Sharing Service on my Computer.\r\n5.Launch the Unity App on two HOLOLENS and both two HOLOLENS successfully to connect to the server.\r\n\r\n## Unity Editor Version\r\n2017.2.0f3\r\n\r\n## Mixed Reality Toolkit Release Version\r\n2017.2.1.3 Hot Fix \r\n",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/1844/comments",
    "author": "shenwooash",
    "comments": [
      {
        "user": "wiwei",
        "created_at": "2019-04-11T20:15:31Z",
        "body": "Closing issues older than 180 days. If this is still an issue, please reactivate with recent information."
      }
    ]
  },
  {
    "number": 1830,
    "title": "NET Native failing",
    "created_at": "2018-03-13T09:13:23Z",
    "closed_at": "2018-03-14T03:30:54Z",
    "labels": [
      "Question"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/1830",
    "body": "NET Native is failing for some reason on Windows 10 Fall Creators Update. We are using HoloToolkit, Unity 2017.1 and VS2015 (minimum and target version of the app is set to Anniversary Update). The solution builds fine on another machine running Windows 10 Creators Update. The error log I get from the NET Native build is attached below. When I search for the methods it complains about, it seems like all of them were introduced in the Creators and Fall Creators updates. \r\n\r\n```\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): warning : ILTransform_0005: Type 'System.Reflection.BindingFlags' was not included in compilation, but was referenced in method 'ReflectionExtensions.GetMethod(Type, string, BindingFlags)'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): warning : ILTransform_0005: Type 'Windows.System.DispatcherQueue' was not included in compilation, but was referenced in method 'BootstrapHelpers.FillTypeMaps0(Dictionary<Type, int>, List<Type>)'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): warning : ILTransform_0005: Type 'Windows.System.DispatcherQueueShutdownStartingEventArgs' was not included in compilation, but was referenced in method 'BootstrapHelpers.FillTypeMaps0(Dictionary<Type, int>, List<Type>)'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): warning : ILTransform_0005: Type 'Windows.System.DispatcherQueueTimer' was not included in compilation, but was referenced in method 'BootstrapHelpers.FillTypeMaps0(Dictionary<Type, int>, List<Type>)'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): warning : ILTransform_0005: Type 'Windows.System.DispatcherQueueHandler' was not included in compilation, but was referenced in method 'BootstrapHelpers.FillTypeMaps0(Dictionary<Type, int>, List<Type>)'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): warning : ILTransform_0005: Type 'Windows.System.DispatcherQueuePriority' was not included in compilation, but was referenced in method 'BootstrapHelpers.FillTypeMaps0(Dictionary<Type, int>, List<Type>)'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): warning : ILTransform_0005: Type 'Windows.System.IDispatcherQueue' was not included in compilation, but was referenced in method 'BootstrapHelpers.FillTypeMaps0(Dictionary<Type, int>, List<Type>)'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): warning : ILTransform_0005: Type 'Windows.System.IDispatcherQueueTimer' was not included in compilation, but was referenced in method 'BootstrapHelpers.FillTypeMaps0(Dictionary<Type, int>, List<Type>)'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): warning : ILTransform_0005: Type 'Windows.UI.Core.CoreWindowActivationMode' was not included in compilation, but was referenced in method 'BootstrapHelpers.FillTypeMaps0(Dictionary<Type, int>, List<Type>)'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): warning : ILTransform_0005: Type 'Windows.UI.Core.ICoreWindow4' was not included in compilation, but was referenced in method 'BootstrapHelpers.FillTypeMaps0(Dictionary<Type, int>, List<Type>)'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): warning : ILTransform_0005: Type 'Windows.UI.Core.ICoreWindow5' was not included in compilation, but was referenced in method 'BootstrapHelpers.FillTypeMaps0(Dictionary<Type, int>, List<Type>)'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): warning : ILTransform_0003: Method '$MethodUtility.$Invoke3344(long, long*)' will always throw an exception due to the missing method 'DispatcherQueue.add_ShutdownCompleted(TypedEventHandler<DispatcherQueue, object>)'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): warning : ILTransform_0003: Method '$MethodUtility.$Invoke3345(long, long*)' will always throw an exception due to the missing method 'DispatcherQueue.add_ShutdownStarting(TypedEventHandler<DispatcherQueue, DispatcherQueueShutdownStartingEventArgs>)'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): warning : ILTransform_0003: Method '$MethodUtility.$Invoke3346(long, long*)' will always throw an exception due to the missing method 'DispatcherQueue.CreateTimer()'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): warning : ILTransform_0003: Method '$MethodUtility.$Invoke3347(long, long*)' will always throw an exception due to the missing method 'DispatcherQueue.GetForCurrentThread()'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): warning : ILTransform_0003: Method '$MethodUtility.$Invoke3348(long, long*)' will always throw an exception due to the missing method 'DispatcherQueue.remove_ShutdownCompleted(EventRegistrationToken)'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): warning : ILTransform_0003: Method '$MethodUtility.$Invoke3349(long, long*)' will always throw an exception due to the missing method 'DispatcherQueue.remove_ShutdownStarting(EventRegistrationToken)'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): warning : ILTransform_0003: Method '$MethodUtility.$Invoke3350(long, long*)' will always throw an exception due to the missing method 'DispatcherQueue.TryEnqueue(DispatcherQueueHandler)'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): warning : ILTransform_0003: Method '$MethodUtility.$Invoke3351(long, long*)' will always throw an exception due to the missing method 'DispatcherQueue.TryEnqueue(DispatcherQueuePriority, DispatcherQueueHandler)'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): warning : ILTransform_0003: Method '$MethodUtility.$Invoke3352(long, long*)' will always throw an exception due to the missing method 'DispatcherQueueHandler.Invoke()'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): warning : ILTransform_0003: Method '$MethodUtility.$Invoke3353(long, long*)' will always throw an exception due to the missing method 'DispatcherQueueTimer.add_Tick(TypedEventHandler<DispatcherQueueTimer, object>)'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): warning : ILTransform_0003: Method '$MethodUtility.$Invoke3354(long, long*)' will always throw an exception due to the missing method 'DispatcherQueueTimer.get_Interval()'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): warning : ILTransform_0003: Method '$MethodUtility.$Invoke3355(long, long*)' will always throw an exception due to the missing method 'DispatcherQueueTimer.get_IsRepeating()'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): warning : ILTransform_0003: Method '$MethodUtility.$Invoke3356(long, long*)' will always throw an exception due to the missing method 'DispatcherQueueTimer.get_IsRunning()'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): warning : ILTransform_0003: Method '$MethodUtility.$Invoke3357(long, long*)' will always throw an exception due to the missing method 'DispatcherQueueTimer.put_Interval(TimeSpan)'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): warning : ILTransform_0003: Method '$MethodUtility.$Invoke3358(long, long*)' will always throw an exception due to the missing method 'DispatcherQueueTimer.put_IsRepeating(bool)'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): warning : ILTransform_0003: Method '$MethodUtility.$Invoke3359(long, long*)' will always throw an exception due to the missing method 'DispatcherQueueTimer.remove_Tick(EventRegistrationToken)'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): warning : ILTransform_0003: Method '$MethodUtility.$Invoke3360(long, long*)' will always throw an exception due to the missing method 'DispatcherQueueTimer.Start()'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): warning : ILTransform_0003: Method '$MethodUtility.$Invoke3361(long, long*)' will always throw an exception due to the missing method 'DispatcherQueueTimer.Stop()'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): warning : ILTransform_0003: Method '$MethodUtility.$Invoke3362(long, long*)' will always throw an exception due to the missing method 'IDispatcherQueue.add_ShutdownCompleted(TypedEventHandler<DispatcherQueue, object>)'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): warning : ILTransform_0003: Method '$MethodUtility.$Invoke3363(long, long*)' will always throw an exception due to the missing method 'IDispatcherQueue.add_ShutdownStarting(TypedEventHandler<DispatcherQueue, DispatcherQueueShutdownStartingEventArgs>)'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): warning : ILTransform_0003: Method '$MethodUtility.$Invoke3364(long, long*)' will always throw an exception due to the missing method 'IDispatcherQueue.CreateTimer()'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): warning : ILTransform_0003: Method '$MethodUtility.$Invoke3365(long, long*)' will always throw an exception due to the missing method 'IDispatcherQueue.remove_ShutdownCompleted(EventRegistrationToken)'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): warning : ILTransform_0003: Method '$MethodUtility.$Invoke3366(long, long*)' will always throw an exception due to the missing method 'IDispatcherQueue.remove_ShutdownStarting(EventRegistrationToken)'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): warning : ILTransform_0003: Method '$MethodUtility.$Invoke3367(long, long*)' will always throw an exception due to the missing method 'IDispatcherQueue.TryEnqueue(DispatcherQueueHandler)'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): warning : ILTransform_0003: Method '$MethodUtility.$Invoke3368(long, long*)' will always throw an exception due to the missing method 'IDispatcherQueue.TryEnqueue(DispatcherQueuePriority, DispatcherQueueHandler)'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): warning : ILTransform_0003: Method '$MethodUtility.$Invoke3369(long, long*)' will always throw an exception due to the missing method 'IDispatcherQueueTimer.add_Tick(TypedEventHandler<DispatcherQueueTimer, object>)'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): warning : ILTransform_0003: Method '$MethodUtility.$Invoke3370(long, long*)' will always throw an exception due to the missing method 'IDispatcherQueueTimer.get_Interval()'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): warning : ILTransform_0003: Method '$MethodUtility.$Invoke3371(long, long*)' will always throw an exception due to the missing method 'IDispatcherQueueTimer.get_IsRepeating()'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): warning : ILTransform_0003: Method '$MethodUtility.$Invoke3372(long, long*)' will always throw an exception due to the missing method 'IDispatcherQueueTimer.get_IsRunning()'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): warning : ILTransform_0003: Method '$MethodUtility.$Invoke3373(long, long*)' will always throw an exception due to the missing method 'IDispatcherQueueTimer.put_Interval(TimeSpan)'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): warning : ILTransform_0003: Method '$MethodUtility.$Invoke3374(long, long*)' will always throw an exception due to the missing method 'IDispatcherQueueTimer.put_IsRepeating(bool)'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): warning : ILTransform_0003: Method '$MethodUtility.$Invoke3375(long, long*)' will always throw an exception due to the missing method 'IDispatcherQueueTimer.remove_Tick(EventRegistrationToken)'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): warning : ILTransform_0003: Method '$MethodUtility.$Invoke3376(long, long*)' will always throw an exception due to the missing method 'IDispatcherQueueTimer.Start()'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): warning : ILTransform_0003: Method '$MethodUtility.$Invoke3377(long, long*)' will always throw an exception due to the missing method 'IDispatcherQueueTimer.Stop()'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): warning : ILTransform_0003: Method '$MethodUtility.$Invoke3540(long, long*)' will always throw an exception due to the missing method 'ICoreWindow4.add_ResizeCompleted(TypedEventHandler<CoreWindow, object>)'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): warning : ILTransform_0003: Method '$MethodUtility.$Invoke3541(long, long*)' will always throw an exception due to the missing method 'ICoreWindow4.add_ResizeStarted(TypedEventHandler<CoreWindow, object>)'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): warning : ILTransform_0003: Method '$MethodUtility.$Invoke3542(long, long*)' will always throw an exception due to the missing method 'ICoreWindow4.remove_ResizeCompleted(EventRegistrationToken)'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): warning : ILTransform_0003: Method '$MethodUtility.$Invoke3543(long, long*)' will always throw an exception due to the missing method 'ICoreWindow4.remove_ResizeStarted(EventRegistrationToken)'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): warning : ILTransform_0003: Method '$MethodUtility.$Invoke3544(long, long*)' will always throw an exception due to the missing method 'ICoreWindow5.get_ActivationMode()'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): warning : ILTransform_0003: Method '$MethodUtility.$Invoke3545(long, long*)' will always throw an exception due to the missing method 'ICoreWindow5.get_DispatcherQueue()'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): warning : ILTransform_0003: Method 'NetworkCRC.ReinitializeScriptCRCs(Assembly)' will always throw an exception due to the missing method 'TypeExtensions.GetMethod(Type, string, BindingFlags)'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): error : ILT0021: Could not resolve method 'System.Runtime.InteropServices.WindowsRuntime.EventRegistrationToken Windows.UI.Core.CoreWindow.add_ResizeCompleted(Windows.Foundation.TypedEventHandler<Windows.UI.Core.CoreWindow, System.Object>)'\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): error : Type 'System.Reflection.BindingFlags' was not included in compilation, but was referenced in method 'ReflectionExtensions.GetMethod(Type, string, BindingFlags)'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): error : Type 'Windows.System.DispatcherQueue' was not included in compilation, but was referenced in method 'BootstrapHelpers.FillTypeMaps0(Dictionary<Type, int>, List<Type>)'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): error : Type 'Windows.System.DispatcherQueueShutdownStartingEventArgs' was not included in compilation, but was referenced in method 'BootstrapHelpers.FillTypeMaps0(Dictionary<Type, int>, List<Type>)'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): error : Type 'Windows.System.DispatcherQueueTimer' was not included in compilation, but was referenced in method 'BootstrapHelpers.FillTypeMaps0(Dictionary<Type, int>, List<Type>)'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): error : Type 'Windows.System.DispatcherQueueHandler' was not included in compilation, but was referenced in method 'BootstrapHelpers.FillTypeMaps0(Dictionary<Type, int>, List<Type>)'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): error : Type 'Windows.System.DispatcherQueuePriority' was not included in compilation, but was referenced in method 'BootstrapHelpers.FillTypeMaps0(Dictionary<Type, int>, List<Type>)'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): error : Type 'Windows.System.IDispatcherQueue' was not included in compilation, but was referenced in method 'BootstrapHelpers.FillTypeMaps0(Dictionary<Type, int>, List<Type>)'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): error : Type 'Windows.System.IDispatcherQueueTimer' was not included in compilation, but was referenced in method 'BootstrapHelpers.FillTypeMaps0(Dictionary<Type, int>, List<Type>)'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): error : Type 'Windows.UI.Core.CoreWindowActivationMode' was not included in compilation, but was referenced in method 'BootstrapHelpers.FillTypeMaps0(Dictionary<Type, int>, List<Type>)'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): error : Type 'Windows.UI.Core.ICoreWindow4' was not included in compilation, but was referenced in method 'BootstrapHelpers.FillTypeMaps0(Dictionary<Type, int>, List<Type>)'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): error : Type 'Windows.UI.Core.ICoreWindow5' was not included in compilation, but was referenced in method 'BootstrapHelpers.FillTypeMaps0(Dictionary<Type, int>, List<Type>)'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): error : Method '$MethodUtility.$Invoke3344(long, long*)' will always throw an exception due to the missing method 'DispatcherQueue.add_ShutdownCompleted(TypedEventHandler<DispatcherQueue, object>)'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): error : Method '$MethodUtility.$Invoke3345(long, long*)' will always throw an exception due to the missing method 'DispatcherQueue.add_ShutdownStarting(TypedEventHandler<DispatcherQueue, DispatcherQueueShutdownStartingEventArgs>)'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): error : Method '$MethodUtility.$Invoke3346(long, long*)' will always throw an exception due to the missing method 'DispatcherQueue.CreateTimer()'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): error : Method '$MethodUtility.$Invoke3347(long, long*)' will always throw an exception due to the missing method 'DispatcherQueue.GetForCurrentThread()'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): error : Method '$MethodUtility.$Invoke3348(long, long*)' will always throw an exception due to the missing method 'DispatcherQueue.remove_ShutdownCompleted(EventRegistrationToken)'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): error : Method '$MethodUtility.$Invoke3349(long, long*)' will always throw an exception due to the missing method 'DispatcherQueue.remove_ShutdownStarting(EventRegistrationToken)'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): error : Method '$MethodUtility.$Invoke3350(long, long*)' will always throw an exception due to the missing method 'DispatcherQueue.TryEnqueue(DispatcherQueueHandler)'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): error : Method '$MethodUtility.$Invoke3351(long, long*)' will always throw an exception due to the missing method 'DispatcherQueue.TryEnqueue(DispatcherQueuePriority, DispatcherQueueHandler)'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): error : Method '$MethodUtility.$Invoke3352(long, long*)' will always throw an exception due to the missing method 'DispatcherQueueHandler.Invoke()'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): error : Method '$MethodUtility.$Invoke3353(long, long*)' will always throw an exception due to the missing method 'DispatcherQueueTimer.add_Tick(TypedEventHandler<DispatcherQueueTimer, object>)'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): error : Method '$MethodUtility.$Invoke3354(long, long*)' will always throw an exception due to the missing method 'DispatcherQueueTimer.get_Interval()'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): error : Method '$MethodUtility.$Invoke3355(long, long*)' will always throw an exception due to the missing method 'DispatcherQueueTimer.get_IsRepeating()'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): error : Method '$MethodUtility.$Invoke3356(long, long*)' will always throw an exception due to the missing method 'DispatcherQueueTimer.get_IsRunning()'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): error : Method '$MethodUtility.$Invoke3357(long, long*)' will always throw an exception due to the missing method 'DispatcherQueueTimer.put_Interval(TimeSpan)'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): error : Method '$MethodUtility.$Invoke3358(long, long*)' will always throw an exception due to the missing method 'DispatcherQueueTimer.put_IsRepeating(bool)'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): error : Method '$MethodUtility.$Invoke3359(long, long*)' will always throw an exception due to the missing method 'DispatcherQueueTimer.remove_Tick(EventRegistrationToken)'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): error : Method '$MethodUtility.$Invoke3360(long, long*)' will always throw an exception due to the missing method 'DispatcherQueueTimer.Start()'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): error : Method '$MethodUtility.$Invoke3361(long, long*)' will always throw an exception due to the missing method 'DispatcherQueueTimer.Stop()'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): error : Method '$MethodUtility.$Invoke3362(long, long*)' will always throw an exception due to the missing method 'IDispatcherQueue.add_ShutdownCompleted(TypedEventHandler<DispatcherQueue, object>)'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): error : Method '$MethodUtility.$Invoke3363(long, long*)' will always throw an exception due to the missing method 'IDispatcherQueue.add_ShutdownStarting(TypedEventHandler<DispatcherQueue, DispatcherQueueShutdownStartingEventArgs>)'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): error : Method '$MethodUtility.$Invoke3364(long, long*)' will always throw an exception due to the missing method 'IDispatcherQueue.CreateTimer()'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): error : Method '$MethodUtility.$Invoke3365(long, long*)' will always throw an exception due to the missing method 'IDispatcherQueue.remove_ShutdownCompleted(EventRegistrationToken)'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): error : Method '$MethodUtility.$Invoke3366(long, long*)' will always throw an exception due to the missing method 'IDispatcherQueue.remove_ShutdownStarting(EventRegistrationToken)'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): error : Method '$MethodUtility.$Invoke3367(long, long*)' will always throw an exception due to the missing method 'IDispatcherQueue.TryEnqueue(DispatcherQueueHandler)'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): error : Method '$MethodUtility.$Invoke3368(long, long*)' will always throw an exception due to the missing method 'IDispatcherQueue.TryEnqueue(DispatcherQueuePriority, DispatcherQueueHandler)'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): error : Method '$MethodUtility.$Invoke3369(long, long*)' will always throw an exception due to the missing method 'IDispatcherQueueTimer.add_Tick(TypedEventHandler<DispatcherQueueTimer, object>)'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): error : Method '$MethodUtility.$Invoke3370(long, long*)' will always throw an exception due to the missing method 'IDispatcherQueueTimer.get_Interval()'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): error : Method '$MethodUtility.$Invoke3371(long, long*)' will always throw an exception due to the missing method 'IDispatcherQueueTimer.get_IsRepeating()'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): error : Method '$MethodUtility.$Invoke3372(long, long*)' will always throw an exception due to the missing method 'IDispatcherQueueTimer.get_IsRunning()'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): error : Method '$MethodUtility.$Invoke3373(long, long*)' will always throw an exception due to the missing method 'IDispatcherQueueTimer.put_Interval(TimeSpan)'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): error : Method '$MethodUtility.$Invoke3374(long, long*)' will always throw an exception due to the missing method 'IDispatcherQueueTimer.put_IsRepeating(bool)'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): error : Method '$MethodUtility.$Invoke3375(long, long*)' will always throw an exception due to the missing method 'IDispatcherQueueTimer.remove_Tick(EventRegistrationToken)'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): error : Method '$MethodUtility.$Invoke3376(long, long*)' will always throw an exception due to the missing method 'IDispatcherQueueTimer.Start()'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): error : Method '$MethodUtility.$Invoke3377(long, long*)' will always throw an exception due to the missing method 'IDispatcherQueueTimer.Stop()'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): error : Method '$MethodUtility.$Invoke3540(long, long*)' will always throw an exception due to the missing method 'ICoreWindow4.add_ResizeCompleted(TypedEventHandler<CoreWindow, object>)'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): error : Method '$MethodUtility.$Invoke3541(long, long*)' will always throw an exception due to the missing method 'ICoreWindow4.add_ResizeStarted(TypedEventHandler<CoreWindow, object>)'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): error : Method '$MethodUtility.$Invoke3542(long, long*)' will always throw an exception due to the missing method 'ICoreWindow4.remove_ResizeCompleted(EventRegistrationToken)'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): error : Method '$MethodUtility.$Invoke3543(long, long*)' will always throw an exception due to the missing method 'ICoreWindow4.remove_ResizeStarted(EventRegistrationToken)'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): error : Method '$MethodUtility.$Invoke3544(long, long*)' will always throw an exception due to the missing method 'ICoreWindow5.get_ActivationMode()'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): error : Method '$MethodUtility.$Invoke3545(long, long*)' will always throw an exception due to the missing method 'ICoreWindow5.get_DispatcherQueue()'. There may have been a missing assembly.\r\n102>C:\\Program Files (x86)\\MSBuild\\Microsoft\\.NetNative\\x86\\ilc\\IlcInternals.targets(936,5): error : Method 'NetworkCRC.ReinitializeScriptCRCs(Assembly)' will always throw an exception due to the missing method 'TypeExtensions.GetMethod(Type, string, BindingFlags)'. There may have been a missing assembly.\r\n========== Rebuild All: 101 succeeded, 1 failed, 0 skipped ==========\r\n```",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/1830/comments",
    "author": "lukasvolf",
    "comments": [
      {
        "user": "StephenHodgson",
        "created_at": "2018-03-14T03:30:53Z",
        "body": "Visual Studio 2017 is required to build projects using the MRTK"
      },
      {
        "user": "lukasvolf",
        "created_at": "2018-03-14T08:46:03Z",
        "body": "I am using an older version of the toolkit when it was still called \"HoloToolkit\". It builds fine in VS2015, Unity 2017.1 on Windows 10 running Creators Update. Tested on multiple machines, once I install the Fall Creators Update the build starts failing. We have a different branch using the latest Mixed Reality Toolkit and VS2017 15.5.7/Unity 2017.2MRTP5 and the issue is the same when I try to build it in NET Native - I get exactly the same output. Unfortunately, in this case the app has minimal target version set to Anniversary Update (because of HoloLens) and the target version is the Fall Creators Update, which means it requires Win 10 Fall Creators Update. We were not able to build that version with NET Native enabled yet."
      }
    ]
  },
  {
    "number": 1780,
    "title": "Error during PhotoCapture save to device",
    "created_at": "2018-03-02T02:36:23Z",
    "closed_at": "2018-03-07T03:21:40Z",
    "labels": [
      "Question"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/1780",
    "body": "## Overview\r\nI am trying to capture photo using the PhotoCapture and saving to the device. \r\nIt is erroring out in \r\n\r\nphotoCaptureObject.TakePhotoAsync(filePath, UnityEngine.XR.WSA.WebCam.PhotoCaptureFileOutputFormat.JPG, OnCapturedPhotoToDisk);\r\n\r\nError:  Failed capturing photo (hr = 0xC00D3704)\r\n\r\nUnityVersion : 2017.3.1p1\r\n\r\nWhat am I missing and is this supported still?\r\n\r\nThe same code was working in Unity 5.X\r\n\r\n",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/1780/comments",
    "author": "kvvishwa",
    "comments": [
      {
        "user": "kvvishwa",
        "created_at": "2018-03-07T03:21:40Z",
        "body": "Got that working, My bad I did not disable Vuforia Behaviour.\r\nNeed to add the below code at the start of the scene.\r\n\r\n VuforiaBehaviour.Instance.enabled = false;  "
      },
      {
        "user": "huangzejie0810",
        "created_at": "2020-03-24T10:48:42Z",
        "body": "I have the same problem,My need is for video and ARCamrea recognition to be present,Now ARCamera and photoCaptureObject operate the camera at the same time,Is there a good solution?"
      }
    ]
  },
  {
    "number": 1766,
    "title": "Button (Interactive script) OnHold Event() is only called once?",
    "created_at": "2018-02-27T17:05:47Z",
    "closed_at": "2018-03-31T15:33:04Z",
    "labels": [
      "Question"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/1766",
    "body": "I am trying to rotate an object to the right while a button is being pressed. The rotating is not the problem but, continuing to rotate is. I have my method attached to the OnHold Event() on a Button Prefab from the MRTK examples folder. Maybe the OnHold Event only detects holds once but, I thought it was more along the lines of the equivalent of Input.GetKey where it continues to perform while the user is Holding the button down. Is this not the case? If not, any possible solutions would be appreciated. ",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/1766/comments",
    "author": "dtb49",
    "comments": [
      {
        "user": "eirikhollis",
        "created_at": "2018-02-28T06:34:53Z",
        "body": "You could add IInputHandler to your script and start something that runs continuously on OnInputDown, and stop on OnInputUp."
      },
      {
        "user": "killerantz",
        "created_at": "2018-03-30T20:54:39Z",
        "body": "Sorry for the delayed response, the onHold event fires once per onHold. @eirikhollis is correct with his suggestion or you could use GestuerInteractive and extend the GestureInteractiveController class if you need something that's more gesture related."
      },
      {
        "user": "StephenHodgson",
        "created_at": "2018-03-31T15:32:20Z",
        "body": "Yeah I thing was designed to only fire once, not continuously."
      }
    ]
  },
  {
    "number": 1656,
    "title": "MRDL Features ETA?",
    "created_at": "2018-01-22T01:58:17Z",
    "closed_at": "2018-01-23T01:35:13Z",
    "labels": [
      "Question"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/1656",
    "body": "App Bar and Bounding Box How long it will take?",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/1656/comments",
    "author": "jerrygg",
    "comments": [
      {
        "user": "StephenHodgson",
        "created_at": "2018-01-22T17:57:31Z",
        "body": "Bounding Box is already in the Development branch.\r\n\r\nNext release for that one."
      },
      {
        "user": "NeerajW",
        "created_at": "2018-01-22T20:41:42Z",
        "body": "@radicalad @Railboy @cre8ivepark thoughts on app bar?"
      }
    ]
  },
  {
    "number": 1580,
    "title": "Supported Unity versions for next release?",
    "created_at": "2018-01-04T14:19:58Z",
    "closed_at": "2018-05-21T23:01:33Z",
    "labels": [
      "Question"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/1580",
    "body": "Hi, I am in the process of starting a new long-term project, and was wondering (since I read it somewhere), if future releases of MRTK will cut support for older Unity versions than 2017.3? \r\nAm I understanding it correctly that starting a new project with 2017.2.1 Unity and MRTK will require an update to 2017.3 for new releases of MRTK following the next (and all future) release?",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/1580/comments",
    "author": "eirikhollis",
    "comments": [
      {
        "user": "StephenHodgson",
        "created_at": "2018-01-04T15:50:31Z",
        "body": "That is correct. "
      },
      {
        "user": "NeerajW",
        "created_at": "2018-02-15T22:24:05Z",
        "body": "Please do give us a scenario where you think the older Unity builds must be supported? We believe it's causing more maintenance issues than not."
      },
      {
        "user": "eirikhollis",
        "created_at": "2018-02-16T07:37:59Z",
        "body": "The question was regarding to if a new project I was starting should be started in 2017.3 or 2017.2.0. I chose 2017.3 from the answer. \r\nPersonally, as long as new Unity versions don't introduce new breaking bugs, I believe only the latest should receive the newest toolkit updates. As you say, supporting older versions is definitely more time-consuming."
      },
      {
        "user": "StephenHodgson",
        "created_at": "2018-02-16T17:47:53Z",
        "body": "They have introduced breaking changes from 2017.3 and beyond."
      },
      {
        "user": "david-c-kline",
        "created_at": "2018-05-21T23:01:33Z",
        "body": "Version 2017.2.1.4 supports Unity 5.6 - 2017.4.\r\nVersion 2017.4.0.0 (coming in May 2018) will officially support Unity 2017.1 - 2018.1 (Unity 5.6 will likely still continue to work, if it does not we will investigate bug reports)"
      }
    ]
  },
  {
    "number": 1568,
    "title": "OnInputClicked with avatar",
    "created_at": "2017-12-26T09:33:08Z",
    "closed_at": "2017-12-28T23:43:27Z",
    "labels": [
      "Question"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/1568",
    "body": "## Overview\r\nI have Avatar and I want to give commands with this code. I don't know it there is better ways to do it.\r\n```\r\npublic class WalkTap : MonoBehaviour, IInputClickHandler\r\n{\r\n    private Animator _animator;\r\n\r\n    void Start()\r\n    {\r\n        GameObject avatar = GameObject.Find(\"Walk\");\r\n        _animator = avatar.GetComponent<Animator>();\r\n    }\r\n\r\n    public void OnInputClicked(InputClickedEventData eventData)\r\n    {\r\n        _animator.Play(\"Walk\");\r\n        eventData.Use(); \r\n    }\r\n}\r\n```\r\n## Expected Behavior\r\nAvatar walks when click avatar. Code works if I use it with cube and click cube, then avatar start to walk.\r\n## Actual Behavior\r\nNot working with avatar\r\n## Steps to reproduce\r\nUse that script with avatar animation.\r\n## Unity Editor Version\r\n2017.2.1f1\r\n## Mixed Reality Toolkit Release Version\r\n2017.2.1.0\r\n",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/1568/comments",
    "author": "jarmohh",
    "comments": [
      {
        "user": "Alexees",
        "created_at": "2017-12-28T17:58:46Z",
        "body": "This is not a mixed reality toolkit problem since the only tool related code, the interface, works. Post this in unity answers."
      },
      {
        "user": "StephenHodgson",
        "created_at": "2017-12-28T23:43:27Z",
        "body": "A agree.  This isn't really a toolkit issue."
      }
    ]
  },
  {
    "number": 1522,
    "title": "Is there an ETA for AppBar and BoundingBox example?",
    "created_at": "2017-12-14T03:42:49Z",
    "closed_at": "2018-02-15T22:14:23Z",
    "labels": [
      "Question"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/1522",
    "body": "I was under the (quite possibly unwarranted) impression that these capabilities were coming soon after the MRDL merge began, but it seems like the process has stalled. Are there any updates in terms of timeline for these and/or any other features coming from MRDL?",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/1522/comments",
    "author": "jimstack",
    "comments": [
      {
        "user": "Railboy",
        "created_at": "2017-12-14T17:26:39Z",
        "body": "We've been working on multi-pointer support and other input prereqs for bounding box manipulation. Once #1486 is merged into the dev branch we'll create a new feature branch for the bounding box. In the meantime any input or suggestions you have for #1486 are always welcome. (C&V from #1497)\r\n\r\nWe've got a pull request open for the bounding box base classes here: #1508"
      },
      {
        "user": "NeerajW",
        "created_at": "2018-02-15T22:14:23Z",
        "body": "Duplicate of #1497 "
      },
      {
        "user": "cre8ivepark",
        "created_at": "2018-02-16T20:53:26Z",
        "body": "@jimstack We opened a pull request for the Bounding Box normal mode with Two hand Gesture.\r\n#1727 \r\nAdjust mode Bounding Box with handles will be added through a different pull request."
      }
    ]
  },
  {
    "number": 1503,
    "title": "Error: Input Button CONTROLLER_LEFT_Menu is not setup ",
    "created_at": "2017-12-11T20:22:09Z",
    "closed_at": "2018-02-15T22:01:07Z",
    "labels": [
      "Question"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/1503",
    "body": "## Overview\r\nI'm getting this error in an existing project when I update to the latest dev branch. It wasn't there prior to the update.\r\n\r\n## Expected Behavior\r\nNo error.\r\n\r\n## Actual Behavior\r\nError:\r\n\r\nArgumentException: Input Button CONTROLLER_LEFT_MENU is not setup.\r\n To change the input settings use: Edit -> Project Settings -> Input\r\nHoloToolkit.Unity.InputModule.XboxControllerInputSource.Update () (at Assets/HoloToolkit/Input/Scripts/InputSources/XboxControllerInputSource.cs:91)\r\n\r\n\r\n## Steps to reproduce\r\n_(Links to sample github project preferred)_\r\nUpdate project to latest dev branch.\r\n\r\n## Unity Editor Version\r\n2017.2.0p2.MRTP5\r\n\r\n## Mixed Reality Toolkit Release Version\r\nv1.2017.2.0-dev\r\n",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/1503/comments",
    "author": "genereddick",
    "comments": [
      {
        "user": "StephenHodgson",
        "created_at": "2018-02-08T16:55:44Z",
        "body": "Be sure to make sure your editor input mapping is up to date."
      },
      {
        "user": "NeerajW",
        "created_at": "2018-02-15T22:01:07Z",
        "body": "This should be solved. Please reopen if that's not the case."
      }
    ]
  },
  {
    "number": 1489,
    "title": "What's with the name of the stabilization branch?",
    "created_at": "2017-12-08T04:52:16Z",
    "closed_at": "2017-12-08T06:25:12Z",
    "labels": [
      "Question"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/1489",
    "body": " v2017.2.0.1-Stabilization?\r\n\r\nI thought we were dropping the v prefix on the releases?\r\n\r\nAlso, shouldn't it be 2017.2.1.0 as it'll most likely reflect the new release Unity will have by the time we approve it?",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/1489/comments",
    "author": "StephenHodgson",
    "comments": [
      {
        "user": "keveleigh",
        "created_at": "2017-12-08T06:17:27Z",
        "body": "I copied the tag from your release draft. Certainly that can change between now and then.\r\n\r\nIf a new Unity release happens, we can address that. The branch name doesn't lock us into a tag.\r\n\r\nI mistakenly kept the `v` this time, but, again, the branch name doesn't lock us into a release tag."
      },
      {
        "user": "StephenHodgson",
        "created_at": "2017-12-08T06:25:12Z",
        "body": "No worries, just asking."
      },
      {
        "user": "keveleigh",
        "created_at": "2017-12-08T06:36:27Z",
        "body": "All good! I wanted to try to explain my thought process as thoroughly as possible."
      }
    ]
  },
  {
    "number": 1319,
    "title": "Sharing Hololenses don't Sync their positions correctly",
    "created_at": "2017-11-08T18:25:41Z",
    "closed_at": "2019-04-11T20:27:11Z",
    "labels": [
      "Question",
      "Platform - HoloLens - First Gen"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/1319",
    "body": "So I have a shared experience that has 1 Instructor and multiple Viewers.  However when I start the application on all the devices their positions aren't Synced together.  So if I start an Instructor in Position A and then start a Viewer in Position B (Real world positions).  The synchronized positioning is skewed by the distance vector between Position A and Position B.  So the only way they can be somewhat synchronized is if I start each app in the same exact real world position.\r\n\r\nSo for example when I start the app in different positions, the Cubes that get placed where a HL is (from RemoteHeadManager) are in a different position based on the distance vector from where each application was loaded.\r\n\r\nI know there is a solution for this.  Do I need to give each HoloCamera a world anchor?  Enable Spatial Mapping?  If someone could please let me know this is extremely time sensitive.",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/1319/comments",
    "author": "kyleWillson",
    "comments": [
      {
        "user": "MrMatthias",
        "created_at": "2017-11-09T09:59:00Z",
        "body": "you need at least one anchor, you could then add all players as child and sync their relative position to that anchor"
      },
      {
        "user": "kyleWillson",
        "created_at": "2017-11-09T15:23:41Z",
        "body": "When you mean add all players as a child, do you mean the cube position that is generated from RemoteHeadManager? Or what?"
      },
      {
        "user": "MrMatthias",
        "created_at": "2017-11-14T12:48:57Z",
        "body": "The origin is based on where you started the app, so you can't sync the worldposition, you have to use a common reference point (world anchor) and synchornize the viewer's relative position, relating to that reference point"
      },
      {
        "user": "NeerajW",
        "created_at": "2018-02-15T18:40:05Z",
        "body": "1. You don't need spatial mapping for World Anchors. They use visual tracking data and not depth data.\r\n2. Yes much like RemoteHeadManager will broadcast relative positions of cubes/users based on the common anchor sphere that has been established. Each player becomes a child of that common anchor point sphere. So once the main speaker establishes an anchor point, others can start using the same. \r\n3. If speaker 1 makes the anchor, then other people need to have the same tracking points he saw since anchors work using visual tracking so making them walk around the space to build good tracking is a must."
      },
      {
        "user": "jayhersk",
        "created_at": "2018-03-18T23:12:47Z",
        "body": "Is the SharingWorldAnchorManager script supposed to sync the positions automatically? Or am I supposed to send the positioning of the anchor from one device to another somehow? Right now I can see the same holograms on each device but they are shifted depending on where I was looking when I started my app. Any advice is appreciated.\r\n\r\nBest,\r\nJaylin"
      },
      {
        "user": "kyleWillson",
        "created_at": "2018-03-19T15:58:07Z",
        "body": "@jayhersk ,  I also encounter that problem as well, and it's quite annoying.  @NeerajW  do you have a fix for that?"
      },
      {
        "user": "wiwei",
        "created_at": "2019-04-11T20:27:11Z",
        "body": "Closing issues older than 180 days. If this is still an issue, please reactivate with recent information."
      }
    ]
  },
  {
    "number": 1313,
    "title": "Current MixedRealityToolkit HoloLens compatibility status with Unity 2017.3 Beta?",
    "created_at": "2017-11-07T18:44:33Z",
    "closed_at": "2017-11-10T05:39:18Z",
    "labels": [
      "Question"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/1313",
    "body": "Hello,\r\n\r\nI am using an older version of the MixedRealityToolkit with HoloLens but was interested in updating my project to the Unity 2017.3 beta. Looking at the releases page it says HoloLens users should stay on 2017.1.2. Has anything changed since that release and is it at all possible currently to get the MixedRealityToolkit for HoloLens working with the Unity 2017.3 beta?",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/1313/comments",
    "author": "atouchet",
    "comments": [
      {
        "user": "StephenHodgson",
        "created_at": "2017-11-07T21:44:57Z",
        "body": "The project only targets release versions of Unity (unless there's a big change to Windows Mixed Reality).  If you need to support the beta, you're more than welcome to post your findings here."
      },
      {
        "user": "atouchet",
        "created_at": "2017-11-10T05:39:18Z",
        "body": "Alright, I will probably end up waiting for the official release as opposed to using the beta."
      }
    ]
  },
  {
    "number": 1310,
    "title": "Voice chat not working in MixedRealityToolkit v.2017.2.0!",
    "created_at": "2017-11-07T11:36:37Z",
    "closed_at": "2017-11-17T07:41:30Z",
    "labels": [
      "Question"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/1310",
    "body": "@StephenHodgson MicrophoneTransmitter and MicrophoneReceiver have been removed from the MixedRealityToolkit v.2017.2.0.\r\nIt is mentioned as \"Group Voice Chat\" feature is given as built in option in Mixedreality Toolkit, but how to implement in a unity project?\r\nWhat are the new scripts or components need to be added for incorporating Voice Chat?\r\nTools Used:\r\nUnity Version : Unity 2017.1.2 f1\r\nToolkit Version : MixedReality Toolkit v.2017.2.0",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/1310/comments",
    "author": "thepeacekpr",
    "comments": [
      {
        "user": "StephenHodgson",
        "created_at": "2017-11-07T16:26:16Z",
        "body": "@mr-mystery It wasn't removed, but moved to the examples folder. It wasn't being well maintained and the dlls do not pass WACK."
      },
      {
        "user": "thepeacekpr",
        "created_at": "2017-11-08T05:48:35Z",
        "body": "So, does it mean we need to import the examples unity package as well to our \"whatever\" project? And what's a WACK?"
      },
      {
        "user": "StephenHodgson",
        "created_at": "2017-11-08T07:15:18Z",
        "body": "Windows application certification kit. It tests your app before it can be published in the app store.\r\n\r\nYou could probably just copy/paste when you need."
      },
      {
        "user": "thepeacekpr",
        "created_at": "2017-11-08T07:41:45Z",
        "body": "Thank you very much bro."
      },
      {
        "user": "thepeacekpr",
        "created_at": "2017-11-17T05:07:35Z",
        "body": "@StephenHodgson If the VOIP didn't pass the wack. And if I implement it from the examples folder to my project, will I be able to upload to the windows store?"
      },
      {
        "user": "StephenHodgson",
        "created_at": "2017-11-17T05:47:58Z",
        "body": "No, you will not."
      },
      {
        "user": "thepeacekpr",
        "created_at": "2017-11-17T06:01:54Z",
        "body": "Thanks for your help."
      }
    ]
  },
  {
    "number": 1303,
    "title": "SharingTest stalling after connection",
    "created_at": "2017-11-06T23:24:49Z",
    "closed_at": "2019-04-11T20:27:13Z",
    "labels": [
      "Question"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/1303",
    "body": "Building the SharingTest scene and deploying on Hololens results in a connection to the running Sharing Service server and then the Hololens app stalls, with no unity splash screen or game objects created. No previous room and anchor information has been persisted as this is the first time sharing has been enabled. Could this impasse be caused by some aspect of SharingWorldAnchorManager that was/is handled differently by the ImportExportAnchorManager or RoomTest scripts?",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/1303/comments",
    "author": "dave-trainor",
    "comments": [
      {
        "user": "wiwei",
        "created_at": "2019-04-11T20:27:13Z",
        "body": "Closing issues older than 180 days. If this is still an issue, please reactivate with recent information."
      }
    ]
  },
  {
    "number": 1299,
    "title": "Do I have to do anything in order for the Dictation Recognizer to work with the keyboard?",
    "created_at": "2017-11-06T17:30:12Z",
    "closed_at": "2018-03-07T17:31:21Z",
    "labels": [
      "Question"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/1299",
    "body": "I am trying to implement the keyboard prefab to my project. I can get it to show up and everything and typing works. However, when I press the \"speech\" button, nothing happens. I have the microphone capability enabled as well as internet client. Is there anything else I need to do in order for the dictation recognizer to work with the keyboard?",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/1299/comments",
    "author": "dtb49",
    "comments": [
      {
        "user": "StephenHodgson",
        "created_at": "2017-11-06T17:41:13Z",
        "body": "Yeah, it needs to be completely refactored to use the `DictationManager` See #834 and #976"
      },
      {
        "user": "dtb49",
        "created_at": "2017-11-06T19:16:46Z",
        "body": "That would be it haha I hadn't even looked at the source code beforehand. But, implemented dictation recognizer from Holograms 212 into it and it works nicely now."
      },
      {
        "user": "keveleigh",
        "created_at": "2018-02-15T21:08:38Z",
        "body": "Fixed via #1496 "
      }
    ]
  },
  {
    "number": 1293,
    "title": "MotionController with Positional tracking off.",
    "created_at": "2017-11-03T19:51:11Z",
    "closed_at": "2017-12-06T22:47:34Z",
    "labels": [
      "Question",
      "Platform - VR"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/1293",
    "body": "Is there a way to reset the motion controller 's position when \r\n I turn on this flag `UnityEngine.XR.InputTracking.disablePositionalTracking = true;` ?\r\n",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/1293/comments",
    "author": "song1shuai",
    "comments": [
      {
        "user": "keveleigh",
        "created_at": "2017-12-06T22:47:34Z",
        "body": "Duplicate of #1376. Closing this in favor of that one with more discussion and a bug report."
      }
    ]
  },
  {
    "number": 1291,
    "title": "Mechanism to know when PrefabSpawnManager spawns a prefab",
    "created_at": "2017-11-02T22:14:58Z",
    "closed_at": "2017-11-02T22:23:10Z",
    "labels": [
      "Question"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/1291",
    "body": "I need to run some local processing on Prefabs that get spawned.  And I was wondering if there was some sort of mechanism (event Action) in place and I didn't see it, that can notify different scripts when a prefab was spawned.  Something like in PrefabSpawnManager:\r\n`public event Action<SyncSpawnedObject> ObjectSpawned;`\r\nThat gets fired when PrefabSpawnManager.Spawn() is about to return?",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/1291/comments",
    "author": "kyleWillson",
    "comments": [
      {
        "user": "StephenHodgson",
        "created_at": "2017-11-02T22:16:07Z",
        "body": "It should all be self contained in the `PrefabSpawnManger` you write on your own. That class is just an example of how you could implement it."
      },
      {
        "user": "kyleWillson",
        "created_at": "2017-11-02T22:23:04Z",
        "body": "Ahhh gotchya.  I just like using your guys' code since its got the support behind it (updates)"
      }
    ]
  },
  {
    "number": 1284,
    "title": "When will MRDL basic controls be merged into MRTK?",
    "created_at": "2017-11-02T06:04:29Z",
    "closed_at": "2017-11-02T22:08:10Z",
    "labels": [
      "Question"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/1284",
    "body": "My team was trying to use the Holographic-Shell-like MRDL App Bar and BoundingBox controls in our MRTK app, and found that MRDL baseline functionality has been successfully merged hours ago. So I wonder when will the MRDL basic controls be merged, and will it land in v1.2017.2.0 or v1.2017.3.0?",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/1284/comments",
    "author": "zhanghai",
    "comments": [
      {
        "user": "StephenHodgson",
        "created_at": "2017-11-02T17:08:52Z",
        "body": "We're still working on it. There's currently an active PR #1197 open for some basic stuff already."
      },
      {
        "user": "cre8ivepark",
        "created_at": "2017-11-02T18:07:39Z",
        "body": "@DreaminginCodeZH PR #1197 includes basic Holographic Button in the InteractableObjectExamples scene. App Bar and BoundingBox control is on phase 2 list - we are updating it to support motion controller's pointer input too."
      },
      {
        "user": "zhanghai",
        "created_at": "2017-11-02T19:04:01Z",
        "body": "Thanks for the quick response! I wonder when will the phase 2 controls be merged, and will it land in v1.2017.2.0 or v1.2017.3.0?"
      },
      {
        "user": "StephenHodgson",
        "created_at": "2017-11-02T19:04:37Z",
        "body": "ASAP"
      },
      {
        "user": "zhanghai",
        "created_at": "2017-11-02T23:19:20Z",
        "body": "Just one more question, is it possible for the AppBar and BoundingBox to be merged within two weeks? If not, our team will have to roll our own solution due to time constraint."
      },
      {
        "user": "cre8ivepark",
        "created_at": "2017-11-03T02:34:40Z",
        "body": "@Railboy could you please share rough timeline for your App Bar + Bounding Box updates?"
      }
    ]
  },
  {
    "number": 1280,
    "title": "Where does the MR camera's transform get its readings from?",
    "created_at": "2017-11-01T08:45:21Z",
    "closed_at": "2018-02-15T21:09:22Z",
    "labels": [
      "Question"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/1280",
    "body": "I've looked through the API but couldn't find how the camera's transform is driven. Where does it receive it's orientation data?",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/1280/comments",
    "author": "Alexees",
    "comments": [
      {
        "user": "StephenHodgson",
        "created_at": "2017-11-01T15:22:55Z",
        "body": "Most likely ` UnityEngine.XR.XRNode.Head`"
      },
      {
        "user": "Alexees",
        "created_at": "2017-11-02T07:24:59Z",
        "body": "The only script I could find using either UnityEngine.XR.XRNode namespace or just XRNode is some FogVolumeCamera. Does this mean the camera is driven from outside the manage side or from within a dll?"
      },
      {
        "user": "StephenHodgson",
        "created_at": "2017-11-02T17:09:19Z",
        "body": "The API above should give you the information you're looking for."
      },
      {
        "user": "NeerajW",
        "created_at": "2018-02-15T21:09:22Z",
        "body": "Please reopen if you still have specific issues. Perhaps asking on Unity forums might help with this one as well."
      }
    ]
  },
  {
    "number": 1278,
    "title": "\"Help Wanted\" Accessing SyncRoot",
    "created_at": "2017-10-31T21:19:02Z",
    "closed_at": "2018-02-15T21:14:17Z",
    "labels": [
      "Question"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/1278",
    "body": "Hi all,\r\nhow can I get Information of some Elements in the SyncRoot from  a script?\r\n\r\nRegards, Hans ",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/1278/comments",
    "author": "hansbickhofe",
    "comments": [
      {
        "user": "StephenHodgson",
        "created_at": "2017-10-31T21:33:07Z",
        "body": "Take a look at the `SpawnManager` and how it get's the `SyncArray<T> SyncSource` from the `SharingStage.Root.InstantiatedPrefabs`.\r\n\r\n\r\nLook at ` SyncSource.GetDataArray()` in particular. "
      },
      {
        "user": "NeerajW",
        "created_at": "2018-02-15T21:14:17Z",
        "body": "Please reopen if you have other specific issues."
      }
    ]
  },
  {
    "number": 1273,
    "title": "Help converting from Hololens AR to Headset MR",
    "created_at": "2017-10-31T09:39:49Z",
    "closed_at": "2018-05-21T22:45:07Z",
    "labels": [
      "Question"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/1273",
    "body": "So I had my project working pretty well in the Hololens Emulator, where I begin with walking around to scan mesh then tapping to build the surfaces to populate the environment.  Now I got my Mixed Reality Headset with 2 motion controllers and trying to adapt my project to work in the VR and having confusions/problems.  I disabled the Hololens camera manager and added the MixedRealityCameraParent, no problem there.  I built a room in Sketchup and imported in, colored with the FastConfigurables, added the Mesh Collider, etc.. All is good there, I can build and I'm no longer floating on just the boundary Floor Quad and can see my motion controller and teleport, happy about that.. \r\nI went to my SpatialMapping component and in the ObjectSurfaceObserver I made my Room Mesh my fbx room model instead of the sample office mesh, and I hope there's a way to make that work to create the SurfacePlane list dynamically from that.  My alternative is to manually place the SurfacePlanes on my walls and floor the same way spatial mapping generates it for my Hololens code to work.  Any advice?\r\n\r\nI'm trying to adapt all my Update() code using GazeManager, gazeHitPoint, gazeObject and tap into the Motion Controller inputs so the left & right hand + trigger replaces the gaze.  I looked through the MotionConrollerVisualizer script and the best hint I could find is to extract the controller info from InteractionManager.GetCurrentReading() but it seems like there should be an easier abstracted way to get the controllers' states.\r\nDoes a trigger click from the 3D controller do the same as a gaze tap in the Input handlers?  I didn't get much out of the MotionControllerTest example unfortunately..\r\n\r\nAnother head scratcher I ran into was figuring out what if statement or #if def used to tell the difference between a Hololens transparent device and a Mixed Reality occluded device run?  That should be a simple one but couldn't find reference anywhere...\r\nThanks, I have more questions on the MR porting process, but I'll save it for after.  I'm just anxious to see my baby working on my goggles..",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/1273/comments",
    "author": "Skquark",
    "comments": [
      {
        "user": "StephenHodgson",
        "created_at": "2017-10-31T14:46:17Z",
        "body": "What version of unity and the toolkit was your old project you're porting?"
      },
      {
        "user": "Skquark",
        "created_at": "2017-10-31T23:43:01Z",
        "body": "I'm on Unity 2017.2.0f3 and on the latest MRTK release build.. I was on the Dev branch for a while so I can get a jump on the mixed reality bits, but then switched back to master when those changes got merged.\r\nMy opening code is based on the SpatialUnderstandingExample with the room scanning from AppState.cs, so when it starts we're walking around room to scan environment and waiting for a tap from OnInputClicked to RequestFinishScan and I can't get that to work to generate the SurfacePlanes to move on to the next parts...\r\nThanks."
      },
      {
        "user": "Skquark",
        "created_at": "2017-11-01T02:45:28Z",
        "body": "Just an update/clarification, I tried forcing the RequestFinishScan and ScanComplete of SpatialUnderstanding with the MixedRealityCamera instead of HololensCamera, and I can't get it to generate the list of SurfacePlanes it was able to extract from the given room mesh model like it was able to do when we were in Hololens mode..\r\nSo right now, the core of my question is how to mimic the effect of finishing a room scan and making the recognized surfaces with an occluded device?  To duplicate the circumstance, open SpatialUnderstandingExample and run it in the Mixed Reality Portal then try to finalize the spatial mapping of a fake room mesh.  Is there a way to hack it to have the same results as Hololens, or do I have to fake it the hard way?"
      },
      {
        "user": "Skquark",
        "created_at": "2017-11-03T01:01:24Z",
        "body": "I'm trying to answer my own question here, but still need help.  I'm figuring out the new Motion Controller Input Interface by taking apart the example script DebugPanelControllerInfo.cs and generating custom events from InteractionManager_InteractionSourceUpdated, so I should be able to get that working right soon.\r\nAlso figured out my question on the if statement for the difference between Mixed Reality and Hololens by using if (HolographicSettings.IsDisplayOpaque) ....\r\n\r\nI'm still stuck on the SurfacePlane generator, and I imagine anybody else using the SpatialMapping from Hololens in their Mixed Reality hybrid project would be having this same issue.. It used to work fine in the editor to finalize the surfaces before the mesh scanning, but no longer since the MixedRealityCameraParent and the preview opening in the Mixed Reality Portal.  So the short of the question is how could we fix the SpatialUnderstandingExample to immediately finalize the mesh provided in ObjectSurfaceObserver to make the SurfacePlane list?  Thanks."
      },
      {
        "user": "StephenHodgson",
        "created_at": "2017-11-03T01:08:17Z",
        "body": "All you need to do is implement the input interfaces in your scripts.  You don't have to subscribe to the `InteractionManger` if you don't need to."
      },
      {
        "user": "Skquark",
        "created_at": "2017-11-03T02:57:57Z",
        "body": "Yeah, I just didn't like that method of attaching the input interface script to every game object that I want to make interactable, didn't flow well with what I'm making.  I already had it working by using the current gaze object when tapping or using the other gesture or motion controls, I worked out some tricky hacks to hold it together.\r\n\r\nHowever, my question wasn't really about that, I'm trying to get my SurfacePlanes back because nothing in my project works without those placed in the world first.  If there's no way to generate the surfaces from the Mixed Reality headsets at this time, let me know so I can manually place the SurfacePlane objects on my walls and floors just so I can move on, but I'd prefer doing it the right way of automatically placing them from the room mesh.  Thanks."
      },
      {
        "user": "david-c-kline",
        "created_at": "2018-05-21T22:45:07Z",
        "body": "The Mixed Reality immersive headsets do not support Spatial Mapping, rather they support setting a boundary which will be displayed to your users as they near it."
      }
    ]
  },
  {
    "number": 1266,
    "title": "InterpolatedValue might be able to use a method \"Await\" ?",
    "created_at": "2017-10-30T19:55:07Z",
    "closed_at": "2018-05-21T22:41:21Z",
    "labels": [
      "Question"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/1266",
    "body": "I inherited some code that uses a modified version of InterpolatedValue.cs, that has a method Await( ). Every time I import the toolkit, I have to re-add this method, and I'm not sure how to get rid of calling that method in the code I inherited. Could be by any chance add this method to InterpolatedValue.cs on the grounds it might be useful?\r\n\r\nhere is the code:\r\n\r\n        /// <summary>\r\n        /// Waits for the interpolator to complete, unless cancelled.\r\n        /// The token won't cancel the execution of the interpoloatr\r\n        /// </summary>\r\n        /// <param name=\"token\"></param>\r\n        /// <returns></returns>\r\n        public CoroutineEx Await(CancellationToken token)\r\n        {\r\n            return CoroutineEx.Run(Awaiter(), token);\r\n        }\r\n\r\n        private IEnumerator<Yield> Awaiter()\r\n        {\r\n            while (IsRunning)\r\n            {\r\n                yield return Yield.WaitForNextFrame;\r\n            }\r\n        }\r\n\r\n",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/1266/comments",
    "author": "erichfrazer",
    "comments": [
      {
        "user": "StephenHodgson",
        "created_at": "2017-10-31T05:22:17Z",
        "body": "I think `CoroutineEx` is not anything available in the current MRTK.\r\n\r\nLast time I saw it I was working on a project there at MSFT."
      },
      {
        "user": "erichfrazer",
        "created_at": "2017-10-31T06:17:17Z",
        "body": "True. I wonder if we could add the Co-routine stuff to the MR Toolkit? If it's not being considered already!"
      },
      {
        "user": "StephenHodgson",
        "created_at": "2017-10-31T14:34:44Z",
        "body": "I guess that depends on the guys who wrote it.\r\n\r\nI found it useful, and a bit more flexible for working with coroutines in editor scripts."
      }
    ]
  },
  {
    "number": 1261,
    "title": "Scene: GrabMechanics doesn't seem to work",
    "created_at": "2017-10-30T05:46:17Z",
    "closed_at": "2017-11-06T16:20:52Z",
    "labels": [
      "Question",
      "Platform - VR"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/1261",
    "body": "Machine: Windows 10 Fall Creators update, Unity: 2017.2. I tried this scene (GrabMechanics) in the editor, and compiled to debug, and in neither one can I pick up and control anything. Should this scene still work? And if not, I wonder if anybody has a quick answer why not? There isn't much in the scene to begin with!\r\n",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/1261/comments",
    "author": "erichfrazer",
    "comments": [
      {
        "user": "keveleigh",
        "created_at": "2017-10-30T15:57:11Z",
        "body": "Yep, I ran this the other day to help somebody else figure it out. The problem he was running into: are you pointing at the objects to interact or actually reaching out, intersecting the blocks with your block hands, and then interacting? They were trying to point and click, but actually \"grabbing\" the objects is the way this sample works.\r\n\r\nAnother thing to check is to make sure you're pressing the right button. If I remember correctly, this scene works with the grasp button, not the trigger.\r\n\r\nLet me know if it still doesn't work for you!"
      },
      {
        "user": "erichfrazer",
        "created_at": "2017-10-30T16:33:27Z",
        "body": "Oop, Grab does work, you DO have to reach out and grab it w/ the chunky block. Well, this is a relief. And yeah, I'm not used to using the Grasp button. You may close this.\r\n\r\nOne thing I can't figure out is where MotionController.cs went. I see the visualizer script file, but the MotionController base script is gone. Has this been replaced with a different set of mechanics for input control? and recently?\r\n"
      },
      {
        "user": "keveleigh",
        "created_at": "2017-10-30T16:36:23Z",
        "body": "There's MotionControllerVisualizer and MotionControllerInfo, which contains the data about the model and animation parameters. I don't believe there's ever been a MotionController script like you describe. The controller controls are routed through InputManager events. Are you perhaps thinking of a script in the MRDL/HUX?"
      },
      {
        "user": "StephenHodgson",
        "created_at": "2017-10-30T16:38:20Z",
        "body": "Ah, I tagged this as a bug cause I didn't get it to work either.  Good to hear."
      },
      {
        "user": "hridpath",
        "created_at": "2017-11-03T22:18:09Z",
        "body": "I am using the Motion Controllers from Dell. I can click and change the active controll to the controller but when I focus on an object and click the Grasp button nothing happens. Do I physically need to move the controller to the object?\r\n"
      },
      {
        "user": "StephenHodgson",
        "created_at": "2017-11-03T22:20:01Z",
        "body": "I believe so"
      },
      {
        "user": "hridpath",
        "created_at": "2017-11-03T22:42:30Z",
        "body": "Sorry to say that even moving the controller to touch/pass through did  not work. I am getting the GLTF material for my controller. I move the controller into position and click/grasp the grab button on the side of the controller. nada\r\nPS. I am running in editor viewing on HMD"
      },
      {
        "user": "hridpath",
        "created_at": "2017-11-03T23:10:35Z",
        "body": "I just tried to force the use of the alternate models and still no interactions.\r\n"
      },
      {
        "user": "keveleigh",
        "created_at": "2017-11-04T00:55:24Z",
        "body": "Looks like there was a bug introduced with the prefab changes in the recent visualizer update. PR incoming with a fix."
      }
    ]
  },
  {
    "number": 1253,
    "title": "Tagalong Script not working as intended",
    "created_at": "2017-10-28T07:30:43Z",
    "closed_at": "2017-10-30T11:37:02Z",
    "labels": [
      "Question"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/1253",
    "body": "Device: HoloLens\r\n\r\nI have added the Tagalong script to a GameObject. It follows me, but it always stays behind me, when I walk away. How can I make it stay inside my Field of View?",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/1253/comments",
    "author": "eluchsinger",
    "comments": [
      {
        "user": "StephenHodgson",
        "created_at": "2017-10-28T16:39:08Z",
        "body": "Try the `SphereBasedTagalong` and reduce it's radius to something like 0.1 and move it out about 2 meters in front of you."
      },
      {
        "user": "eluchsinger",
        "created_at": "2017-10-30T11:37:02Z",
        "body": "Works. Thanks!"
      }
    ]
  },
  {
    "number": 1241,
    "title": "Replacement for Unlit/NoDepth and how to make 3D text always visible (not blocked by anything)",
    "created_at": "2017-10-26T20:05:14Z",
    "closed_at": "2019-04-11T20:27:21Z",
    "labels": [
      "Question"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/1241",
    "body": "Hi there, \r\n\r\nI was developing using the HoloLensToolKit before. To make target indicator not blocked by anything, the shader is set to Unlit/NoDepth. After I switched to MixedRealityToolKit, I see that the NoDepth shader is considered as obsolete now. Is there a replacement for the Unlet/NoDepth shader now? I cannot find it in the shader options. \r\n\r\nAlso, before, a 3D text would always be visible even if there is an object in front of it. Now, this is not the case. With the default shader from MixedRealityToolKit, a 3D text would not be visible if there is an object between the camera and the text. What do I need to do to change this?\r\n\r\nThanks in advance.\r\n",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/1241/comments",
    "author": "qfliu",
    "comments": [
      {
        "user": "StephenHodgson",
        "created_at": "2017-10-26T20:10:02Z",
        "body": "I believe you can just use Unity's default text shader"
      },
      {
        "user": "qfliu",
        "created_at": "2017-10-26T22:52:15Z",
        "body": "@StephenHodgson \r\n\r\nI tried to create a 3D text with default values. This works in version 5.6.1f1, but not version 2017.2.0b9. With version 5.6.1f1, I was using HoloLensToolKit; with 2017.2.0b9, I am using MixedRealityToolkit-Unity. By \"works\", I mean that the text would not be blocked by a surface plane I generated."
      },
      {
        "user": "wiwei",
        "created_at": "2019-04-11T20:27:20Z",
        "body": "Closing issues older than 180 days. If this is still an issue, please reactivate with recent information."
      }
    ]
  },
  {
    "number": 1234,
    "title": "Can a SyncSpawnModel get notified when a new User joins the session, and filter content based on specific components to that User",
    "created_at": "2017-10-25T18:13:06Z",
    "closed_at": "2019-04-11T20:27:25Z",
    "labels": [
      "Question",
      "Sharing / Networking"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/1234",
    "body": "So my ideal scenario is this: \r\n\r\n- There are two User \"roles\": Instructor and Viewer.  Where the Instructor has all the interactive power and a viewer can simply just view whats going on.  \r\n- On App start, but before connecting to the Sharing Server the User will choose to either Instructor or Viewer.  Which this info will be contained locally in SharingUserInfo.cs\r\n- I have a SceneContainer, that as you guessed contains multiple scenes (As GameObjects, not Unity Scenes)\r\n-  I only want 1 scene container to be spawned.  So currently, only the instructor spawns the scene container.  But if I add another instructor, it spawns another.  Is there a way to check the sharing server to see what has been spawned, so we don't have repeats?\r\n- Is there a way for the Model to get Notified when a User joins the session?  I found SessionUsersTracker.UserJoined, which I think will suit my needs\r\n- Once a User joins, can the existing SyncSpawnModel access the new User's SharingUserInfo component?  And then Filter content based on that?  This is the main thing I am concerned with, I think the SyncSpawnModel would just call SharingUserInfo.Instance.getUserInfo() to get the info (since its local).  And then to filter the content I would need to link somehow the HoloToolkit User to SharingUserInfo so they are the same User.  Which I would then check if that User needs any filtering on On_Property_Changed in the Model?\r\n\r\nIm pretty sure this is pretty solid logic, I just don't know how to check for existing spawned models, and accessing User specific components.\r\n",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/1234/comments",
    "author": "kyleWillson",
    "comments": [
      {
        "user": "StephenHodgson",
        "created_at": "2017-10-25T19:14:29Z",
        "body": "I'll try to answer some of these questions on my next livestream this weekend and update this issue."
      },
      {
        "user": "kyleWillson",
        "created_at": "2017-10-25T20:21:53Z",
        "body": "That sounds awesome!  Thanks Stephen!"
      },
      {
        "user": "wiwei",
        "created_at": "2019-04-11T20:27:24Z",
        "body": "Closing issues older than 180 days. If this is still an issue, please reactivate with recent information."
      }
    ]
  },
  {
    "number": 1227,
    "title": "How do I use the UX controls with a RigidBody?",
    "created_at": "2017-10-24T14:51:32Z",
    "closed_at": "2019-04-11T20:27:29Z",
    "labels": [
      "Question"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/1227",
    "body": "Hi!\r\n\r\nIn order to use the Bounding Box component that's part of the MRDL, the root gameobject needs a rigidbody component attached to it.\r\n\r\nHowever, it seems that the slider component (and the other UX components) don't work when there is a rigidbody on any of their parent gameobjects.\r\n\r\nDoes anyone know of a way around this?\r\n\r\nThanks in advance!",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/1227/comments",
    "author": "HattMarris1",
    "comments": [
      {
        "user": "wiwei",
        "created_at": "2019-04-11T20:27:28Z",
        "body": "Closing issues older than 180 days. If this is still an issue, please reactivate with recent information."
      },
      {
        "user": "AWSi-DR-TS",
        "created_at": "2020-09-03T09:08:47Z",
        "body": "I also run into this problem. Is there a fix by now?\r\n\r\nThanks :)"
      }
    ]
  },
  {
    "number": 1217,
    "title": "Any chanches to build solution in new version of unity?",
    "created_at": "2017-10-20T18:51:47Z",
    "closed_at": "2017-10-20T18:57:54Z",
    "labels": [
      "Question"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/1217",
    "body": "Hi. Unity 2017.2.f03 now released and, as i see, there is a branch for Unity 2017.2 (Dev_Unity_2017.2.0).\r\nI trying tu build something, but i can't. I can't even build your example scenes.\r\n\r\nError:\r\n```\r\nAssets\\Scripts\\HoloToolkit\\Input\\Scripts\\Utilities\\Extensions\\InteractionSourceExtensions.cs(101,39): error CS1929: 'SpatialInteractionController' does not contain a definition for 'TryGetRenderableModelAsync' and the best extension method overload 'InteractionSourceExtensions.TryGetRenderableModelAsync(InteractionSource)' requires a receiver of type 'InteractionSource'\r\n```\r\n\r\nAnd then:\r\nError building Player because scripts had compiler errors\r\n\r\nThis errors occurs only during the build process (Build project in your Build Window). \r\nReally will be gratefull if you help me with this errors or maybe say, what version of Unity, version \\ branch of SDK i need to use, to get stable work) It will save me a lot of time, thanks)\r\n",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/1217/comments",
    "author": "Hitomilras",
    "comments": [
      {
        "user": "StephenHodgson",
        "created_at": "2017-10-20T18:57:54Z",
        "body": "See #1184"
      }
    ]
  },
  {
    "number": 1216,
    "title": "Compiler error when build app",
    "created_at": "2017-10-20T17:14:55Z",
    "closed_at": "2017-10-20T17:16:52Z",
    "labels": [
      "Question"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/1216",
    "body": "I've an empty Projekt, just with the Toolkit inside. My Scene is just Setup with prefabs: camera, Cursor, inputmanager and spatialmapping.\r\n\r\nBut when i try to build the app, I'm getting the following Compiler error:\r\n\r\n```\r\nAssets\\HoloToolkit\\Input\\Scripts\\Utilities\\Extensions\\InteractionSourceExtensions.cs(103,39): error CS1929: 'SpatialInteractionController' does not contain a definition for 'TryGetRenderableModelAsync' and the best extension method overload 'InteractionSourceExtensions.TryGetRenderableModelAsync(InteractionSource)' requires a receiver of type 'InteractionSource'\r\n```",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/1216/comments",
    "author": "maxklock",
    "comments": [
      {
        "user": "StephenHodgson",
        "created_at": "2017-10-20T17:16:21Z",
        "body": "Sounds like you're targeting the wrong API target."
      },
      {
        "user": "StephenHodgson",
        "created_at": "2017-10-20T17:16:48Z",
        "body": "See #1184"
      }
    ]
  },
  {
    "number": 1214,
    "title": "What MRTK + Unity version for stable sharing?",
    "created_at": "2017-10-20T14:40:29Z",
    "closed_at": "2017-10-28T01:57:34Z",
    "labels": [
      "Question"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/1214",
    "body": "Hey Devs, \r\nI'm trying to build a sharing experience for the HoloLens but it seems that everything newer than Unity2017.1 seems to be very buggy and crashes the editor when pressing play.\r\n \r\nHowever the UNET sharing seems to only work for Unity2017.2 and above.\r\n\r\nSo what would be the ideal MRTK + Unity version to get a stable sharing to work \r\n(Preferably with UNET since then you don't need a pc running as server)\r\n\r\nThanks alot",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/1214/comments",
    "author": "DineshPunni",
    "comments": [
      {
        "user": "StephenHodgson",
        "created_at": "2017-10-20T17:10:08Z",
        "body": "The UNET example probably needs some work, and getting it cleaned up.\r\nCurrently it has a lot of example code/assets that aren't really suitable for extending.\r\n\r\nYou could read through it and make your own implementation.\r\n\r\nI've got a friend who's been using 2017.1 and UNET for their project and it's just fine."
      },
      {
        "user": "DineshPunni",
        "created_at": "2017-10-21T16:00:29Z",
        "body": "@StephenHodgson thanks for the quick answer.\r\nI got it working using Unity2017.1.0p5 and the MRTK release from september. \r\n\r\nNow the next challenge is to get it run smoothly and with custom prefabs. \r\n\r\nCould you help me on what i have to do to send custom synced commands? \r\nI have a Menu which is based on a finite state machine. I want to change states of the menu on one Hololense while the other Hololense is connected to it and also applies those changes.\r\n\r\nWould it be enough to add a Network ID component on the menu and then use the [Command] keyword when switching states?"
      },
      {
        "user": "StephenHodgson",
        "created_at": "2017-10-21T17:54:45Z",
        "body": "I just did a livestream this morning on the topic, but I was covering the Sharing Service first.  I might get into UNet a bit more later."
      },
      {
        "user": "DineshPunni",
        "created_at": "2017-10-22T00:22:41Z",
        "body": "Wooow amazing! Do you have a link of the record for it? \r\nWould be awesome"
      },
      {
        "user": "StephenHodgson",
        "created_at": "2017-10-28T01:57:34Z",
        "body": "Indeed I did.  Search on YouTube"
      }
    ]
  },
  {
    "number": 1210,
    "title": "Hololens with Unity 2017.2.0f3 not working?",
    "created_at": "2017-10-20T10:37:05Z",
    "closed_at": "2018-02-14T22:43:20Z",
    "labels": [
      "Question",
      "Platform - HoloLens - First Gen"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/1210",
    "body": "Hello!\r\n\r\nThere is a mention in the front page of this repository that:\r\n\r\n\"Currently we are waiting on a fix for HoloLens development from Unity, for how you should use the following versions of Unity and the \"Release\" version of the MRTK Asset: ...\"\r\n\r\nAlso, issue #1184 says that one should stick with 2017.1.x. So, I presume one should not use 2017.2.0 with Hololens but wait for fixes? \r\n\r\nIf I try to use the Holographic Emulation in Unity, it freezes the whole editor. I am able to deploy and run examples from the example package, but I do get these:\r\n\r\n> Run-Time Check Failure #0 - The value of ESP was not properly saved across a function call.  This is usually a result of calling a function declared with one calling convention with a function pointer declared with a different calling convention.\r\n\r\n... also, trying to run my own application that uses the VRTK - Unity package, I fall short when the SDK Manager from that package informs me this:\r\n\r\n> Ignoring SDK Setup 'HoloLens' because the following VR device names are missing from the PlayerSettings:\r\n> HoloLens\r\n\r\nI guess these are issue that hopefully Unity fixes in near future?\r\n\r\nbests,\r\nMarkus\r\n",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/1210/comments",
    "author": "markus-at-fake",
    "comments": [
      {
        "user": "samharper94",
        "created_at": "2017-10-20T11:11:25Z",
        "body": "For me, it works in 2017.2.0f3 MRTP (no Vuforia) but there are a lot of issues. I also get the freeze if I use holographic emulation, but I also get a freeze if I just use the play mode at all. Seemingly this is an issue with the Fall Creator's Update and Unity though.\r\n\r\nMain issue I seem to be getting in 2017.2.0f3 MRTP is the hand draggable script doesn't move any objects (tap to place does) and the tracking is very poor when the frame rate dips.\r\n\r\nSee #1184 for more info!"
      },
      {
        "user": "kloskow",
        "created_at": "2017-10-29T20:09:21Z",
        "body": "I am having very hard times making ar markers work on new Vuforia and Unity integrated release. Documentations also seems to be out dated on Vuforia's page. Any ideas how to link HoloLens Camera with AR camera?"
      },
      {
        "user": "jasonhbartlett",
        "created_at": "2017-11-15T18:05:15Z",
        "body": "Any update on this?  I wanted to try and build a Hololens app with MRTK and Vuforia and I'm not sure which versions of each I should be using.  As Vuforia is now integrated into Unity 2017.2, but 2017.2 is a no-go for Hololens dev's, what is the best path?"
      },
      {
        "user": "StephenHodgson",
        "created_at": "2017-11-15T18:11:33Z",
        "body": "See #1335"
      },
      {
        "user": "kloskow",
        "created_at": "2017-11-15T18:19:31Z",
        "body": "so far I was told by Vuforia support that there is no link between HololensCamera and ARCamera from Vuforia package. Basically, the ARCamera prefab from Vuforia does the entire job. So far, I have not managed to get the holograms working with suggested by their supports settings. Holograms appear once every so often and seem to have very incorrect tracking. ARToolkit has also comes with an image recognition function so I believe I might give it a go as of now. "
      },
      {
        "user": "NeerajW",
        "created_at": "2018-02-14T22:43:20Z",
        "body": "Please reopen if your question was not answered."
      }
    ]
  },
  {
    "number": 1170,
    "title": "Notified when a specific SyncPrimitive changes",
    "created_at": "2017-10-16T15:27:37Z",
    "closed_at": "2019-04-11T20:27:37Z",
    "labels": [
      "Question",
      "Sharing / Networking"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/1170",
    "body": "I am trying to understand how to setup sharing, while setting up an exploratory test I was wondering something.  From what I can tell, if a SyncPrimitive child changes in a SyncObejct, the ObjectChanged flag will be fired.  But does that ObjectChanged flag tell you which particular SyncPrimitive Child changed? Or does it just say, \"hey, there was a change in the children\"?  Which is the way I think it works.  Is that correct?\r\n\r\nSo based on above, if I want to be notified of which particular SyncPrimitive Changed, I wrap SyncBool in a SyncObject wrapper.  Like this: \r\n```\r\n[SyncDataClass]\r\npublic class SyncNotifyingBool : SyncObject\r\n{\r\n    [SyncData] public SyncBool IsActive;\r\n}\r\n```\r\nNow I can be notified when individual SyncPrimitives Change in my SyncObejct class like:\r\n```\r\n[SyncDataClass]\r\npublic class SyncSpawnedTestContainer : SyncSpawnedObject\r\n{\r\n    [SyncData] public SyncNotifyingBool IsAActive;\r\n\r\n    [SyncData] public SyncNotifyingBool IsBActive;\r\n```\r\n\r\nIs that generally the right idea overall?",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/1170/comments",
    "author": "kyleWillson",
    "comments": [
      {
        "user": "Ristophonics",
        "created_at": "2018-02-07T21:38:53Z",
        "body": "Okay solved this issue by altering SyncSpawnedObject to inlcude a Syncbool.\r\n\r\n    /// <summary>\r\n    /// A SpawnedObject contains all the information needed for another device to spawn an object in the same location\r\n    /// as where it was originally created on this device.\r\n    /// </summary>\r\n    [SyncDataClass]\r\n    public class SyncSpawnedObject : SyncObject\r\n    {\r\n        [SyncData] public SyncTransform Transform;\r\n\r\n        [SyncData] public SyncString Name;\r\n\r\n        [SyncData] public SyncString ParentPath;\r\n\r\n        [SyncData] public SyncString ObjectPath;\r\n\r\n        [SyncData] public SyncBool NetworkBoolean00; // new SyncBool\r\n\r\n\r\n This Syncbool (the datamodel) is then initialized before instantiation in the PrefabSpawnmanager like so:\r\n\r\n             // Add the data model object to the networked array, for networking and history purposes\r\n            dataModel.Initialize(instanceName, parent.transform.GetFullPath(\"/\"));\r\n            dataModel.Transform.Position.Value = localPosition;\r\n            dataModel.Transform.Rotation.Value = localRotation;\r\n            dataModel.NetworkBoolean00.Value = false; // the new bool on SyncSpawnedObject\r\n\r\nand at the same time the TransformSynchronizer is being added I also find my script on my prefab called BoolSynchronizer using the GetComponentInChildren AND set its boolDataModel to the same we created earlier on Spawn\r\n\r\n            // Setup the transform synchronization\r\n            TransformSynchronizer transformSynchronizer = instance.EnsureComponent<TransformSynchronizer>();\r\n            transformSynchronizer.TransformDataModel = dataModel.Transform;\r\n            BoolSynchronizer boolSynchronizer = instance.GetComponentInChildren<BoolSynchronizer>();\r\n            if(boolSynchronizer != null)\r\n            {\r\n                boolSynchronizer.boolDataModel = dataModel.NetworkBoolean00;\r\n            }\r\n\r\n\r\nThis is 90% the way there. The last 10% is writing your own BoolSynchronizer to do what you want with it and what happens when the variable changes. Took a few days of reading over the code again and again. \r\n"
      },
      {
        "user": "Firifire",
        "created_at": "2018-04-23T14:23:33Z",
        "body": "@Ristophonics Could you share your BoolSynchronizer. Having trouble implementing it like the way transformSynchronizer works."
      },
      {
        "user": "Ristophonics",
        "created_at": "2018-04-24T04:08:50Z",
        "body": "@Firifire here is the most stripped down version. Please post any improvement. Regards\r\n\r\n```\r\nnamespace HoloToolkit.Sharing\r\n{\r\n\r\n    public class BoolSynchronizer : MonoBehaviour\r\n    {\r\n        [SerializeField] public bool _thisToggle00;\r\n        [SerializeField] public GameObject _GameobjectToToggle00;\r\n\r\n        public SyncBool boolDataModel00;\r\n\r\n        private void Start()\r\n        {\r\n            _thisToggle00 = false;\r\n        }\r\n\r\n        public void ToggleOffSwitch00()\r\n        {\r\n            if (_thisToggle00 == true)\r\n            {\r\n                Debug.Log(\"Toggling OFF\");\r\n                _thisToggle00 = false;\r\n                boolDataModel00.Value = _thisToggle00;\r\n                Debug.Log(\"Syncbool Value is NOW\" + boolDataModel00.Value.ToString());\r\n            }\r\n        }\r\n\r\n        public void ToggleOnSwitch00()\r\n        {\r\n            if (_thisToggle00 == false)\r\n            {\r\n                Debug.Log(\"Toggling ON\");\r\n                _thisToggle00 = true;\r\n                boolDataModel00.Value = _thisToggle00;\r\n                Debug.Log(\"Syncbool Value is NOW\" + boolDataModel00.Value.ToString());\r\n            }\r\n        }\r\n\r\n        private void CheckBoolStatus()\r\n        {\r\n            if (_thisToggle00 != boolDataModel00.Value)\r\n            {\r\n                _thisToggle00 = boolDataModel00.Value;\r\n            }\r\n        }\r\n\r\n        private void FixedUpdate()\r\n        {\r\n            if (_thisToggle00)\r\n            {\r\n                _GameobjectToToggle00.SetActive(true);\r\n            }\r\n            if (!_thisToggle00)\r\n            {\r\n                _GameobjectToToggle00.SetActive(false);\r\n            }\r\n            CheckBoolStatus();\r\n        }\r\n    }\r\n}\r\n```"
      },
      {
        "user": "Firifire",
        "created_at": "2018-04-25T11:58:44Z",
        "body": "@Ristophonics Thanks. Seems like ObjectChanged was not working for me. \r\n\r\nWell, with your help. I am currently progressing like this.\r\n\r\nI have altered SyncSpawnedObject to include two additional function\r\n\r\n```\r\n ...      \r\n        public virtual void SecondaryInitilize() //To initialize variables\r\n        {\r\n\r\n        }\r\n\r\n        public virtual void AttachSync(GameObject instance) //To attach Synchronizer\r\n        {\r\n\r\n        }\r\n```\r\n\r\nThen in PrefabSpawnManager I add two lines \r\n\r\n```\r\n...\r\n            dataModel.Initialize(instanceName, parent.transform.GetFullPath(\"/\"));\r\n            dataModel.Transform.Position.Value = localPosition;\r\n            dataModel.Transform.Rotation.Value = localRotation;\r\n            dataModel.SecondaryInitilize(); //Initialize Variables\r\n\r\n...\r\n            // Setup the transform synchronization\r\n            TransformSynchronizer transformSynchronizer = instance.EnsureComponent<TransformSynchronizer>();\r\n            transformSynchronizer.TransformDataModel = dataModel.Transform;\r\n            dataModel.AttachSync(instance); //Attach Sync\r\n\r\n```\r\n\r\ninstead of adding variables to SyncSpawnedObject. I create another SyncDataClass inheriting SyncSpawnedObject, and overriding the functions\r\n\r\n```\r\n/// <summary>\r\n/// A SpawnedObject contains all the information needed for another device to spawn an object in the same location\r\n/// as where it was originally created on this device.\r\n/// </summary>\r\n[SyncDataClass]\r\npublic class SyncToggle: SyncSpawnedObject \r\n{\r\n    [SyncData] public SyncBool NetworkBoolean00; // new SyncBool`\r\n\r\n    public override void SecondaryInitilize(GameObject instance)\r\n    {\r\n        NetworkBoolean00 = false;\r\n    }\r\n    public override void AttachSync(GameObject instance)\r\n    {\r\n        BoolSynchronizer boolSynchronizer = instance.EnsureComponent<BoolSynchronizer >();\r\n        boolSynchronizer.boolDataModel = NetworkBoolean00;\r\n    }\r\n\r\n```"
      },
      {
        "user": "wiwei",
        "created_at": "2019-04-11T20:27:36Z",
        "body": "Closing issues older than 180 days. If this is still an issue, please reactivate with recent information."
      }
    ]
  },
  {
    "number": 1125,
    "title": "What are \"rooms\"?",
    "created_at": "2017-10-11T21:45:41Z",
    "closed_at": "2019-04-11T20:27:40Z",
    "labels": [
      "Question",
      "Sharing / Networking"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/1125",
    "body": "Hey guys, another terminology question. :)\r\n\r\nWhat is a \"room\"? I understand the concept of a \"session\" as essentially a collection of users who are communicating over a shared network. However, it looks like there is sometimes this thing called a \"room\" which is in a session. What is the purpose of a \"room\" that a \"session\" cannot accomplish? I don't see much documentation about \"rooms\" here on Github.\r\n\r\nAt this point, my best guess is that a session is terminologically equivalent to a \"lobby\" where everyone is on the same network, then a room would be a filter where you only get messages from people in the same room as you even though, technically, you may be connected to everyone in the session?\r\n\r\nThanks again,\r\n\r\nEric",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/1125/comments",
    "author": "motionsmith",
    "comments": [
      {
        "user": "wiwei",
        "created_at": "2019-04-11T20:27:40Z",
        "body": "Closing issues older than 180 days. If this is still an issue, please reactivate with recent information."
      }
    ]
  },
  {
    "number": 1124,
    "title": "What is the point of sharing anchors?",
    "created_at": "2017-10-11T21:37:37Z",
    "closed_at": "2018-02-14T22:38:16Z",
    "labels": [
      "Question",
      "Platform - HoloLens - First Gen"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/1124",
    "body": "Hey guys,\r\n\r\nThere is so much great stuff here. We're doing some experiments with your Sharing namespace. I have a few architectural and/or philosophical questions to make sure that I'm not missing something.\r\n\r\nWe deployed SharingTest.unity which effectively syncs users' camera transforms. The head transforms are relative to a sphere hologram, which either IS or IS CONTAINED BY an \"anchor\".\r\n\r\nI'm trying to understand what the point of \"sharing\" anchors (AKA uploading/downloading anchors) is. I understand what anchors are in HL's device coordinate system. However, in SharingTest, there is no shared coordinate system data, so each device's spheres are in different places. Likewise, when I move my sphere, that sphere doesn't move on the other clients' devices.\r\n\r\nIf two people are in the same room, a fiducial marker would effectively align the devices' coordinate systems by allowing the clients to adjust their holograms relative to the markers. I thought anchors would have something to do with that, but I don't see anything like that occuring in this demo.\r\n\r\nThanks, I'm sure I'm missing something.\r\n\r\nEric",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/1124/comments",
    "author": "motionsmith",
    "comments": [
      {
        "user": "NeerajW",
        "created_at": "2018-02-14T22:38:16Z",
        "body": "The point of sharing an anchor is to that HoloLens1 shared their reference point coordinate with HoloLens2 can then localize to the same coordinate system. They have to be the same visual tracking points and physical space. You will have to write extra code to broadcast the location of the shared holograms when it's moving. You cannot move an object which has an anchor attached to it. You can move a hologram which is a child of an anchor.\r\n\r\nPlease reopen if your question was not answered."
      }
    ]
  },
  {
    "number": 1042,
    "title": "Bug when trying to connect HoloLens together",
    "created_at": "2017-09-29T19:38:56Z",
    "closed_at": "2017-10-28T01:51:34Z",
    "labels": [
      "Question",
      "Platform - HoloLens - First Gen"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/1042",
    "body": "I'm not sure if that happens to anyone else but, when I start my application and I am trying to anchor or import an anchor, the process will get hung up and never finish. The problem does not go away with a simple restart of the application. It forces me to basically restart my  HoloLens almost every time I go to test it out.\r\n\r\nFor example, I've noticed it happens more often than not when during one iteration HoloLens1 is the host and HoloLens2 is the client. However, if I make changes and re-deploy except I make HoloLens2 host about 90% of the time I am forced to restart HoloLens2 and sometimes even HoloLens1.",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/1042/comments",
    "author": "dtb49",
    "comments": [
      {
        "user": "StephenHodgson",
        "created_at": "2017-09-29T22:42:25Z",
        "body": "On the sharing stage, could you enable detailed logging, run it again, and share the output with us?"
      }
    ]
  },
  {
    "number": 1040,
    "title": "Stuck between master and RC Beta branch",
    "created_at": "2017-09-28T14:56:38Z",
    "closed_at": "2017-10-05T09:47:53Z",
    "labels": [
      "Question"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/1040",
    "body": "Hi, \r\n\r\nI'm completely clueless on how to find a way to get to work with the MRTK and Hololens.\r\nI finally got to work my dev env ( meaning VS17 or Unity + MRTK managin both to deploy and build the app).  \r\nBUT ! When I use the master branch with Unity 2017.1.1.f1 I'm stuck with\r\n ```Error! RenderTexture.GenerateMips failed: render texture does not have mip maps (set useMipMap to true).```\r\n that's freaking annoying because it floods my console a lot and could even lower performances.\r\n\r\nOn the other hand, with Unity 2017.2.0f1 (RC) and beta branch, I'm being told my target device ( Hololens isn't up to date) ` DEP3321: To deploy this application, your deployment target should be running Windows Universal Runtime version 10.0.16288.0 or higher. You currently are running version 10.0.14393.1715. Please update your OS, or change your deployment target to a device with the appropriate version.\tGTS_Demo`\r\nI'm already running Insider on it and it's up to date :(\r\n(Latest SDK and insider update installed on the dev computer)\r\n\r\n\r\nAnd finally, master branch MRTK with a beta Unity doesn't work, as I understand API changed a lot.\r\n\r\nI know this is not bug related but I'm starting to loose hope on finding a stable dev environment...  Plus Unity forums and  Microsoft Hololens forums never have shown very helpful\r\n\r\nThanks a lot in advance !",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/1040/comments",
    "author": "drenghel",
    "comments": [
      {
        "user": "jessemcculloch",
        "created_at": "2017-09-28T15:06:40Z",
        "body": "Hey Andre,\r\n\r\nThe generate mipmaps error is benign, you can ignore it, although like you mentioned, it fills the logs and is annoying.\r\n\r\nThe issue you are running into with 2017.2 is a pretty easy fix.  On the unity build settings window, you probably have the build target set to \"latest installed\" where as HoloLens is at version 15063. If you set that to match, it should solve that problem."
      },
      {
        "user": "drenghel",
        "created_at": "2017-09-28T15:46:00Z",
        "body": "Holy cow, it's finally working ! thanks a lot @jessemcculloch ! \r\nI'm a bit confused, isn't the latest SDK (16 something) needed to run the beta MRTK ?  "
      },
      {
        "user": "jessemcculloch",
        "created_at": "2017-09-28T15:59:51Z",
        "body": "Yes and no. It needs to be installed for some of the API's for the Immersive Headsets and Motion Controllers to compile. But the OS on the HoloLens itself is only at 15063."
      },
      {
        "user": "drenghel",
        "created_at": "2017-09-28T16:06:56Z",
        "body": "Noted !\r\nBut as I expected something else doesn't work.\r\nI'm attempting to build&run the SpatialUnderstanding scene. But it crashed my Unity or throws an exception in VS or crashes on Hololens. Is it an known issue ? I can't get to work any spatial visualization since this morning ^^\""
      },
      {
        "user": "jessemcculloch",
        "created_at": "2017-09-28T18:12:59Z",
        "body": "Did you grab the pre-release of Dev_Unity_2017.2 from the releases page, or did you just download the raw code from the branch this morning?"
      },
      {
        "user": "drenghel",
        "created_at": "2017-09-29T12:40:07Z",
        "body": "My bad, forgot to answer.\r\nYup I did :)\r\nAnd there is more I never managed to get to work SpatialMapping from MRTK, even in the 'old' version.\r\nI check `drawVisualMeshes` but never show a thing ( So I used the Unity vanilla component )"
      }
    ]
  },
  {
    "number": 1025,
    "title": "Ability to have camera pass-through for Mixed Reality glasses ",
    "created_at": "2017-09-27T00:03:11Z",
    "closed_at": "2017-10-28T01:44:52Z",
    "labels": [
      "Question"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/1025",
    "body": "I've been plugging away on my AR app for a while, was getting close to done, but now I'm worried about compatibility with all the \"Mixed Reality\" devices coming next month.  I've been designing with the Hololens in mind, and being able to see your room and real surfaces and mapping on top rather than a VR house, but the more I look into the Mixed Reality Portal, it seems like our Unity apps will run in the Lake House environment rather than what the camera sees in front of you.  I don't have my glasses until the 17th, but would like to know how this gets handled and can't find the info anywhere.\r\nDo we have to code something special to project the right and left cameras as the video background for the two eyes and align it up to the spatial mapped surfaces in real world, or is that automatic to simulate how a Hololens works?  My app would not be the same in a psudo MR world without the Augmented part of it.\r\nI found that Vuforia supports the camera projection to left and right eye with some setup, but would rather not have to go that route if I can do it with the MixedRealityToolkit, or if there's something that I'm missing.. I prefer the Hololens way of AR much better, but I know that the majority of users will be on the cheaper consumer devices, so we gotta make it work.  Thanks..",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/1025/comments",
    "author": "Skquark",
    "comments": [
      {
        "user": "kewlniss",
        "created_at": "2017-09-27T00:40:16Z",
        "body": "@Skquark Unfortunately there is confusion with the terminology of Mixed Reality and how the immersive headsets compare to the HoloLens. These new $300 headsets are basically VR headsets. There is no passthrough capability. The cameras on the front are depth sensors like the HoloLens (so you don't run into a wall), but you won't be able to see through. Experiences on these devices are totally virtual. The Mixed Reality terminology refers to the \"spectrum\" of realities from physical to purely virtual and everything in between. Microsoft is set on using this term. While it is accurate, there are too many expectations that these cheaper headsets have similar functionality to the $3,000 HoloLens and that just is not the case. They share the sensor technology, much like the kinect, but the immersive headsets do not have AR capabilities."
      },
      {
        "user": "Skquark",
        "created_at": "2017-09-27T01:23:04Z",
        "body": "Damn, that's what I was afraid of... So to make our Hololens applications function on the Mixed Reality headsets, we would have to emulate a fake room like in the editor's SpatialMapping component's Room Model, and we build a 3D set to match the room mesh surfaces?  Or are we limited to only use Microsoft's Lake House in the portal to place our objects into?  Trying to figure out how to adapt to this in-between fake AR and still provide a functional experience.. When I first saw the headsets I was all excited thinking they would give a similar experience to the Hololens by faking the real world in the black transparency with the camera view aligned, and I hope we'll have a workaround in the near future.\r\n\r\nSo what parts of the Toolkit won't work with the consumer headsets?  Can we still use the SpatialProcessing to create surfaces from scanned or fake mesh?  Are the Anchor Manager locations based on physical points or virtual points?  Are we forced to use the Boundaries to fence our workspace in VR?  Will there be a way to port our MRTK development project to Tango or Apple ARKit since those are made for real-world augmentation with the camera?  Sorry for all the questions, but I haven't found these dev issues covered clearly anywhere.. Just when I thought I was in the home stretch for releasing my app, I gotta worry about being compatible with every other device since most people are not going to invest $3000 vs ~$300, and I would hate to see all the hard work I've put in only work for the rich....."
      },
      {
        "user": "StephenHodgson",
        "created_at": "2017-09-27T03:07:59Z",
        "body": "> it seems like our Unity apps will run in the Lake House environment rather than what the camera sees in front of you.\r\n\r\nThis is not true.  The HoloLens workflow and experiences are not changing.  We're just adding the VR headset support to the toolkit.  You shouldn't see much of a change as far as the look and feel of HoloLens apps (at least that's the goal)."
      },
      {
        "user": "Skquark",
        "created_at": "2017-09-27T09:05:57Z",
        "body": "That's reassuring to hear, glad the VR headset features will be integrating soon.. What should I be planning for to adapt my app (which relies on the generated surface planes) to work best on the Mixed Reality headsets? When the VR support is implemented, will we still be scanning the room and generating the world mesh with access to the cameras that we can project in the background view? Or do we skip the spatial scanning and load up a decorated room or house environment with the Surface Planes set static?\r\nJust trying to get a jump on the workflow since millions of people are about to have a new toy in their hands in a few weeks, and we're all trying to give them something tangible to play with..  Can't wait to see everyone else's projects here out in the wild when the time comes, a new paradigm is being born..,"
      },
      {
        "user": "scottcher",
        "created_at": "2017-10-24T18:54:19Z",
        "body": "Didn't Microsoft just announce an in-library method for determining the hardware capabilities to allow developers to understand what type of platform they are running on?  Immersive or see-through?"
      },
      {
        "user": "StephenHodgson",
        "created_at": "2017-10-24T18:58:21Z",
        "body": "Unity did.\r\n\r\n```\r\nHolographicSettings.isOpaque\r\n```"
      }
    ]
  },
  {
    "number": 1002,
    "title": "Voice chat not working",
    "created_at": "2017-09-21T17:05:01Z",
    "closed_at": "2019-04-11T20:27:46Z",
    "labels": [
      "Question",
      "Sharing / Networking"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/1002",
    "body": "i added the both script to the main camera and when joined to session and i was able to hear only my voice not the voice of other user that running the app in unity",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/1002/comments",
    "author": "meah",
    "comments": [
      {
        "user": "edwinckc",
        "created_at": "2017-09-21T20:24:53Z",
        "body": "Not sure this is the same problem you're having, but hope it helps.\r\n\r\nI originally tried placing both MicrophoneTransmitter and MicrophoneReceiver on the camera directly, but I got a warning and kept hearing my own echo in voice chat. \r\n\r\n```\r\nGameObject has both an AudioSource and an AudioListener attached. While built-in filters like lowpass are instantiated separately, the custom script DSP filter components may only be used by either the AudioSource or AudioListener at a time. In this case it was attached to the AudioListener first, so it remains connected to this.\r\n```\r\n\r\nCreating two empty game objects under the camera, and then adding the trasmitter and receiver scripts to each one respectively, fixed the problem for me. It's not a live stream though, so on a local network I get 0.5s lag and over Azure it's up to 10s lag."
      },
      {
        "user": "wiwei",
        "created_at": "2019-04-11T20:27:46Z",
        "body": "Closing issues older than 180 days. If this is still an issue, please reactivate with recent information."
      }
    ]
  },
  {
    "number": 992,
    "title": "Occulsion shader doesn't compile in 2017.1.1p2",
    "created_at": "2017-09-19T04:22:06Z",
    "closed_at": "2018-05-21T22:19:59Z",
    "labels": [
      "Question",
      "No Repro",
      "Shaders / Materials"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/992",
    "body": "Anyone notice that the Occlusion shader won't compile in 2017.1.p2? Maybe something went awry when I upgraded my project but I had to revert to 2017.1f1 to get it back to normal. After the upgraded it said the current CPU was not supported by this shader. I think it also wouldn't draw the wireframe shader--although that doesn't seem to throw any errors.\r\n\r\nHad the same problem with a few shaders in the MRDesignLabs package.",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/992/comments",
    "author": "flarb",
    "comments": [
      {
        "user": "StephenHodgson",
        "created_at": "2017-10-28T01:43:08Z",
        "body": "I hadn't seen this issue at all. Try right clicking on the shaders that are giving you problems and reimport them to see if it solves the issue."
      }
    ]
  },
  {
    "number": 984,
    "title": "How to save spatial understanding results ?",
    "created_at": "2017-09-17T17:26:24Z",
    "closed_at": "2019-04-11T20:27:48Z",
    "labels": [
      "Question",
      "Platform - HoloLens - First Gen"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/984",
    "body": "After scanning the room and trying to \"understand\" it, is there a way to save the result of all this \"understanding\" process (on the device,locally) in order to avoid rescanning/understanding again at each launch ?",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/984/comments",
    "author": "Emerson92",
    "comments": [
      {
        "user": "Weasy666",
        "created_at": "2017-12-18T19:26:41Z",
        "body": "I'm also interested in this.\r\nIt should be possible, if i'm not wrong Asobo is doing something like this in Fragments.\r\nIf my memory is correct, they are even warning the user when the differences between saved and current room are to big."
      },
      {
        "user": "DamienYannSerres",
        "created_at": "2018-01-11T08:36:02Z",
        "body": "Maybe #188 could help. There's code in it to that end. I couldn't get it to work but who knows.\r\nOn the other hand there is a SaveSpatialMeshes in SpatialUnderstandingCustomMesh hinting that we can save this mesh. But I can't find how to load it.\r\n\r\n**EDIT : After further investigation, it seems the SaveSpatialMeshes in SpatialUnderstandingCustomMesh is the same one as in the FileSurfacObserver. They both comes from \"inheritance\" (I don't know if it's the right term in C#) of MeshSaver. I think it just saves the MappingMesh and you have to do Understanding treatment again. But I am pretty new to this world, I may have missed some informations."
      },
      {
        "user": "wiwei",
        "created_at": "2019-04-11T20:27:47Z",
        "body": "Closing issues older than 180 days. If this is still an issue, please reactivate with recent information."
      }
    ]
  },
  {
    "number": 939,
    "title": "Sharing Service schema Backwards Compatibility.",
    "created_at": "2017-09-07T04:11:45Z",
    "closed_at": "2017-10-28T01:34:21Z",
    "labels": [
      "Question"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/939",
    "body": "HI, I have a problem with sharing service. I developed few hololens apps using HTK V 1.5.6. For all those apps I used sharing service executable file provided in HTK 1.5.6 with schema 15 hosted on a public IP.\r\n\r\nRecently I developed 2 hololens apps with VOIP features using HTK V 1.5.8. In order to make this app work, I updated my sharing server with the new version available in 1.5.8 with schema 17. After that all my old apps using sharing service stop working.\r\nWith out migrating my previous apps, how can I make the sharing server to understand schema 17 and previous schema 15.\r\n\r\nThank you in advance",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/939/comments",
    "author": "RaoAM",
    "comments": [
      {
        "user": "StephenHodgson",
        "created_at": "2017-09-07T04:14:17Z",
        "body": "I don't think backwards compatibility is not currently implemented in the sharing service.  My only suggestion is to have two servers, or to upgrade your old projects.  (Unsure about what's entailed in this, sorry)"
      },
      {
        "user": "StephenHodgson",
        "created_at": "2017-10-28T01:34:21Z",
        "body": "Going to close this.  It's probably been archived by google by now."
      }
    ]
  },
  {
    "number": 923,
    "title": "How to avoid double handling in the inputManager",
    "created_at": "2017-09-01T23:52:31Z",
    "closed_at": "2017-10-18T19:13:41Z",
    "labels": [
      "Question"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/923",
    "body": "I am developing a HoloLens project that has the following feature: User can use the voice command to instruct a game Object to do several things. For example, if the user says \"Give me a candy\", the game object will generate a candy and the total number of candies will increment by one. \r\n\r\nI want to set the gameObject to be a global listener in the inputManager so that it can listen to the user's command without requiring user to look at it. But in the real implementation, it comes a problem. When user is indeed looking at it and saying \"Give me a candy\", the game object will actually generate two candies: one is handled as global listener, one is handled as the focused gameobject. \r\n\r\nI want to prevent this scenario happening, which means when game object should be able to filter out either the global listener command or the focused gameobject command. One way I can think of right now is to unregister the game object away from the global listener queue when it becomes the focused game object and register it back when it becomes not focused game object.  But I am suspicious about the performance. Actively register/unregister a gameobject (sounds) a lot of overhead. But I am not familiar with the architecture behind it, so can anyone help me better evaluate this solution?\r\n\r\nOr is there any other ways that are more efficient to handle this double handling problem? \r\n\r\nThanks in advance\r\n\r\nDK ",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/923/comments",
    "author": "DKandrew",
    "comments": [
      {
        "user": "DKandrew",
        "created_at": "2017-09-04T22:46:53Z",
        "body": "I just tried to implement the solution I mentioned above: Inherit the IFocusable class, implement \r\n```\r\nOnFocusEnter(){\r\n  RemoveGlobalListener();\r\n}\r\nOnFocusExit(){\r\n  AddGlobalListener();\r\n}\r\n```\r\nThe result is that, the game object cannot recognize my voice when it is the FocusedObject, but can recognize my voice when it is not the FocusedObject. **This result means the ISpeechHandler can only send keyword event to global listeners. If you are not global listener, you cannot receive the event even though you are FocusedObject.**\r\n\r\nReverting back to the initial version, (the one without IFocusable), things happen: the double handling issue disappears! But I don't think the problem is solved, let me explain:\r\nRight now, the set up of my project is: it has two game objects, both of them are registered as global listeners. A is the candy generator game object we were talking about. B is another game object which does completely different things than A. \r\nI observe that even though A only catch up the voice command once at a time (which is what we want!), but B will catch up the voice command twice even though I deliberately put my gaze away from B. \r\nThis result shows that: **I have one global listener handle the keyword only once at a time but another global listener handle the keyword twich at a time.** So there is a discrepancy in global listeners. \r\n\r\nThis makes me start to suspect the implementation inside the InputManager. I am happy that A only handle the event once now, but I just feel like getting lucky.  I wonder if someone can tell me whether my observations from the previous experiments are right or wrong. \r\n\r\n"
      },
      {
        "user": "StephenHodgson",
        "created_at": "2017-09-04T23:03:50Z",
        "body": "@DKandrew do you have an example scene you can share with us?\r\n\r\nJust make a fork of this repo and branch it with an added example scene."
      },
      {
        "user": "DKandrew",
        "created_at": "2017-09-05T04:21:58Z",
        "body": "Oops. I made a mistake. I set the B object to be OverrideFocusedObject in the InputManager. This can explain my two observations.\r\n1, When A is unregistered from the Global Listener (GL), the FocusedObject will become B (since it is overridden) Therefore, the speech event cannot send to A.\r\n2, Because B is always the FocusedObject, it will handle the input event twice. One as GL, and the other as FocusedObject. Since A is the GL and could never be the FocusedObject, it will receive the event only once. \r\n\r\nI run an isolated test that confirms InputManager will send the input event to two objects: GLs and Focused Object. Then I implement my initial idea about avoiding doubling event handling.\r\n```\r\nOnFocusEnter(){\r\n  RemoveGlobalListener();\r\n}\r\nOnFocusExit(){\r\n  AddGlobalListener();\r\n}\r\n```\r\nNow it works! The result is very good. I also run a memory test on my entire system and don't see any noticeable overhead which concludes that it could be a practical solution to my original question. \r\n\r\n[Leaving this post open for several days before closing it just in case if there are any further issues]"
      },
      {
        "user": "ghost",
        "created_at": "2017-09-05T06:48:34Z",
        "body": "I came across a similar problem but with the tap-gesture instead of a voice command. I used the following mechanic:\r\n\r\n```\r\nvoid OnInputClicked(InputClickedEventData eventData)\r\n{\r\n  if(eventData.Used) return;\r\n  eventData.Use();\r\n\r\n  // do stuff\r\n}\r\n```"
      },
      {
        "user": "DKandrew",
        "created_at": "2017-09-05T13:41:04Z",
        "body": "@HoloFan That is also a very interesting solution. Thank you!"
      },
      {
        "user": "StephenHodgson",
        "created_at": "2017-10-18T19:13:41Z",
        "body": "This should be fixed now with the latest input updates."
      }
    ]
  },
  {
    "number": 922,
    "title": "Using SpatialUnderstanding Saved Mesh in Unity Editor",
    "created_at": "2017-09-01T20:08:15Z",
    "closed_at": "2019-04-11T20:27:58Z",
    "labels": [
      "Question",
      "Platform - HoloLens - First Gen"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/922",
    "body": "Using the SaveSpatialUnderstanding scene from the SavingSpatialMeshes example, I have saved a nice mesh of my environment. After converting the room to a .obj, In the SpatialUnderstandingExample scene, I have set the Room Model to use this mesh.\r\nWhen I run the example in the editor, it loads the mesh (white color to represent SpatialMapping) but it doesn't properly scan and process the space.  I only see the green mesh sporadically spaced out. I don't think this is expected behaviour.\r\n\r\nBetter yet, is it possible to use this saved Mesh and have the scanned state = Done? This would really speed up development because we can test in the editor, as opposed to continuously deploying to a HoloLens or the emulator.",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/922/comments",
    "author": "dannycarrera",
    "comments": [
      {
        "user": "wiwei",
        "created_at": "2019-04-11T20:27:57Z",
        "body": "Closing issues older than 180 days. If this is still an issue, please reactivate with recent information."
      }
    ]
  },
  {
    "number": 914,
    "title": "Tap to Place Sharing",
    "created_at": "2017-08-31T09:07:18Z",
    "closed_at": "2018-05-21T22:11:04Z",
    "labels": [
      "Question",
      "Sharing / Networking"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/914",
    "body": "Hello everyone:\r\nWhen work with Spectator View sample ,you suggest using Unet to share the scene. So I tried using Unet to sharing my scenes. I had tried to using the \"UNetSharedHologram.CS\" which is coming from the Spectator View sample.But there is a problem. In the server you can tap and place the model at where you want ,the client also can see where it is . On the contrary the client tap and place the model, the server has no reaction. I want using this scripts for my project, how can I deal with it ,or can you give me any more sample to study how to share my scenes with Unet?",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/914/comments",
    "author": "TinyTangS",
    "comments": [
      {
        "user": "TinyTangS",
        "created_at": "2017-08-31T09:15:57Z",
        "body": "At the same time , the sample for us to study how to make the share scene is too rare. The academy of 240   was a way to share scene how concise it is.The academy of 250 with unity 2017.2.0 Beta 2. which is without archive. How hard for me to study for it."
      },
      {
        "user": "david-c-kline",
        "created_at": "2018-05-21T22:11:04Z",
        "body": "The academy courses should be updated correctly by a newer Unity 2017 release automatically when opened."
      }
    ]
  },
  {
    "number": 913,
    "title": "Holotoolkit Remote Mapping cannot send meshes",
    "created_at": "2017-08-31T03:42:02Z",
    "closed_at": "2017-10-28T01:34:06Z",
    "labels": [
      "Question",
      "Platform - HoloLens - First Gen"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/913",
    "body": "I tried to build RemoteMapping and I can see the wireframe mesh appear in my HoloLens but can not get any meshes sent from Hololens to Unity. I wonder if there is something wrong with my server IP. Does anyone know what address should I put in Server IP? I just use the IPv4 address of wireless LAN adapter Wi-Fi. If I use the correct address, is there any other issue may cause this situation?\r\n\r\nWhat I have done:\r\n1. Build the scene as shown in test scenes.\r\n2. Enable the SpatialPerception,InternetClientServer, PrivateNetworkClientServer, and Microphone capabilities.\r\n3. Check the state of connection port is Listening.\r\n\r\nAnything missing?",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/913/comments",
    "author": "mengruoshan",
    "comments": [
      {
        "user": "angelaHillier",
        "created_at": "2017-08-31T22:00:05Z",
        "body": "It's been a while since I've tried this (I now use the Windows Device Portal for capturing meshes instead), but have you opened port 11000 in your firewall? Another common problem is when the wrong element has focus in the Editor (make sure that the 'Game view' has focus when saving.\r\n\r\nHere's the relevant excerpt from the SpatialMapping Readme:\r\nThe RemoteMapping scene uses the SpatialMapping and RemoteMapping prefabs to send spatial mapping data between the HoloLens and the app running in the Unity editor. To run this test, you must first open port 11000 on your firewall and then set the IPv4 address of your PC in the 'RemoteMeshTarget' and 'RemoteMeshSource' components. You can then build and deploy to the HoloLens. Once you see the wireframe mesh appear in your HoloLens, press the 'play' button in Unity to run the app in Editor. Ensure that the 'Game view' has focus, and then press the 'N' key (RemoteMappingKey) to switch to using the network as the spatial mapping source in the Editor. Once you are confident that you have a good mesh, say the 'Send Meshes' (SendMeshesKeyword) to send the meshes from the HoloLens to the Unity Editor. Press the 'S' key (SaveFileKey) to save the mesh to your PC. Press the 'play' button to stop the app from running in the Unity editor. Now, press 'play' one more time to restart the app. This time, press the 'L' key (LoadFileKey) to load the mesh that you previously saved into the Editor."
      },
      {
        "user": "mengruoshan",
        "created_at": "2017-09-03T13:03:59Z",
        "body": "@angelaHillier \r\nI checked the state of the port 11000 is listening. Is that correct? If not, what state of the port is expected?\r\n"
      },
      {
        "user": "mengruoshan",
        "created_at": "2017-09-04T05:53:51Z",
        "body": "I opened the port on my firewall and it works. Thank you very much. @angelaHillier "
      },
      {
        "user": "StephenHodgson",
        "created_at": "2017-10-28T01:34:06Z",
        "body": "Going to close this.  It's probably been archived by google by now."
      }
    ]
  },
  {
    "number": 901,
    "title": "Cursor invisible",
    "created_at": "2017-08-29T14:04:09Z",
    "closed_at": "2018-02-14T22:35:37Z",
    "labels": [
      "Question"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/901",
    "body": "Hello when i add prefab Basic Cursor to my project its invisible for somre reason.\r\n\r\nin editor and in demos it is visible\r\n\r\ndon't see any errors in console, what can be the problem?",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/901/comments",
    "author": "friuns2",
    "comments": [
      {
        "user": "friuns2",
        "created_at": "2017-08-29T14:07:11Z",
        "body": "and  IsHandVisible is always false"
      },
      {
        "user": "StephenHodgson",
        "created_at": "2017-10-28T02:01:58Z",
        "body": "@friuns2 ever figure this out?"
      },
      {
        "user": "NeerajW",
        "created_at": "2018-02-14T22:35:37Z",
        "body": "Please reopen if your question was not answered."
      }
    ]
  },
  {
    "number": 898,
    "title": "How to launch Unity UWP app as 2D instead of Mixed Reality Portal",
    "created_at": "2017-08-28T21:08:16Z",
    "closed_at": "2017-08-28T23:58:48Z",
    "labels": [
      "Question",
      "Platform - VR"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/898",
    "body": "Anyone know how to prevent a Unity App build as a UWP from launching in the Mixed Reality Portal if running on a local machine?",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/898/comments",
    "author": "StephenHodgson",
    "comments": [
      {
        "user": "jessemcculloch",
        "created_at": "2017-08-28T22:04:56Z",
        "body": "Sorry, just re-read the title.\r\n\r\nCan you explain what you are seeing happen vs. what you want to see happen?\r\n"
      },
      {
        "user": "StephenHodgson",
        "created_at": "2017-08-28T22:21:37Z",
        "body": "I'd like to launch the UWP app as a normal application on desktop, but instead it launches the Mixed Reality Portal and then runs in the portal."
      },
      {
        "user": "jessemcculloch",
        "created_at": "2017-08-28T22:25:08Z",
        "body": "How are you launching it?  Via the start menu, or when you run it in debug mode in Visual Studio, or when you are hitting play in Unity?"
      },
      {
        "user": "StephenHodgson",
        "created_at": "2017-08-28T22:38:52Z",
        "body": "Via Start Menu."
      },
      {
        "user": "jessemcculloch",
        "created_at": "2017-08-28T22:46:17Z",
        "body": "Interesting, I have not seen this.  Let me try to replicate"
      },
      {
        "user": "StephenHodgson",
        "created_at": "2017-08-28T23:05:46Z",
        "body": "Thanks Jesse"
      },
      {
        "user": "jessemcculloch",
        "created_at": "2017-08-28T23:16:32Z",
        "body": "Hate to ask a dumb question, but you don't have Virtual Reality Enabled in the player settings, do you?"
      },
      {
        "user": "StephenHodgson",
        "created_at": "2017-08-28T23:58:47Z",
        "body": "@jessemcculloch that was the right question to be asking!  Thanks!\r\n\r\nThat was it!"
      },
      {
        "user": "jessemcculloch",
        "created_at": "2017-08-29T00:00:01Z",
        "body": "LOL, glad to help"
      }
    ]
  },
  {
    "number": 896,
    "title": "Hololens Re-scanning the environment with spatial understanding",
    "created_at": "2017-08-28T11:28:20Z",
    "closed_at": "2017-10-28T01:41:08Z",
    "labels": [
      "Question",
      "Platform - HoloLens - First Gen"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/896",
    "body": "I'm using spatial understanding to scan the environment and generate the spatial meshes. (According to the example in the HoloToolkit spatial understanding example)\r\n\r\nAfter generating the meshes initially, i want to have an option to re-scan the environment again(removing the old meshes and regenerating new meshes or updating the old meshes). Is there any possible ways where i can achieve this. Any help would be much appreciated.",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/896/comments",
    "author": "Rishanthakumar",
    "comments": [
      {
        "user": "StephenHodgson",
        "created_at": "2017-10-28T01:41:08Z",
        "body": "Duplicate of #231"
      }
    ]
  },
  {
    "number": 895,
    "title": "We should reconsider the Set Scene Settings option(s) that are in the Toolkit Menu",
    "created_at": "2017-08-27T21:18:44Z",
    "closed_at": "2017-10-03T17:46:11Z",
    "labels": [
      "Question",
      "Platform - VR"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/895",
    "body": "Those settings right now are very HoloLens centric.  Almost all the settings that are being done in that are not what is needed for Immersive Headsets.  I would like to see a discussion on how this can be better implemented for all cases, Immersive Apps, Holographic Apps, and Hybrid/Asymmetric Apps.",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/895/comments",
    "author": "jessemcculloch",
    "comments": [
      {
        "user": "StephenHodgson",
        "created_at": "2017-08-27T21:22:43Z",
        "body": "Agreed, I've already taken some steps to do this in my utilities update."
      },
      {
        "user": "jessemcculloch",
        "created_at": "2017-08-27T21:32:59Z",
        "body": "I am wondering if we start pushing people to using some of the prefabs.  A lot of this is taken care of by things like the HololensCamera, Mixed Reality Camera, and Mixed Reality Camera Parent prefabs.  Maybe a drop down that offers them which camera we put in the scene?"
      }
    ]
  },
  {
    "number": 891,
    "title": "Plane Generation",
    "created_at": "2017-08-24T21:37:55Z",
    "closed_at": "2018-05-21T22:07:46Z",
    "labels": [
      "Question",
      "Platform - HoloLens - First Gen"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/891",
    "body": "(I am sorry if this should not be posted here. I tried to find a button to add \"Question\" L abel, but was unable to find it when I create this issue)\r\n\r\nI am trying to get a surfacePlane for a wall in a room. I built my program based on the SpatialMapping/SpatialUnderstanding example from the HoloLenToolKit example. \r\n\r\nFrom my understanding, the scanning part is trying to figure our where you are in the already stored mesh in Hololens. Then, the planes are generated based on that mesh. Currently, when I face a wall and try to find a plane for that wall. It does not always give me the same plane. For the wall in front of me, there can be multiple plane generated and the result would depend on which plane is processed first. Then, I try to find the largest plane in front of me instead. However, there are planes that are similar size and the resulted plane is still inconsistent.\r\n\r\nIs there a way to make sure you always find the same plane? I am currently using remote holographic to run my program due to some constraint, I am unsure whether that is the cause of the problem.\r\n\r\nThanks in advance.",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/891/comments",
    "author": "qfliu",
    "comments": [
      {
        "user": "david-c-kline",
        "created_at": "2018-05-21T22:07:46Z",
        "body": "There is no mechanism for ensuring that a generated plane is exactly the same as an earlier one. The HoloLens is continually updating it's understanding of the world, so refinements are almost inevitable.\r\n\r\nOne thing you COULD do is to scan the room, generate planes and anchor (using WorldAnchors) them for later use."
      }
    ]
  },
  {
    "number": 850,
    "title": "How to share custom SyncObject via SharedStage?",
    "created_at": "2017-08-12T11:53:05Z",
    "closed_at": "2018-05-21T22:04:50Z",
    "labels": [
      "Question",
      "Sharing / Networking"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/850",
    "body": "Hi,\r\n\r\nI am trying to use Sharing in my project.\r\nI would like to share some data without transformation (I don't need to create it on scene in some place).\r\n\r\nNow SyncRoot contains list of SyncSpawnedObject that as far as I understand is created specially for objects that placed on the scene (it has transformation, rotatation, etc).\r\n\r\nAccording to the documentation I can create own SyncRoot implementation with another SyncArray.\r\n\r\n> By default, the SyncRoot object (which inherits from SyncObject) only contains an array of InstantiatedPrefabs, which may not be enough for your application.\r\n\r\nBut how can I use new sync model with SharedStage? I noticed that it creates SyncRoot directly in Connect method, so I can't create my own sync model.\r\n\r\n> Root = new SyncRoot(Manager.GetRootSyncObject());\r\n\r\nProbably I missed something, how can I share data via SharedStage?\r\n\r\nThanks for help. ",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/850/comments",
    "author": "GAnatoliy",
    "comments": [
      {
        "user": "robinkruyt",
        "created_at": "2018-07-18T09:41:26Z",
        "body": "I agree with @GAnatoliy. It is unclear how to add your own fields to the SyncRoot but the documentation states you can. Any news on this? Why was the issue closed without an answer?"
      }
    ]
  },
  {
    "number": 802,
    "title": "Is there a way create a menu, similar to the holo start menu (Movement)?",
    "created_at": "2017-07-21T19:19:58Z",
    "closed_at": "2017-07-26T19:35:29Z",
    "labels": [
      "Question"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/802",
    "body": "I wanted to know if there a way to create a menu/gameObject which will follow the movements of camera; just like the Holo Start menu.\r\nTo describe a little more, Just like how the start menu doesn't move until you look away from the FOV, can I create a menu which moves similar to it?",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/802/comments",
    "author": "pampas93",
    "comments": [
      {
        "user": "ghost",
        "created_at": "2017-07-24T10:50:52Z",
        "body": "Take a look at the \"Tag-Along\"-Scripts. There are a few different ones which might fullfill your requirements. And don't forget to attach the Billboard-Script to force the menu to face the camera. "
      },
      {
        "user": "pampas93",
        "created_at": "2017-07-26T19:35:20Z",
        "body": "@HoloFan Perfect. Works like a charm.\r\n"
      }
    ]
  },
  {
    "number": 787,
    "title": "Holograms sticks to holocamera",
    "created_at": "2017-07-18T18:08:29Z",
    "closed_at": "2017-10-28T01:33:37Z",
    "labels": [
      "Question"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/787",
    "body": "The hologram in the scene is being moved to the origin (the cameras position) on startup. \r\n\r\nUsing SpatialMapping, WorldAnchorManager, TapToPlace and InputManager in the scene.\r\n\r\n",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/787/comments",
    "author": "DrunkReaperMatt",
    "comments": [
      {
        "user": "StephenHodgson",
        "created_at": "2017-07-18T23:39:08Z",
        "body": "Make sure you don't have a script that's changing the position of your object."
      },
      {
        "user": "DrunkReaperMatt",
        "created_at": "2017-07-19T12:14:49Z",
        "body": "I have no scripts that changes the position of the object attached to the hologram. Only the TapToPlace and the Interpolator scripts were added to my object, outside the script i created."
      },
      {
        "user": "StephenHodgson",
        "created_at": "2017-10-28T01:33:37Z",
        "body": "@DrunkReaperMatt did you ever figure out what the problem was?\r\n\r\nbtw we've updated the Hololens camera to the MixedRealityCameraParent, give it a try."
      }
    ]
  },
  {
    "number": 782,
    "title": "Messages brodcasted lost with Sharing Service",
    "created_at": "2017-07-14T18:02:56Z",
    "closed_at": "2018-02-14T22:31:53Z",
    "labels": [
      "Question",
      "Sharing / Networking"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/782",
    "body": "Hi all,\r\nI'm using the Sharing Service with CustomMessage to create a Master/Slave configuration between 2 hololens.\r\n\r\nIt's working fine but I have one problem, in some moments, specially when the slave joins the room, the master sends lot of messages and someone get lost and don't arrive to the slave.\r\nIf I put a Log before sending messages all works fine because the log slows the sending process.\r\n\r\nI'm using the following method:\r\n\r\n```\r\nserverConnection.Broadcast(\r\n  msg,\r\n  MessagePriority.Immediate,\r\n  MessageReliability.ReliableOrdered,\r\n  MessageChannel.Avatar);\r\n```\r\n\r\nAnyone has an idea of how to solve the problem?\r\n\r\nThank you.",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/782/comments",
    "author": "fraspadafora",
    "comments": [
      {
        "user": "StephenHodgson",
        "created_at": "2017-07-26T22:35:35Z",
        "body": "Shot in the dark here, but try making sure there's a connection between the two before sending messages?"
      },
      {
        "user": "DKandrew",
        "created_at": "2017-07-28T15:31:56Z",
        "body": "Hi fraspadafora, \r\n\r\nI wonder how you achieve the master/slave configuration. Do you manually assign the priority to each HoloLens or have some automatic solution like \"the first one join the session will be the master\"? Would you share your idea to me? Thanks!"
      },
      {
        "user": "StephenHodgson",
        "created_at": "2017-10-28T01:45:53Z",
        "body": "Sounds like you aren't reading/writing all your bits in the right order"
      },
      {
        "user": "NeerajW",
        "created_at": "2018-02-14T22:31:53Z",
        "body": "Please reopen if your question was not answered."
      }
    ]
  },
  {
    "number": 739,
    "title": "Asynchronous functions in Unity",
    "created_at": "2017-06-24T00:51:24Z",
    "closed_at": "2017-10-28T01:29:11Z",
    "labels": [
      "Question"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/739",
    "body": "In meshsaver.cs, asynchronous functions are utilized. However, when I try to implement them in my own application, I get a 'Feature asynchronous functions cannot be used because it is not part of the C# 4.0 language specification' error. How do I implement async functions in Unity?",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/739/comments",
    "author": "gjrgj",
    "comments": [
      {
        "user": "StephenHodgson",
        "created_at": "2017-06-24T00:53:45Z",
        "body": "Unity, by default targets .net 3.5.  In your player settings you can update it to .net 4.6."
      },
      {
        "user": "gjrgj",
        "created_at": "2017-06-24T01:07:29Z",
        "body": "I have had it set that way since I began my project and it's thrown the error regardless :("
      },
      {
        "user": "StephenHodgson",
        "created_at": "2017-06-24T01:14:29Z",
        "body": "You might want inquire over in the Unity forums to see if anyone might know."
      },
      {
        "user": "waynebaby",
        "created_at": "2017-06-26T09:15:18Z",
        "body": "@gjrgj \r\n\r\nIt is not implemented in current published version of unity (5.6 1f1). And it could be  implemented in the following versions.\r\n\r\nCurrently you have to use callbacks to expose your interfaces, and use coroutines to wait for value change.\r\n\r\n\r\n"
      },
      {
        "user": "christjt",
        "created_at": "2017-06-26T10:40:33Z",
        "body": "@waynebaby I have also found that this is mostly the solution you will have to go with. You may find it easier to wrap your code with promises (uPromse) such that handling your async code may be easier."
      },
      {
        "user": "gjrgj",
        "created_at": "2017-06-26T13:07:11Z",
        "body": "I did some more research over the weekend and I think I understand how to do it - will using preprocessor directives to ignore certain blocks of code in Unity still compile them within Visual Studio? For UWP apps, I'm under the impression that the VS compiler can selectively deal with code that isn't built with the Unity compiler. Is that true? "
      },
      {
        "user": "christjt",
        "created_at": "2017-06-26T13:44:06Z",
        "body": "While this is very doable, do even UWP apps support async keywords? And even if it turns out they do, is this really optimal? I am working on a project which is starting to take a quite large code base. The more you differentiate the version for HoloLens vs the Unity editor (which you typically develop with), the more problems you will have with maintenance and further development. Also, you may in the future want to implement spectator view, etc. which depends on a working mono solution. Just my subjective take on this."
      },
      {
        "user": "gjrgj",
        "created_at": "2017-06-26T15:11:37Z",
        "body": "I see, thanks for the feedback. @christjt they do I believe, as one of the scripts in Microsoft's Holotoolkit utilizes async (meshsaver.cs). \r\n\r\nJust to affirm my understanding of the Unity -> VS dev process: if I wrap code with a #if (WINDOWS_UWP) directive, then it will be ignored when compiling the project build within Unity. However, when building the final version in VS to target the Windows store, the code in this block will be compiled and used in the final version of the app. So even though it is ignored by Unity, it will still work and be present in the end?"
      },
      {
        "user": "christjt",
        "created_at": "2017-06-26T15:44:50Z",
        "body": "Haven't read up that much about the different compiler directives, but I usually use #if NETFX_CORE for whatever is to only be run on HoloLens and #if UNITY_EDITOR for only unity stuff. (#if !UNITY_EDITOR can be used for anything **BUT** the unity editor if you wanna be clever) "
      },
      {
        "user": "gjrgj",
        "created_at": "2017-06-26T15:51:32Z",
        "body": "I figured it out - I just wasn't understanding the function of the .sln that is generated. Unity generates whatever files VS needs from it, then final building of C# 5/6 and UWP stuff is compiled within VS. So stuff like async functions can be used with the WINDOWS_UWP directive and will be ignored by Unity. I guess the rule of thumb is: for UWP, only worry about compilation within VS."
      },
      {
        "user": "StephenHodgson",
        "created_at": "2017-10-28T01:29:11Z",
        "body": "Going to close this.  It's probably been archived by google by now."
      },
      {
        "user": "isurfraz",
        "created_at": "2018-07-19T14:49:23Z",
        "body": "Still getting this. 2017.4.6f1 with latest holotoolkit as well as on 2018.1.8 and 2018.2"
      }
    ]
  },
  {
    "number": 734,
    "title": "PrefabSpawnManager is not working without sharingstage",
    "created_at": "2017-06-20T20:17:53Z",
    "closed_at": "2017-10-28T01:28:14Z",
    "labels": [
      "Question"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/734",
    "body": "we are working on a new app that has to work with a multi device but also standalone. we tried to use the PrefabSpawnManager but without the SharingStage connected ends up in being not functional. Does someone has good alternative? if no alternative would be interested in a updated version that works also without the sharing stage active?",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/734/comments",
    "author": "davesmits",
    "comments": [
      {
        "user": "StephenHodgson",
        "created_at": "2017-10-28T01:28:14Z",
        "body": "You should def use the sharing stage."
      }
    ]
  },
  {
    "number": 690,
    "title": "NearFadePlane sample",
    "created_at": "2017-05-24T21:26:48Z",
    "closed_at": "2017-06-24T12:04:34Z",
    "labels": [
      "Question"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/690",
    "body": "are there any examples how the nearfadeplane works? tried to get it working but not getting it to work\r\n",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/690/comments",
    "author": "davesmits",
    "comments": [
      {
        "user": "thebanjomatic",
        "created_at": "2017-05-25T13:54:22Z",
        "body": "@davesmits I usually add the script to the camera with the camera's near plane fade set to 0.25, and the near plane fade script set to fade from 0.85 to 0.3. The only other thing you need to do is ensure that the shaders you are using support it. This is true for most of the holotoolkit shaders, and you can look at their source to see how to apply it to your own shaders as well."
      }
    ]
  },
  {
    "number": 671,
    "title": "HoloToolkit menu item not visible",
    "created_at": "2017-05-15T09:11:35Z",
    "closed_at": "2017-05-18T11:28:15Z",
    "labels": [
      "Question"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/671",
    "body": "Hello,\r\nI followed the gettingStarted guide but after Step 2 there is no \"HoloToolkit\" menu item displayed in Unity. I tried to install it several times but unfortunately without success. I have tried to install HoloToolkit-Unity with Unity Version 5.5.0f3 (with Version 1.5.5.0 of HoloToolkit-Unity) and 5.6.0f3 (with Version 1.5.6. of HoloToolkit-Unity).\r\nWhat am I doing wrong? Or is it a bug? Thank you for your help in advance.\r\nCheers,\r\nCarpeTempus",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/671/comments",
    "author": "CarpeTempus",
    "comments": [
      {
        "user": "StephenHodgson",
        "created_at": "2017-05-16T20:31:47Z",
        "body": "Make sure you don't have any compile errors. Until these are resolved you won't see the new menu item after the package is imported."
      },
      {
        "user": "CarpeTempus",
        "created_at": "2017-05-18T08:52:29Z",
        "body": "Hmm, unfortunately the console did not came up with compile errors. Anyway, I noticed that a new version of Unity (5.6.1f1) and HoloToolkit-Unity (1.5.7)  was released and so I gave it a try and installed both. After creating a new empty project and import of the HoloToolkit-Unity the menu item is now displayed.\r\nNext I will try to import step by step my project code into this new project..\r\n\r\nLong story short: my problem is solved, thank you for your help :)"
      },
      {
        "user": "StephenHodgson",
        "created_at": "2017-05-18T11:28:15Z",
        "body": "Glad to hear!"
      }
    ]
  },
  {
    "number": 654,
    "title": "Double Tap recognition",
    "created_at": "2017-05-05T12:42:04Z",
    "closed_at": "2017-06-30T09:34:06Z",
    "labels": [
      "Question"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/654",
    "body": "Hello,\r\n\r\nI want to use a double Tap gesture. I noticed, that the InputClickedEventData provides a TapCount. \r\n\r\nBut when I try the follwoing, only the `Signle Tap` is displayed.\r\n\r\nAm I missing something? Or do I need to set up some timer to recognize two single Taps in a short time?\r\n\r\n```\r\n    public void OnInputClicked(InputClickedEventData eventData)\r\n    {\r\n      if (eventData.TapCount > 1)\r\n        Debug.Log(\"Double Tap\");\r\n      else\r\n        Debug.Log(\"Single Tap\");\r\n    }\r\n```\r\n\r\nThanks in advance.",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/654/comments",
    "author": "ghost",
    "comments": [
      {
        "user": "ghost",
        "created_at": "2017-05-05T12:48:04Z",
        "body": "Hi !\r\nI use that and it's work, try it :)\r\n\r\n```\r\n    public class a_clickcount : MonoBehaviour, IPointerClickHandler\r\n    {\r\n        int tap;\r\n        public void OnPointerClick(PointerEventData eventData)\r\n        {\r\n            tap = eventData.clickCount;\r\n     \r\n            if (tap == 2)\r\n            {\r\n                // do something\r\n            }\r\n     \r\n        }\r\n    }\r\n```"
      },
      {
        "user": "ghost",
        "created_at": "2017-05-08T06:06:45Z",
        "body": "@EmreSuzenExia Thanks for your answer. In which namespace does the IPointerClickHandler lives? I tried the \"HoloToolkit.Unity.InputModule\", but this one does not contain the interface."
      },
      {
        "user": "killerantz",
        "created_at": "2017-05-09T14:59:09Z",
        "body": "The HoloToolkit.Unity.InputModule is the correct namespace. The interface and method have been renamed to IInputClickHandler and OnInputClicked(InputClickedEventData eventData). The property to check is eventData.TapCount, but I am only getting \"1\" as a result in the Editor. The EditorHandsInput does state that only single taps are handled in the editor.\r\n\r\n```\r\n// We currently only support single taps in editor.\r\ninputManager.RaiseInputClicked(this, editorHandData.HandId, 1);\r\n```"
      },
      {
        "user": "ghost",
        "created_at": "2017-05-10T09:05:07Z",
        "body": "@killerantz Thank you for that answer."
      },
      {
        "user": "ghost",
        "created_at": "2017-05-10T13:26:18Z",
        "body": "I tried out the TapCount Property using the HoloLens. But it only picks up two single taps... Even using the Bluetooth Clicker does not change the behaviour.\r\n\r\nAny more ideas on how to enable double Tapping?"
      },
      {
        "user": "ghost",
        "created_at": "2017-05-10T13:30:11Z",
        "body": "Why you don't use my example ?\r\n\r\n```\r\nint tap;\r\npublic void OnPointerClick(PointerEventData eventData)\r\n{\r\n    tap = eventData.clickCount;\r\n}\r\n```\r\n"
      },
      {
        "user": "killerantz",
        "created_at": "2017-05-10T14:19:13Z",
        "body": "The IPointerClickHandler is in the UnityEngine.EventSystems namespace."
      },
      {
        "user": "ghost",
        "created_at": "2017-05-10T14:39:09Z",
        "body": "@EmreSuzenExia : I tried that one out. Put I think I'm missing something out. The method is not called.\r\n\r\nI have an InputManager, a HoloCamera, a cursor and a simple cube (to which my test script is attached) is the scene. Is there somethin else missing?"
      },
      {
        "user": "killerantz",
        "created_at": "2017-05-10T15:45:26Z",
        "body": "I have not been able to get double-tap to work with the IPointerClickHandler, I only get zeros as the clickCount. You'll need to have EventSystem added to the scene for IPointerClickEvents to occur. Just add a UI button to the scene and the EventSystem comes in as well.\r\n\r\nI was able to get double-taps to work using IInputClickHandler and OnInputClicked(InputClickedEventData eventData) though. \r\n\r\nFirst thing is the GesturesInput is not setup to handle double-tap detection, so you need to add it to the recognizable gestures by opening HoloToolkit/UI/Scripts/InputSources/GesturesInput.cs\r\n\r\nOn line 46 add GestureSettings.DoubleTap to the gestureRecognizer like this.\r\n\r\n`gestureRecognizer.SetRecognizableGestures(GestureSettings.Tap | \r\n                                                      GestureSettings.ManipulationTranslate |\r\n                                                      GestureSettings.Hold |\r\n                                                      GestureSettings.DoubleTap);`\r\n\r\n\r\nThen in the OnInputClicked handler look at the tapCount which should be 1 or 2.\r\n`public virtual void OnInputClicked(InputClickedEventData eventData)\r\n {\r\n            print(eventData.TapCount);\r\n }`\r\n\r\nTwo events will fire on a double-tap (1 and 2), so if you want to capture both single-taps and double-taps on the same object, you will have to delay the single-tap execution to see if a double-tap does not immediately follow. I hope that makes sense.\r\n\r\nMaybe there's a part of the EventSystem that needs to register to listen for double taps to get the IPointer stuff working, but I haven't dug that far into it yet."
      },
      {
        "user": "StephenHodgson",
        "created_at": "2017-05-10T15:47:08Z",
        "body": "> First thing is the GesturesInput is not setup to handle double-tap detection, so you need to add it to the recognizable gestures by opening HoloToolkit/UI/Scripts/InputSources/GesturesInput.cs\r\n\r\nDoes it make sense that we actually make this change to the project?"
      },
      {
        "user": "killerantz",
        "created_at": "2017-05-10T16:06:51Z",
        "body": "I think so, we have references to double-tap in the InputManager, but it is not enabled. Looks like it was an oversight. \r\n\r\nI was wondering if there were any issues by having it enabled but not expecting it, like getting the double events fired during a double tap. Maybe it's something that we make it easier to enable as part of the framework? Just in case there is something we are missing.\r\n\r\nRight now you can rapid fire single taps when double-tap is not recognized. This is the same outcome of having double-tap enabled, but not checking for tap counts. Having it enabled doesn't seem to change the behavior of the click event, just provides more data from my quick tests."
      },
      {
        "user": "ghost",
        "created_at": "2017-05-11T06:11:13Z",
        "body": "@killerantz : Thank you very much for your throughout investigation of this.\r\n\r\nI'm not sure, but maybe we can define a new interface to only register doubleTaps?\r\nOr might it be better to mention the detection of single and double taps in the IInputClickedHandler?"
      },
      {
        "user": "Deaa-B",
        "created_at": "2017-07-03T11:29:19Z",
        "body": "I've tried this but the problem i always get the single tap then the double tap is there any idea of how to make the single tap waits if there is another tap or not ? like one second for example ?\r\n\r\n```\r\nvoid Start()\r\n    {\r\n        StartCoroutine(HoldSphere());\r\n\r\n        _gestureRecognizer = new GestureRecognizer();\r\n        _gestureRecognizer.TappedEvent += GestureRecognizerOnTappedEvent;\r\n        _gestureRecognizer.SetRecognizableGestures(GestureSettings.Tap | GestureSettings.DoubleTap );\r\n        _gestureRecognizer.StartCapturingGestures();\r\n        _gestureRecognizer.TappedEvent += (source, tapCount, ray) =>\r\n        {\r\n            if (tapCount == 1)\r\n           {\r\n                HoldSphere();\r\n                if (tapCount == 2)\r\n                    Shoot1();\r\n          }\r\n                else Shoot();\r\n            \r\n        };\r\n    }\r\n    IEnumerator HoldSphere()\r\n    {\r\n        yield return new WaitForSeconds(1);\r\n    }\r\n```"
      },
      {
        "user": "killerantz",
        "created_at": "2017-07-10T14:13:29Z",
        "body": "When listening for a double tap there needs to be a way to cancel the single tap code execution.\r\n\r\nAdding a local bool, like _hasDoubleTap could do it. I believe there's a 0.3 - 0.4 second threshold for a double tap to register.\r\n\r\n```\r\nbool _hasDoubleTap;\r\nvoid Start()\r\n{    \r\n    StartCoroutine(HoldSphere());\r\n\r\n    _gestureRecognizer = new GestureRecognizer();\r\n    _gestureRecognizer.TappedEvent += GestureRecognizerOnTappedEvent;\r\n    _gestureRecognizer.SetRecognizableGestures(GestureSettings.Tap | GestureSettings.DoubleTap );\r\n    _gestureRecognizer.StartCapturingGestures();\r\n    _gestureRecognizer.TappedEvent += (source, tapCount, ray) =>\r\n    {\r\n        if (tapCount == 2)\r\n       {\r\n            _hasDoubleTap = true;\r\n            Shoot();\r\n      }\r\n      else \r\n      {\r\n          _hasDoubleTap = false;\r\n          HoldSpere();\r\n      }\r\n    };\r\n}\r\nIEnumerator HoldSphere()\r\n{\r\n    yield return new WaitForSeconds(0.4f);\r\n    if(!_hasDounleTap){\r\n      // execute single tap\r\n    }\r\n}\r\nvoid Shoot()\r\n{\r\n   // execute double tap\r\n{\r\n```\r\n\r\n"
      },
      {
        "user": "Deaa-B",
        "created_at": "2017-07-10T15:00:40Z",
        "body": "@killerantz \r\nthanks, but still the same problem.\r\nI only can define one gesture, either the first or the second tap, or the first and then the second.\r\ni want for example if i have one tap to throw a sphere, a double tap to throw a cube but first see if i have a single or double tap and then act.\r\nI've tried everything i hope I've cleared my point now.\r\nhere is my whole code\r\n\r\n```\r\npublic GestureRecognizer _gestureRecognizer;\r\n\r\n    public float ForceMagnitude = 300f;\r\n    void Start()\r\n    {\r\n\r\n       \r\n\r\n        _gestureRecognizer = new GestureRecognizer();\r\n        _gestureRecognizer.TappedEvent += GestureRecognizerOnTappedEvent;\r\n        _gestureRecognizer.SetRecognizableGestures(GestureSettings.Tap | GestureSettings.DoubleTap );\r\n        _gestureRecognizer.StartCapturingGestures();\r\n        _gestureRecognizer.TappedEvent += (source, tapCount, ray) =>\r\n        {\r\n            if (tapCount == 1)\r\n                StartCoroutine(HoldSphere());\r\n\r\n            else if (tapCount == 2)\r\n                Shoot();\r\n            else\r\n                Shoot1();\r\n        };\r\n    }\r\n    IEnumerator HoldSphere()\r\n    {\r\n        yield return new WaitForSeconds(1);\r\n    }\r\n\r\n    private void GestureRecognizerOnTappedEvent(InteractionSourceKind source, int tapCount, Ray headRay)\r\n    {\r\n      \r\n\r\n\r\n\r\n    }\r\n\r\n    private void Shoot()\r\n    {\r\n        var eyeball = GameObject.CreatePrimitive(PrimitiveType.Sphere);\r\n        eyeball.transform.localScale = new Vector3(0.1f, 0.1f, 0.1f);\r\n        var rigidBody = eyeball.AddComponent<Rigidbody>();\r\n        rigidBody.mass = 0.5f;\r\n        rigidBody.position = transform.position;\r\n        var forward =  transform.forward;\r\n        forward = Quaternion.AngleAxis(-7, transform.right) * forward;\r\n        rigidBody.AddForce(forward * ForceMagnitude);\r\n    }\r\n    private void Shoot1()\r\n    {\r\n        var eyeball = GameObject.CreatePrimitive(PrimitiveType.Cube);\r\n        eyeball.transform.localScale = new Vector3(0.1f, 0.1f, 0.1f);\r\n        var rigidBody = eyeball.AddComponent<Rigidbody>();\r\n        rigidBody.mass = 0.5f;\r\n        rigidBody.position = transform.position;\r\n        var forward = transform.forward;\r\n        forward = Quaternion.AngleAxis(-7, transform.right) * forward;\r\n        rigidBody.AddForce(forward * ForceMagnitude);\r\n    }\r\n```"
      },
      {
        "user": "killerantz",
        "created_at": "2017-07-10T17:08:30Z",
        "body": "Honestly, if we have to check the tap count and wait for seconds to tell the difference between a single and double tap, then the double tap functionality is not really in place. If it were, there would be a DoubleTap Event and the system would handle all this. So it may be best to roll your own for now, it's the same amount of code and less hassle.\r\n\r\n```\r\nprivate Coroutine _tapRoutine;\r\nvoid Start()\r\n{\r\n    _gestureRecognizer = new GestureRecognizer();\r\n    _gestureRecognizer.TappedEvent += GestureRecognizerOnTappedEvent;\r\n    _gestureRecognizer.SetRecognizableGestures(GestureSettings.Tap);\r\n    _gestureRecognizer.StartCapturingGestures();\r\n    _gestureRecognizer.TappedEvent += (source, tapCount, ray) =>\r\n    {\r\n            if (_tapRoutine == null)\r\n            {\r\n                _tapRoutine = StartCoroutine(TapTimer());\r\n            }\r\n            else\r\n            {\r\n                StopCoroutine(_tapRoutine);\r\n                _tapRoutine = null;\r\n                print(\"doubleTap!\");\r\n                Shoot();\r\n            }\r\n    };\r\n}\r\n\r\nprivate IEnumerator TapTimer()\r\n{\r\n      yield return new WaitForSeconds(0.3f);\r\n      print(\"singleTap!\");\r\n      _tapRoutine = null;\r\n      Shoot1();\r\n}\r\n```"
      }
    ]
  },
  {
    "number": 647,
    "title": "Best practice sending over image files from backend server to HoloLens?",
    "created_at": "2017-05-01T13:18:51Z",
    "closed_at": "2017-10-28T01:24:17Z",
    "labels": [
      "Question"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/647",
    "body": "I'm currently using a JSON txt file as a configuration file to get several lightweight stuff like strings and numbers. But for my current project I want to get some images from my own webserver and show it into the HoloLens app. \r\n\r\nThe thing is: I want it to be configurable, and for that purpose I'm currently using a Base64 byte array in a JSON file to get the image. Problem is, when I read and process this array the HoloLens app freezes for a couple of seconds when the app gets started and I initialize the JSON. \r\n\r\nI presume there is a better way to load images dynamically, but what is the better way?",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/647/comments",
    "author": "gkh38",
    "comments": [
      {
        "user": "genereddick",
        "created_at": "2017-05-01T15:56:29Z",
        "body": "How are you loading the JSON file and the images? From inside a Coroutine?"
      },
      {
        "user": "ignavus",
        "created_at": "2017-05-08T10:04:45Z",
        "body": "You can try to do all of the work on other thread and then use InvokeOnAppThread() to to constructed the texture2D object that unity uses.\r\nBut this also can cause lag since most of the function unity uses to load images are synchronous, so you can use a coroutine inside the function written inside InvokeOnAppThread to set the texture pixel by pixel and yield the coroutine once it exceeds a certain time threshold.\r\nThe last approach increase the loading time (not by much if you are loading images sparsely) but it ensures a smooth experience"
      },
      {
        "user": "ghost",
        "created_at": "2017-07-05T11:50:14Z",
        "body": "@gkh38 : Any news? Could you improve the dynamic loading of images?"
      },
      {
        "user": "christjt",
        "created_at": "2017-07-06T08:41:23Z",
        "body": "Hmmm, never really had any problem loading images dynamically. Just dump your image data into the texture and you should be good to go. What methods are you using to load your image? And what seems to be the bottleneck(parsing your json or loading the texture)? Can either @gkh38 or @HoloFan elaborate on what the performance problem is?"
      },
      {
        "user": "StephenHodgson",
        "created_at": "2017-10-28T01:24:17Z",
        "body": "Going to close this.  It's probably been archived by google by now."
      }
    ]
  },
  {
    "number": 642,
    "title": "Align to spatial mesh?",
    "created_at": "2017-04-27T15:24:28Z",
    "closed_at": "2017-10-28T01:24:38Z",
    "labels": [
      "Question",
      "Platform - HoloLens - First Gen"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/642",
    "body": "I want to align gameobjects that use \"TapToPlace\" to the mesh created by spatial mapping.\r\n\r\nI think I'm on the right track by modifying the TapToPlace.cs script. I have added a public gameobject which I drag the cursor object to, and then I have modified the following code:\r\n\r\n```\r\nif (Physics.Raycast(headPosition, gazeDirection, out hitInfo, 30.0f, spatialMappingManager.LayerMask))\r\n                {\r\n                    // Rotate this object to face the user.\r\n                    Quaternion toQuat = Camera.main.transform.localRotation;\r\n                    toQuat.x = 0;\r\n                    toQuat.z = 0;\r\n\r\n                    var cursorRotation = cursor.transform.localRotation; // get cursors rotation\r\n\r\n                    // Move this object to where the raycast\r\n                    // hit the Spatial Mapping mesh.\r\n                    // Here is where you might consider adding intelligence\r\n                    // to how the object is placed.  For example, consider\r\n                    // placing based on the bottom of the object's\r\n                    // collider so it sits properly on surfaces.\r\n                    if (PlaceParentOnTap)\r\n                    {\r\n                        // Place the parent object as well but keep the focus on the current game object\r\n                        Vector3 currentMovement = hitInfo.point - gameObject.transform.position;\r\n                        ParentGameObjectToPlace.transform.position += currentMovement;\r\n                        ParentGameObjectToPlace.transform.rotation = toQuat;\r\n                    }\r\n                    else\r\n                    {\r\n                        gameObject.transform.position = hitInfo.point;\r\n                        //gameObject.transform.rotation = toQuat; // old code\r\n                        gameObject.transform.rotation = cursorRotation; // new rotation\r\n                    }\r\n                }\r\n```\r\n\r\nHowever, it just doesn't seem quite right. Especially, when trying to place an object on a ceiling, it does not face downwards.",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/642/comments",
    "author": "paulcanning",
    "comments": [
      {
        "user": "angelaHillier",
        "created_at": "2017-04-27T23:00:47Z",
        "body": "You might need to call RecalculateNormals() for the SpatialMapping mesh in order to tell the difference between a floor/ceiling/wall, etc. \r\n\r\nIn the Holograms 230 Academy version of the HoloToolkit, SpatialMappingObserver.cs will call this after creating a new mesh when you set the 'RecalculateNormals' option to 'true'. This is done in the SurfaceObserver_OnDataReady() function:\r\n```\r\nif (RecalculateNormals)\r\n{\r\n    MeshFilter filter = surface.GetComponent<MeshFilter>();\r\n    if(filter != null && filter.sharedMesh != null)\r\n    {\r\n          filter.sharedMesh.RecalculateNormals();\r\n    }\r\n}\r\n```\r\n\r\nI don't believe this option was ever added to the official HoloToolkit, but it might be a good addition for cases when the meshes need to have the correct normals."
      },
      {
        "user": "paulcanning",
        "created_at": "2017-04-28T10:25:18Z",
        "body": "I have implemented this and it seems to work a bit better, although it seems like the cursor doesn't always lie \"flat\" along the spatial mesh. I'm hoping that increasing the triangles per cubic metre helps."
      },
      {
        "user": "jessemcculloch",
        "created_at": "2017-05-05T00:50:49Z",
        "body": "Try this @paulcanning\r\n\r\n`gameObject.transform.rotation = Quaternion.LookRotation(-hitInfo.normal, Vector3.up);`"
      },
      {
        "user": "sebrk",
        "created_at": "2017-08-09T22:03:54Z",
        "body": "Any update on this? I'm facing the same issue. Sometimes the spawned object is really weirdly aligned although I'm facing a flat wall and it looks flat judging the wall mesh itself."
      },
      {
        "user": "StephenHodgson",
        "created_at": "2017-10-28T01:24:38Z",
        "body": "Going to close this.  It's probably been archived by google by now."
      }
    ]
  },
  {
    "number": 625,
    "title": "DLL Not Find，I try to Config DLL into X64 or X86,while ,this does not help",
    "created_at": "2017-04-19T04:09:45Z",
    "closed_at": "2017-09-16T00:25:46Z",
    "labels": [
      "Question"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/625",
    "body": "DllNotFoundException: SpatialUnderstanding\r\n",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/625/comments",
    "author": "nrchuanqi",
    "comments": [
      {
        "user": "Sacristan",
        "created_at": "2017-04-19T08:15:07Z",
        "body": "Can You please provide more info. \r\n\r\nCan You find SpatialUnderstanding.dll in project ? "
      },
      {
        "user": "jessemcculloch",
        "created_at": "2017-04-29T17:01:35Z",
        "body": "If you have added the DLL into your project, but it still can't be found when you run your app, try deleting the App folder (or whatever you build from unity to), and then restart unity and then do a fresh build."
      },
      {
        "user": "StephenHodgson",
        "created_at": "2017-05-30T17:02:54Z",
        "body": "@nrchuanqi did you resolve this issue?"
      }
    ]
  },
  {
    "number": 596,
    "title": "\"Failed to world lock serialization failed\"",
    "created_at": "2017-03-31T12:14:20Z",
    "closed_at": "2017-10-28T01:21:39Z",
    "labels": [
      "Question",
      "Platform - HoloLens - First Gen"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/596",
    "body": "\"Failed to world lock serialization failed\"\r\nI sometimes get this error after creating a WorldAnchor in a UNet Sharing project (Host). What does it mean?",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/596/comments",
    "author": "MrMatthias",
    "comments": [
      {
        "user": "lukaswerz",
        "created_at": "2017-06-08T11:26:52Z",
        "body": "Same Problem here"
      },
      {
        "user": "fraspadafora",
        "created_at": "2017-06-30T11:51:26Z",
        "body": "I found the problem.\r\nIn my case the problem was that the spatial mapping of the room was 300mb. So the exporting method fails. The solution was to remove the room spaces from the Hololens. To remove the spaces go in Settings -> System -> Spaces"
      },
      {
        "user": "sebrk",
        "created_at": "2017-09-08T13:54:46Z",
        "body": "I got this too. Clearing the space fixed it. This should probably be a more detailed error message in any case but is there a way to check this in runtime?"
      },
      {
        "user": "StephenHodgson",
        "created_at": "2017-10-28T01:21:39Z",
        "body": "Going to close this.  It's probably been archived by google by now.\r\n\r\nPlease open a new issue if it still exists."
      }
    ]
  },
  {
    "number": 595,
    "title": "Spatial Understanding Issue with Videos/Animations",
    "created_at": "2017-03-30T06:49:45Z",
    "closed_at": "2017-10-28T01:27:30Z",
    "labels": [
      "Question",
      "Platform - HoloLens - First Gen"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/595",
    "body": "Hello,\r\n\r\nwe experienced big issues/difficulties as soon as we include the spatialunderstanding in our Project (spatialmapping alone works just fine). To clarify the Situation i explain briefly what we are trying to do:\r\n\r\nWe have sceneloader-scene which loads different scenes. Our spatialmapping/understanding is attached to a managerobject in the sceneloader scene ... we scan our room (during the sceneloader scene) finalize the scan via RequestFinishScan() ... the scan finishs we attach the occlusion material, everything is just fine. Then we load another scene, in this scene there are mecanim animations ... if we calculate the **rotations** of these **animations via \"euler\"** solver (rightclick the rotation parameter in the animation tab) the whole object **flickers** even after completing the animation. Ok we found a solution to this behaviour in changing the solver to \"quaternion euler\" ... remember this all works fine **WITHOUT** the spatialunderstanding module included. Also the behaviour is visible in the editor + hololens. We can also not get rid of this behaviour if we just delete the spatialunderstanding prefab ... the problem still exists. Only a restart of unity itself resets the state. There might be some weired stuff going on in the background with the .dll functions ... also we didn't even use any of our own functions for the spatialunderstanding yet. This happens with the BASIC module.\r\nSo lets move away from the animation problem which we eventually \"fixed\" (more like avoided the problem). The next big issue is using spatial understanding with movie textures ... same procedure with sceneloader etc. ... this time we include movie textures in scene 1. The quality of the textures were set to 0.5 they are like 100 mb in total ... this time around in the editor all works fine and without any issues. As soon as we deploy it to our hololens and load scene 1 the app crashes ... ok maybe a performance issue we thought ---> lower quality to 0.3. Look at that the movie plays but we got NO Sound .... ---> we remove spatialunderstanding ---> everything works fine!\r\n\r\nI hope I could clarify our Situation ... its very frustrating because we invested much time into spatialunderstanding functions and just wanted to use them -.-. Also even in case I repeat myself this all happens only with the spatialunderstanding module ... spatialmapping works fine!",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/595/comments",
    "author": "MatzeBehm",
    "comments": [
      {
        "user": "ForrestTrepte",
        "created_at": "2017-05-18T00:03:24Z",
        "body": "In issue #520, I noticed that Spatial Understanding was changing the floating point rounding mode and that was causing strange problems when I later tried to capture photos. In #656, I changed Spatial Understanding to restore the rounding mode after it is called. It is possible that your issues with animation and movies could be caused by the same underlying issue, so you may want to check if this is still a problem in recent versions of HoloToolkit that have the 5fc993ca8bc232dfddc7a34e22a5d8714189487b commit."
      },
      {
        "user": "StephenHodgson",
        "created_at": "2017-10-28T01:27:30Z",
        "body": "Going to close this.  It's probably been archived by google by now."
      }
    ]
  },
  {
    "number": 588,
    "title": "Problem with ReflectionExtensions and why is it needed?",
    "created_at": "2017-03-24T14:11:16Z",
    "closed_at": "2017-04-11T08:46:43Z",
    "labels": [
      "Question"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/588",
    "body": "Hello,\r\n\r\nI faced an issue with holotoolkit today on Unity 5.5.1.f1\r\nI had a line of code in one of my scripts that was \r\n`FieldInfo[] fieldArray = GetType().GetFields(BindingFlags.Public | BindingFlags.NonPublic | BindingFlags.Instance);`\r\n\r\nAnd when adding holotoolkit, the ReflectionExtensions raised an error when trying to build, due to the GetFields method returning an IEnumerable instead of an array in the extension.\r\nI temporarily fixed the problem by doing this :\r\n`#if UNITY_METRO && !UNITY_EDITOR\r\n        FieldInfo[] fieldArray = GetType().GetFields(BindingFlags.Public | BindingFlags.NonPublic | BindingFlags.Instance).ToArray();\r\n#else\r\n        FieldInfo[] fieldArray = GetType().GetFields(BindingFlags.Public | BindingFlags.NonPublic | BindingFlags.Instance);\r\n#endif`\r\nas I need my code to be able to work with and without holotoolkit. But I was wondering why this extension is needed ? I guess it was useful at some point or on older versions of Unity maybe ? Or did I miss a detail somewhere ?\r\n\r\nThanks",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/588/comments",
    "author": "flonou",
    "comments": [
      {
        "user": "kiyoaki",
        "created_at": "2017-03-27T01:10:13Z",
        "body": "I faced same problem, and requested #577."
      },
      {
        "user": "flonou",
        "created_at": "2017-03-31T11:18:37Z",
        "body": "So you proposed to move these extensions to a namespacen which should help. But are they all still needed in the end ? It doesn't seem like it to me"
      },
      {
        "user": "StephenHodgson",
        "created_at": "2017-04-07T20:03:32Z",
        "body": "Did moving to the new namespace fix this issue?\r\n\r\nI think keeping this class around is a good idea, because there are others that use this.  It's just a tool for convenience. "
      },
      {
        "user": "flonou",
        "created_at": "2017-04-11T08:46:43Z",
        "body": "Yes the move to the new namespace fixed the issue"
      }
    ]
  },
  {
    "number": 580,
    "title": "How to clean memory of taptoplace?",
    "created_at": "2017-03-22T16:25:47Z",
    "closed_at": "2017-03-23T18:36:58Z",
    "labels": [
      "Question"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/580",
    "body": "Hi,\r\n\r\nI'm using the TapToPlace script for a game I'm working on, but every time I close the app and reopen it, the object is where I put it last time, I try to change the initial position but it does not Work.\r\n\r\nIt's any way to clean the position when the app restarts?\r\n",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/580/comments",
    "author": "mauricioalfonso007",
    "comments": [
      {
        "user": "assert-not-singularity",
        "created_at": "2017-03-23T08:51:03Z",
        "body": "You have to delete the WorldAnchor set in the WorldAnchorManager by the TapToPlace script."
      },
      {
        "user": "mattfedocsg",
        "created_at": "2017-03-23T11:51:07Z",
        "body": "@niklas87 is right.  Also, it may benefit you to make an object pool to keep track of which objects have tap to place and what their anchor names are."
      },
      {
        "user": "mauricioalfonso007",
        "created_at": "2017-03-23T18:36:58Z",
        "body": "Thank guys,\r\n\r\nit works like a charm."
      }
    ]
  },
  {
    "number": 571,
    "title": "Tap to place parent",
    "created_at": "2017-03-19T18:22:02Z",
    "closed_at": "2017-09-13T02:17:21Z",
    "labels": [
      "Question"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/571",
    "body": "I am using the tap to place script when the app started to let the user move a cube around the room for choosing a location to place holograms.\r\n\r\nWhen I move my cube around and place it again it seems like only some of the holograms are move to the location of the cube and some are still in the old location. I cannot find a difference in these game objects.\r\n\r\nThe cube with the Tap to Place script is inside a game object called \"holograms\". The place parent on tap is checked and the Parent game object is set to the Holograms object. The holograms object has a bunch of other objects that will appear by script.\r\n",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/571/comments",
    "author": "StarWardo",
    "comments": [
      {
        "user": "mattfedocsg",
        "created_at": "2017-03-19T18:26:15Z",
        "body": "You need to check and make sure the friendly anchor name is different for each object.  If they are all the same and you go to move them, they will all snap back to that one anchor.  You can see Issue #567 and follow if I can get an answer on instantiation as well. "
      },
      {
        "user": "StarWardo",
        "created_at": "2017-03-19T18:30:05Z",
        "body": "I only need one object as anchor. \r\n\r\nThe object is used to place a group of holograms where the user wants them. But some of the holograms keep the old position."
      },
      {
        "user": "mattfedocsg",
        "created_at": "2017-03-19T19:35:43Z",
        "body": "You will have to change the anchor position per object if you had any previous anchors attached to that object.  Try clearing the anchor store as well.  Ive come across this issue before."
      },
      {
        "user": "nyp-leon",
        "created_at": "2018-02-13T06:40:46Z",
        "body": "@mattfedocsg  What do u mean by anchor position and anchor store? How do I clear the anchor store? I'm trying to tap to place a bunch of holograms but only some are above to be moved and relocated. Same problem I guess..\r\n\r\n\r\n"
      }
    ]
  },
  {
    "number": 567,
    "title": "Instantiating a Clone w/ TapToPlace as a Component",
    "created_at": "2017-03-15T11:25:33Z",
    "closed_at": "2017-10-28T01:20:56Z",
    "labels": [
      "Question"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/567",
    "body": "I am not sure if this is \"by design\", but if you have an object that has TapToPlace.cs added as a component, with a saved friendly anchor name specified and then go to instantiate a clone, the clones position and anchor matches that of the original object.  Even if you try to instantiate the object with a new pos and rot.  I assume because the position is saved by anchor.\r\n\r\nI fixed this on my end by instantiating the object, changing the anchor name, attaching the anchor to the WorldAnchorManager, then changing the position and rotation.\r\n\r\nI feel like the script should have done this for me though.  Maybe check to see if the world anchor store already has that key anchor name?  Then at on destroy remove the anchor that was cloned?\r\n\r\nI guess it is just my opinion, but anyone else have any thoughts?  Or maybe I am missing something?  Thanks!",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/567/comments",
    "author": "mattfedocsg",
    "comments": [
      {
        "user": "mattfedocsg",
        "created_at": "2017-03-21T16:11:07Z",
        "body": "If anyone is having issues with this, I've just been updating the friendly name with the date down to the second or millisecond that the object was instantiated.  Then, in best gaming practice, throw that object in a pool.  So instantiate the object with a new position, change the anchor name, and attach the anchor.  Done.\r\n\r\n`GameObject gameObject= GameObject.Instantiate(OriginalObject, pos, rot);`\r\n\r\n`gameObject.GetComponent<TapToPlace>().SavedAnchorFriendlyName = \"gameObject_\" + System.DateTime.Now.ToString(\"yyyyMMddhhmmss\");`\r\n\r\n `WorldAnchorManager.Instance.AttachAnchor(gameObject, gameObject.GetComponent<TapToPlace>().SavedAnchorFriendlyName);`"
      },
      {
        "user": "StephenHodgson",
        "created_at": "2017-06-27T21:16:39Z",
        "body": "@mattfedocsg With the latest PR You would just need to make sure the `GameObject` names are unique."
      }
    ]
  },
  {
    "number": 550,
    "title": "Sharing Transformations?",
    "created_at": "2017-03-07T14:09:09Z",
    "closed_at": "2017-10-28T01:20:15Z",
    "labels": [
      "Question"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/550",
    "body": "Is it possible to manipulate objects in a shared scene? Maybe use `HandDraggable` to transform different objects and update the anchors?",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/550/comments",
    "author": "Nakle",
    "comments": [
      {
        "user": "Ziugy",
        "created_at": "2017-03-07T16:28:16Z",
        "body": "You normally use a network layer for synchronizing objects in a shared experience: HoloToolkit.Sharing, UNET. I've been using UNET with custom NetworkBehaviours or NetworkTransform / NetworkTransformChild for syncing local position / rotation relative to shared world anchor(s). I would recommend looking at SharingWithUNET under HoloToolkit-Examples."
      },
      {
        "user": "Nakle",
        "created_at": "2017-03-07T18:41:47Z",
        "body": "Allright, thanks! I will look at the UNet samples asap. I figured that the `HandDraggable` would sync the positions between users by it self.."
      },
      {
        "user": "StephenHodgson",
        "created_at": "2017-03-11T16:16:57Z",
        "body": "If you're using the sharing system, take a look at the SharingSpawnTest scene:\r\n\r\n1. Add the InputManager.prefab to the scene\r\n2. Add the DefaultCursor.prefab to the scene\r\n3. Add `HandDraggable` to either/both of the spawn object prefabs located in `Sharing/Tests/Prefabs`\r\n4. ???\r\n5. Profit"
      },
      {
        "user": "StephenHodgson",
        "created_at": "2017-10-28T01:20:15Z",
        "body": "The Sharing libraries have been updated to include sync transform components."
      }
    ]
  },
  {
    "number": 544,
    "title": "Access violation running sharing prefab on emulator",
    "created_at": "2017-03-02T12:58:24Z",
    "closed_at": "2017-10-28T01:19:13Z",
    "labels": [
      "Question"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/544",
    "body": "Hi,\r\nAfter adding the sharing prefab to my project\r\n\r\nI keep getting this error, when trying to run it on emulator:\r\nmaybe someone have an idea?\r\n\r\n\r\nSharingService: Local Machine Name: hololens-5h8ea\r\n \r\n(Filename: C:/buildslave/unity/build/artifacts/generated/Metro/runtime/DebugBindings.gen.cpp Line: 51)\r\n\r\n\r\nSharingService: Connecting to Server at 10.110.72.73:20602\r\n \r\n(Filename: C:/buildslave/unity/build/artifacts/generated/Metro/runtime/DebugBindings.gen.cpp Line: 51)\r\n\r\n\r\nSetting up 1 worker threads for Enlighten.\r\n\r\n  Thread -> id: b98 -> priority: 1 \r\n\r\nThe program '[416] VCC.exe' has exited with code -1073741819 (0xc0000005) 'Access violation'.\r\n\r\n",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/544/comments",
    "author": "geshas",
    "comments": [
      {
        "user": "christjt",
        "created_at": "2017-03-20T13:50:58Z",
        "body": "Closing unity + emulator and building from Unity again usually fixes this bug for me. Not sure why / where Access violation comes from though."
      },
      {
        "user": "StephenHodgson",
        "created_at": "2017-10-28T01:19:13Z",
        "body": "Going to close this.  It's probably been archived by google by now."
      },
      {
        "user": "furkee",
        "created_at": "2018-01-03T14:51:42Z",
        "body": "I am running into same issue. I think this should be re-opened as the suggested solution is not really a solution but a tiresome work around."
      },
      {
        "user": "StephenHodgson",
        "created_at": "2018-01-03T23:44:26Z",
        "body": "@furkee please open a new issue with a list of repro steps and the exact access code violation.\r\nThanks"
      },
      {
        "user": "dtoceaneering",
        "created_at": "2018-09-20T07:52:24Z",
        "body": "Hi, StephenHodgson\r\nI am also at the same issue.I am getting this issue while making a build on Hololens device or Emulator.\r\nI want to open web browser inside Hololnes,but i am able to do this due tho these type of issue.Could you please suggest how to fix it.\r\n\r\n "
      }
    ]
  },
  {
    "number": 521,
    "title": "Changing cursor according to hovered object (Custom Cursor)",
    "created_at": "2017-02-16T08:14:12Z",
    "closed_at": "2017-02-20T15:26:35Z",
    "labels": [
      "Question"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/521",
    "body": "**What I am trying to do:**\r\nIf my gaze hits a target (TargetedObject in Cursor.cs) I wanna show a custom cursor like in the hologram app where the cursor becomes two arrows for rotating the object. \r\n\r\nIs there any simple way to achieve this?\r\nAs far as I know there is a \"contextual\" state in the Cursor.cs which is meant for something like this, but it isn't used anywhere...\r\n\r\n**I already made a simple approach (if u like it I will be glad to make a PR):**\r\nIn the CursorModifier.cs I add public objects for the cursors when the targeted object is observed/interact hovered or not.\r\nIn the ObjectCursor.cs I override the \"OnFocusedObjectChanged\" function to also check if the targeted object has a CursorModifier component and also if the component has prefabs for the current state. If it has, I instantiate the according prefab, set the custom cursor alongside the \"CursorOnHolograms\" and \"CursorOffHolograms\" and set a flag that a custom cursor should be used.\r\n\r\nwhat do you think about my approach? since it is still under development I won't post code before I beautified and tested it a bit more ;)",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/521/comments",
    "author": "cnspaha",
    "comments": [
      {
        "user": "StephenHodgson",
        "created_at": "2017-02-16T14:53:34Z",
        "body": "Hi @cnspaha.  I've seen many projects just create their own implementation of the cursor and just animate the cursor changes via `OnFocusedObjectChanged`.  Checking the layer is much more efficient than using `GetComponent<T>` and trying to Instantiate Objects every time you need to change the Cursor.  Take a look at the `DefaultCursor.prefab` and `AnimatedCursor.cs` for examples of setting your own cursor states, and triggering them via the Cursor's Animator."
      }
    ]
  },
  {
    "number": 501,
    "title": "In sharing, how to update the position of the spawnObject?",
    "created_at": "2017-02-04T00:44:37Z",
    "closed_at": "2017-02-07T16:19:04Z",
    "labels": [
      "Question"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/501",
    "body": "Hi, \r\n\r\nOnce I spawned a cube, I moved a new position when I clicked as shown below. But, the new position was not synchronized with other HLs. \r\n\r\npublic void OnInputClicked(InputClickedEventData eventData)\r\n{\r\nDefaultSyncModelAccessor spawnedObject =        GameObject.Find(\"Cube\").GetComponent<DefaultSyncModelAccessor>();\r\nSyncSpawnedObject cube = (SyncSpawnedObject ) spawnedObject.SyncModel; (I am not sure ??)\r\nVector3 position = Random.onUnitSphere * 2;\r\ncube.Transform.Position = position;\r\n }\r\n\r\nPlease help me to fix my problem,\r\nThanks,\r\nWoon ",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/501/comments",
    "author": "bobbycho",
    "comments": [
      {
        "user": "StephenHodgson",
        "created_at": "2017-02-06T19:25:13Z",
        "body": "Still trying to figure this out myself @bobbycho."
      },
      {
        "user": "bobbycho",
        "created_at": "2017-02-06T19:39:54Z",
        "body": "Thanks HodgsonSDAS. Please let me know when you resolve it.\r\n\r\nThanks again,\r\nWoon"
      },
      {
        "user": "bobbycho",
        "created_at": "2017-02-07T16:19:04Z",
        "body": "I figured it out. Once I changed the root of the spawned objects, synctransform did not work well.\r\nI fixed it.\r\n\r\nThanks,\r\nWoon"
      }
    ]
  },
  {
    "number": 469,
    "title": "Sharing with UNET scene runtime error in log, devices never connect",
    "created_at": "2017-01-22T23:54:14Z",
    "closed_at": "2017-01-25T07:42:55Z",
    "labels": [
      "Question"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/469",
    "body": "I'm trying to run the SharingWithUNET test scene on my devices but they can't connect to each other or the editor. The server is broadcasting, but the client never gets the broadcast. I see this error on the HoloLens from VS' output:\r\n\r\n\"host id out of bound id {-1} max id should be greater 0 and less than {1}\"\r\n\r\nAnyone else see this?",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/469/comments",
    "author": "flarb",
    "comments": [
      {
        "user": "StephenHodgson",
        "created_at": "2017-01-24T02:29:04Z",
        "body": "@darax, any ideas?"
      },
      {
        "user": "flarb",
        "created_at": "2017-01-25T02:13:01Z",
        "body": "I'm not sure this error message has anything to do with the reason why they can't connect. I've narrowed it down to something wrong with my actual LAN. If I connect my HoloLens devices via iPhone hotspot, they connect. Has to be some weird firewall setting."
      },
      {
        "user": "flarb",
        "created_at": "2017-01-25T07:42:55Z",
        "body": "Ah, we can close this....I turned off all firewalls (on my dev box and firewall) and now it works. "
      }
    ]
  },
  {
    "number": 456,
    "title": "Should we remove the unused ExtensibleInputModule branch?",
    "created_at": "2017-01-07T00:53:24Z",
    "closed_at": "2017-01-18T23:27:42Z",
    "labels": [
      "Question"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/456",
    "body": "Work for the ExtensibleInputModule has been merged into the Master branch.\r\n\r\nDoes it make since to keep this branch?",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/456/comments",
    "author": "StephenHodgson",
    "comments": [
      {
        "user": "jessemcculloch",
        "created_at": "2017-01-11T17:37:57Z",
        "body": "I think its time to clean it up, I cant see any reason to keep it"
      },
      {
        "user": "NeerajW",
        "created_at": "2017-01-18T20:07:47Z",
        "body": "Yes!"
      },
      {
        "user": "StephenHodgson",
        "created_at": "2017-01-18T21:23:52Z",
        "body": "@NeerajW yes we should remove, or yes we should keep it?"
      },
      {
        "user": "NeerajW",
        "created_at": "2017-01-18T22:37:21Z",
        "body": "Q: Should we remove the unused ExtensibleInputModule branch?\r\nA: Yes remove :)"
      }
    ]
  },
  {
    "number": 436,
    "title": "How can I Anchor the position on load scene?",
    "created_at": "2016-12-27T14:38:31Z",
    "closed_at": "2017-10-28T01:17:16Z",
    "labels": [
      "Question"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/436",
    "body": "The position when I load the next scene ,the position is changed, After mapping the room ,I find some position to place GameObjects, I use an empty GameObject with WorldAnchor and DonDestoryOnLoad Script On it to save the position,but when load to the next scene and get the position ,some Info has changed,Can you help me ? How to keep the virtual Object position in the real world,even I load scene  ",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/436/comments",
    "author": "WarrenMondeville",
    "comments": [
      {
        "user": "jessemcculloch",
        "created_at": "2017-08-15T21:20:17Z",
        "body": "@WarrenMondeville - Is this still something you need answers to?  or can we close this?"
      },
      {
        "user": "StephenHodgson",
        "created_at": "2017-10-28T01:17:16Z",
        "body": "Going to close this.  It's probably been archived by google by now."
      }
    ]
  },
  {
    "number": 310,
    "title": "Visual Studio Build fails in Unity 5.5 beta",
    "created_at": "2016-10-28T08:23:47Z",
    "closed_at": "2016-11-02T22:26:35Z",
    "labels": [
      "Question"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/310",
    "body": "Visual Studio builds are successful on the 5.4 but seem to be failing if the solution is being built from 5.5 beta version of Unity via WiFi deploy. It doesn't throw any error but says \"remote device is taking too long to respond\" and fails eventually. I migrated the 5.5 project to the stable Unity version(5.4) and built the VS solution and it deploys successfully like they used to originally. It's kind of annoying to switch between the versions because Holographic Remoting makes life so much easier and the scenes from 5.5 can't be opened in 5.4 coz of different versions. I'm assuming this is a Unity issue since it's in Beta,  Is this a known issue or am I doing something wrong?\n",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/310/comments",
    "author": "kotAPI",
    "comments": [
      {
        "user": "StephenHodgson",
        "created_at": "2016-10-28T13:51:20Z",
        "body": "Are you completely deleting your exported folder on each build?\n"
      },
      {
        "user": "kotAPI",
        "created_at": "2016-10-28T17:57:05Z",
        "body": "I've tried both, I did fresh builds and replaced old builds with the new ones. I've built a couple of other apps and they build perfectly with the beta. I've no clue why my project doesn't build. Do builds fail if the app is heavy? I'm currently using couple of heavy mesh(about 70mb) models in my project. \n"
      },
      {
        "user": "NeerajW",
        "created_at": "2016-10-31T17:04:49Z",
        "body": "@kotAPI I've deployed apps with over that and worked. Perhaps try deploying with fewer assets first if you think your WiFi is unable to handle so much data?\n"
      },
      {
        "user": "kotAPI",
        "created_at": "2016-11-01T14:00:29Z",
        "body": "@NeerajW you're probably right, the builds seem to be failing if the meshes are heavy. I think this question can be closed, thanks for the help guys.\n"
      }
    ]
  },
  {
    "number": 300,
    "title": "Failed to build appx from solution. Error code: 1",
    "created_at": "2016-10-20T20:36:59Z",
    "closed_at": "2016-10-26T13:59:38Z",
    "labels": [
      "Question"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/300",
    "body": "When using the build window and running in Parallels I am unable to build appx from solution. I've tried changing the target to x86 and the app builds and deploys fine from VS. I'm convinced this has something to do with the build directory.\n1. No spaces in targets or names\n2. Latest builds. \n3. 5.4 0f3\n4. Project resides on c:/ (not using mapped drive)\n",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/300/comments",
    "author": "markamccorkle",
    "comments": [
      {
        "user": "NeerajW",
        "created_at": "2016-10-20T22:06:38Z",
        "body": "Are you compiling to the default App directory that is used by the window?\nCould you also please paste the path of your app?\n"
      },
      {
        "user": "markamccorkle",
        "created_at": "2016-10-21T02:08:24Z",
        "body": "I tried creating a separate build directory. That worked so I simply removed the previous WindowsStoreApp directory and let it recreate the dir. That allows me to now build the solution successfully and the build shows below. However, I am unable to actually deploy the app now from the build window. \n\n_Build dir_\nC:\\Users\\user\\Source\\hololens\\HoloR\\WindowsStoreApp\n\nWhen attempting to install from the build window...\n**Without \"Uninstall first\" checked and manually removing the app from the device first.**\nError: \nSystem.Net.WebException: Error getting response stream (ReadDone1): ReceiveFailure ---> System.IO.IOException: EndRead failure ---> System.Net.Sockets.SocketException: An existing connection was forcibly closed by the remote host.\n\n**With \"Uninstall first\" checked.**\nError:\nSystem.NullReferenceException: Object reference not set to an instance of an object\n  at HoloToolkit.Unity.BuildDeployPortal.InstallApp (System.String appFullPath, ConnectInfo connectInfo, Boolean waitForDone) [0x00226] in C:\\Users\\markmccorkle\\Source\\hololens\\HoloR\\Assets\\HoloToolkit\\Build\\Editor\\BuildDeployPortal.cs:246 \n"
      },
      {
        "user": "darax",
        "created_at": "2016-10-21T16:17:37Z",
        "body": "I wonder if it has to do with USB on parallels. Can you deploy to 'device' from Visual Studio?  Did you have to do anything special (like give VS permission to talk to 127.0.0.1 port 10080 on your firewall?) to enable this?  \n"
      },
      {
        "user": "markamccorkle",
        "created_at": "2016-10-21T20:32:27Z",
        "body": "Building from VS works fine. \n"
      },
      {
        "user": "Hitomilras",
        "created_at": "2017-08-01T10:26:58Z",
        "body": "Build from VS works fine, may be, but we must pass the project in the form of .appx file and  we can't fix this issue for a long time :( \r\n\r\nCan someone help please :)?"
      },
      {
        "user": "StephenHodgson",
        "created_at": "2017-08-01T14:43:39Z",
        "body": "Please open a new issue with details of the errors. Thanks"
      }
    ]
  },
  {
    "number": 120,
    "title": "TextToSpeechManager.cs why Monobehavior instead of Singleton?",
    "created_at": "2016-07-14T16:13:46Z",
    "closed_at": "2016-07-18T18:31:22Z",
    "labels": [
      "Question"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/120",
    "body": "I didn't want to have to drop a TextToSpeechManager script throughout my project, so I converted it to a Singleton instead of a MonoBehavior. This seems far more intuitive to me, being able to bring up an instance of TextToSpeechManager throughout any script and just call SpeakText(). What was the reasoning behind Monobehavior instead?\n",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/120/comments",
    "author": "paravorheim",
    "comments": [
      {
        "user": "jwittner",
        "created_at": "2016-07-14T17:05:13Z",
        "body": "When @jbienz brought the TextToSpeechmanager(TST) it was originally built as a Singleton. The design issue was that the TST encapsulates the audio source, but there are compelling situations where you want to organize TST through many independent audio sources and the Singleton by design confuses this architecture. By encapsulating the audio source we also simplify the interface and keep responsibility for controlling AudioSource objects in the Asset configuration data of the Unity scene rather than in the script. \n\nOn the plus side for your situation, our implementation of Singleton caches the first instance of `<T>` it finds in the scene so you only have to drop an instance in the editor once, You can then go ahead and declare a Singleton<TST> in your script and use it. The binding will happen automatically on first access.\n\nLet me know if any of that is unclear!\n"
      },
      {
        "user": "jwittner",
        "created_at": "2016-07-14T17:07:06Z",
        "body": "I'm starting to think maybe we should drop the `Manager` from this type name.\n"
      },
      {
        "user": "paravorheim",
        "created_at": "2016-07-14T17:11:35Z",
        "body": "Yeah, I agree with your explanation. Thank you!\n"
      },
      {
        "user": "NeerajW",
        "created_at": "2016-07-18T16:00:48Z",
        "body": "Ok to close this issue?\n"
      }
    ]
  },
  {
    "number": 8693,
    "title": "Allow adding customized handles to bounds control",
    "created_at": "2020-09-28T12:18:22Z",
    "closed_at": "2022-08-25T02:15:33Z",
    "labels": [
      "Feature Request",
      "Help Wanted",
      "UX Controls - Bounds Control"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/8693",
    "body": "## Describe the problem\r\n\r\nWe're already creating handles via factory pattern and configurations in bounds control. Potentially users could create their own version of handles through this system. However what's missing is:\r\n- Some methods in handles might still be access restricted to internal \r\n- The logic for actually modifying the transform is still inside of the bounds control class. If we move that logic into the handles we could swap handles and logic easier.\r\nStretch goal: We're not limiting the handles to Translate\\Scale\\Rotate but instead have a more flexible way (list) of adding handles. That way a bounds control could be created with just having eg scale handles, or several different types of rotation handles depending on where they were created. (Stretch goal can be moved into separate issue)\r\n\r\n## Describe the solution you'd like\r\n\r\nUsers can plug their own handles into existing translation / scale / rotate handle configuration slots and bounds control uses those configurations to perform manipulation.\r\n\r\nHandles are not limited to the three available transform slots but there can be user defined amount of handles plugged into the system.\r\n\r\n## Describe alternatives you've considered\r\n\r\nUsers can plug their own handles into existing translation / scale / rotate handle configuration slots and bounds control uses those configurations to perform manipulation.\r\n\r\nHandles are limited to the three available transform slots.\r\n\r\n\r\n",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/8693/comments",
    "author": "thalbern",
    "comments": [
      {
        "user": "Zee2",
        "created_at": "2022-08-25T02:15:33Z",
        "body": "Handle customization is prefab-based in MRTK3 and quite flexible. Closing this as stale for now."
      }
    ]
  },
  {
    "number": 8081,
    "title": "NearInteractionGrabbable Ignores Child Colliders",
    "created_at": "2020-06-19T17:12:13Z",
    "closed_at": "2022-08-31T18:05:32Z",
    "labels": [
      "Bug",
      "Help Wanted",
      "Interactions",
      "Input System - Near Interaction"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/8081",
    "body": "## Describe the bug\r\n\r\n**NearInteractionGrabbable** only honors the colliders found on the same object where it is applied. This is different than **Rigidbody** which honors all colliders found in its children.\r\n\r\nIn my application I have an oscillating fan hologram with rotating head. This necessitates having two different colliders. One at the base and one that rotates with the head.\r\n\r\nWhen colliders only exist in the children, **NearInteractionGrabbable** does not work. However it's worth pointing out that far interactions through **ObjectManipulator** work fine with child colliders, as do **Rigidbodies**.\r\n\r\n## Expected behavior\r\n\r\nI would expect **NearInteractionGrabbable** to find and honor colliders in children. If not the entire child tree, at least immediate children. If necessary (and as an optimization strategy), **NearInteractionGrabbable** could skip the child search if it finds colliders on the immediate GameObject where it's applied. However, this should be clearly documented if implemented.\r\n\r\n## Your setup (please complete the following information)\r\n\r\n- Unity Version 2019.2.21f1\r\n- MRTK Version 2.4\r\n\r\n## Target platform (please complete the following information)\r\n\r\n- HoloLens 2",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/8081/comments",
    "author": "jbienzms",
    "comments": [
      {
        "user": "Zee2",
        "created_at": "2020-07-10T03:36:07Z",
        "body": "Hi, thanks for reporting this!\r\n\r\nI ran into a similar issue previously with an internal prototype, I brought it up with the team.\r\n\r\nThe workaround is that you can actually still do this, you just need to add another `NearInteractionGrabbable` on each child collider objects. Messy, but it works exactly as you'd expect."
      },
      {
        "user": "jbienzms",
        "created_at": "2020-07-10T21:58:18Z",
        "body": "Thanks for the workaround @Zee2. I really appreciate that. But yes, it does seem rather wasteful to add NearInteractionGrabbable for every object with a collider. The fan in my project has 3. Since this isn't required for a RigidBody, I'd love to see ObjectManipulator work the same way."
      },
      {
        "user": "Zee2",
        "created_at": "2020-07-13T20:13:10Z",
        "body": "Agreed. Definitely onboard with your assessment of the wastefulness.... I believe it is a result of how we use NearInteractionGrabbables to determine which objects can actually receive the interaction events; however, this doesn't line up with how Unity does child colliders. I'll bring this up with the team.\r\n\r\nEdit: With regard to the wastefulness; putting another NearInteractionGrabbable on each child collider _shoudn't_ actually have any adverse performance impact; the NearInteractionGrabbable is very lightweight and is basically just used as a marker for the object to signify that it can receive the relevant events. So, you should feel comfortable using the workaround in the meantime because it shouldn't cause perf issues for you."
      },
      {
        "user": "deibu",
        "created_at": "2020-10-02T00:26:14Z",
        "body": "I also ran into this issue with having buttons underneath an object with the ObjectManipulator component. I tried the workaround with adding NearInteractionGrabbables to my child objects, but it doesn't seem to work unless I also add an ObjectManipulator to them. Do you have any other ideas for a workaround when you don't want the child objects to have ObjectManipulator as well?"
      },
      {
        "user": "stale[bot]",
        "created_at": "2022-04-18T16:45:23Z",
        "body": "This issue has been marked as stale by an automated process because it has not had any recent activity. It will be automatically closed in 30 days if no further activity occurs. If this is still an issue please add a new comment with more recent details and repro steps.\n"
      },
      {
        "user": "Zee2",
        "created_at": "2022-08-31T18:05:32Z",
        "body": "XRI handles this gracefully by being able to explicitly associate colliders with individual interactables, even with complex nesting hierarchies."
      }
    ]
  },
  {
    "number": 8080,
    "title": "TapToPlace.StartPlacement Ignored if Called Before Start",
    "created_at": "2020-06-19T17:02:05Z",
    "closed_at": "2020-07-16T22:00:12Z",
    "labels": [
      "Solvers - General",
      "Bug",
      "Help Wanted"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/8080",
    "body": "## Describe the bug\r\n\r\nIf **StartPlacement** is called on **TapToPlace** before the **TapToPlace** component has started, the request will never be fulfilled and no error is generated.\r\n\r\nThis is due to an `If` condition in the `Start` method of **TapToPlace**. The condition checks to see if `AutoStart` is **false**. If `AutoStart` is **false**, `SolverHandler.UpdateSolvers` is also set to **false**.\r\n\r\n## Expected behavior\r\n\r\nIn Unity it's not very easy to control the starting order of behaviors. Therefore, a behavior that references and uses **TapToPlace** may get started before **TapToPlace** itself. If the controlling behavior calls **StartPlacement** before **TapToPlace** has started, I would expect **TapToPlace** to begin working once it has started.\r\n\r\nOne may ask \"Why not just set `TapToPlace.AutoStart` to true?\" The problem is that the controlling behavior may decide whether to start in Placing mode or Creating mode based on previously saved data. Therefore whether or not TapToPlace should start is up to the calling component. If the calling component just sets `AutoStart = true` in this case, that may not work either if TapToPlace was actually started first.\r\n\r\n## Your setup (please complete the following information)\r\n\r\n- Unity Version 2019.2.21f1\r\n- MRTK Version 2.4\r\n\r\n## Target platform (please complete the following information)\r\n\r\n- HoloLens 2",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/8080/comments",
    "author": "jbienzms",
    "comments": [
      {
        "user": "wiwei",
        "created_at": "2020-06-23T02:51:03Z",
        "body": "Tagging as help wanted since this should be a good first issue to pick up."
      },
      {
        "user": "Synergiz-RROUINVY",
        "created_at": "2020-07-07T14:57:43Z",
        "body": "A simple and dirty delay of 10 ms (or more depending of your machine) between component activation and StartPlacement() can be a temporary workaround."
      },
      {
        "user": "jbienzms",
        "created_at": "2020-07-07T15:53:49Z",
        "body": "The start order and length of start time will vary by each machine. I do not believe that a hard-coded delay of 10 ms will solve this problem for good.\r\n\r\nA more resilient approach IMO would be a way of knowing if the behavior has been Started. In StartPlacing, if the behavior hasn't started the method would set a flag called startRequested. This flag would be checked during Start. Or something similar to this."
      }
    ]
  },
  {
    "number": 7597,
    "title": "Initial Policheck pass on mrtk repo",
    "created_at": "2020-03-30T16:38:29Z",
    "closed_at": "2020-06-18T21:22:58Z",
    "labels": [
      "Documentation",
      "Help Wanted"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/7597",
    "body": "## Describe the issue\r\nPipelines are set up for policheck but initial filtering needs to be done.\r\n",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/7597/comments",
    "author": "thalbern",
    "comments": [
      {
        "user": "wiwei",
        "created_at": "2020-06-18T21:22:58Z",
        "body": "Closing this one out since this was completed"
      }
    ]
  },
  {
    "number": 7386,
    "title": "NearInteractionGrabbable triggers exception when ManipulationHandler Component is disabled",
    "created_at": "2020-02-25T08:20:15Z",
    "closed_at": "2020-07-23T17:45:49Z",
    "labels": [
      "Bug",
      "Help Wanted"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/7386",
    "body": "## Describe the bug\r\n\r\n`InvalidOperationException: NearInteractionGrabbable requires a BoxCollider, SphereCollider, CapsuleCollider or a convex MeshCollider on an object. Otherwise grab interaction will not work correctly.`\r\n\r\nOn an active GameObject with disabled ManipulationHandler Component.\r\n\r\n`Collider[] colliders = gameObject.GetComponents<Collider>();`\r\n\r\n**the `GetComponent `does not include disabled components, an alternative could be to use `GetComponentsInChildren(includeInactive:true)` which has an extra param (sadly the GetComponent does not have this extra param)**\r\ni don't know if searching in children would have any side effect here.\r\n\r\n## To reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n1. Create a GameObject with a ManipulationHandler\r\n2. Disable the ManipulationHandler by hand or by code\r\n3. When enabling the gameobject, the exception got triggered\r\n\r\n## Alternative workaround\r\nby code, Enable gameobject first, then disable component\r\n\r\n## Expected behavior\r\n\r\nno exception\r\n\r\n## Your setup (please complete the following information)\r\n\r\n- Unity Version [e.g. 2018.4.13f1]\r\n- MRTK Version 2.2/2.3\r\n\r\n",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/7386/comments",
    "author": "gilbdev",
    "comments": [
      {
        "user": "MaxWang-MS",
        "created_at": "2020-07-16T01:05:29Z",
        "body": "Hi @gilbdev, I cannot reproduce the issue using Unity 2018.4.24f1 and MRTK 2.4, could you try to update to the latest versions and see if the problem still persists? Also, if that still happens please give us a more detailed repro procedure, as the current one is slightly confusing (the supposedly buggy NearInteractionGrabbable script is not mentioned in the repro procedure)"
      },
      {
        "user": "MaxWang-MS",
        "created_at": "2020-07-23T17:45:49Z",
        "body": "Please reopen the issue if you are still encountering this problem."
      }
    ]
  },
  {
    "number": 7274,
    "title": "ObjectManipulator should be more general to support non-hand inputs",
    "created_at": "2020-02-10T20:45:47Z",
    "closed_at": "2022-10-05T06:03:25Z",
    "labels": [
      "Feature Request",
      "Help Wanted",
      "UX Controls - ObjectManipulator"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/7274",
    "body": "## Describe the problem\r\n\r\nI would like to scale, rotation, and translate objects using inputs besides hands (such as a game pad). If the object has a ManipulationHandler, it would seem logical to use it to perform the transforms so that they will obey the active constraints, and also to trigger related events (OnManipulationStarted, ...).\r\n\r\nCurrently ManipulationHandler contains hard-coded logic specific to one and two-handed gestures and does not provide public methods for applying transforms through other inputs.\r\n\r\n## Describe the solution you'd like\r\n\r\nIn my opinion ManipulationHandler should be more general, handling the application of transforms to an object along with the related constraints and side effects. The logic related to specific input controls (such as hands) should be modular and extensible, since transforms could be triggered by anything including game pads, voice commands, or other input methods.\r\n\r\n## Describe alternatives you've considered\r\n\r\nI have considered manipulating object transforms directly. Unfortunately, this bypasses the pre-existing constraints and events in the manipulation handler.",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/7274/comments",
    "author": "adambehringer",
    "comments": [
      {
        "user": "adambehringer",
        "created_at": "2020-02-11T00:18:21Z",
        "body": "Note that this has accessibility implications as well."
      },
      {
        "user": "Alexees",
        "created_at": "2020-02-18T16:51:33Z",
        "body": "Related #7104"
      },
      {
        "user": "polar-kev",
        "created_at": "2020-06-15T22:23:50Z",
        "body": "ObjectManipulator replaces ManipulationHandler as of 2.4.0 but this issue is still relevant."
      },
      {
        "user": "david-c-kline",
        "created_at": "2021-04-07T17:27:32Z",
        "body": "This looks to be for non-VR / non-Hand controls (ex: xbox controller). Things to consider:\r\n\r\n- Controls to use to engage a behavior (ex: Press A and use triggers to resize)\r\n- How to target the specific manipulation handle (ex: upper right, front corner)?\r\n- Accessibility considerations (ex: difficulty holding a control while adjusting another)"
      },
      {
        "user": "adambehringer",
        "created_at": "2021-04-07T17:46:40Z",
        "body": "Generalizing the behavior of ObjectManipulator would aid the integration of controller such as the Xbox Controller. However, it would also be useful for things like speech commands (\"scale up the blue box by 50%\") or indirect controls such as a holographic control panel that manipulates 3D objects in the scene.\r\n\r\nIn both those cases, selecting specific handles is probably not part of the user flow. So I would suggest that manipulations should be accessible directly through an API, and not exclusively through the manipulations widgets. I'd still want the API calls to be limited by the manipulation constraints though. Part of the issue with bypassing ObjectManipulator is missing out on those constraints."
      },
      {
        "user": "RogPodge",
        "created_at": "2021-07-14T21:14:01Z",
        "body": "This is an excellent suggestion and we'll make sure to consider it for the next evolution of our MRTK UI tools!"
      },
      {
        "user": "RogPodge",
        "created_at": "2022-04-10T21:08:03Z",
        "body": "This is officially a reality with MRTK v3. Look forward to using the object manipulator with controllers, eye gaze and more in the upcoming version.\r\n\r\nController support still pending but the hooks for it are reality available."
      },
      {
        "user": "Zee2",
        "created_at": "2022-10-05T06:03:25Z",
        "body": "This is definitely a reality in MRTK3! ObjectManipulator works uniformly across all input modalities, including any custom interactors you might cook up yourself."
      }
    ]
  },
  {
    "number": 5895,
    "title": "SearchForAndEnableExistingPlayspace throws an exception",
    "created_at": "2019-09-06T09:26:16Z",
    "closed_at": "2019-10-14T06:46:46Z",
    "labels": [
      "Bug",
      "Help Wanted"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/5895",
    "body": "## Describe the bug\r\n\r\nMixedRealityPlayspace automatically register to EditorSceneManager.sceneClosed.\r\n\r\nI've my own editor 'play' overide (basically hooking the Play button, to launch a rootscene-with mixedrealitytoolkit and playspace), even if that rootscene is not currently active or loaded.\r\nduring that hook, i call UnityEditor.SceneManagement.EditorSceneManager:OpenScene\r\nwhich will trigger the event EditorSceneManagerSceneClosed that is catched by MixedRealityPlayspace.\r\n\r\n```\r\nArgumentException: The scene is not loaded.\r\nUnityEngine.SceneManagement.Scene.GetRootGameObjects (System.Collections.Generic.List`1[T] rootGameObjects) (at C:/buildslave/unity/build/Runtime/Export/SceneManager/Scene.cs:91)\r\nUnityEngine.SceneManagement.Scene.GetRootGameObjects () (at C:/buildslave/unity/build/Runtime/Export/SceneManager/Scene.cs:75)\r\nMicrosoft.MixedReality.Toolkit.Utilities.RuntimeSceneUtils+<GetRootGameObjectsInLoadedScenes>d__2.MoveNext () (at Assets/MixedRealityToolkit/Utilities/Scenes/RuntimeSceneUtils.cs:56)\r\nMicrosoft.MixedReality.Toolkit.MixedRealityPlayspace.SearchForAndEnableExistingPlayspace (System.Collections.Generic.IEnumerable`1[T] rootGameObjects) (at Assets/MixedRealityToolkit/Utilities/MixedRealityPlayspace.cs:274)\r\nMicrosoft.MixedReality.Toolkit.MixedRealityPlayspace.SceneManagerSceneUnloaded (UnityEngine.SceneManagement.Scene scene) (at Assets/MixedRealityToolkit/Utilities/MixedRealityPlayspace.cs:247)\r\nUnityEngine.SceneManagement.SceneManager.Internal_SceneUnloaded (UnityEngine.SceneManagement.Scene scene) (at C:/buildslave/unity/build/Runtime/Export/SceneManager/SceneManager.cs:253)\r\nUnityEditor.SceneManagement.EditorSceneManager:OpenScene(String, OpenSceneMode)\r\n```\r\n\r\n## To reproduce\r\n\r\nSteps to reproduce the behavior:\r\nhopefully this is the minimal code that should help reproduce :\r\n```\r\n[InitializeOnLoad]\r\npublic static class PlayService\r\n{\r\n\tstatic PlayService()\r\n\t{\r\n\t\tEditorApplication.playModeStateChanged += OnPlaymodeChanged;\r\n\t}\r\n\tprivate static void OnPlaymodeChanged(PlayModeStateChange state)\r\n\t{\r\n\t\tswitch (state)\r\n\t\t\t{\r\n\t\t\tcase PlayModeStateChange.ExitingEditMode:\r\n\t\t\tEditorSceneManager.OpenScene(SceneUtility.GetScenePathByBuildIndex(0), OpenSceneMode.Single);\r\n\t\t\tbreak;\r\n\t\t\t}\r\n\t}\r\n}\r\n```\r\nthen : click on Unity default Play Button.\r\nwhen calling OpenScene, it will first unload all scenes, hence there are no scenes opened anymore, which leads to the exception when trying to get gameobjects.\r\n\r\n(be sure to uncheck \"clear on play\" in the unity console, as the error will be cleared just before entering play mode)\r\n\r\n## Expected behavior\r\n\r\nno exception\r\n\r\n\r\n## Your Setup (please complete the following information)\r\n\r\n- Unity Version [2018.4.2f1]\r\n- MRTK Version [v2.0.0]\r\n\r\n## Target Platform (please complete the following information)\r\n\r\n- HoloLens\r\n\r\n",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/5895/comments",
    "author": "gilbdev",
    "comments": [
      {
        "user": "gilbdev",
        "created_at": "2019-09-06T09:39:31Z",
        "body": "potential fix:\r\nadd same 'hack' in `RuntimeSceneUtils.GetRootGameObjectsInLoadedScenes` that is in EditorSceneUtils\r\n```\r\n\t\t\t\tif (!loadedScene.isLoaded)\r\n\t\t\t\t{   // Oh, Unity.\r\n\t\t\t\t\tcontinue;\r\n\t\t\t\t}\r\n```\r\n\r\nnote to myself: i should probably do some nice PRs"
      },
      {
        "user": "wiwei",
        "created_at": "2019-09-09T16:52:34Z",
        "body": "@gilbdev, if you feel good about sending out a PR, we can definitely review it and get it in (@Railboy because this is in some of the scene work that he did)"
      }
    ]
  },
  {
    "number": 5832,
    "title": "Input logger scene for new devices",
    "created_at": "2019-08-30T15:20:07Z",
    "closed_at": "2019-10-30T19:16:48Z",
    "labels": [
      "Feature Request",
      "Help Wanted"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/5832",
    "body": "## Describe the problem\r\n\r\nNow that there's active work on the workflow for adding additional devices to the MRTK it's rather tedious to get all the input reading from new controllers.\r\n\r\n## Describe the solution you'd like\r\n\r\nOne Testscene with a big panel one can view all the possible inputs on the device and write them down to create a new DeviceManager.\r\nNot all input comes from the Unity.Input class, so it should probably be generic enough that you maybe just plug a different script on it and reading comes from whatever new API there is.\r\n\r\n## Describe alternatives you've considered\r\n\r\nlogging everything to the console and read that\r\n",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/5832/comments",
    "author": "Alexees",
    "comments": [
      {
        "user": "wiwei",
        "created_at": "2019-09-04T00:14:20Z",
        "body": "Tagging with Help Wanted - definitely would be an awesome thing to have for making new device onramp easier."
      },
      {
        "user": "keveleigh",
        "created_at": "2019-09-06T17:20:45Z",
        "body": "I have basically this scene lying around from the early vNext days. I'll go find it and clean it up!"
      },
      {
        "user": "julenka",
        "created_at": "2019-09-23T23:53:49Z",
        "body": "@Davidkline-ms please don't close this issue until the scene in your PR #5902 has a scene description panel and a doc file."
      }
    ]
  },
  {
    "number": 5763,
    "title": "Code execution when opening ParabolicPointer in prefab mode leading to error",
    "created_at": "2019-08-23T13:19:33Z",
    "closed_at": "2019-09-01T04:31:30Z",
    "labels": [
      "Editor",
      "Bug",
      "Help Wanted",
      "Input System - Pointer"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/5763",
    "body": "## Describe the bug\r\n\r\nWhen opening ParabolicPointer in prefab mode, an error is thrown because the ParabolocTeleportPointer has the ExecuteAllways attribute set, calls Start at that moment and soemwhere down the line Destroy is called, which is not allowed and maybe not even desired:\r\n\r\n```\r\nDestroy may not be called from edit mode! Use DestroyImmediate instead.\r\nAlso think twice if you really want to destroy something in edit mode. Since this will destroy objects permanently.\r\nUnityEngine.Object:Destroy(Object)\r\nMicrosoft.MixedReality.Toolkit.Input.<Start>d__18:MoveNext() (at Assets/MixedRealityToolkit/MixedRealityToolkit.SDK/Features/UX/Scripts/Pointers/BaseControllerPointer.cs:167)\r\nSystem.Runtime.CompilerServices.AsyncVoidMethodBuilder:Start(<Start>d__18&)\r\nMicrosoft.MixedReality.Toolkit.Input.BaseControllerPointer:Start()\r\nMicrosoft.MixedReality.Toolkit.Teleport.TeleportPointer:<>n__0()\r\nMicrosoft.MixedReality.Toolkit.Teleport.<Start>d__21:MoveNext() (at Assets/MixedRealityToolkit/MixedRealityToolkit.SDK/Features/UX/Scripts/Pointers/TeleportPointer.cs:110)\r\nSystem.Runtime.CompilerServices.AsyncVoidMethodBuilder:Start(<Start>d__21&)\r\nMicrosoft.MixedReality.Toolkit.Teleport.TeleportPointer:Start()\r\n```\r\n\r\nI also received a different error once I created a variant, but I could not reproduce it a second time\r\n\r\n## To reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n1. Open ParabolicPointer in prefab mode\r\n\r\n## Expected behavior\r\n\r\nNo errors\r\n\r\n## Your Setup (please complete the following information)\r\n\r\n- Unity Version  2018.4.6f1\r\n- MRTK mrtk_development\r\n\r\n## Target Platform (please complete the following information)\r\n\r\n- Editor\r\n",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/5763/comments",
    "author": "Alexees",
    "comments": [
      {
        "user": "Troy-Ferrell",
        "created_at": "2019-08-23T17:06:47Z",
        "body": "So does *PokePointer* prefab, *DefaultControllerPointer* prefab.  It's under `BaseControllerPointer.cs`\r\n\r\nThis is more or less an editor only bug"
      },
      {
        "user": "Alexees",
        "created_at": "2019-08-25T16:46:28Z",
        "body": "I'm not sure if this is related, but creating either a full copy or a variant of the ParabolicPointer and using it instead of it has some really weird behaviour.\r\nAs soon as you run the game, NullReferenceExceptions are thrown. Checking the \"original\" prefab shows that the game has added a cursor to it.\r\nAltering a prefab is something that should never happen and for some reason only happens to a copy or variant."
      }
    ]
  },
  {
    "number": 5674,
    "title": "Add ability to set min/max values for pinch slider",
    "created_at": "2019-08-15T20:27:32Z",
    "closed_at": "2022-08-31T17:32:00Z",
    "labels": [
      "UX Controls - General",
      "Feature Request",
      "Help Wanted",
      "UX Controls - Slider"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/5674",
    "body": "## Overview\r\nThe Pinch Slider's min / max values are currently hard coded to 0 and 1. But what if I want a slider to control a value from -5 to 5? I need to write my own component. It would be nice if instead we could configure the min / max values directly on pinch slider.\r\n\r\n## New Fields\r\nThe following new public properties would be added, with private serialized backers:\r\n\r\n- MinValue - minimum value of slider. Default is 0.\r\n- MaxValue - maximum value of slider. MaxValue > MinMvalue. Default is 1.\r\n- Value would be updated so that MinValue <= Value <= MaxValue\r\n\r\n## Tests to Add\r\n- [ ] If code tries to set  MinValue > MaxValue, throw and error\r\n- [ ] When Value gets updated, verify that slider moves to correct position. Set Min = -1, Max = 1, then set value to 0. Verify that value thumb is at correct position. Test for other Min and Max values.\r\n- [ ] Move slider with hand. Change Min and Max Values. Check that the Value of the slider is correct. If slider is in middle and min = 2, max = 4, then value should be 3. If min = 3 and max = 11 then value should be 7.\r\n\r\n## Documentation to Add\r\n- [ ] Add docs describing min and max value fields\r\n",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/5674/comments",
    "author": "julenka",
    "comments": [
      {
        "user": "Zee2",
        "created_at": "2022-08-31T17:32:00Z",
        "body": "Duplicate of #10803 ."
      }
    ]
  },
  {
    "number": 5398,
    "title": "UI Slider only pinchable",
    "created_at": "2019-07-22T13:03:57Z",
    "closed_at": "2022-08-25T02:43:01Z",
    "labels": [
      "UX Controls - General",
      "Feature Request",
      "Help Wanted",
      "UX Controls - Slider"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/5398",
    "body": "## Describe the bug\r\n\r\nUsing Unity UI Slider allows you to air-tap on one value to choose it with the gaze cursor on HoloLens 1 with MRTK 1/HTK . Now with MRTK V2 you have the \"Pinch slider\" behaviour, the value is handled by your hand position.\r\n\r\n## To reproduce\r\n\r\nSteps to reproduce the behavior:\r\n\r\n1. Create a Canvas/UI environnement for HoloLens.\r\n2. Place a slider. \r\n3. Try to air-tap on a specific value to select it.\r\n4. Don't move your gaze and airtap with different hand positions.\r\n\r\n## Expected behavior\r\n\r\nWhen you click (air-tap) a value on a UI slider,  this value should be selected.\r\n\r\n## Your Setup (please complete the following information)\r\n\r\n- Unity Version 2018.3.14f1\r\n- MRTK Version RC2.1\r\n\r\n## Target Platform (please complete the following information)\r\n\r\n- HoloLens\r\n",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/5398/comments",
    "author": "Kent1LG",
    "comments": [
      {
        "user": "wiwei",
        "created_at": "2019-08-20T16:56:53Z",
        "body": "@julenka do you know what the usability stuff says about how this should work? i.e. is the snap to location not enabled because of lack of sufficient precision?"
      },
      {
        "user": "julenka",
        "created_at": "2019-08-22T20:01:59Z",
        "body": "We haven't yet explored this question. Many sliders in traditional 2D GUI have this behavior. The question is whether it makes sense for a pinch slider, in 3D. I could see it making sense if you instead of pinching the slider poked to a specific value. However whether a pinch should auto snap to a given value is an open question. I would love to see a prototype or a pull request of this as an option in the slider and give it a try! That's the best thing to do. \r\n\r\nShouldn't be too hard to prototype, however core MRTK devs are pretty focused on fixing existing bugs in behavior and adding docs vs. adding new features for the next month or so. This would be a great bug for somebody interested in contributing to MRTK to try!"
      },
      {
        "user": "Zee2",
        "created_at": "2022-08-25T02:43:01Z",
        "body": "I believe all sliders in MRTK2/3 are all pokable and pinchable, with optional snapping."
      }
    ]
  },
  {
    "number": 5202,
    "title": "BoundingBox toggleable collider",
    "created_at": "2019-07-04T06:41:53Z",
    "closed_at": "2022-10-13T19:04:04Z",
    "labels": [
      "Feature Request",
      "Help Wanted",
      "UX Controls - Bounds Control"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/5202",
    "body": "## Describe the problem\r\n\r\nIt's not always desirable to active the BoundingBox via its own BoxCollider. Because of this collider any interaction is blocked for the actual target object, meaning:\r\n- you can't click it\r\n- you cannot let your gaze move across the actual surface\r\n\r\n## Describe the solution you'd like\r\n\r\nIt should be possible to disable the BoundingBox collider in favor of the objects collider. The BoundingBox can be activated via its Active property.\r\n\r\n## Describe alternatives you've considered\r\n\r\nAdding the whole BoundingBox only at runtime. But that's unfeasible. the box initializes a few things in it's Start method, so if you want to for example set a different maximum scale, you need to yield for that to happen.\r\n\r\n## Additional context\r\n\r\nI am not entirely sure why the BoundingBox is so tightly coupled with their targets. The old toolkit created a BoundingBox that could be used with different object, depending on which one you chose it should operate on, or am I missing something here?",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/5202/comments",
    "author": "Alexees",
    "comments": [
      {
        "user": "Zee2",
        "created_at": "2022-10-13T19:04:04Z",
        "body": "MRTK3 can use the object's collider for BoundsControl."
      }
    ]
  },
  {
    "number": 5028,
    "title": "BoundingBox uses null check on structs",
    "created_at": "2019-06-24T14:17:17Z",
    "closed_at": "2019-07-24T23:39:40Z",
    "labels": [
      "Bug",
      "Help Wanted"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/5028",
    "body": "## Describe the bug\r\n\r\nTwo Vector3 variables (maximumScale, minimumScale) are checked for null:\r\n\r\n```\r\n        public float ScaleMaximum\r\n        {\r\n            get\r\n            {\r\n                return maximumScale != null ? maximumScale.x : scaleMaximum;\r\n            }\r\n        }\r\n\r\n        public float ScaleMinimum\r\n        {\r\n            get\r\n            {\r\n                return minimumScale != null ? minimumScale.x : scaleMinimum;\r\n            }\r\n        }\r\n```\r\n\r\nI would have fixed it myself, but I don't know what the coding convention says about nullables.\r\n",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/5028/comments",
    "author": "Alexees",
    "comments": [
      {
        "user": "wiwei",
        "created_at": "2019-06-26T17:08:19Z",
        "body": "Yeah, this actually just doesn't make any sense. It would make a lot of sense to just remove the null checks here. We should fix this up, but also marking as Help Wanted since it's a relatively simple thing to do."
      },
      {
        "user": "wiwei",
        "created_at": "2019-07-24T23:39:40Z",
        "body": "Closing this issue, as the linked PR has gone in."
      }
    ]
  },
  {
    "number": 4823,
    "title": "Hololens 2 System keyboard for Unity Editor",
    "created_at": "2019-06-10T21:54:09Z",
    "closed_at": "2020-04-07T18:05:56Z",
    "labels": [
      "Feature Request",
      "Help Wanted"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/4823",
    "body": "In MRTK with first HoloLens it was possibly to use the holographic keyboard within the Unity Editor.\r\nIn MRTKv2 for HoloLens 2 using the keyboard in the editor is no longer possible due to the leveraging of the OS's keyboard (which is great). Would it be possible to add a holographic keyboard from original MRTK skinned like the new HoloLens OS to be used when in the Unity Editor?\r\n",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/4823/comments",
    "author": "derekfreed",
    "comments": [
      {
        "user": "Alexees",
        "created_at": "2019-11-05T08:02:45Z",
        "body": "I've been working on porting the HTK keyboard over #6466"
      },
      {
        "user": "julenka",
        "created_at": "2020-04-07T18:05:56Z",
        "body": "Fixed in #6492 "
      }
    ]
  },
  {
    "number": 4469,
    "title": "Xbox Controller ManipulationHandler Using Bumpers should move object forward / backward",
    "created_at": "2019-05-18T01:28:15Z",
    "closed_at": "2021-11-11T23:18:27Z",
    "labels": [
      "Feature Request",
      "Help Wanted",
      "Interactions",
      "Input - Xbox Controller"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/4469",
    "body": "In the Mixed Reality Shell, using a gamepad controller has the following behavior:\r\n\r\n- Joystick moves the object up/down/left/right in camera space\r\n- Bumpers move the object forward/back\r\n- Object can be rotated using secondary bumpers\r\n\r\nAfter #4398 the gamepad will move the object up/down/left/right in camera space, but will not move it forward/backward or rotate the object in camera space.\r\n\r\nWe should either create a new component \"GamepadManipulation\", or add functionality to ManipulationHandler, to match the shell.",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/4469/comments",
    "author": "julenka",
    "comments": [
      {
        "user": "polar-kev",
        "created_at": "2021-11-11T23:18:27Z",
        "body": "In MRTK v3, xbox controllers can move, rotate and pinch objects."
      }
    ]
  },
  {
    "number": 4310,
    "title": "Public properties in SurfaceMagnetism are missing",
    "created_at": "2019-05-13T11:51:15Z",
    "closed_at": "2019-06-24T10:01:57Z",
    "labels": [
      "Solvers - General",
      "Feature Request",
      "Help Wanted"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/4310",
    "body": "## Describe the bug\r\n\r\nNot exactly a bug per se, but while the SolverHandler, RadialView, Orbital, and a couple other Solvers have their private properties also exposed as public properties, that is not the case for SurfaceMagnetism. The only public accessible property is OnSurface.\r\nI want to add a SurfaceMagnetism Component and setup its variables during runtime, which is not possible currently.\r\n\r\n## To reproduce\r\n\r\nTake a look at the SurfaceMagnetism class.\r\n\r\n## Expected behavior\r\n\r\nPublic Properties to all the private variables that can be edited in the Inspector in Unity.\r\n\r\n\r\n## Setup\r\n\r\n- Unity 2018.3.14f\r\n- MRTK v2.0.0 RC1 Refresh\r\n",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/4310/comments",
    "author": "thedevleon",
    "comments": [
      {
        "user": "wiwei",
        "created_at": "2019-05-14T22:58:15Z",
        "body": "@cre8ivepark @keveleigh  do you have any history/background for why these variables weren't made public? Seems like a fairly obvious extension point that we should enable."
      },
      {
        "user": "keveleigh",
        "created_at": "2019-05-15T00:17:15Z",
        "body": "I'm not aware of any specific reason. I know other solvers have had public properties added over time, so it's possible this is one that hasn't been worked on yet."
      },
      {
        "user": "Troy-Ferrell",
        "created_at": "2019-06-24T10:01:57Z",
        "body": "This is a dupe of #4650 "
      }
    ]
  },
  {
    "number": 4260,
    "title": "UnityTouchController controller should be Handedness.None",
    "created_at": "2019-05-10T00:45:14Z",
    "closed_at": "2020-12-25T14:13:53Z",
    "labels": [
      "Input System - General",
      "Bug",
      "Help Wanted",
      "Stale"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/4260",
    "body": "Note: There is some special-case handling in BaseDeviceManager.RequestPointers for Handedness.Any which should be looked into.\r\n\r\n[MixedRealityController(\r\n    SupportedControllerType.TouchScreen,\r\n    new[] { Handedness.Any })] // should be None as Any is a combination of Handedness.Left | Right | Other\r\npublic class UnityTouchController : BaseController\r\n{\r\n...\r\n}",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/4260/comments",
    "author": "chbecker-ms",
    "comments": [
      {
        "user": "chbecker-ms",
        "created_at": "2019-05-10T00:45:22Z",
        "body": "Comment from Daniel:\r\n\r\nThis is not actually a bug and does not cause any problems, and should be done for consistency reasons. Sometimes we use Handedness.Any and sometimes we use Handedness.None if there is no designated handedness for a controller per se."
      },
      {
        "user": "chbecker-ms",
        "created_at": "2019-05-10T00:45:29Z",
        "body": "Ported from internal database."
      },
      {
        "user": "wiwei",
        "created_at": "2019-05-15T00:32:43Z",
        "body": "Seems like a good candidate for anyone to jump in and help out."
      },
      {
        "user": "stale[bot]",
        "created_at": "2020-02-20T03:39:06Z",
        "body": "This issue has been marked as stale by an automated process because it has not had any recent activity. It will be automatically closed in 30 days if no further activity occurs. If this is still an issue please add a new comment with more recent details and repro steps.\n"
      },
      {
        "user": "stale[bot]",
        "created_at": "2020-03-21T03:55:56Z",
        "body": "This issue has been closed by an automated process because it is stale. If this is still an issue please add a new comment with more recent details and repro steps.\n"
      },
      {
        "user": "stale[bot]",
        "created_at": "2020-12-25T14:13:32Z",
        "body": "This issue has been closed by an automated process because it is stale. If this is still an issue please add a new comment with more recent details and repro steps.\n"
      }
    ]
  },
  {
    "number": 4257,
    "title": "Can't see hand mesh when simulated in editor",
    "created_at": "2019-05-10T00:29:29Z",
    "closed_at": "2021-11-11T21:53:43Z",
    "labels": [
      "Feature Request",
      "Help Wanted",
      "Input Simulation"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/4257",
    "body": "Set hand visualization in Hand Tracking Profile to just be the mesh (make all joints null).\r\nSimulate hands in editor using mouse + keyboard\r\nExpected: I see the mesh, or at least some hand joint visualization so that I cdan see what my simulated hand is doing\r\n\r\nActual: I see nothing.\r\n\r\n\r\nFrom Lukas:\r\nJulia, isn't the hand mesh provided entirely through the Mirage API?\r\n\r\nOnly WindowsMixedRealityController raises the HandMeshUpdated event, using data obtained from SpatialInteractionSourceState through the handMeshObserver. The \"hand\" mesh prefab appears to be just a cube, with actual geometry generated at runtime from vertex buffers. So we couldn't use it directly for simulating the hand.\r\n\r\nI've been playing with the idea of getting an actual rigged hand model working, with a SkinnedMeshRenderer and regular bone objects. This could work both for simulating a human hand in AR as well as VR hands in various shapes and sizes.\r\n\r\nThe tricky part here is getting the deformation bones to line up properly with the joints as reported by the input system, especially when considering that different devices may use different joint models. When directly attaching deformation bones to the joint objects it leads to stretching and/or gaps because the rest pose doesn't match.\r\n\r\nAlso the orientation of joint objects in the BaseHandVisualizer is computed with -Z=forward, which doesn't match what DCC tools do (Blender uses Y for bone direction, Maya/Max use X). So the most robust solution for transferring tracked or simulated joints onto the hand model would probably be a set of LookAt constraints on the bones to make them follow joints, rather than copying transforms directly.\r\n\r\nFrom Julia:\r\nI was thinking what you were saying -- a rigged hand mesh. You're right that the mesh is provided by the Mirage API. I actually don't think we even need this for ship necessarily so I moved it back to P3. It's really a nice to have.",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/4257/comments",
    "author": "chbecker-ms",
    "comments": [
      {
        "user": "chbecker-ms",
        "created_at": "2019-05-10T00:29:40Z",
        "body": "Ported from internal database."
      },
      {
        "user": "wiwei",
        "created_at": "2019-05-15T00:36:26Z",
        "body": "Nice to have, would tag with \"Help Wanted\" but I think it's a fairly significant chunk of work (@lukastoenneMS correct me if I'm wrong here)"
      },
      {
        "user": "polar-kev",
        "created_at": "2021-11-11T21:53:43Z",
        "body": "Closing since there is now a rigged hand visualizer in v2 that meets this need."
      }
    ]
  },
  {
    "number": 4255,
    "title": "Add a Solver Tracked Object option for the tip of a pointer",
    "created_at": "2019-05-09T21:32:53Z",
    "closed_at": "2020-04-13T17:23:23Z",
    "labels": [
      "Solvers - General",
      "Feature Request",
      "Help Wanted"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/4255",
    "body": "## Describe the problem\r\n\r\nI'd like to position an object at the tip of a pointer that I'm using on an articulated hand. It would be nice if I could just pick this like I pick a controller point.\r\n\r\n## Describe the solution you'd like\r\n\r\nTracked Object To Reference could be set to \"Right Pointer\", \"Left Pointer\", or \"Gaze Pointer\".\r\n",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/4255/comments",
    "author": "Ecnassianer",
    "comments": [
      {
        "user": "danielescudero",
        "created_at": "2019-05-30T22:11:27Z",
        "body": "Since headgaze is not the only option anymore it makes sense for solvers to follow not only hands but pointers."
      },
      {
        "user": "julenka",
        "created_at": "2020-04-13T17:23:23Z",
        "body": "Fixed by #6280"
      }
    ]
  },
  {
    "number": 4213,
    "title": "Make hand mesh / joint visualization a platform setting",
    "created_at": "2019-05-07T13:37:16Z",
    "closed_at": "2019-08-29T16:52:00Z",
    "labels": [
      "Feature Request",
      "ISV",
      "Help Wanted",
      "Controller Visualization"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/4213",
    "body": "## Describe the problem\r\n\r\nOn Hololens 2 we usually don't want to visualize hand mesh / joints for performance reason, however for eg the hand input simulation in editor we still want to show the joints. Currently you have to modify the profile (or setting in the example scene) to switch the mesh / joints on / off whenever you switch your debugging / testing scenario from editor to hololens 2. It would be great to have this as a per platform setting to avoid having to change the profile everytime you're deploying on device.\r\n\r\n## Describe the solution you'd like\r\n\r\nA per platform setting for hand mesh / joing visualization.\r\n\r\n\r\n",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/4213/comments",
    "author": "thalbern",
    "comments": [
      {
        "user": "Yoyozilla",
        "created_at": "2019-05-09T21:27:15Z",
        "body": "This would be nice to have. We should also add a doc in the perf section to note this. "
      },
      {
        "user": "Yoyozilla",
        "created_at": "2019-05-09T21:30:51Z",
        "body": "Docs needs to be soon. "
      },
      {
        "user": "wiwei",
        "created_at": "2019-05-15T00:58:58Z",
        "body": "@Yoyozilla, is the Urgency-Soon issue for the documentation guidelines, or for everything?"
      },
      {
        "user": "Yoyozilla",
        "created_at": "2019-05-16T15:44:07Z",
        "body": "urgency soon on Doc. \r\n"
      },
      {
        "user": "Yoyozilla",
        "created_at": "2019-06-05T22:44:09Z",
        "body": "removing urgency soon as we have the HL2 default profile now. "
      },
      {
        "user": "wiwei",
        "created_at": "2019-06-07T12:46:27Z",
        "body": "This is still a painpoint for folks using this, and I'm plus1ing this because folks are still keen on getting this fixed.\r\n\r\nThe hand joint problem is still there even with the HL2 profiles"
      }
    ]
  },
  {
    "number": 3307,
    "title": "Proposal: Persist profile inspector foldout settings",
    "created_at": "2019-01-02T22:59:08Z",
    "closed_at": "2020-02-25T00:22:59Z",
    "labels": [
      "Editor",
      "Feature Request",
      "Help Wanted"
    ],
    "url": "https://github.com/microsoft/MixedRealityToolkit-Unity/issues/3307",
    "body": "## Overview\r\nThe Unity project panel will remember the expand / collapse settings for the file system. It would be nice for the profile inspectors to do the same with the new foldouts.\r\n\r\n## Requirements\r\n- Persist / read the user's desired foldout states for each profile\r\n\r\nNOTE: We need to determine the correct behavior when a customer uses the default profiles (i.e. should we persist the foldout settings for the default profiles?)\r\n\r\n## Acceptance Criteria\r\n- [ ] Foldouts default to expanded the first time the Mixed Reality Toolkit is configured\r\n- [ ] User settings are persisted across loads of a given project\r\n",
    "comments_url": "https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/3307/comments",
    "author": "david-c-kline",
    "comments": [
      {
        "user": "Troy-Ferrell",
        "created_at": "2020-02-25T00:22:59Z",
        "body": "This should be done as the profile system uses SessionState keys via\r\n\r\nBaseMixedRealityProfileInspector.cs\r\nprotected static void RenderFoldout(ref bool currentState, string title, Action renderContent, string preferenceKey = null)"
      }
    ]
  }
]