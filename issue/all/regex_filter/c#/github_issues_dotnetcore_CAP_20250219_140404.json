[
  {
    "number": 1624,
    "title": "Support Request for MongoDB.EntityFrameworkCore",
    "created_at": "2024-12-05T16:01:37Z",
    "closed_at": "2024-12-09T01:54:06Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/1624",
    "body": "Hi,\r\n\r\nI really like your package. I use it with EntityFramework when using data storage environments like Postgres and SqlServer.\r\n\r\nAre you planning to add EntityFramework (MongoDB.EntityFrameworkCore) support to your MongoDb package?",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/1624/comments",
    "author": "AdemCatamak",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2024-12-06T01:15:11Z",
        "body": "Hi,\r\n\r\nFor this library, not seeing any benefit from using EntityFrameworkCore, we need to provide more customization using the native syntax."
      }
    ]
  },
  {
    "number": 1606,
    "title": "Outbox Only",
    "created_at": "2024-11-01T21:30:01Z",
    "closed_at": "2024-11-08T02:18:13Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/1606",
    "body": "Hello, \r\n\r\nMy goal is to use CAP, but only to implement the outbox pattern. I want to consume and process messages directly from RabbitMQ myself, without involving the cap.received table in between. How can I achieve this?",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/1606/comments",
    "author": "muratyuceer",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2024-11-04T07:18:01Z",
        "body": "CAP is highly integrated with the published and received database tables. If you do not use these tables, you will need to implement all storage functionalities yourself.\r\n\r\nWhen business code consumption fails due to message context, using the received table does not block the processing of subsequent messages."
      }
    ]
  },
  {
    "number": 1578,
    "title": "Question about support for RabbitMQ RPC",
    "created_at": "2024-09-03T09:29:12Z",
    "closed_at": "2024-09-18T07:08:46Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/1578",
    "body": "亲爱好的开发者你们好\r\n     首先感谢你们为开源社区做的贡献，让我们愉快地使用这款优秀的中间件，我在学习过程中遇到一个问题，那就是我所涉及的场景会使用到RabbitMQ的RPC模式，请问在CAP中支持使用RPC模式吗，我现在使用的是最新版本的CAP8.2.0 又仔细查看了官方文档，没有相关的介绍，所以过来咨询一下。\r\n\r\n\r\n",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/1578/comments",
    "author": "18108296886",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2024-09-05T08:22:23Z",
        "body": "Hi,\r\n\r\nWe do not support the Request-Response mode. In fact, messages are always delivered asynchronously, the RPC mechanism in RabbitMQ is essentially similar to our callback-based publishing.\r\n\r\nIn your case, I think using gRPC would be a more suitable choice!"
      }
    ]
  },
  {
    "number": 1574,
    "title": "support CDC",
    "created_at": "2024-08-13T04:50:30Z",
    "closed_at": "2024-08-14T09:35:17Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/1574",
    "body": "Hi,\r\nI just ask do we will support CDC (change data capture) with tools like Debezium in the future, and when working with RabbitMQ, can we  more flexible config exchange type like Direct, Fanout or Header, now I see we currently only use Topic Exchange. Thanks.",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/1574/comments",
    "author": "ductai202",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2024-08-14T01:09:11Z",
        "body": "Hi,\r\n\r\n> I just ask do we will support CDC (change data capture) with tools like Debezium in the future.\r\n\r\nNo plan and no support in the future, that doesn't fit our design.\r\n\r\n> when working with RabbitMQ, can we more flexible config exchange type like Direct, Fanout or Header, now I see we currently only use Topic Exchange.\r\n\r\nWe provide an upper level abstraction for the Broker, if you want to be flexible you should use other libraries specialized for RabbitMQ such as EasyNetQ\r\n"
      },
      {
        "user": "ductai202",
        "created_at": "2024-08-14T05:24:07Z",
        "body": "> We provide an upper level abstraction for the Broker\r\n\r\nwhat does it really means, can you explain more information"
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2024-08-14T05:45:34Z",
        "body": "The feature we provide requires ensuring that all brokers are available, which may involve utilizing specific functions of a particular broker. This means that when you switch between any supported brokers, the code does not need to be changed, similar to how EF database providers work."
      },
      {
        "user": "ductai202",
        "created_at": "2024-08-14T09:35:17Z",
        "body": "I see, thanks for your answer !"
      }
    ]
  },
  {
    "number": 1567,
    "title": "BUG: NATS throws exceptions when custom consumer configurations are set",
    "created_at": "2024-07-24T12:36:10Z",
    "closed_at": "2024-07-29T02:44:34Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/1567",
    "body": "# Configuration\r\n\r\nIn my Program.cs, I have CAP configured like so:\r\n\r\n```cs\r\nbuilder.Services.AddCap(o =>\r\n{\r\n    o.UseEntityFramework<NotificationDataContext>(opt => opt.Schema = \"Outbox\");\r\n    o.UseNATS(opt =>\r\n    {\r\n        var natsUrl = builder.Configuration.GetValue<string>(\"NatsSettings:Url\")!;\r\n\r\n        opt.Servers = natsUrl;\r\n        opt.StreamOptions = strOpts =>\r\n        {\r\n            strOpts.WithRetentionPolicy(NATS.Client.JetStream.RetentionPolicy.Limits);\r\n            strOpts.WithStorageType(NATS.Client.JetStream.StorageType.File);\r\n            strOpts.WithDuplicateWindow(NATS.Client.Internals.Duration.OfMinutes(1));\r\n            strOpts.WithDiscardPolicy(NATS.Client.JetStream.DiscardPolicy.Old);\r\n\r\n            strOpts.Build();\r\n        };\r\n\r\n        opt.ConsumerOptions = consOpts =>\r\n        {\r\n            consOpts.WithBackoff(\r\n                NATS.Client.Internals.Duration.OfSeconds(5),\r\n                NATS.Client.Internals.Duration.OfSeconds(30),\r\n                NATS.Client.Internals.Duration.OfMinutes(1),\r\n                NATS.Client.Internals.Duration.OfMinutes(2),\r\n                NATS.Client.Internals.Duration.OfMinutes(5),\r\n                NATS.Client.Internals.Duration.OfMinutes(10)\r\n            );\r\n\r\n            consOpts.WithAckPolicy(NATS.Client.JetStream.AckPolicy.Explicit);\r\n            consOpts.WithDeliverPolicy(NATS.Client.JetStream.DeliverPolicy.All);\r\n            consOpts.WithReplayPolicy(NATS.Client.JetStream.ReplayPolicy.Instant);\r\n        };\r\n    });\r\n});\r\n```\r\n\r\nI have an interface and class:\r\n\r\n**IUserService:**\r\n\r\n```cs\r\npublic interface IUserService\r\n{\r\n    Task HandleEvent(DateTime time);\r\n}\r\n```\r\n\r\n**UserService:**\r\n\r\n```cs\r\npublic class UserService: IUserService\r\n{\r\n    [CapSubscribe(\"test.show.time\")]\r\n    public async Task HandleEvent(DateTime time)\r\n    {\r\n        Console.WriteLine(\"message time is:\" + time);\r\n    }\r\n}\r\n```\r\n\r\nThese are both registered as scoped services.\r\n\r\n```cs\r\nservices.AddScoped<IUserService, UserService>();\r\n```\r\n\r\n# How To Reproduce\r\n\r\n1. Using Docker, start a new nats server:\r\n`docker run -it -p 4222:4222 -p 8222:8222 -p 8080:8080 --name nats -d nats:2.10.14 -js -m 8222`.\r\n\r\n2. Set `natsUrl` in `Program.cs` to `\"nats://localhost:4222\"`.\r\n\r\n3. Start the application. \r\n4. Close the application.\r\n5. Start the application again. This exception should appear in the terminal: \r\n\r\n**Error Log:**\r\n```text  \r\nNATS.Client.NATSJetStreamClientException: [SUB-90016] Existing consumer cannot be modified. [AckWait]\r\n   at NATS.Client.JetStream.JetStream.CreateSubscription(String userSubscribeSubject, PushSubscribeOptions pushSubscribeOptions, PullSubscribeOptions pullSubscribeOptions, String queueName, EventHandler`1 userHandler, Boolean autoAck, PullMessageManager pmmInstance)\r\n   at NATS.Client.JetStream.JetStream.PushSubscribeAsync(String subject, String queue, EventHandler`1 handler, Boolean autoAck, PushSubscribeOptions options)\r\n   at DotNetCore.CAP.NATS.NATSConsumerClient.Subscribe(IEnumerable`1 topics)\r\n```\r\n\r\n# Expected Behaviour\r\n\r\nAn exception should not be thrown here because the consumer configuration is not changing. If I don't provide a custom consumer configuration, no exception is thrown on application restart.\r\n",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/1567/comments",
    "author": "henrychris",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2024-07-25T14:29:03Z",
        "body": "In the NATS Server, the BackOff option overrides the AckWait option, ignoring the AckWait settings. This can cause an inconsistency between the NATS client configuration and the server configuration, leading to exceptions when the application restarts. Since CAP internally provides a default value for AckWait, you need to reset the AckWait option to avoid configuration comparison issues.\r\n\r\n```\r\nconsOpts.WithBackoff(\r\n    NATS.Client.Internals.Duration.OfSeconds(5),\r\n    NATS.Client.Internals.Duration.OfSeconds(30),\r\n    NATS.Client.Internals.Duration.OfMinutes(1),\r\n    NATS.Client.Internals.Duration.OfMinutes(2),\r\n    NATS.Client.Internals.Duration.OfMinutes(5),\r\n    NATS.Client.Internals.Duration.OfMinutes(10)\r\n);\r\nconsOpts.WithAckWait(null);    // add this line !!!!\r\n```"
      },
      {
        "user": "henrychris",
        "created_at": "2024-07-25T21:48:03Z",
        "body": "I just tried this out, and it works! Thank you so much! Do I close this myself, or will you do the honours?"
      }
    ]
  },
  {
    "number": 1565,
    "title": "Incorrect order of messages sent between version 7.2 and 8.1",
    "created_at": "2024-07-18T03:08:24Z",
    "closed_at": "2024-07-19T01:42:55Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/1565",
    "body": "当极短的时间内发布连续消息，消费端接受的消息不是按顺序消费，而是乱序。使用的是内存队列。\r\n`using DotNetCore.CAP;\r\nusing Microsoft.Extensions.DependencyInjection;\r\nusing Microsoft.Extensions.DependencyInjection.Extensions;\r\nusing Microsoft.Extensions.Logging;\r\nusing Savorboard.CAP.InMemoryMessageQueue;\r\n\r\n\r\nnamespace ConsoleApp3\r\n{\r\n    internal class Program\r\n    {\r\n        static async Task Main(string[] args)\r\n        {\r\n            var container = new ServiceCollection();\r\n\r\n            container.AddCap(config =>\r\n            {\r\n                config.UseInMemoryMessageQueue();\r\n                config.UseInMemoryStorage();\r\n            });\r\n            container.AddLogging(p =>\r\n            {\r\n                p.AddFilter(n => n == LogLevel.Error);\r\n                p.AddConsole();\r\n            });\r\n            container.TryAddSingleton<TestCapSubscribe>();\r\n            container.AddSingleton<TestPublish>();\r\n            IServiceProvider serviceProvider = container.BuildServiceProvider();\r\n            var bootstrapper = serviceProvider.GetService<IBootstrapper>();\r\n            await bootstrapper.BootstrapAsync();\r\n            var testPublish = serviceProvider.GetService<TestPublish>();\r\n            await testPublish.TestPublishAsync();\r\n            Console.ReadLine();\r\n        }\r\n    }\r\n    public class TestPublish\r\n    {\r\n        private readonly ICapPublisher _capPublisher;\r\n\r\n        public TestPublish(ICapPublisher capPublisher)\r\n        {\r\n            _capPublisher = capPublisher;\r\n        }\r\n        public async Task TestPublishAsync()\r\n        {\r\n            for (int i = 0; i < 1000; i++)\r\n            {\r\n              //  _capPublisher.Publish();\r\n               await _capPublisher.PublishAsync(\"Test\", $\"{DateTime.Now}+{i}\");\r\n            }\r\n        }\r\n    }\r\n\r\n\r\n    public class TestCapSubscribe : ICapSubscribe\r\n    {\r\n        [CapSubscribe(\"Test\")]\r\n        public async Task SubscribeInfoAsync(string content)\r\n        {\r\n            Console.WriteLine(content);\r\n        }\r\n    }\r\n}\r\n\r\n`\r\n这是测试代码，请排查下",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/1565/comments",
    "author": "catsoul",
    "comments": [
      {
        "user": "catsoul",
        "created_at": "2024-07-18T06:20:53Z",
        "body": "在7.2.2的版本会错乱，如果使用延迟发布的方法，消费端 消费几百条消息后，就无法消费了。8.0版本也有这个问题"
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2024-07-18T12:25:13Z",
        "body": "See Release notes of version 7.2 and  version 8.1 `Breaking Changes`."
      }
    ]
  },
  {
    "number": 1539,
    "title": "Is the message data structure compatible with older versions of 3.0?",
    "created_at": "2024-05-29T06:27:21Z",
    "closed_at": "2024-05-29T07:28:55Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/1539",
    "body": "我们用得蛮早的。 2.几版本就在使用； \r\n后面升级到3.1版本； 发现老版本跟新版本的消息体格式不兼容；\r\n现在打算升到最新版； 消息体内容格式 兼容么？ ",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/1539/comments",
    "author": "doufeng007",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2024-05-29T06:49:01Z",
        "body": "3.0到最新版可直升"
      }
    ]
  },
  {
    "number": 1538,
    "title": "消息持久化支持达梦数据库吗",
    "created_at": "2024-05-28T09:34:27Z",
    "closed_at": "2024-05-28T09:44:40Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/1538",
    "body": "国内信创风气下，达梦数据库采用日渐增多，社区暂时还没有看到DM8的消息存储持久化。",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/1538/comments",
    "author": "pccai",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2024-05-28T09:43:43Z",
        "body": "No plan.  \r\n\r\nIf MySQL is not compatible, then you need to fork and tweak the sql."
      }
    ]
  },
  {
    "number": 1535,
    "title": "Optimizing RabbitMQ Performance and Managing Multiple Instances in CAP",
    "created_at": "2024-05-22T01:22:23Z",
    "closed_at": "2024-05-22T01:49:45Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/1535",
    "body": "你好，我有几个问题想请教\r\n\r\n使用RabbitMQ：\r\n\r\n1、cap采用了单个队列（如：cap.queue.XXXX.v1）来处理所有的消息，这对性能是否有影响。\r\n比如在两个场景中，场景1中有10w个消息，场景2中有10个消息，但他们都会投递到同一个队列，造成场景2的无故等待。我可以如何处理这种情况\r\n\r\n2、我可以如何注入多个实例\r\n项目中我可能会使用多个CAP，在对接多个项目时，可能项目A使用MQ1实例，项目B使用MQ2实例，我可以如何注入并获取到不同的实例来发送或处理消息",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/1535/comments",
    "author": "907080752",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2024-05-22T01:37:15Z",
        "body": "1、没有影响，RabbitMQ单个队列性能可以达到数万到数十万条消息每秒。同时我们支持指定设置Group来将消息投递到独立的队列。\r\n2、不支持。简单来说数据收集项目不是CAP要支持的场景，这种场景不需要使用发件箱模式。你可以使用前置工具聚合后再使用CAP处理。"
      },
      {
        "user": "907080752",
        "created_at": "2024-05-22T01:41:34Z",
        "body": "ok，明白。谢谢"
      }
    ]
  },
  {
    "number": 1511,
    "title": "cap.received 和  cap.published 关系型数据库情况如何改成分表或分库存储",
    "created_at": "2024-04-07T05:42:04Z",
    "closed_at": "2024-04-08T01:05:36Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/1511",
    "body": "1、有时候业务数据太大，需要分表或分库存储",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/1511/comments",
    "author": "gogo1008",
    "comments": [
      {
        "user": "1124541815",
        "created_at": "2024-04-07T08:01:13Z",
        "body": "还真有这种场景，数据多了咋分表。先不谈分库，分表问题"
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2024-04-07T09:52:24Z",
        "body": "这不属于这个库要解决的范畴。 \r\n\r\n不过简单来说如果你不想定期清理数据，可以定时将表中的数据转到其他表或者其他数据库进行存档。"
      }
    ]
  },
  {
    "number": 1501,
    "title": "Does CAP support dynamic subscriber?",
    "created_at": "2024-03-22T03:51:43Z",
    "closed_at": "2024-03-25T02:33:32Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/1501",
    "body": "CapSubscribe的Name属性是否支持动态赋值？\r\n目前是Attribute只能给固定值，是否支持动态赋值？\r\n",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/1501/comments",
    "author": "lvcao99",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2024-03-22T06:26:41Z",
        "body": "HI,\r\n\r\nSimply put, we do not support that.\r\n\r\nI don't know your use case, but dynamic subscribers mean you might also need to dynamically consumer handlers. Perhaps issue #1326 might help you, but that's beyond our scope of support.\r\n\r\nWe do support dynamic stopping and starting, so maybe you can do something when registering the subscriber context."
      }
    ]
  },
  {
    "number": 1499,
    "title": "How to config connection RabbitMQ cluster",
    "created_at": "2024-03-08T08:33:24Z",
    "closed_at": "2024-03-14T14:34:58Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/1499",
    "body": "如何连接同一个ip不同端口的集群(192.168.13.100:5672,192.168.13.100:5673,192.168.13.100:5674)这种，并且需要自定义账号密码、vhost",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/1499/comments",
    "author": "hao15239129517",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2024-03-08T09:01:30Z",
        "body": "CAP support rabbitmq client native conntionfactory, you can use it to config."
      },
      {
        "user": "hao15239129517",
        "created_at": "2024-03-10T08:24:43Z",
        "body": "Can you give an example? I didn't find how to use it"
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2024-03-11T00:59:44Z",
        "body": "> Can you give an example? I didn't find how to use it\r\n\r\nHow do you config use RabbitMQ.Client?"
      }
    ]
  },
  {
    "number": 1494,
    "title": "Does CAP have a Java version",
    "created_at": "2024-03-01T07:49:59Z",
    "closed_at": "2024-03-04T09:50:12Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/1494",
    "body": "Net's technology stack has always used CAP. Now we have a Java technology stack. Do you have support for the Java version?",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/1494/comments",
    "author": "knowyi",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2024-03-04T09:49:57Z",
        "body": "No, Someone create a Java port a few years ago, but it seems that it has not been updated."
      }
    ]
  },
  {
    "number": 1489,
    "title": "是否考虑让CAP的持久化的时候,可配置orm框架",
    "created_at": "2024-02-22T08:28:01Z",
    "closed_at": "2024-02-23T01:34:54Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/1489",
    "body": "如题:CAP的持久存储部分使用的是.net core的ef,有些项目可能各种原因,使用了其他的orm产品,作为维护栈考虑,在接入CAP的时候是否考虑可以使用其他orm配置接管对应的操作,谢谢.",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/1489/comments",
    "author": "0xblack",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2024-02-22T09:44:41Z",
        "body": "没看懂，你指的使用其他ORM持久化什么东西？  \r\n\r\n另外CAP操作数据库使用的原生 ado.net"
      },
      {
        "user": "0xblack",
        "created_at": "2024-02-24T02:27:27Z",
        "body": "不好意思,我描述有误,我是在使用DotNetCore.CAP.MySq这个库进行持久化配置的时候,它是依赖efcore的,我是想说,这个部分是否可以在orm这一层进行抽象,让它可以轻松的切换到其他的orm框架呢?"
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2024-02-25T10:41:53Z",
        "body": "为什么要切换？ 建议看下代码再思考一下你的提问"
      }
    ]
  },
  {
    "number": 1483,
    "title": "Question about consumer not received message",
    "created_at": "2024-02-05T09:30:01Z",
    "closed_at": "2024-02-10T00:54:53Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/1483",
    "body": "你好，生产环境延迟队列出现了两次消息丢失问题，每次丢失都是一批数据。\r\n\r\n版本及环境如下：\r\n.netcore 7.0\r\ncap7.1.4\r\nmysql8.0.22\r\n\r\n发布消息代码：\r\n...\r\nawait CapPublisher.PublishDelayAsync(TimeSpan.FromMinutes(10), key, data);\r\nawait uow.CompleteAsync();\r\n...\r\n\r\ncap.published表中能查询到丢失消息记录，StatusName是Succeeded，看状态应该是被正常消费掉了。\r\n但我自己的Subscriber程序并没有输出任何日志，且cap.received表中没有找到与cap.published表相同的cap-msg-id。\r\n\r\n正常情况应该会在cap.received有条记录，到这儿线索就断了不知道从何排查起因，对于我这种情况还请作者能指导下思路！",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/1483/comments",
    "author": "haoyk",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2024-02-06T02:58:41Z",
        "body": "For such issues, unless you can reproduce them, you will need to investigate the reasons why messages were not received from the Broker yourself. This is because I do not know the type of your Broker, your server logs, the details of your deployment environment, or whether there have been any restarts or crashes involving the database, Broker, server, etc."
      }
    ]
  },
  {
    "number": 1474,
    "title": "希望通过环境变量限制消费端执行",
    "created_at": "2024-01-22T09:11:51Z",
    "closed_at": "2024-01-26T01:05:30Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/1474",
    "body": "我有一个需求，同一套代码部署到多台服务器。我希望通过环境变量控制不同服务器进行不同的事件消费。\r\n例：\r\n我的系统中现在有三个消息发送和三个消费，分别是 A、B、C。\r\n我想在第1台服务器 消费A ，第2台服务消费B，第3台服务消费C。\r\n代码都是同一个系统。\r\n\r\n有现成的解决方案吗？如果有请告知实现方式。\r\n如果没有，会有开发计划吗？",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/1474/comments",
    "author": "longjie12315",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2024-01-24T09:18:08Z",
        "body": "You can use group to fanout the message and use filter to ignore by the env."
      }
    ]
  },
  {
    "number": 1466,
    "title": "Middleware to log",
    "created_at": "2024-01-08T19:42:01Z",
    "closed_at": "2024-01-09T01:22:12Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/1466",
    "body": "Hello,\r\n\r\nIs there any possibility to add middleware to implement a log resource. I would like to add logs by Serilog, but I noticed that is not possible to add my custom headers into log.\r\n\r\n\r\nThanks.",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/1466/comments",
    "author": "gcm10000",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2024-01-09T01:21:49Z",
        "body": "We use Microsoft.Extensions.Logging for logging, which supports filters on the consumer side, where you can use SerialLog to add header"
      },
      {
        "user": "gcm10000",
        "created_at": "2024-01-09T13:51:01Z",
        "body": "Sure. Yesterday I spent my entire day trying to implement that one. I was able to do it, but this one looks like a legacy code. It could be better if add the functionality like a middleware of ASP.NET Core.\r\n\r\n\r\nAs well, I would like to share my code to other developers.\r\n\r\n```csharp\r\npublic class LoggingCapFilter : SubscribeFilter, ISubscribeFilter\r\n{\r\n    private readonly Dictionary<string, IDisposable> _disposables = new();\r\n    private readonly ISubscriberLogIdentificationService _logSubscriberLogIdentificationService;\r\n    private readonly ILogger<LoggingCapFilter> _logger;\r\n\r\n\r\n    public LoggingCapFilter(\r\n        ILogIdentificationService logIdentificationService,\r\n        ILogger<LoggingCapFilter> logger)\r\n    {\r\n\r\n        _logSubscriberLogIdentificationService = (ISubscriberLogIdentificationService)logIdentificationService;\r\n        _logger = logger;\r\n    }\r\n\r\n    public override Task OnSubscribeExecutingAsync(ExecutingContext context)\r\n    {\r\n        _logSubscriberLogIdentificationService.SetIds(context.DeliverMessage.Headers);\r\n\r\n        ApplyPropertyIntoLog(context, nameof(ILogIdentificationService.TraceId));\r\n        ApplyPropertyIntoLog(context, nameof(ILogIdentificationService.EventIdentifier));\r\n        ApplyPropertyIntoLog(context, nameof(ILogIdentificationService.ParentId));\r\n\r\n        var spanId = _logSubscriberLogIdentificationService.SpanId;\r\n        _disposables.Add(nameof(ILogIdentificationService.SpanId), LogContext.PushProperty(nameof(ILogIdentificationService.SpanId), spanId));\r\n\r\n        var requestAsMessage = context.DeliverMessage.Value;\r\n        var requestBody = JsonConvert.SerializeObject(requestAsMessage);\r\n        _logger.LogInformation(\"Request Body: {RequestBody}\", requestBody);\r\n\r\n        return Task.CompletedTask;\r\n    }\r\n\r\n    private string? ApplyPropertyIntoLog(\r\n        ExecutingContext context, string id)\r\n    {\r\n        var traceId = GetPropertyOrDefault(context, id);\r\n        if (traceId is not null)\r\n        {\r\n            var traceIdProperty = LogContext.PushProperty(id, traceId);\r\n            _disposables.Add(id, traceIdProperty);\r\n        }\r\n\r\n        return traceId;\r\n    }\r\n\r\n    public override Task OnSubscribeExecutedAsync(ExecutedContext context)\r\n    {\r\n        DisposeLogProperties();\r\n\r\n        return Task.CompletedTask;\r\n    }\r\n\r\n    public override Task OnSubscribeExceptionAsync(ExceptionContext context)\r\n    {\r\n        DisposeLogProperties();\r\n\r\n        return Task.CompletedTask;\r\n    }\r\n\r\n    private static string? GetPropertyOrDefault(\r\n        ExecutingContext context,\r\n        string idName)\r\n    {\r\n        if (!context.DeliverMessage.Headers.TryGetValue(idName, out string? header))\r\n        {\r\n            return default;\r\n        }\r\n\r\n        return header;\r\n    }\r\n\r\n    private void DisposeLogProperties()\r\n    {\r\n        DisposeLogProperty(nameof(ILogIdentificationService.SpanId));\r\n        DisposeLogProperty(nameof(ILogIdentificationService.ParentId));\r\n        DisposeLogProperty(nameof(ILogIdentificationService.EventIdentifier));\r\n        DisposeLogProperty(nameof(ILogIdentificationService.TraceId));\r\n\r\n        _disposables.Clear();\r\n    }\r\n\r\n    private void DisposeLogProperty(string id)\r\n    {\r\n        if (_disposables.TryGetValue(id, out var logProperties))\r\n        {\r\n            logProperties.Dispose();\r\n        }\r\n    }\r\n}\r\n\r\n```"
      }
    ]
  },
  {
    "number": 1451,
    "title": "Configure Kafka for outbox in runtime",
    "created_at": "2023-12-07T15:02:07Z",
    "closed_at": "2023-12-09T13:38:48Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/1451",
    "body": "Hi! We have environment with several independent Kafka servers. In some cases we need to send message using outbox pattern to kafka-1, in other to kafka-2.\r\n\r\nIs there a way to do it with CAP? As I can see now I can configure only one server using:\r\n```c#\r\nbuilder.Services.AddCap(x =>\r\n{\r\n   ...\r\n    x.UseKafka(c =>\r\n    {\r\n        c.Servers = \"kafka-a-1-v1:9092,kafka-b-1-v1:9092\";\r\n    });\r\n});\r\n```\r\nAnd I want something like\r\n```c#\r\nbuilder.Services.AddCap(x =>\r\n{\r\n   ...\r\n    x.UseKafka(c =>\r\n    {\r\n        c.ServersProvider = (topic, context) => ...;\r\n    });\r\n});\r\n```\r\n\r\n\r\n",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/1451/comments",
    "author": "mnovikov-mindbox",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2023-12-07T15:15:22Z",
        "body": "We don't support connecting multiple non-clustered Kafka Brokers, but there is a way you can test it.\r\n\r\nYou can try injecting and then modifying\r\nThe value of `Servers` in `IOptions<KafkaOptions>` options. You need to call stop api before doing this and call start api after making the changes.\r\n\r\n```\r\napp.MapGet(\"/control/start\", async () =>\r\n{\r\n     var bootstrapper = app.Services.GetRequiredService<IBootstrapper>();\r\n     await bootstrapper.BootstrapAsync();\r\n});\r\n\r\napp.MapGet(\"/control/stop\", async () =>\r\n{\r\n     var bootstrapper = app.Services.GetRequiredService<IBootstrapper>();\r\n     await bootstrapper.DisposeAsync();\r\n});\r\n```\r\n\r\nI haven't tested if it works."
      },
      {
        "user": "mnovikov-mindbox",
        "created_at": "2023-12-07T15:27:18Z",
        "body": "@yang-xiaodong thanks for answering! \r\nI don't see stop and start as a solution, because I can have several parallel requests part of with need to be publish to kafka-1 and other part to kafka-2 and `IBootstrapper` is Singletone.\r\n\r\n>We don't support connecting multiple non-clustered Kafka Brokers\r\n\r\nDo you have any plans to support it? Or it's totaly against CAP logic?"
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2023-12-07T15:46:50Z",
        "body": "No plan to support, you can create  a proxy or bridge project at front for your case."
      }
    ]
  },
  {
    "number": 1447,
    "title": "使用 Autofac 注入的时候，继承 ICapSubscribe 的类不生效",
    "created_at": "2023-12-06T08:27:18Z",
    "closed_at": "2023-12-07T02:29:53Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/1447",
    "body": "``` c#\r\nbuilder.Host.UseServiceProviderFactory(new AutofacServiceProviderFactory());\r\nbuilder.Host.ConfigureContainer<ContainerBuilder>(containerBuilder =>\r\n{\r\n   containerBuilder.RegisterType<CapLogService>().As<ICapLogService>();\r\n});\r\n\r\nbuilder.Services.AddCap(cap =>\r\n{\r\n    cap.UseInMemoryStorage();\r\n    cap.UseInMemoryMessageQueue();\r\n});\r\n```",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/1447/comments",
    "author": "dongweimeng",
    "comments": [
      {
        "user": "dongweimeng",
        "created_at": "2023-12-06T08:36:58Z",
        "body": "``` c#\r\nbuilder.Services.AddTransient<ICapLogService, CapLogService>();\r\n\r\n```\r\n使用微软的注入方式可以。CAP 不支持 Autofac 注入么？"
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2023-12-07T02:29:27Z",
        "body": "`Microsoft.Extensions.DependencyInjection` has become the de facto standard. We do not have the resources to investigate the support of all third-party DI library. This depends on the third-party DI's compatibility with `Microsoft.Extensions.DependencyInjection`. \r\n\r\nCAP provides `IConsumerServiceSelector` to support custom consumer lookup logic. If you encounter issues with registering consumers when using a third-party framework, please customize it."
      }
    ]
  },
  {
    "number": 1420,
    "title": "Dynamic subscriber",
    "created_at": "2023-11-02T10:33:37Z",
    "closed_at": "2023-11-02T10:55:57Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/1420",
    "body": "版本：cap3.1.2\r\n我想知道cap有没有动态注销消费者，和动态注册消费者的能力\r\n",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/1420/comments",
    "author": "henrydingchina",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2023-11-02T10:55:12Z",
        "body": "No， We only directly support restart processor，You need to manage subscriber by yourself"
      }
    ]
  },
  {
    "number": 1363,
    "title": "Is it possible to have parallel subscribers to a topic?",
    "created_at": "2023-06-21T00:59:05Z",
    "closed_at": "2023-06-22T12:39:47Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/1363",
    "body": "I've two subscribers methods on my application:\r\n\r\n- One that receives some data to process, **which I want to enable a certain degree of parallelism**, to process five messages at a time on distinct scopes;\r\n- Another subscriber that sends mail messages, **which I don't want to enable parallelism** because I have a limit to sending emails per minute. With only one instance of this subscriber, I can throttle this.\r\n\r\nCurrently on CAP, I can only have one instance of each subscriber using `UseDispatchingPerGroup=true` and different groups on `[CAPSubscribe]` attribute. I can't consume messages in parallel from a specific topic.\r\n\r\nIs there a way to have some subscribers to work in parallel while others remain unique/singletons?",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/1363/comments",
    "author": "xilapa",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2023-06-21T03:03:43Z",
        "body": "CAP does not support setting the thread count separately for each consumer. One simple way is to enable multiple CAP instances to configure individual thread counts for each instance.\r\n\r\nProgram.cs\r\n```cs\r\nusing DotNetCore.CAP;\r\nusing Microsoft.Extensions.DependencyInjection;\r\nusing Microsoft.Extensions.Logging;\r\n\r\nvar uniqueSc = new ServiceCollection();\r\nuniqueSc.AddLogging(x => x.AddConsole());\r\nuniqueSc.AddSingleton<SendEmail>();\r\nuniqueSc.AddCap(x =>\r\n{\r\n    x.DefaultGroupName = \"Unique\";\r\n    x.UseRabbitMQ(aa =>\r\n    {\r\n        aa.HostName = \"192.168.3.57\";\r\n        aa.UserName = \"user\";\r\n        aa.Password = \"wJ0p5gSs17\";\r\n    });\r\n    x.UseInMemoryStorage();\r\n    x.ConsumerThreadCount = 1;\r\n});\r\nawait uniqueSc.BuildServiceProvider().GetRequiredService<IBootstrapper>().BootstrapAsync();\r\n\r\nvar parallelSc = new ServiceCollection();\r\nparallelSc.AddLogging(x => x.AddConsole());\r\nparallelSc.AddSingleton<ParallelProcess>();\r\nparallelSc.AddCap(x =>\r\n{\r\n    x.DefaultGroupName = \"Parallel\";\r\n    x.UseRabbitMQ(aa =>\r\n    {\r\n        aa.HostName = \"192.168.3.57\";\r\n        aa.UserName = \"user\";\r\n        aa.Password = \"wJ0p5gSs17\";\r\n    });\r\n    x.ConsumerThreadCount = 5;\r\n    x.UseInMemoryStorage();\r\n});\r\nawait parallelSc.BuildServiceProvider().GetRequiredService<IBootstrapper>().BootstrapAsync();\r\n\r\nConsole.ReadLine();\r\n\r\nclass SendEmail : ICapSubscribe\r\n{\r\n    [CapSubscribe(\"send.email\")]\r\n    public async Task Send()\r\n    {\r\n        await Task.Delay(1000);\r\n        Console.WriteLine(\"Send Email: \" + DateTime.Now);\r\n    }\r\n}\r\n\r\nclass ParallelProcess : ICapSubscribe\r\n{\r\n    [CapSubscribe(\"parallel.process\")]\r\n    public async Task Process()\r\n    {\r\n        await Task.Delay(1000);\r\n        Console.WriteLine(\"Parallel Process: \" + DateTime.Now);\r\n    }\r\n}\r\n```\r\n"
      },
      {
        "user": "xilapa",
        "created_at": "2023-06-21T22:05:51Z",
        "body": "Thx. I'll try that."
      }
    ]
  },
  {
    "number": 1346,
    "title": "事务的问题",
    "created_at": "2023-05-31T07:57:37Z",
    "closed_at": "2023-06-02T06:33:47Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/1346",
    "body": "感觉简单，实用。\r\n但我自己有事务工作单元。我编译看事务那里调用了database.begentransaction().\r\n我觉得是不是应该在publish的时候指定一个事务会更好一点。",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/1346/comments",
    "author": "floweroflove",
    "comments": [
      {
        "user": "floweroflove",
        "created_at": "2023-05-31T07:58:18Z",
        "body": "我的事务会存在嵌套，因为内部使用了database.begentransaction().会导致我的事务嵌套有两个事务上下文"
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2023-05-31T08:14:05Z",
        "body": "The transaction must be commit by CAP, because CAP should be ensure the buffer message flush to Broker."
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2023-06-02T06:33:46Z",
        "body": "No response, closed!"
      }
    ]
  },
  {
    "number": 1340,
    "title": "CAP Retry issue",
    "created_at": "2023-05-23T07:37:49Z",
    "closed_at": "2023-05-24T08:13:26Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/1340",
    "body": "CapSubscribe service execute for a long time( over 60 seconds), the retry logic will be trigger, how can I disable it, can I use the FailedRetryInterval field, or have other timeout field setting?",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/1340/comments",
    "author": "rubin-yu",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2023-05-24T08:13:25Z",
        "body": "CAP is not design for long-running tasks, you can use quartz or hangfire for long-running"
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2023-06-03T14:50:51Z",
        "body": "related issue #1226 "
      }
    ]
  },
  {
    "number": 1339,
    "title": "Ability to skip outbox for certain event publishes",
    "created_at": "2023-05-18T20:49:27Z",
    "closed_at": "2023-05-22T07:35:28Z",
    "labels": [
      "duplicate",
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/1339",
    "body": "Hello dears,\r\n\r\nWe have a use case where we have events with very large payloads sent out to different services, the event publishing is not transactional with the database and can happen as a standalone operation. ",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/1339/comments",
    "author": "shkarface",
    "comments": [
      {
        "user": "3ldar",
        "created_at": "2023-05-19T10:01:03Z",
        "body": "In order to utilize the outbox pattern you need to have a transaction between CAP and the DB operation, we achieve this by starting a transaction with an overload that accepts an `ICapPublisher` instance. If you skip this step and directly publish via `capPublisher.PublishAsync` the outbox pattern will also be ignored."
      },
      {
        "user": "shkarface",
        "created_at": "2023-05-20T01:47:38Z",
        "body": "Thank you for the response.\n\nThe transactional outbox is one of the main reasons we use CAP. but there are certain scenarios that we don't want the message to go to an outbox. We have a use case like this:\n\nPOST v1/create:\nThis will create a resource and publish an event to resource.created in a transactional.\n\n\nSUBSCRIBER resource.created:\n\nthis subscriber does a few checks, and will publish a message with a very large payload.\n\nSince there are no DB transactions, there is no need for the outbox pattern"
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2023-05-20T03:40:23Z",
        "body": "Hi @shkarface \r\nOutbox pattern is our design goal, and we provide InMemoryStorage at same case.  With your describe I recommend you use the client directly for batch publishing where high performance is required or very large payloads.\r\n\r\nRefer : #1015  #1051"
      }
    ]
  },
  {
    "number": 1336,
    "title": "PublishAsync doesn't use DefaultGroupName",
    "created_at": "2023-05-15T17:12:29Z",
    "closed_at": "2023-05-17T04:59:16Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/1336",
    "body": "We have one kafka instance that we are trying to use for QA, UAT, DEV enviornments.\r\n\r\nI am setting DefaultGroupName like this: api.qa, api.uat, api.dev.\r\n\r\nWhen we publish message FROM api that has DefaultGroupName as api.qa. I am hoping for the api instance that has api.qa group name to pick that up, but right now all api instance pick it up.\r\n\r\nHow can this be set up so publish only works api with matching DefaultGroupName",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/1336/comments",
    "author": "jmogera",
    "comments": [
      {
        "user": "3ldar",
        "created_at": "2023-05-15T18:11:49Z",
        "body": "Well, the `DefaultGroupName` is a consumer property for Kafka. It defines the consumer group name. It allows Kafka consumers to consume the same messages by using different consumer group names. (This is how Kafka works, it has no routing mechanism, You might consider RabbitMQ which supports complex routing mechanisms) For Kafka what you can do is separate topics by adding prefixes etc. Or you can add a header that adds the environment by developing a subscriber filter that checks the environment and decides to process the message or not."
      },
      {
        "user": "3ldar",
        "created_at": "2023-05-15T20:16:18Z",
        "body": "I am adding a sample configuration that adds the custom header and a `SubscribeFilter` serves the purpose: \r\n\r\n> Program.cs\r\n```\r\nvar builder = WebApplication.CreateBuilder(args);\r\n\r\nbuilder.Services.AddCap(cap =>\r\n                        cap.UseKafka(kafka => \r\n                                     kafka.CustomHeaders = (_) => \r\n                                        new () { new KeyValuePair<string, string>(\"ENV\", builder.Configuration[\"ASPNETCORE_ENVIRONMENT\"] ?? \"Development\") }))\r\n                .AddSubscribeFilter<EnvSubscribeFilter>();\r\n```\r\n\r\n> EnvSubscribeFilter.cs\r\n```\r\npublic class EnvSubscribeFilter : SubscribeFilter\r\n    {\r\n        private readonly IConfiguration configuration;\r\n\r\n        public EnvSubscribeFilter(IConfiguration configuration)\r\n        {\r\n            this.configuration = configuration;\r\n        }\r\n\r\n        public override Task OnSubscribeExecutingAsync(ExecutingContext context)\r\n        {\r\n            var envName = this.configuration[\"ASPNETCORE_ENVIRONMENT\"];\r\n            var header = context.DeliverMessage.Headers[\"ENV\"];\r\n\r\n            if (header != envName)\r\n            {\r\n                throw new SkipExecutionExcepiton();\r\n            }\r\n            return base.OnSubscribeExecutingAsync(context);\r\n        }\r\n\r\n        public override Task OnSubscribeExceptionAsync(ExceptionContext context)\r\n        {\r\n            if (context.Exception is SkipExecutionExcepiton)\r\n            {\r\n                context.ExceptionHandled = true;\r\n            }\r\n\r\n            return base.OnSubscribeExceptionAsync(context);\r\n        }\r\n\r\n        private class SkipExecutionExcepiton : Exception\r\n        {\r\n        }\r\n    }\r\n```\r\n\r\n**You should keep using different consumer group names to make this work as the message should be processed by all the environments otherwise if an environment processes a message the other environments won't get the message. And the message will exist in all the environments storages.** This is not an optimal solution but it should serve the purpose. There is another option which is to separate topics by environment. You can do it by conditional compilation with processor directives and adding symbols at builds and checking those symbols like this \r\n```\r\n#if ENV_DEV\r\n[CapSbuscribe(\"my_topic_dev\")]\r\n#elif ENV_UAT\r\n[CapSbuscribe(\"my_topic_uat\")]\r\n#elif ENV_QA\r\n[CapSbuscribe(\"my_topic_qa\")]\r\n#else\r\n[CapSbuscribe(\"my_topic\")]\r\n#endif\r\npublic async Task Process(string message) {}\r\n```\r\n\r\nThere is another way to achieve this which is to use `IL Emit` to dynamically build topic attributes at the startup and register the event handlers which is mentioned in #1326 \r\n"
      },
      {
        "user": "jmogera",
        "created_at": "2023-05-19T00:07:23Z",
        "body": "@\r\n\r\n> I am adding a sample configuration that adds the custom header and a `SubscribeFilter` serves the purpose:\r\n> \r\n> > Program.cs\r\n> \r\n> ```\r\n> var builder = WebApplication.CreateBuilder(args);\r\n> \r\n> builder.Services.AddCap(cap =>\r\n>                         cap.UseKafka(kafka => \r\n>                                      kafka.CustomHeaders = (_) => \r\n>                                         new () { new KeyValuePair<string, string>(\"ENV\", builder.Configuration[\"ASPNETCORE_ENVIRONMENT\"] ?? \"Development\") }))\r\n>                 .AddSubscribeFilter<EnvSubscribeFilter>();\r\n> ```\r\n> \r\n> > EnvSubscribeFilter.cs\r\n> \r\n> ```\r\n> public class EnvSubscribeFilter : SubscribeFilter\r\n>     {\r\n>         private readonly IConfiguration configuration;\r\n> \r\n>         public EnvSubscribeFilter(IConfiguration configuration)\r\n>         {\r\n>             this.configuration = configuration;\r\n>         }\r\n> \r\n>         public override Task OnSubscribeExecutingAsync(ExecutingContext context)\r\n>         {\r\n>             var envName = this.configuration[\"ASPNETCORE_ENVIRONMENT\"];\r\n>             var header = context.DeliverMessage.Headers[\"ENV\"];\r\n> \r\n>             if (header != envName)\r\n>             {\r\n>                 throw new SkipExecutionExcepiton();\r\n>             }\r\n>             return base.OnSubscribeExecutingAsync(context);\r\n>         }\r\n> \r\n>         public override Task OnSubscribeExceptionAsync(ExceptionContext context)\r\n>         {\r\n>             if (context.Exception is SkipExecutionExcepiton)\r\n>             {\r\n>                 context.ExceptionHandled = true;\r\n>             }\r\n> \r\n>             return base.OnSubscribeExceptionAsync(context);\r\n>         }\r\n> \r\n>         private class SkipExecutionExcepiton : Exception\r\n>         {\r\n>         }\r\n>     }\r\n> ```\r\n> \r\n> **You should keep using different consumer group names to make this work as the message should be processed by all the environments otherwise if an environment processes a message the other environments won't get the message. And the message will exist in all the environments storages.** This is not an optimal solution but it should serve the purpose. There is another option which is to separate topics by environment. You can do it by conditional compilation with processor directives and adding symbols at builds and checking those symbols like this\r\n> \r\n> ```\r\n> #if ENV_DEV\r\n> [CapSbuscribe(\"my_topic_dev\")]\r\n> #elif ENV_UAT\r\n> [CapSbuscribe(\"my_topic_uat\")]\r\n> #elif ENV_QA\r\n> [CapSbuscribe(\"my_topic_qa\")]\r\n> #else\r\n> [CapSbuscribe(\"my_topic\")]\r\n> #endif\r\n> public async Task Process(string message) {}\r\n> ```\r\n> \r\n> There is another way to achieve this which is to use `IL Emit` to dynamically build topic attributes at the startup and register the event handlers which is mentioned in #1326\r\n\r\n@3ldar I  tried adding EnvSubscribeFilter code, but when you produce the message both dev and qa environment pick up the same message.\r\n\r\nmy subscribe is like this: \r\n`[CapSubscribe(\"client.export\")]` with no group name\r\n\r\nand in Program.cs\r\n`builder.Services.AddCap(options =>\r\n{\r\n    options.DefaultGroupName = builder.Configuration.GetValue<string>(\"Kafka:Environment\");\r\n    options.ConsumerThreadCount = 10;\r\n    options.FailedRetryCount = 2;\r\n    options.UseKafka(k =>\r\n    {\r\n        k.CustomHeaders = (_) => new() { new KeyValuePair<string, string>(\"Environment\", builder.Configuration.GetValue<string>(\"Kafka:Environment\") ?? \"local\") };\r\n        k.Servers = builder.Configuration.GetConnectionString(\"Kafka\");\r\n        k.MainConfig.Add(\"allow.auto.create.topics\", \"true\");\r\n    });\r\n    options.UseSqlServer(builder.Configuration.GetConnectionString(\"SqlServer\"));\r\n}).AddSubscribeFilter<EnvironmentSubscribeFilter>();`\r\n\r\nNo luck with this\r\n"
      },
      {
        "user": "3ldar",
        "created_at": "2023-05-19T11:54:07Z",
        "body": "\r\n> @3ldar I tried adding EnvSubscribeFilter code, but when you produce the message both dev and qa environment pick up the same message.\r\n> \r\n> my subscribe is like this: `[CapSubscribe(\"client.export\")]` with no group name\r\n> \r\n> and in Program.cs `builder.Services.AddCap(options => { options.DefaultGroupName = builder.Configuration.GetValue<string>(\"Kafka:Environment\"); options.ConsumerThreadCount = 10; options.FailedRetryCount = 2; options.UseKafka(k => { k.CustomHeaders = (_) => new() { new KeyValuePair<string, string>(\"Environment\", builder.Configuration.GetValue<string>(\"Kafka:Environment\") ?? \"local\") }; k.Servers = builder.Configuration.GetConnectionString(\"Kafka\"); k.MainConfig.Add(\"allow.auto.create.topics\", \"true\"); }); options.UseSqlServer(builder.Configuration.GetConnectionString(\"SqlServer\")); }).AddSubscribeFilter<EnvironmentSubscribeFilter>();`\r\n> \r\n> No luck with this\r\n\r\n@jmogera I have managed to make it work on my local. (So it should work on your side too) As I said both ends will consume the message but only the one that has the correct environment value will actually process the message. Do not let the logs deceive you. It will log something like the below \r\n> info: DotNetCore.CAP.Internal.SubscribeExecutor[0]\r\n>      Executing subscriber method 'FooConsumer.HandleFoo' on group 'cap.queue.consumerqa.v1'\r\n\r\nbut that doesn't mean it actually executes the handler.\r\n\r\n\r\n"
      }
    ]
  },
  {
    "number": 1323,
    "title": "Disabling cap logs",
    "created_at": "2023-05-02T22:13:29Z",
    "closed_at": "2023-05-03T12:07:35Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/1323",
    "body": "hi,\r\n\r\nwhile using cap library, it writes a lot of log in addition to my app's logs. Is there a way to disable cap's log?",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/1323/comments",
    "author": "cagataykiziltan",
    "comments": [
      {
        "user": "3ldar",
        "created_at": "2023-05-03T10:18:28Z",
        "body": "Yeap you can do it by modifying `appsettings.json` files logging section like below :\r\n```\r\n\"Logging\": {\r\n    \"LogLevel\": {\r\n      \"Default\": \"Information\",\r\n      \"Microsoft\": \"Warning\",\r\n      \"Microsoft.Hosting.Lifetime\": \"Information\",\r\n      \"DotNetCore.CAP\" : \"Warning\r\n \r\n    }\r\n  }\r\n```"
      },
      {
        "user": "cagataykiziltan",
        "created_at": "2023-05-03T10:32:04Z",
        "body": "thanks a lot @3ldar "
      },
      {
        "user": "canperk",
        "created_at": "2024-04-26T14:32:49Z",
        "body": "We cannot do that in yaml files like\n\nLogging__LogLevel__DotnetCore.CAP"
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2024-04-26T15:18:34Z",
        "body": "@canperk \r\n \r\n`Logging__LogLevel__DotnetCore.CAP`  -->  `Logging__LogLevel__DotNetCore.CAP` ？\r\n\r\nn to N"
      },
      {
        "user": "canperk",
        "created_at": "2024-04-30T08:23:10Z",
        "body": "@yang-xiaodong  This is the full configuration but I suspect there is priority issue here:\r\n\r\n```\r\n- name: Logging__LogLevel__Default\r\n  value: \"Information\"\r\n- name: Logging__LogLevel__DotNetCore.CAP\r\n  value: \"Warning\"\r\n- name: Logging__LogLevel__Microsoft\r\n  value: \"Warning\"\r\n- name: Logging__LogLevel__Microsoft.Hosting.Lifetime\r\n  value: \"Information\"\r\n- name: \"Logging__ApplicationInsights__LogLevel__Default\"\r\n  value: \"Information\"\r\n- name: \"Logging__ApplicationInsights__LogLevel__Microsoft\"\r\n  value: \"Error\"\r\n```"
      }
    ]
  },
  {
    "number": 1313,
    "title": "Expcetion: Standalone servers do not support transactions",
    "created_at": "2023-04-14T03:25:37Z",
    "closed_at": "2023-04-14T13:16:48Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/1313",
    "body": "I deploy .NET app with mongo DB standalone server then it throw exception\r\nfail: DotNetCore.CAP.Processor.MessageDelayedProcessor[0]\r\n      Schedule delayed message failed!\r\n      System.NotSupportedException: Standalone servers do not support transactions.\r\n         at MongoDB.Driver.Core.Bindings.CoreSession.EnsureTransactionsAreSupported()\r\n         at MongoDB.Driver.Core.Bindings.CoreSession.StartTransaction(TransactionOptions transactionOptions)\r\n         at DotNetCore.CAP.MongoDB.MongoDBDataStorage.ScheduleMessagesOfDelayedAsync(Func`3 scheduleTask, CancellationToken token)\r\n         at DotNetCore.CAP.Processor.MessageDelayedProcessor.ProcessDelayedAsync(IDataStorage connection, ProcessingContext context) in D:\\lib\\CAP\\src\\DotNetCore.CAP\\Processor\\IProcessor.Delayed.cs:line 51\r\nCould you add a config to enable/disable transaction?\r\nThanks",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/1313/comments",
    "author": "hungvimanh",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2023-04-14T13:16:48Z",
        "body": "Only MongoDB 4.0+ cluster support transaction, We need to use transactions to guarantee the mutex for multiple instance concurrency get data."
      }
    ]
  },
  {
    "number": 1305,
    "title": "Getting retry count from somewhere",
    "created_at": "2023-03-29T10:27:12Z",
    "closed_at": "2023-04-05T04:26:05Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/1305",
    "body": "Hi, while using cap i want to understand if ı am in retry or not, can ı get retry count from cap models in code running?\r\n\r\nthanks.",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/1305/comments",
    "author": "cagataykiziltan",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2023-03-29T13:40:01Z",
        "body": "Hi,\r\nNo, the retry count is used internally by the CAP and is not open to users."
      }
    ]
  },
  {
    "number": 1292,
    "title": "file scoped namespaces",
    "created_at": "2023-03-14T14:01:17Z",
    "closed_at": "2023-03-18T07:24:53Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/1292",
    "body": "currently project is partially using file scoped namespaces. \r\nonly several projects: DotNetCore.CAP, DotNetCore.CAP.SqlServer and DotNetCore.CAP.AzureServiceBus.Test are converted to file scoped namespaces, \r\nshould not all projects be converted to file scoped namespaces?",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/1292/comments",
    "author": "Revazashvili",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2023-03-18T07:24:18Z",
        "body": "Hello, this is not urgent and important, maybe a change will be made in a major version in the future"
      }
    ]
  },
  {
    "number": 1275,
    "title": "collection of all messages in  Unacked in rabbitmq",
    "created_at": "2023-02-19T11:12:44Z",
    "closed_at": "2023-02-20T14:06:06Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/1275",
    "body": "I am using dotnetcore cap with rabbitmq and try to process almost 30k message.As soon as 30 k messages are published, 30 k of them are transferred to Unacked instead of piling up in the queue, and problems are experienced when there is no response for a while. Is there a way to process these messages from rabbit mq ready status without putting them into memory queue?",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/1275/comments",
    "author": "cagataykiziltan",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2023-02-19T12:49:31Z",
        "body": "Yes, you can use `BasicQos` option to control the prefetch size, see #1270 and #1267\r\n\r\nThe BasicQosOptions will be released in version 7.1.0, currently available in preview version."
      },
      {
        "user": "nunorelvao",
        "created_at": "2023-02-20T09:13:29Z",
        "body": "Hi @yang-xiaodong , any idea when can we expect 7.1.0 to be released fully as stable nuget? Currently updating projects and in need for this options but cannot use pre-release version in PRD. Thanks."
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2023-02-20T14:06:05Z",
        "body": "\r\n> Hi @yang-xiaodong , any idea when can we expect 7.1.0 to be released fully as stable nuget? Currently updating projects and in need for this options but cannot use pre-release version in PRD. Thanks.\r\n\r\nWe're introducing new features, we released preview and need time to get feedback, maybe in the next week, I'm not sure"
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2023-02-20T14:06:56Z",
        "body": "Keep the thread clean, please open a new issue for other questions"
      }
    ]
  },
  {
    "number": 1256,
    "title": "The access path of the dashboard conflicts with the fallback route",
    "created_at": "2023-01-02T12:43:30Z",
    "closed_at": "2023-01-06T01:02:13Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/1256",
    "body": "Fallback map:\r\n\r\n```\r\napp.UseEndpoints(endpoints =>{\r\n               //other route map ...\r\n                endpoints.MapFallbackToController(\"{appKey=main}/{controller=home}/{action=index}\", \"Index\", \"Home\");\r\n});\r\n```\r\n\r\nThis will result in never being able to access/cap\r\nCan I advance the routing of the cap?",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/1256/comments",
    "author": "bxjg1987",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2023-01-04T08:15:30Z",
        "body": "This may be that the static file has been fallback, Try\r\n```\r\napp.UseEndpoints(endpoints =>\r\n{\r\n    //other route map ...\r\n    endpoints.MapFallbackToController(\"{appKey=main}/{controller=home}/{action=index}:nonfile\", \"Index\", \"Home\");\r\n});\r\n```"
      }
    ]
  },
  {
    "number": 1234,
    "title": "Messages are not getting consumed before the consumer class creation",
    "created_at": "2022-11-07T21:27:37Z",
    "closed_at": "2022-11-13T11:05:39Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/1234",
    "body": "I'm just wondering if there is a way to re-queue messages which are not consumed. I ask this since I have implemented the consumer class after publishing the message, and I expected that unhandled messages will be handled after they found a consumer implementation. But it seems not possible, you have to implement first the consumer before publishing the message. I know this is a dumb question and for sure I have to do it that way, but I just want to know if there's a way to handle those messages that were published before the ACTUAL creation of the consumer class.",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/1234/comments",
    "author": "dylangrijalva",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2022-11-09T09:20:33Z",
        "body": "If you are using Kafka, the default behavior is what you said."
      },
      {
        "user": "dylangrijalva",
        "created_at": "2022-11-09T19:32:52Z",
        "body": "I'm not using Kafka, I tried with Redis Stream and Rabbit MQ, and messages are only consumed when there is a handler, but If I publish the messages before creating the handler, the messages won't be consumed after the handler is created, I didn't find any related in the official docs. The only approach is to manually find the unconsumed messages in the dashboard and re-queue them, but it's not practical. btw: Thanks for the reply!"
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2022-11-10T02:40:34Z",
        "body": "The publishing and consumption of CAP are separated, and the publisher does not know whether the consumer exists, so it depends on the default behavior of the Broker. For RabbitMQ, if the message reaches the Exchange and does not find the consumer queue, the message will be discarded. For RedisStreams, only options are provided from the beginning of the stream or from the newly arrived message, our default behavior is to start reading from the new message"
      }
    ]
  },
  {
    "number": 1167,
    "title": "Consumer message priority feature request",
    "created_at": "2022-07-01T09:54:41Z",
    "closed_at": "2022-07-04T11:46:16Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/1167",
    "body": "实际业务场景下重要的订阅消息可能被大量低级别消息长时间阻塞，能否增加订阅队列权重优先处理高权重队列消息？",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/1167/comments",
    "author": "coolyuwk",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2022-07-01T10:00:51Z",
        "body": "You can place messages to different groups, and then set each group to have there own dispatcher to true( `UseDispatchingPerGroup=true` ) so that the message can be processed separately.\r\n\r\n See : #1027 \r\n\r\n"
      }
    ]
  },
  {
    "number": 1159,
    "title": "如何捕获Publish的异常",
    "created_at": "2022-06-17T03:34:57Z",
    "closed_at": "2022-06-18T09:00:57Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/1159",
    "body": "你好，在不使用事务的情况下，如何捕获Publish的异常。\r\n\r\n public async Task<IActionResult> CapDemo()\r\n{\r\n\t\t // do something ...\r\n\t\t\t\t\r\n                // 发送消息给客户端时发生异常，如何捕获\r\n                _capBus.Publish(\"kjframe.test\", DateTime.Now);\r\n\t\t\t\t\r\n                return Ok();\r\n            }\r\n\r\n",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/1159/comments",
    "author": "jue668",
    "comments": [
      {
        "user": "xiangxiren",
        "created_at": "2022-06-17T06:26:56Z",
        "body": "try catch"
      },
      {
        "user": "jue668",
        "created_at": "2022-06-17T07:12:14Z",
        "body": "捕获不到，在执行Publish的时候若是失败或者异常都捕获不到，只有超过重试次数后在FailedThresholdCallback回调函数中可见"
      },
      {
        "user": "xiangxiren",
        "created_at": "2022-06-17T07:19:57Z",
        "body": "Publish方法只保证消息成功插入到发送表中。发送到消息队列，并不会中断业务。重试线程会将消息多次发送到消息队列，直到发送成功为止，除非达到重试次数。"
      }
    ]
  },
  {
    "number": 1145,
    "title": "Subscriber does not consume messages 订阅端不消费消息",
    "created_at": "2022-05-27T16:29:37Z",
    "closed_at": "2022-05-30T06:28:28Z",
    "labels": [
      "help wanted",
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/1145",
    "body": "# Environment 环境\r\n\r\ndotnet: `.NetCore3.1`\r\ncap: `3.0.4`\r\nkafka: `2.3.0`\r\nmysql: `8.0.21`\r\nCentOS: `7.7.1908`\r\n\r\n# Code 代码\r\n\r\n## Publish 发布端\r\n\r\n```c#\r\nforeach(var item in list){ //less than 1000\r\n      _capBus.Publish(\"services.function\", model);\r\n}\r\n```\r\n\r\n## Subscribe 订阅端\r\n\r\n```c#\r\n[CapSubscribe(\"services.function\")]\r\npublic async Task Function(FuncModel model)\r\n{\r\n    //Business Process\r\n}\r\n```\r\n\r\n# Issues 问题\r\n\r\nHello, I have a problem that CAP has been unable to consume messages, and the messages were consumed only after the subscriber service was restarted. During this time, no error message was reported. After the service is restarted, there is no problem, the same problem occurs again after a period of time. The code is very simple, the publisher service publish the message in loop, even the messages is less than 1000, it is published successfully. However, the subscriber service does not consume the messages. The publishing service and the subscriber service are not one service, but they are deployed on the same centos server. Kafka is single deployed, and the configuration of Kafka is the default configuration. I have checked issues, and I don't seem to find the same problem, may be i did something wrong, but I can't find the reason, so i launched this issue ticket, thank you.\r\n\r\n\r\n您好，我有一个问题是关于cap一直无法消费消息，再重启订阅端服务后，消息才被消费。在这期间，没有任何的报错信息。重启服务后，一段时间都不会有问题，过一段时间后，又会发生同样的问题。代码非常简单，就是发布端循环发布消息，消息量不是很大，不到1000条的情况下，消息都发布成功了。但订阅端一直不进行消费。发布端和订阅端不是同一个服务，分开但部署在同一台centos服务器上的。kafka也是单机部署，且kafka的配置也是默认配置，没有做过调整。我查看了issues，好像没有发现有同样的问题，这可能是我的问题，但我找不到原因，想请教一下，谢谢。\r\n\r\n\r\n\r\n",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/1145/comments",
    "author": "Willxup",
    "comments": [
      {
        "user": "Willxup",
        "created_at": "2022-05-27T16:57:53Z",
        "body": "show the message info in `cap.received` :\r\n```json\r\n{ \"Headers\" :\r\n\t{ \r\n\t\t\"cap-callback-name\" : NULL,\r\n\t\t\"cap-msg-id\" : \"1527519622303399936\",\r\n\t\t\"cap-msg-name\" : \"services.function\",\r\n\t\t\"cap-msg-type\" : \"FuncModel\",\r\n\t\t\"cap-senttime\" : \"5/20/2022 1:20:32 PM +08:00\",\r\n\t\t\"cap-corr-id\" : \"1527519622303399936\",\r\n\t\t\"cap-corr-seq\" : \"0\",\r\n\t\t\"cap-msg-group\" : \"MqDefaultGroup.v1\" \r\n\t},\r\n\t\"Value\" :{}\r\n}\r\n```\r\n`Added: 2022-05-27 19:12:42`\r\n`Retries: 0`\r\n`StatusName: Succeeded`\r\n\r\nPublished time is 2022-05-20 13:20:32\r\nReceived time is 2022-05-27 19:12:42"
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2022-05-30T02:52:28Z",
        "body": "Hello,\r\n\r\nI also can't find the reason based on your description, I think you have two options.\r\n\r\n1. If you cannot upgrade to the latest version, please try to use 3.1.2 to see if the issue can be repeated?\r\n2. Check the Kafka server log to see if there is any abnormal message on the server?"
      },
      {
        "user": "Willxup",
        "created_at": "2022-05-30T03:56:04Z",
        "body": "Hello, thanks for your reply. I have checked kafka server already and could not find any error logs. I will upgrade the cap version to 3.1.2 and keep watching. Thanks."
      }
    ]
  },
  {
    "number": 1126,
    "title": "在使用netcore下的cap消息框架的时候，发现发送和接收消息容易造成拥堵，1条/1s",
    "created_at": "2022-04-16T14:10:49Z",
    "closed_at": "2022-04-20T05:40:57Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/1126",
    "body": "在使用netcore下的cap消息框架的时候，发现发送和接收消息容易造成拥堵。\r\n\r\n情况1：publish之后，本地库中待发记录在增多。然后重启应用后，每秒只能发送一条到消息中间件中，原因是cap源码中针对恢复型消息（也就是停机重启后，从数据库查询待发记录表）每处理一条，等待1s。因此积压消息的送出频率1条/s 。 且无法通过修改配置文件的方式调整；\r\n\r\n情况2：消费者接收消息中间件的消息后写入本地数据库标记为待处理，然后由调度线程负责调用消费者函数，如果消费者这里处理速度慢，就会造成消息堆积到本地。这时候如果关闭程序重新启动，那么消费者处理消息的频率被设置为1条/s 。",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/1126/comments",
    "author": "pwm812",
    "comments": [
      {
        "user": "pwm812",
        "created_at": "2022-04-16T14:15:38Z",
        "body": "请问这个有办法解决吗？访问量大的时候影响很大。。。。"
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2022-04-18T00:58:16Z",
        "body": "所以你的问题都是出现在重启应用，你重启应用的原因是什么？"
      },
      {
        "user": "pwm812",
        "created_at": "2022-04-18T10:11:11Z",
        "body": "感谢回复！！其实并没有刻意的去重启应用，我猜测是这样的：因为应用是部署在k8s中，当访问量大的时候会自动伸缩增长为多个pods（相当于多个应用），这时候可能Published表中已经积压了不少数据了，然后访问压力逐渐减少，所以相应的pods也释放了，所以是不是这个原因导致了重启应用一样的效果呢？\r\n还有请问一下，这里每发送一条后需要wait 1s，这是出于什么原因呢？现目前有没有什么办法可以解决这个问题呢？\r\n谢谢！"
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2022-04-19T09:53:40Z",
        "body": "由于CAP主要用于处理业务场景，并非ETL等。 所以正常场景下，缓存区应该都是空的，也就是说消息发送速度大于生产速度。\r\n\r\n对于你描述的情况，生产速度大于发送速度，就是在缓存区产生堆积，当堆积到一定量的时候就会触发背压机制。此时应用重启会导致缓冲区的数据丢失在重新启动后从数据库拉取，并1s发送一条。\r\n\r\n接下来我回答你的问题，或者说我认为你的场景存在的问题。\r\n\r\n1、Pod的伸缩，当Pod数量增加时，一切正常。 那么为什么缓冲区还有数据的时候（我认为缓冲区有数据就说明生产压力还是比较大）Pod都会变少呢？ 是否设计或者伸缩策略不合理？ 这不符合正常场景！\r\n\r\n2、1s一条其实主要处理的是失败的消息，对于Schedules的消息并不是我们的主要设计策略（不属于正常场景），当应用重启后，如果我们一次性将消息载入内存并进行高频发送，这可能会影响应用的正常吞吐和业务运作，很显然应用中正常的消息需要等待这批消息处理完才能被处理。\r\n\r\n\r\n通过 `ProducerThreadCount` 和 `ConsumerThreadCount` 配置项可以使用多个生产/消费者提高速度。"
      },
      {
        "user": "pwm812",
        "created_at": "2022-04-19T10:18:23Z",
        "body": "感谢解答！！最近在压测，确实应该是生产速度大于了消费速度了，我去试试你说的那两个配置看看有没有帮助。谢谢"
      }
    ]
  },
  {
    "number": 1110,
    "title": ".NetStandard 2.0 support quesiton",
    "created_at": "2022-03-28T13:00:11Z",
    "closed_at": "2022-03-29T07:06:13Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/1110",
    "body": "I just noticed that CAP is supporting .netstandard 2.1 only.\r\nIt implies that it can't be consumed by a .net4.7.2 project.\r\nIs there any particular contraint which prevents CAP to target .netstandard 2.0?\r\n",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/1110/comments",
    "author": "IlSocio",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2022-03-29T07:03:47Z",
        "body": "We do not support .NET Framework since the inception of the project"
      }
    ]
  },
  {
    "number": 1080,
    "title": "Duplicated receive messages",
    "created_at": "2022-02-04T07:20:30Z",
    "closed_at": "2022-02-15T06:39:45Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/1080",
    "body": "The problem occurs when we publish about 1k messages in a loop. We are publishing one message for each record but the same message is being received more than once.  \r\n\r\nMultiple messages are being saved in the cap.received collection, for the same published message that was saved in cap.published collection.  We found that when we put a delay between publishing processes in a loop, received message duplication is being decreased.\r\n\r\nWe are using, \r\nCap.MongoDB to persist queue messages.\r\nCap version 3.1.22 for publisher and 5.2.0 for subscriber\r\n",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/1080/comments",
    "author": "yavuzsyl",
    "comments": [
      {
        "user": "omeerkorkmazz",
        "created_at": "2022-02-04T08:26:53Z",
        "body": "@yang-xiaodong,\r\n\r\nWe noticed the same problem, too. Let me reproduce the problem with details.\r\n\r\nWe have a cron job that runs in a specified time interval. Basically, there is a `foreach` flow, and each iteration, we do some business and publish messages via `ICapPublisher`. Imagine that there is no concurrent or async publishing process. We recognized that the cap received counts are more than the published ones after an unexpected number of messages were published. What I mean is that not all messages, but, most of the messages are duplicated and processed more than once based on the received or duplicated counts. (e.g., we published 30k messages synchronously, however, 45k messages received)\r\n\r\nMore interestingly, this issue happens for a large number of messages. \r\nFor instance, we published 100, 200, 500, or 1000 messages sequentially, there was no duplication. However, when we tried to publish 10k 15k, or 30k messages, more than 4-5k messages were duplicated and received more than once.\r\n\r\nHere is a list of processes we faced the same issue;\r\n- Single thread foreach flow and sync publishing\r\n- Single thread foreach flow and async publishing\r\n- Parallel foreach and sync publishing\r\n- Parallel foreach and async publishing\r\n\r\n"
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2022-02-06T03:59:51Z",
        "body": "Hi,\r\nPossible reason, A large number of messages are placed in the published table. Before they are successfully sent to the Broker, the status is Scheduled. Due to the impact of the sent speed, this process exceeds 4 minutes. When it exceeds 4 minutes, it is picked up by the retry thread and sent again."
      },
      {
        "user": "omeerkorkmazz",
        "created_at": "2022-02-06T11:04:48Z",
        "body": "@yang-xiaodong,\r\n\r\nThanks for your explanation. So, here is what all we know; a message is published, placed in the published table, and marked as Scheduled. If a message is sent successfully to the target broker, the sent message is re-marked as Succeeded. We are OK with this process. \r\n\r\nIf I understand correctly, you mean that the sending process of messages can exceed 4 minutes due to the sent speed effects (e.g., a large number of messages, network latency, etc.). If the process exceeds a given time, the CAP retries to send a message to the target broker again. It seems that the send-retry mechanism is triggered per 4 minutes. At that moment, something occurs like a race condition, the same message is sent more than once. Is this what we are fronting?\r\n\r\nIs there any way to prevent this duplication?\r\n\r\n- Locking the message, while sending a broker?\r\n- Increasing the producer thread count so that the process can't exceed 4 minutes? \r\n- Modifying the exceeding process time for each publisher?\r\n\r\n"
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2022-02-07T01:29:44Z",
        "body": "Hi @omeerkorkmazz  \r\n\r\nThis is a known issue.\r\n\r\n1. You may have applied the CAP in the wrong scenario. The outbox mode is not suitable for processing big data scenarios, such as ETL. CAP is mainly suitable for transaction business scenarios in microservices, not data processing.\r\n\r\n2. Increasing the number of producer threads can help alleviate this but cannot be avoided, it depends on the processing speed of the database and the broker.\r\n\r\n3. In scenarios that need to prevent repetition, it is necessary to ensure idempotency through business rules"
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2022-11-23T12:01:51Z",
        "body": "We improved this behavior in version 7.0, now default will not pre-fetch to memory to sovle the slow consumer issue.\r\n"
      }
    ]
  },
  {
    "number": 1070,
    "title": "Share the same SQL server as CAP storage for multiple services",
    "created_at": "2022-01-15T01:14:41Z",
    "closed_at": "2022-01-18T09:18:14Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/1070",
    "body": "Hi, I'm wondering if it's a good practice to share the same message storage for multiple services using CAP? For example, some of our microservices doesn't have a database, it just receives messages from azure service bus and process them. Can I just create a centralised SQL server as CAP message store and share them between these services? \r\n\r\nThanks",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/1070/comments",
    "author": "waterydan",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2022-01-15T09:09:36Z",
        "body": "Yes, You can use `TableNamePrefix` option to specify that each service uses the different table.\r\n\r\n```\r\npublic void ConfigureServices(IServiceCollection services)\r\n{\r\n    services.AddCap(x =>\r\n    {\r\n        x.UseKafka(\"\");\r\n        x.UseMySql(opt =>\r\n        {\r\n            opt.ConnectionString = \"connection string\";\r\n            opt.TableNamePrefix = \"appone\"; // different table name prefix here\r\n        });\r\n    });\r\n}\r\n```"
      },
      {
        "user": "waterydan",
        "created_at": "2022-01-18T05:57:15Z",
        "body": "That worked perfectly. Thanks!"
      },
      {
        "user": "dengyangxi",
        "created_at": "2023-06-06T03:15:18Z",
        "body": "@yang-xiaodong  \r\nDoes Microsoft's SQL Server support custom table prefixes         \r\nTableNamePrefix   "
      }
    ]
  },
  {
    "number": 1069,
    "title": "Object reference not set to an instance of an object.",
    "created_at": "2022-01-12T17:28:04Z",
    "closed_at": "2022-01-14T09:34:18Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/1069",
    "body": "When submitting multiple messages in a transaction, Exception:\r\n\r\nat DotNetCore.CAP.PostgreSql.DbConnectionExtensions.ExecuteNonQuery(IDbConnection connection, String sql, IDbTransaction transaction, Object[] sqlParams)\r\n\r\nHere is sample code:\r\n\r\n```\r\n  [Route(\"~/ef/transaction\")]\r\n    public IActionResult EntityFrameworkWithTransaction([FromServices]AppDbContext dbContext)\r\n    {\r\n        using (var trans = dbContext.Database.BeginTransaction(_capBus, autoCommit: true))\r\n        {\r\n            //your business logic code\r\n\r\n            _capBus.Publish(\"xxx.services.show.time\", DateTime.Now);\r\n            _capBus.Publish(\"xxx.services.show.time\", DateTime.Now);\r\n        }\r\n\r\n        return Ok();\r\n    }\r\n```\r\n\r\nThe error occurs at the second publish.  If it's not wrapped in a transaction, no error occurs",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/1069/comments",
    "author": "c5racing",
    "comments": [
      {
        "user": "xiangxiren",
        "created_at": "2022-01-13T01:13:45Z",
        "body": "`autoCommit: false`\r\nAnd Commit transaction manually；\r\n`trans.Commit();`"
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2022-01-14T09:34:18Z",
        "body": "Setting `AutoCommit = true` means commit the transaction on publish, if you need to send multiple events, you need to switch to committing the transaction manually because we can't detect when the transaction needs to be committed"
      }
    ]
  },
  {
    "number": 1067,
    "title": "Using EF, Configuring DBContext setup OnConfiguring() not in Startup",
    "created_at": "2022-01-10T03:22:34Z",
    "closed_at": "2022-01-12T17:48:31Z",
    "labels": [
      "question",
      "fixed"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/1067",
    "body": "I am using EFCore 6 in a multi-tenant environment so in my startup.cs, I don't configure the Connection String but rather in the OnConfiguring() method of DBContext because there are multiple databases.\r\n\r\nStartup.cs:\r\n\r\n```\r\n            services.AddDbContext<UserPolicyDbContext>();\r\n\r\n            services.AddCap(x =>\r\n            {\r\n                x.UseDashboard();\r\n                x.UseEntityFramework<UserPolicyDbContext>();\r\n                string host = Configuration.GetValue<string>(\"RabbitMQ:Host\");\r\n                x.UseRabbitMQ(host);\r\n            });\r\n```\r\n\r\nUserPolicyDbContext.cs:\r\n```\r\n   protected override void OnConfiguring(DbContextOptionsBuilder optionsBuilder)\r\n        {\r\n            if (!optionsBuilder.IsConfigured)\r\n            {\r\n                var connectionString = _sharedRepository.GetDistrictConnectionStrings(_authenticatedUser.DistrictId.Value);\r\n                optionsBuilder.UseNpgsql(connectionString.Connections.UserPolicyConnectionString, options =>\r\n                {\r\n                    options.EnableRetryOnFailure();\r\n                });\r\n            }\r\n        }\r\n```\r\n\r\nFrom the documentation, CAP can autodiscover; however, at startup, there is no valid connection string.  Are there any options to configure CAP after startup? \r\n\r\nAdditionally, If I inject ICapPublisher into my DBContext so I can publish messages on the SaveChanges(), I get a stack overflow immediately.  How can I access ICapPublisher  within the context?\r\n",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/1067/comments",
    "author": "c5racing",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2022-01-10T06:21:15Z",
        "body": "If you want to use ICapPublisher   in DbContext, you need to configure with `UsePostgreSql(\"Connection String\")` not  `x.UseEntityFramework<UserPolicyDbContext>()`, In fact, we only get the connection string from the DbContext.\r\n"
      },
      {
        "user": "c5racing",
        "created_at": "2022-01-12T17:48:31Z",
        "body": "Thank you!"
      }
    ]
  },
  {
    "number": 1032,
    "title": "aliyun kafka group authorization failed exception",
    "created_at": "2021-11-02T05:47:21Z",
    "closed_at": "2021-11-05T05:37:15Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/1032",
    "body": "使用阿里云的kafka出现\r\n\r\n如下报错\r\n\r\n DotNetCore.CAP.Internal.ConsumerRegister[0]\r\n      Broker: Group authorization failed\r\n      Confluent.Kafka.ConsumeException: Broker: Group authorization failed\r\n         at Confluent.Kafka.Consumer`2.Consume(Int32 millisecondsTimeout)\r\n         at Confluent.Kafka.Consumer`2.Consume(CancellationToken cancellationToken)\r\n         at DotNetCore.CAP.Kafka.KafkaConsumerClient.Listening(TimeSpan timeout, CancellationToken cancellationToken)\r\n         at DotNetCore.CAP.Internal.ConsumerRegister.<>c__DisplayClass18_1.<Execute>b__2()\r\n2021-11-02 13:41:57.6424|ERROR|DotNetCore.CAP.Internal.ConsumerRegister|Broker: Group authorization failed\r\n\r\n\r\n\r\n在\r\ndocker下的kafka则没有问题\r\ngroupName已指定\r\n",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/1032/comments",
    "author": "dazhu6666",
    "comments": [
      {
        "user": "dazhu6666",
        "created_at": "2021-11-02T06:09:34Z",
        "body": "阿里云的kafka不能用  .  这个字符\r\n\r\n长度限制为 3 ~ 64 个字符，只能包含英文、数字、短横线（-）以及下划线（_），且至少包含一个英文或数字"
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2021-11-03T01:08:05Z",
        "body": "We are unable to assist with environmental issues. From the perspective of the exception, the exception is caused by uthorization failed"
      }
    ]
  },
  {
    "number": 1019,
    "title": "consumer threads be set separately according to groups",
    "created_at": "2021-10-19T03:04:52Z",
    "closed_at": "2021-10-19T09:25:28Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/1019",
    "body": "Hello, can consumer threads be set separately according to groups?",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/1019/comments",
    "author": "xtxk110",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2021-10-19T09:16:34Z",
        "body": "Hello,\r\nNo and we have no plans to support this feature"
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2021-11-12T03:38:05Z",
        "body": "#1027 "
      }
    ]
  },
  {
    "number": 1015,
    "title": "Is it possible to disable outbox?",
    "created_at": "2021-10-11T20:38:40Z",
    "closed_at": "2021-10-19T09:17:04Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/1015",
    "body": null,
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/1015/comments",
    "author": "remotenode",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2021-10-12T08:52:55Z",
        "body": "Hello, the outbox pattern is one of the purposes of creating this repository. \r\n\r\nWe provide InMemoryStorage to process messages in memory without using database, but if you want to ignore it completely, this is not our design goal, so we don't provide disabling way.\r\n"
      }
    ]
  },
  {
    "number": 971,
    "title": "[Question] Does CAP preserve ordering of messages?",
    "created_at": "2021-08-09T13:23:56Z",
    "closed_at": "2021-08-13T03:48:55Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/971",
    "body": "Could not find the answer in the doc, so sorry for opening the ticket/\r\n\r\nWe use kafka + postgresql, will a subscriber receive messages in the same order as they were sent? What if we failed (exception, etc) while consuming a message, will it block the processing of other messages?",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/971/comments",
    "author": "viktor-nikolaev",
    "comments": [
      {
        "user": "xiangxiren",
        "created_at": "2021-08-10T06:49:13Z",
        "body": "Order cannot be guaranteed"
      },
      {
        "user": "viktor-nikolaev",
        "created_at": "2021-08-10T08:40:52Z",
        "body": "@xiangxiren thanks,\r\nOrder cannot be guaranteed even in the \"happy\" path? ie when nothing has failed and all messages been processed successfully? "
      },
      {
        "user": "xiangxiren",
        "created_at": "2021-08-11T01:17:12Z",
        "body": "> @xiangxiren thanks,\r\n> Order cannot be guaranteed even in the \"happy\" path? ie when nothing has failed and all messages been processed successfully?\r\n\r\nYes, there is no guarantee that the order is absolutely correct."
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2021-08-11T04:40:20Z",
        "body": "Actually, \"happy\" path can guarantee the order, when broker or consumer fails, it cannot guaranteed "
      },
      {
        "user": "xiangxiren",
        "created_at": "2021-08-12T02:09:08Z",
        "body": "> Actually, \"happy\" path can guarantee the order, when broker or consumer fails, it cannot guaranteed\r\n\r\nCan the order of message confirmation be guaranteed after the business logic is processed?"
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2021-08-13T03:48:55Z",
        "body": "> Can the order of message confirmation be guaranteed after the business logic is processed?\r\n\r\nYes, it's sequential in memory"
      }
    ]
  },
  {
    "number": 932,
    "title": "RabbitMQ Questions",
    "created_at": "2021-07-05T12:15:15Z",
    "closed_at": "2021-07-06T01:30:59Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/932",
    "body": "I have 3 questions.\r\n\r\n1. Is to an option to set RabbitMQ ExchangeType = Direct?\r\n2. How to send messages to multiple exchanges from 1 microservice?\r\n3. In our application, API don't have rights to create CAP tables. Is it possible to avoid Runtime table creation?",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/932/comments",
    "author": "dweep-shah05",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2021-07-05T14:07:20Z",
        "body": "1. NO\r\n2. NO WAY\r\n3. NO"
      }
    ]
  },
  {
    "number": 930,
    "title": "How can I change the Exchange Type of rabbitmq?",
    "created_at": "2021-07-04T11:13:18Z",
    "closed_at": "2021-07-05T02:20:30Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/930",
    "body": "By default, the Exchange Type of rabbitmq is “topic”, but sometimes we need to use \"direct\" exchange type. It seems no way to change it currently. When we need to do system Integration by MQ with other system, we cannot suppose the other system to use \"topic\" exchange. So how can I do with such scenario?\r\n",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/930/comments",
    "author": "icemount",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2021-07-05T02:20:30Z",
        "body": "Since we need to take advantage of the features of Topic Exchange Type, so we don't support change the Exchange Type."
      }
    ]
  },
  {
    "number": 926,
    "title": "Question about consumer group in microservice",
    "created_at": "2021-07-02T02:38:32Z",
    "closed_at": "2021-07-12T06:46:10Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/926",
    "body": "您好,同一个微服务部署了多份,都要收到广播信息,订阅者组要怎么设置呢,[CapSubscribe(\"xxx.services.show.time\", Group = \"group1\" )]  Group并不能设置动态值或随机值,望解答 \r\n",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/926/comments",
    "author": "suichuan",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2021-07-02T02:52:34Z",
        "body": "通常情况下，一个服务拥有多个实例是只需要其中一个实例来消费消息的。如果你的场景特殊，你可以在实例启动时，通过向 DefaultGroupName 选项中指定动态值（如环境变量）来达到这一目的。\r\n\r\nNormally, a service has multiple instances and there is only one instance is needed to consume messages. If your scenario is special, you can achieve this goal by specifying dynamic values (such as environment variables) in the DefaultGroupName option when the instance startup.\r\n\r\n```\r\nservices.AddCap(x =>\r\n  {\r\n      // DefaultGroupName  默认值为程序集名称，你可以在此指定\r\n      x.DefaultGroupName = Environment.GetEnvironmentVariable(\"Group\");\r\n  });\r\n```\r\n\r\n友情提醒：请再次确认你的需求设计是否合理，因为在我看来这个需求是不合理的。"
      },
      {
        "user": "neozhu",
        "created_at": "2021-07-02T04:27:13Z",
        "body": "随机动态 在Publish/Subscribe 确实不多见，一个发布多个订阅这本身就是支持的\r\n"
      },
      {
        "user": "alexpee",
        "created_at": "2021-07-02T10:00:48Z",
        "body": "Hi , I have a subscriber service that running in multiple concurrent replica in K8s environment. If these replica instances are subscribing to the same topic and using same group id, can we guarantee the message will only be picked up by only one instance and process once only? Should I de-couple the listener to a singleton backgrounder process to avoid the racing condition?\r\n\r\np/s: The replica are using same database for the cap.received table.\r\n\r\nThank you"
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2021-07-02T10:03:49Z",
        "body": ">  Should I de-couple the listener to a singleton backgrounder process to avoid the racing condition?\r\n\r\nI'm not understand what you mean?"
      },
      {
        "user": "alexpee",
        "created_at": "2021-07-02T10:25:34Z",
        "body": "> > Should I de-couple the listener to a singleton backgrounder process to avoid the racing condition?\r\n> \r\n> I'm not understand what you mean?\r\n\r\nIs it better to run only one subscriber instance instead of multiple concurrently?"
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2021-07-03T10:19:35Z",
        "body": "No, decide whether to use multiple instances according your needs.\r\n\r\nIf you have the new question, please open a new issue so that we can focus on the issues discussed in this thread"
      }
    ]
  },
  {
    "number": 919,
    "title": "When Consumers have a lot of unread messages, readiness and liveness give not 200 status code to kubernates",
    "created_at": "2021-06-24T07:21:19Z",
    "closed_at": "2021-06-29T01:49:57Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/919",
    "body": "Our services restart every time when the service will start and read a lot of unread messages from kafka, because the service gives not 200 status code to kubernates and kubernates restart the service. After that all repeat. Our message from kafka don`t have errors, but takes a lot of CPU, memory.\r\n\r\nConsumers: ASP.NET Core\r\nDotnetCAP: version 5.0.3",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/919/comments",
    "author": "kvandake",
    "comments": [
      {
        "user": "kvandake",
        "created_at": "2021-06-24T08:13:39Z",
        "body": "May be move consumers to HostedService?"
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2021-06-24T08:24:53Z",
        "body": "What is your question?   \"takes a lot of CPU, memory\" or \"not 200 status code to kubernates\" ? "
      },
      {
        "user": "kvandake",
        "created_at": "2021-06-24T08:29:48Z",
        "body": "The messages from kafka are processed before the service starts."
      },
      {
        "user": "kvandake",
        "created_at": "2021-06-24T08:33:15Z",
        "body": "When the messages are processing, kubernates try to send readiness and liveness and get not 200 status code."
      },
      {
        "user": "kvandake",
        "created_at": "2021-06-24T08:34:07Z",
        "body": "My question - Can move consumers to Hosted Service?"
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2021-06-24T08:36:42Z",
        "body": "In ASP.NET Core, CAP uses `services.AddHostedService<Bootstrapper>();` to register to run in the background"
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2021-06-26T12:01:25Z",
        "body": "If you want to delay the start of CAP manually, you can do like this:\r\n\r\n```cs\r\npublic void ConfigureServices(IServiceCollection services)\r\n{\r\n    services.AddCap(x =>\r\n    {\r\n         // ...\r\n    });\r\n\r\n    var hostDescriptor = services.FirstOrDefault(x => x.ServiceType == typeof(IHostedService) \r\n    && x.ImplementationType.IsAssignableTo(typeof(IBootstrapper)));\r\n    if (hostDescriptor != null)\r\n    {\r\n        services.Remove(hostDescriptor);\r\n    }\r\n}\r\n```\r\n\r\n```cs\r\npublic void Configure(IApplicationBuilder app)\r\n{\r\n    Task.Run(async () => {\r\n        await Task.Delay(5000);\r\n        await app.ApplicationServices.GetRequiredService<IBootstrapper>().BootstrapAsync(default);\r\n    });\r\n    // ...\r\n}\r\n```"
      }
    ]
  },
  {
    "number": 913,
    "title": "How can i close these debug information?",
    "created_at": "2021-06-22T03:02:11Z",
    "closed_at": "2021-06-22T03:25:01Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/913",
    "body": "2021-06-22 10:55:23.6411||DEBUG|12|DotNetCore.CAP.Processor.TransportCheckProcessor|Transport connection checking... \r\n2021-06-22 10:55:23.6411||DEBUG|12|DotNetCore.CAP.Processor.TransportCheckProcessor|Transport connection healthy! \r\n\r\n非developmnet环境下运行，如何关闭这个调试信息呢，tks？",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/913/comments",
    "author": "pccai",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2021-06-22T03:07:56Z",
        "body": "appsettings.json\r\n\r\n```\r\n{\r\n  \"Logging\": {\r\n    \"LogLevel\": {\r\n      \"DotNetCore.CAP.Processor.TransportCheckProcessor\": \"None\"\r\n    }\r\n  }\r\n}\r\n```"
      }
    ]
  },
  {
    "number": 831,
    "title": "\"cap-exception\":\"SubscriberExecutionFailedException-->Object must implement IConvertible.\"}",
    "created_at": "2021-04-16T03:43:15Z",
    "closed_at": "2021-04-19T01:05:45Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/831",
    "body": "Could you please explain why publishing a simple event object structure such as two strings.\r\n\r\npublic class xEvent\r\n{\r\n  public string SessionId { get; set; }\r\n  public string EmailAddress { get; set; }\r\n}\r\n\r\nThen in the CapSubscribe the debug breakpoint is never hit. Until a server restart or if I change the ExpiresAt time in the table.\r\n\r\nFor some reason this exception gets written into the content column of the cap.received table.\r\n\r\n\"cap-exception\":\"SubscriberExecutionFailedException-->Object must implement IConvertible.\"},\"Value\":{\"SessionId\":\"55b00d9d-0735-4bb4-aa6f-cbffe6d24670\",\"EmailAddress\":\"anemail@googlemail.com\"}\r\n\r\nThe job is eventually successful but why is the retries 3 and then it takes a restart for the item to be processed?\r\n\r\nThank you\r\n\r\nAdrian",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/831/comments",
    "author": "Codare",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2021-04-16T05:05:26Z",
        "body": "Hello,\r\n\r\nConsumers using `CapSubscribe` cannot hit the debug breakpoint, this is an issue that needs to be investigated. They work well in my environment.\r\n\r\nLet me explain your other question.\r\n\r\nIn CAP, whether it is sending or subscribing, we will all retry when it fails. The number of retries depends on the options value of `FailedRetryCount`. The actual execution process will be slightly different. If the sender or executor encounters a failure during the first round of sending or execution, it will directly retry three times. We think this is a reasonable value. If all three attempts in the first round fail, the subsequent retry work will be processed by the retry processor. The retry processor will always process messages generated four minutes ago,  this is because if real-time processing may cause the message to be repeated pick up from the storage. \r\n\r\nThe above mechanisms have nothing to do with whether to restart the application or not, and I think it may be the reason why you  believe that restarting the application takes effect.\r\n\r\nThanks"
      }
    ]
  },
  {
    "number": 804,
    "title": "When do you can release the .net 5 Versio of CAP? (a message from nuget by Andreas)",
    "created_at": "2021-03-22T04:08:55Z",
    "closed_at": "2021-03-23T01:13:11Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/804",
    "body": "*This is a message from nuget by Andreas.*\r\n\r\n> User hilki1 <andreas.h\\*\\*\\*\\*n@h\\*\\*\\*\\*nit.ch> sends the following message to the owners of Package 'DotNetCore.CAP 5.0.0-preview-132888327'.\r\n\r\nHi\r\n\r\nWhen do you can release the .net 5 Versio of CAP? Thx in Advance.\r\n\r\nAndreas\r\n",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/804/comments",
    "author": "alexinea",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2021-03-23T01:13:11Z",
        "body": "Hello, Version 5.0 was released a few minutes ago"
      }
    ]
  },
  {
    "number": 797,
    "title": "Any plan to support golang or nodejs?",
    "created_at": "2021-03-10T06:07:28Z",
    "closed_at": "2021-03-10T06:21:43Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/797",
    "body": "FEATURE request\r\n\r\nany plan to support Golang or nodejs?\r\n",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/797/comments",
    "author": "adxpcc",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2021-03-10T06:21:43Z",
        "body": "Hello,\r\nWe have no plan to support other languages"
      }
    ]
  },
  {
    "number": 747,
    "title": "Question about IDbContextTransaction  extension methods",
    "created_at": "2020-12-21T10:42:12Z",
    "closed_at": "2020-12-22T09:24:59Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/747",
    "body": "英文水平有限,请允许我使用中文😅\r\n\r\n你好 @yang-xiaodong.\r\n首先感谢您提供cap 这个非常好用的组件.\r\n我是这几天在尝试使用cap写了几个小的样例， 准备之后在我的项目中正式使用他。\r\n在用到事务的时候， 我这边有一点小的疑问，\r\n1. 由cap来的扩展方法来创建一个 IDbContextTransaction 对象的这种方式，如果换成由cap 来接受一个IDbContextTransaction对象会不会更好一些。\r\n2. BeginTransaction 中的 “autoCommit”参数，虽然这个参数是可选的，在我的理解中cap应该是更关注消息的传递这一块， 如果我使用cap来帮我提交业务代码，在职责会不会有一些模糊。\r\n\r\n可能表达上没那么的条理清晰， 不要介意😶😶😶",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/747/comments",
    "author": "Goleven",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2020-12-22T01:16:13Z",
        "body": "Hello, let me answer you question,\r\n\r\n> 由cap来的扩展方法来创建一个 IDbContextTransaction 对象的这种方式，如果换成由cap 来接受一个IDbContextTransaction对象会不会更好一些\r\n\r\nI think the extension method is more in line with the user experience. Of course, you can ignore the extension method to encapsulate and pass in IDbContextTransaction by yourself. This is entirely up to you.\r\n\r\n> BeginTransaction 中的 “autoCommit”参数，虽然这个参数是可选的，在我的理解中cap应该是更关注消息的传递这一块， 如果我使用cap来帮我提交业务代码，在职责会不会有一些模糊。\r\n\r\nAutoCommit aims to provide a simple way to help commit transactions, because it is still attached to the ICapTransaction object, so I think its responsibilities are clear"
      }
    ]
  },
  {
    "number": 718,
    "title": "How to configure node discovery  service check with cousul use tcp or grpc?",
    "created_at": "2020-11-16T01:39:56Z",
    "closed_at": "2020-11-16T01:45:50Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/718",
    "body": "",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/718/comments",
    "author": "zqlovejyc",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2020-11-16T01:41:35Z",
        "body": "This library does not provide service check features"
      }
    ]
  },
  {
    "number": 716,
    "title": "is there anyway to ack rabbitmq message by myself",
    "created_at": "2020-11-13T07:41:35Z",
    "closed_at": "2020-11-16T03:47:25Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/716",
    "body": "if i want to reject a message,and i want to consumer it later,i need to throw an exception,like that \r\n\r\n`  [CapSubscribe(\"queueName\")]\r\n\r\n  public async Task SubscribeAsync(string message)\r\n\r\n  {\r\n\r\n        throw new Exception(\"i don't want to ack message\");\r\n\r\n }`\r\n",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/716/comments",
    "author": "szg",
    "comments": [
      {
        "user": "redochenzhen",
        "created_at": "2020-11-13T09:56:06Z",
        "body": "I don't think you can do this in a CAP 'Subscriber'. Maybe 'RabbitMQ.Client' can help to work around.\r\n\r\n'"
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2020-11-13T10:06:28Z",
        "body": "If you do not ack the message, you will not be able to receive subsequent messages unless you use the dead letter queue.\r\n\r\nCAP is designed to be flexible, it will automatically retry and eventually consistency."
      }
    ]
  },
  {
    "number": 676,
    "title": "Like to add Subscription at runtime",
    "created_at": "2020-09-25T14:51:20Z",
    "closed_at": "2020-09-29T09:32:11Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/676",
    "body": "I would like to add Subscriptions for routing keys at runtime, and add an EventHandler, insted of using CanSubscribe Attribute. Is there a way to do that?",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/676/comments",
    "author": "hilkenan",
    "comments": [
      {
        "user": "wificlub-code",
        "created_at": "2020-09-26T10:32:58Z",
        "body": "\r\npublic class CustomConsumerServiceSelector : ConsumerServiceSelector\r\n    {\r\n        public CustomConsumerServiceSelector(IServiceProvider serviceProvider) : base(serviceProvider)\r\n        { \r\n        }\r\n\r\n        protected override IEnumerable<ConsumerExecutorDescriptor> FindConsumersFromInterfaceTypes(IServiceProvider provider)\r\n        {\r\n            var executorDescriptorList = new List<ConsumerExecutorDescriptor>();\r\n            executorDescriptorList.AddRange(base.FindConsumersFromInterfaceTypes(provider));\r\n\r\n            var eventHandlerTypeInfo = typeof(IIntegrationEventHandler).GetTypeInfo();\r\n\r\n            foreach (var service in ServiceCollectionExtensions.ServiceCollection.Where(o => o.ImplementationType != null && o.ServiceType != null))\r\n            {\r\n\r\n                //TODO:\r\n            }\r\n            return executorDescriptorList;\r\n        }\r\n    }\r\n\r\n    public interface IIntegrationEventHandler<in TIntegrationEvent> : IIntegrationEventHandler\r\n       where TIntegrationEvent : class\r\n    {\r\n        Task HandleAsync(TIntegrationEvent @event);\r\n    }\r\n\r\n    public interface IIntegrationEventHandler\r\n    {\r\n    }"
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2020-09-26T17:16:53Z",
        "body": "Hi @hilkenan \r\nSubscription at runtime is not currently supported"
      }
    ]
  },
  {
    "number": 665,
    "title": "does cap support delay queue？",
    "created_at": "2020-09-11T02:43:08Z",
    "closed_at": "2020-09-13T07:11:49Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/665",
    "body": "when i query db,it return nothing,but\ni am sure that,it would return data after several hours. when i get nonthing,i need\npublish a delay queue excute after 1 hour until it returns sm data. but cap doesn't support delay queue currently. how to do?thanks!",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/665/comments",
    "author": "csabc",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2020-09-11T12:53:35Z",
        "body": "You can use CAP with Quartz.NET or Hangfire"
      },
      {
        "user": "csabc",
        "created_at": "2020-09-12T11:36:42Z",
        "body": "in some cases,cap is running on microserver A,hangfire is running on microserver B,cap has  handed event,but no hangfire server runs on server A. cap\n needs to  a delay queue to process some task... I think there is no need to also run a hangfire service on microserver A."
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2020-09-13T07:11:49Z",
        "body": "It depends on how you use Hangfire, you can also integrate Hangfire and CAP together, and then use CAP to perform the delayed action of the callback"
      }
    ]
  },
  {
    "number": 638,
    "title": "cap support  rabbitmq qos?",
    "created_at": "2020-08-21T03:06:36Z",
    "closed_at": "2020-08-25T10:05:20Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/638",
    "body": "cap support qos?",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/638/comments",
    "author": "doufeng007",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2020-08-21T14:14:51Z",
        "body": "You can customize `IConsumerClient` to get the expected behavior"
      }
    ]
  },
  {
    "number": 556,
    "title": "Subscribe to multiple message types per topic",
    "created_at": "2020-04-27T14:12:44Z",
    "closed_at": "2020-05-01T12:22:08Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/556",
    "body": "Hi, we're using this library for pub/sub with kafka as our broker. We have everything running successfully, but I haven't been able to successfully subscribe to multiple message types per topic.\r\n\r\nGiven this example, we have a users topic, and publish UserCreated and UserUpdated events. The publish side is working as expected, and the messages have a cap-msg-type header with the corresponding type.\r\n\r\n```\r\npublic abstract class UserEvent\r\n{\r\n    protected UserEvent(Guid userId, string name, DateTime createdOn)\r\n    {\r\n        Name = name;\r\n        CreatedOn = createdOn;\r\n        UserId = userId;\r\n    }\r\n\r\n    public Guid UserId { get; }\r\n    \r\n    public string Name { get; }\r\n    \r\n    public DateTime CreatedOn { get; }\r\n}\r\n\r\npublic class UserCreated : UserEvent\r\n{\r\n    public UserCreated(Guid userId, string name, DateTime createdOn) : base(userId, name, createdOn) { }\r\n    \r\n    public static UserCreated Create(string name) => new UserCreated(Guid.NewGuid(), name, DateTime.Now);\r\n}\r\n\r\npublic class UserUpdated : UserEvent\r\n{\r\n    public UserUpdated(Guid userId, string name, DateTime createdOn) : base(userId, name, createdOn) { }\r\n    \r\n    public static UserUpdated Create(Guid userId, string name) => new UserUpdated(userId, name, DateTime.Now);\r\n}\r\n```\r\n\r\nHowever, on the subscribe side, I would like to have individual handlers for each message type.\r\n\r\n```\r\npublic interface IHandleEvent<in TEvent> : ICapSubscribe\r\n{\r\n    Task Handle(TEvent @event);\r\n}\r\n\r\npublic class UserCreatedHandler : IHandleEvent<UserCreated>\r\n{\r\n    private readonly ILogger<UserCreatedHandler> _logger;\r\n\r\n    public UserCreatedHandler(ILogger<UserCreatedHandler> logger) => _logger = logger;\r\n\r\n    [CapSubscribe(\"cap.kafka.sqlserver\")]\r\n    public Task Handle(UserCreated @event)\r\n    {\r\n        _logger.LogInformation($\"Handled UserCreated with Id {@event.UserId}\");\r\n        \r\n        return Task.CompletedTask;\r\n    }\r\n}\r\n\r\npublic class UserUpdatedHandler : IHandleEvent<UserUpdated>\r\n{\r\n    private readonly ILogger<UserUpdatedHandler> _logger;\r\n\r\n    public UserUpdatedHandler(ILogger<UserUpdatedHandler> logger) => _logger = logger;\r\n\r\n    [CapSubscribe(\"cap.kafka.sqlserver\")]\r\n    public Task Handle(UserUpdated @event)\r\n    {\r\n        _logger.LogInformation($\"Handled UserUpdated with Id {@event.UserId}\");\r\n        \r\n        return Task.CompletedTask;\r\n    }\r\n}\r\n```\r\n\r\nIn this example, I want 2 subscribers for the same topic, and have the messages routed by type, but I don't see a mechanism in the library to support this. Only the first subscriber handles all messages types, and the groups concept doesn't really fit here.\r\n\r\nBased on this it looks like my options are to provide an impl for IConsumerRegister and IConsumerServiceSelector, or to have a single CAP handler for each topic, and have another mechanism to route specific message types. Have you ran into this, or have a recommendation on how to approach this?\r\n\r\nAlso, thank you for this great lib.\r\n",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/556/comments",
    "author": "jblackburn21",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2020-04-29T01:43:30Z",
        "body": "Hello,\r\n\r\nCAP does not read the type of message content for routing. On the contrary, as long as your subscribed message can be deserialized correctly, even if it is different from the sender of the message type, it also can be accepted. This scenario is very common in cross-service .\r\n\r\nIn response to your question, I suggest you take one of two ways.\r\n\r\n* Use different topics for different operations, namely `cap.kafka.sqlserver.usercreated` and `cap.kafka.sqlserver.userupdated`\r\n\r\n* Use the topic `cap.kafka.sqlserver`, but add a type to your UserEvent, and then you control the routing. E.g\r\n```cs\r\n[CapSubscribe (\"cap.kafka.sqlserver\")]\r\npublic Task Handle (UserEvent @event)\r\n{\r\n     if (@event.Type == \"UserCreate\") \r\n     {\r\n         HandleUserCreated (@event);\r\n     } \r\n     else if (@event.Type == \"UserUpdated\") \r\n     {\r\n         HandleUserUpdated (@event);\r\n     }\r\n}\r\n```\r\nAt present, `cap-msg-type` header it is just a record, it has not been used in actual use.\r\n\r\nIn your scenario, you may be able to use this header for routing without add the type to your UserEvent class\r\n\r\n"
      },
      {
        "user": "jblackburn21",
        "created_at": "2020-04-29T23:23:00Z",
        "body": "Thank you for the suggestions."
      }
    ]
  },
  {
    "number": 535,
    "title": "Question about failed message retry deplay time",
    "created_at": "2020-03-31T09:25:41Z",
    "closed_at": "2020-04-01T15:04:19Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/535",
    "body": "一次获取 200 条需要重试的消息，每条消息之间需要等待一秒。200条消息发送后需要等待 60秒（默认配置）。如果出现大量的消息发送失败，这个重试轮询会不会太慢了点。\r\n\r\n```\r\n// Copyright (c) .NET Core Community. All rights reserved.\r\n// Licensed under the MIT License. See License.txt in the project root for license information.\r\n\r\nusing System;\r\nusing System.Collections.Generic;\r\nusing System.Linq;\r\nusing System.Threading.Tasks;\r\nusing Microsoft.Extensions.DependencyInjection;\r\nusing Microsoft.Extensions.Logging;\r\nusing Microsoft.Extensions.Options;\r\n\r\nnamespace DotNetCore.CAP.Processor\r\n{\r\n    public class MessageNeedToRetryProcessor : IProcessor\r\n    {\r\n        private readonly TimeSpan _delay = TimeSpan.FromSeconds(1);\r\n        private readonly ILogger<MessageNeedToRetryProcessor> _logger;\r\n        private readonly IPublishMessageSender _publishMessageSender;\r\n        private readonly ISubscriberExecutor _subscriberExecutor;\r\n        private readonly TimeSpan _waitingInterval;\r\n\r\n        public MessageNeedToRetryProcessor(\r\n            IOptions<CapOptions> options,\r\n            ILogger<MessageNeedToRetryProcessor> logger,\r\n            ISubscriberExecutor subscriberExecutor,\r\n            IPublishMessageSender publishMessageSender)\r\n        {\r\n            _logger = logger;\r\n            _subscriberExecutor = subscriberExecutor;\r\n            _publishMessageSender = publishMessageSender;\r\n            _waitingInterval = TimeSpan.FromSeconds(options.Value.FailedRetryInterval);\r\n        }\r\n\r\n        public async Task ProcessAsync(ProcessingContext context)\r\n        {\r\n            if (context == null)\r\n            {\r\n                throw new ArgumentNullException(nameof(context));\r\n            }\r\n\r\n            var connection = context.Provider.GetRequiredService<IStorageConnection>();\r\n\r\n            await Task.WhenAll(ProcessPublishedAsync(connection, context), ProcessReceivedAsync(connection, context));\r\n\r\n            await context.WaitAsync(_waitingInterval);\r\n        }\r\n\r\n        private async Task ProcessPublishedAsync(IStorageConnection connection, ProcessingContext context)\r\n        {\r\n            context.ThrowIfStopping();\r\n\r\n            var messages = await GetSafelyAsync(connection.GetPublishedMessagesOfNeedRetry);\r\n\r\n            foreach (var message in messages)\r\n            {\r\n                await _publishMessageSender.SendAsync(message);\r\n\r\n                await context.WaitAsync(_delay);\r\n            }\r\n        }\r\n\r\n        private async Task ProcessReceivedAsync(IStorageConnection connection, ProcessingContext context)\r\n        {\r\n            context.ThrowIfStopping();\r\n\r\n            var messages = await GetSafelyAsync(connection.GetReceivedMessagesOfNeedRetry);\r\n\r\n            foreach (var message in messages)\r\n            {\r\n                await _subscriberExecutor.ExecuteAsync(message);\r\n\r\n                await context.WaitAsync(_delay);\r\n            }\r\n        }\r\n\r\n        private async Task<IEnumerable<T>> GetSafelyAsync<T>(Func<Task<IEnumerable<T>>> getMessagesAsync)\r\n        {\r\n            try\r\n            {\r\n                return await getMessagesAsync();\r\n            }\r\n            catch (Exception ex)\r\n            {\r\n                _logger.LogWarning(1, ex, \"Error : Get messages of type '{messageType}' failed. Retrying...\", typeof(T).Name);\r\n\r\n                return Enumerable.Empty<T>();\r\n            }\r\n        }\r\n    }\r\n}\r\n```",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/535/comments",
    "author": "cuibty",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2020-04-01T01:52:52Z",
        "body": "你只考虑到了失败转向成功的过程，而没有考虑到一直失败的情况。 \r\n大多数情况下失败的会一直失败，这会对数据库和应用会的负载会有较大影响。\r\n另外，为什么会堆积了大量失败的消息，这个问题你需要思考一下?"
      },
      {
        "user": "cuibty",
        "created_at": "2020-04-03T14:16:31Z",
        "body": "thks"
      }
    ]
  },
  {
    "number": 530,
    "title": "Repeated query and delivery of messages",
    "created_at": "2020-03-22T01:37:06Z",
    "closed_at": "2020-03-27T14:51:16Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/530",
    "body": "How to ensure that querying message tables and sending messages will not be duplicated when distributed systems use CAP\r\n\r\nPS:中文\r\n程序多开并在使用CAP时，如何保证查询消息表和发送消息不会重复。",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/530/comments",
    "author": "cysnet",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2020-03-27T14:51:16Z",
        "body": "We only reread the failed message table and send it under abnormal conditions. If there are multiple instances reading the error message at the same time, it may theoretically lead to repeated delivery. In any case if you is sensitive to the message repeatability that you need to guarantee the idempotence."
      }
    ]
  },
  {
    "number": 526,
    "title": "ICapPublisher transaction & Is Subscription also a singleton?",
    "created_at": "2020-03-13T01:43:54Z",
    "closed_at": "2020-03-14T11:46:27Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/526",
    "body": "大大你好, 我看了好几个CAP版本的文档,  里面提到ICapPublisher已经被设定成了单例, 在任何地方通过构造函数注入都可以安全使用, 那么多次发布消息的情况下, ICapPublisher对象的事务会不会有冲突呀.\r\n比如: 数据服务类A,  构造方法中注入了ICapPublisher,    在A类的Update方法中using了DbContext, 同时将事务对象进行赋值, 类似如下:\r\n\r\n`\r\nusing (var dbTransaction = await DbContext.BeginTransactionAsync())\r\n                        {\r\n                            CapPublisher.Transaction.Value = CapPublisher.ServiceProvider.GetService<ICapTransaction>();\r\n                            var capTransaction = CapPublisher.Transaction.Value.Begin(dbTransaction, false);\r\n                            //todo 执行具体实体更新业务....\r\n\r\n                            CapPublisher.Publish(\"里面来一次\", \"...\");\r\n                            await DbContext.SaveChangesAsync();\r\n                            capTransaction.Commit();\r\n                        }\r\n                        CapPublisher.Publish(\"在外面再来一次\", \"...\");`\r\n\r\n在using中进行的那次消息发布, 会和DbContext保持一个事务, 那么外面那一次会不会重新开一个事务?  只是不能和上面那一个using中的事务保持一致性而已吗?\r\n如果部署成线上的服务, 会有较大的并发, ICapPublisher不断游走在\"里面来一次\" 和 \"外面再来一次\", 因为其是单例的原因, 事务方面会造成干扰吗?\r\n\r\n第二个问题是关于Subscription的问题, 比如API收到一个GET请求, 如果有个类注入为Scoped的, 类似.NET的HttpContext, 再这次请求的过程中都保持为同一个, 直到请求结束,  而如果将一个方法加上了订阅的特性, 一旦收到订阅, 订阅本身属于一个Scoped吗? 还是说也是单例的? \r\n\r\n问题有点多, 烦请大大有时间的时候解答, 感激不尽...\r\n",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/526/comments",
    "author": "JonFly",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2020-03-14T11:46:27Z",
        "body": "1、CAP使用 AsyncLocal 来存储事务\r\n2、在执行消费者方法时，CAP会打开一个Scope来执行注入"
      }
    ]
  },
  {
    "number": 520,
    "title": "Message Adaper in version 3.0",
    "created_at": "2020-03-09T02:32:14Z",
    "closed_at": "2020-03-10T03:48:08Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/520",
    "body": "3.0 无法支持异构系统消息，2.6可以，目前只能从修改此DotNetCore.CAP.Kafka程序集才能达到要求，能否增加一个消息适配接口？",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/520/comments",
    "author": "yuyixg",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2020-03-09T05:36:39Z",
        "body": "Please describe your issue in detail"
      },
      {
        "user": "yuyixg",
        "created_at": "2020-03-09T09:40:37Z",
        "body": "异构系统的消息格式各种各样的，目前cap要求消息头里面必须有两个信息，一个为MessageId，另一个是MessageName，如果是老旧系统或者其他非cap系统那么这两个消息头肯定是不存在的，目前无法很简单的兼容这种消息，但是在cap2.6 中是可以转换的。"
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2020-03-10T03:48:08Z",
        "body": "3.0 的消息对消息结构是没有限制的，所以更加灵活。另外，我们删除了v2.6中的消息适配器。\r\n消息头在是我们用来对消息进行识别的，如果没有将无法正常工作。\r\n在异构系统中，消息头是需要约定的一致的。\r\n\r\n如果是旧系统无法修改代码的情况下，你可以简单的通过写一个消费者程序将消息转换然后重新投递到新队列的方式来做到这一点。\r\n"
      }
    ]
  },
  {
    "number": 493,
    "title": "How to ignore retry caused by some exception such as primary key conflict, I usually use primary key conflict to ensure idempotence during insert operation",
    "created_at": "2020-01-20T07:08:47Z",
    "closed_at": "2020-01-20T07:18:10Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/493",
    "body": "      How to ignore retry caused by some exception such as primary key conflict, I usually use primary key conflict to ensure idempotence during insert operation.I hope these messages can become faild messages directly instead of trying to retry multiple times\r\n",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/493/comments",
    "author": "dingsongjie",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2020-01-20T07:18:10Z",
        "body": "Add `try catch` at your consumer\r\n```C#\r\ntry\r\n{\r\n    //Your code\r\n}\r\ncatch (SqlException e )\r\n{\r\n    if (e.Number == primary key conflict code)\r\n    {\r\n            //ignore\r\n    }\r\n   \r\n}\r\n```"
      },
      {
        "user": "dingsongjie",
        "created_at": "2020-01-20T08:55:00Z",
        "body": "```cs\r\ntry\r\n{\r\n    //Your code\r\n}\r\ncatch (SqlException e )\r\n{\r\n    if (e.Number == primary key conflict code)\r\n    {\r\n            //ignore\r\n    }\r\n   \r\n}\r\n```\r\nThe above code will make consumers consume normally instead of generating a Fail.\r\nI just want ignore retry  when some special exception happens"
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2020-01-20T09:14:08Z",
        "body": "The above code just ignore the sqlexception of the exception code is primary key conflict, can you get it?\r\n\r\nJust catch your focus exception and ignore it!\r\n"
      }
    ]
  },
  {
    "number": 476,
    "title": "关于事务的控制权",
    "created_at": "2020-01-08T02:54:27Z",
    "closed_at": "2020-01-08T05:55:43Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/476",
    "body": "```csharp\r\npublic override async Task CommitAsync(CancellationToken cancellationToken = default)\r\n{\r\n    Debug.Assert(DbTransaction != null);\r\n\r\n    switch (DbTransaction)\r\n    {\r\n        case IDbTransaction dbTransaction:\r\n            dbTransaction.Commit();\r\n            break;\r\n        case IDbContextTransaction dbContextTransaction:\r\n            await dbContextTransaction.CommitAsync(cancellationToken);\r\n            break;\r\n    }\r\n    Flush();\r\n}\r\n```\r\n\r\n如何在外部控制事务提交？\r\n\r\n因为提交事务的操作中可能还有其他操作，不是简单 tran.Commit() 就完事。\r\n\r\n如果把事务提交权交给 Cap，整个事务就终断。\r\n\r\n伪代码如下：\r\n\r\n```csharp\r\nusing (var uow = ....())\r\n{\r\n    _capPublisher.Transaction.Value.Begin(uow.Transaction);\r\n    //...\r\n    uow.Commit(); // 这样提交 _capPublisher.Flush 没有被执行\r\n}\r\n\r\nusing (var uow = ....())\r\n{\r\n    _capPublisher.Transaction.Value.Begin(uow.Transaction);\r\n    //...\r\n    capPublisher.Commit(); // 这样提交 uow.Commit 内部其他逻辑没有被执行\r\n}\r\n```\r\n\r\n建议：开放 Flush 方法给外部使用",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/476/comments",
    "author": "2881099",
    "comments": [
      {
        "user": "2881099",
        "created_at": "2020-01-08T03:35:05Z",
        "body": "个人的建议：\r\n\r\n如果事务由 cap 发起，可以由 cap 来控制\r\n\r\n如果事务由外部发起，应该由外部控制，cap 提供 Flush 方法"
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2020-01-08T05:55:43Z",
        "body": "The question has been externally answered"
      }
    ]
  },
  {
    "number": 474,
    "title": "Question about why reading message from database delay by 4 minutes",
    "created_at": "2020-01-06T09:46:34Z",
    "closed_at": "2020-01-09T13:29:49Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/474",
    "body": "为什么消息持久化到数据库后重新读取要等待4分钟,还不能自定义时间\r\n",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/474/comments",
    "author": "allanhboy",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2020-01-08T05:53:15Z",
        "body": "I do not know why you need this feature?\r\n\r\nI can explain why we set up a delayed four minutes to read the message from the database.\r\n\r\nBy default, when the CAP is started, a retry thread is enabled. Instead, the retry thread reads unsent or failed messages from the database every 1 minute. This is a mechanism to ensure availability.\r\n\r\nIn some cases, if the message is directly read from the database in real time, it may have serious consequences, such as when the message is persisted and before it is sent, then its status is `Scheduled`. At this time, the retry thread will read the message and send it. This will cause repeated sending of messages. In order to solve this problem we set a delay of 4 minutes. This can try to avoid the problem of uncommitted messages being sent"
      },
      {
        "user": "allanhboy",
        "created_at": "2020-01-09T05:27:29Z",
        "body": "可是我一使用事务同步事件的推送后,就必定会触发这可恶的4分钟机制,如果不使用事务推送就是瞬间执行,但是为了确保消息,我又不得不使用事务进行推送"
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2020-01-09T05:50:43Z",
        "body": "Please show the code of how you use transactions to publish messages"
      },
      {
        "user": "allanhboy",
        "created_at": "2020-01-09T06:56:10Z",
        "body": "就是使用的eShopOnContainers的实例 \r\n```\r\npublic class OrderingIntegrationEventService : IOrderingIntegrationEventService\r\n    {\r\n        private readonly ICapPublisher _eventBus;\r\n        private readonly OrderingContext _orderingContext;\r\n        private readonly ILogger<OrderingIntegrationEventService> _logger;\r\n\r\n        public OrderingIntegrationEventService(ICapPublisher eventBus,\r\n            OrderingContext orderingContext,\r\n            ILogger<OrderingIntegrationEventService> logger)\r\n        {\r\n            _orderingContext = orderingContext ?? throw new ArgumentNullException(nameof(orderingContext));\r\n            _eventBus = eventBus ?? throw new ArgumentNullException(nameof(eventBus));\r\n            _logger = logger ?? throw new ArgumentNullException(nameof(logger));\r\n        }\r\n\r\n        public async Task AddAndSaveEventAsync(object evt)\r\n        {\r\n            _logger.LogInformation(\"----- Enqueuing integration event to repository ({@IntegrationEvent})\", evt);\r\n\r\n            _eventBus.Transaction.Begin(_orderingContext.GetCurrentTransaction().GetDbTransaction());\r\n            await _eventBus.PublishAsync(evt.GetGenericTypeName(), evt);\r\n        }\r\n    }\r\n```"
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2020-01-09T13:29:49Z",
        "body": "你真是惜字如金啊，连自己环境都不提供，代码也不知道格式化。eShop是使用的 SQL Server 会自动检测事务提交Flush消息，其他数据库自己看源码吧，太气了！"
      }
    ]
  },
  {
    "number": 468,
    "title": "why _publishedMessageQueue.TryTake，not _publishedMessageQueue.Take?",
    "created_at": "2019-12-26T06:53:18Z",
    "closed_at": "2019-12-26T13:42:35Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/468",
    "body": "What are the reason to use  TryTake?  it is same to run next  while？",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/468/comments",
    "author": "doufeng007",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2019-12-26T13:42:35Z",
        "body": "Take is invoke TryTake at the inner, and it does not support timeout"
      }
    ]
  },
  {
    "number": 466,
    "title": "_capBus.Publish() is sync or async？;",
    "created_at": "2019-12-23T08:15:43Z",
    "closed_at": "2019-12-23T11:22:59Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/466",
    "body": "_capBus.Publish();\r\n otherCode();\r\n\r\nI means :\r\nwhether_capBus.Publish() will block  flowing code ( otherCode()) or not ?\r\n",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/466/comments",
    "author": "enginnerFrankLiu",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2019-12-23T11:22:59Z",
        "body": "Write event table synchronously"
      }
    ]
  },
  {
    "number": 465,
    "title": "Can not find function \"BeginTransaction\"",
    "created_at": "2019-12-23T02:46:09Z",
    "closed_at": "2019-12-23T11:23:41Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/465",
    "body": "        [HttpGet(\"pdb\")]\r\n        public IActionResult GetDb()\r\n        {\r\n            using (var trans = _dbContext.Database.BeginTransaction(_capBus, autoCommit: true))\r\n            {\r\n                //业务代码\r\n\r\n                _capBus.Publish(\"xxx.services.show.time\", DateTime.Now);\r\n            }\r\n            return Ok();\r\n        }",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/465/comments",
    "author": "cysnet",
    "comments": [
      {
        "user": "cysnet",
        "created_at": "2019-12-23T03:00:31Z",
        "body": "BeginTransaction  method is not overloaded with two parameters\r\n\r\n\r\n"
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2019-12-23T11:23:41Z",
        "body": "You need import `DotNetCore.CAP` namespace"
      }
    ]
  },
  {
    "number": 443,
    "title": "请问CAP是怎么保证消息的顺序的？",
    "created_at": "2019-12-01T06:02:00Z",
    "closed_at": "2019-12-01T15:01:29Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/443",
    "body": "可能会有多个人先后修改同一条数据，针对修改操作，请问CAP是怎么保证修改的顺序的？",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/443/comments",
    "author": "xubb1988",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2019-12-01T15:01:29Z",
        "body": "Message-based architecture does not strictly guarantee messages sequence.\r\nDuplicated of #29"
      }
    ]
  },
  {
    "number": 433,
    "title": "Question about how to using RabbitMQ",
    "created_at": "2019-11-18T00:07:10Z",
    "closed_at": "2019-11-20T03:58:49Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/433",
    "body": "现在cap使用rabbitmq，是和queue绑定的？如果服务a是发布者，服务b既是发布者，也是a的订阅者，服务b 的订阅和发布可以使用不同的队列吗？",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/433/comments",
    "author": "haoas",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2019-11-19T03:39:24Z",
        "body": "你的理解可能有问题。\r\n\r\nCAP屏蔽了底层的消息传输，我们讨论应该是基于上层ＣＡＰ的使用方式以及概念来进行。\r\n\r\n现在你提的问题，既有底层这种和具体ＭＱ有关系的绑定，又有上层发布订阅这种逻辑概念的使用方式，所以我无法理解你的意思。"
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2019-11-20T03:58:49Z",
        "body": "no response , closed!"
      }
    ]
  },
  {
    "number": 415,
    "title": "How to configure non root path access for dashboard?",
    "created_at": "2019-10-21T14:11:32Z",
    "closed_at": "2019-10-22T07:40:42Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/415",
    "body": "Our service is deployed in a secondary directory, for example, “/service/user”. How to configure “/service /user/cap” to work normally? thx",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/415/comments",
    "author": "one-sword",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2019-10-22T07:40:42Z",
        "body": "You can use dashboard option of `PathMatch` to setting it.\r\n\r\n```\r\nx.UseDashboard(opt => opt.PathMatch = \"/service/user/cap\");\r\n```"
      }
    ]
  },
  {
    "number": 408,
    "title": "我想问一下作者是如何解决rabbitmq.client  并发时 得不到队列数据的问题的",
    "created_at": "2019-10-11T00:53:46Z",
    "closed_at": "2019-10-16T14:05:35Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/408",
    "body": "我想问一下作者是如何解决rabbitmq.client  并发时 得不到队列数据的问题的",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/408/comments",
    "author": "winlj",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2019-10-11T01:16:43Z",
        "body": "If you want someone to answer your question, you need describe your problem in detail"
      }
    ]
  },
  {
    "number": 386,
    "title": "How to subscribe multiple message in console app",
    "created_at": "2019-08-26T06:29:24Z",
    "closed_at": "2019-08-26T06:51:11Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/386",
    "body": "Hi yang-xiaodong\r\n\r\n Follow by issues #275.\r\n I'd like to ask you how to subscribe multiple message in console app?\r\n\r\nTks so much\r\n",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/386/comments",
    "author": "tuongntk",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2019-08-26T06:42:38Z",
        "body": "You can add multiple consumer method to subscribe multiple message.\r\n\r\n```cs\r\n[CapSubscribe(\"sample.rabbitmq.mysql.test1\")]\r\npublic void Subscribe1(DateTime time)\r\n{\r\nConsole.WriteLine($@\"{DateTime.Now}, Subscriber1 invoked, Sent time:{time}\");\r\n}\r\n\r\n[CapSubscribe(\"sample.rabbitmq.mysql.test2\")]\r\npublic void Subscribe2(DateTime time)\r\n{\r\nConsole.WriteLine($@\"{DateTime.Now}, Subscriber2 invoked, Sent time:{time}\");\r\n}\r\n```"
      },
      {
        "user": "tuongntk",
        "created_at": "2019-08-26T06:45:39Z",
        "body": "Tks yang, but in your sample code i found that:\r\n\r\n```cs\r\n public Task StartAsync(CancellationToken cancellationToken)\r\n{\r\n    _logger.LogInformation(\"Timed Background Service is starting.\");\r\n    _timer = new Timer(Publish, null, TimeSpan.Zero, TimeSpan.FromSeconds(5));\r\n    return Task.CompletedTask;\r\n}\r\n```\r\nYou start timer with Publish callback.\r\n\r\nIs it right if i implement more and more subcribers methods. Does it affect to any method ?\r\nTks so much\r\n\r\n"
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2019-08-26T06:49:16Z",
        "body": "Timer is just to show for example, you can publish or subscribe  messages wherever you want. "
      },
      {
        "user": "tuongntk",
        "created_at": "2019-08-26T06:51:11Z",
        "body": "tks so much"
      }
    ]
  },
  {
    "number": 368,
    "title": "并发高的时候使用MYSQL作为持久化问题",
    "created_at": "2019-07-17T09:42:30Z",
    "closed_at": "2019-07-17T12:11:19Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/368",
    "body": "并发高的时，CAP会操作Mysql频繁。导业务也受到影响。请问除了替换In-Memory Storage琮替代外。设置消息过期时间：SucceedMessageExpiredAfter 为5天。是不是可以减少对DB的操作？\r\n\r\n或有什么好的方式。可以减小CAP对DB的操作？\r\n\r\n谢谢",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/368/comments",
    "author": "yaobo-lab",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2019-07-17T10:23:13Z",
        "body": "你使用CAP的场景是什么，以及你的并发是什么业务产生的？ 抛开具体场景谈怎么优化没有意义。"
      },
      {
        "user": "yaobo-lab",
        "created_at": "2019-07-17T10:52:18Z",
        "body": "场景：公司员工在运营后台。选择广东地区100W用户，推送一条消息。  使用CAP。生产消息，订阅消息 处理推送。推送失败后重试5次。"
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2019-07-17T11:14:31Z",
        "body": "你这个是实现层面有问题，实际上推送给100W用户只应该产生一条消息。这个消息内容是生产这个消息的上下文参数。\r\n\r\n比如你把用户信息存储到某个地方比如Redis，然后消息内容携带Redis参数，让消费者去消费Redis即可。\r\n\r\n另外，我们做消息推送也并不是一下子把所有消息都发给100w用户，而是只推送在线用户，对于非在线用户在其登录或者在线的时候再去拉消息。"
      }
    ]
  },
  {
    "number": 323,
    "title": "Feature request: Add option to prefix topics",
    "created_at": "2019-04-19T07:43:10Z",
    "closed_at": "2019-07-27T02:28:31Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/323",
    "body": "**Motivation**\r\nWe have different environments which we need to maintain. As we do not want to run the same infrastructure multiple times (e.g. one kafka cluster for each environment or even for each developer) we are looking for a way to share a single instance.\r\n\r\n**Suggestion**\r\nMy suggestion would be to make this a (optional) configuration option (e.g. \"topic.prefix\").\r\n\r\nIt could be as simple as\r\n\r\n`\r\nprotected TopicAttribute(string name)\r\n        {\r\n            Name = StaticConfiguration.TopicPrefix + name;\r\n        }\r\n`\r\n\r\n(Unfortunately Attributes are a bit cumbersome when it comes to IoC and ctor() injections)\r\n\r\nWhat do you think? Maybe this even relates to #57? (language barrier ahead)",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/323/comments",
    "author": "naymore",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2019-04-21T04:57:19Z",
        "body": "For `TopicAttribute`, you can customize to extend it, for example\r\n\r\n```C#\r\npublic class MySubscribeAttribute : TopicAttribute\r\n{\r\n    public CapSubscribeAttribute(string name)\r\n      :base(StaticConfiguration.TopicPrefix + name)\r\n    {\r\n      \r\n    }\r\n}\r\n```\r\nThen ,you can init the `StaticConfiguration.TopicPrefix` at application startup\r\n"
      },
      {
        "user": "naymore",
        "created_at": "2019-04-22T16:02:10Z",
        "body": "True. Although this is probably more of a hacky short-term solution.\r\n\r\nI thought about moving this into its own class solely responsible for extending topic/queue names and injecting it into the class responsible for tieing consumers to topics. And of course I need the same mechanism for publishers as well."
      }
    ]
  },
  {
    "number": 304,
    "title": "多数据库，只建了一个库的表的问题",
    "created_at": "2019-03-22T09:00:25Z",
    "closed_at": "2019-03-22T10:03:55Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/304",
    "body": "使用了两个数据库，只有其中一个数据库自动创建了数据表，另一个需要手工创建数据表\r\nx.UseSqlServer(ConnnectionFactory.ConnectionString);\r\nx.UseSqlServer(ConnnectionFactory.ConnectionString2);\r\n\r\n能看到CapOptions.Extensions有两个数据库的对像，按我的理解应该是支持多数据库建表的",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/304/comments",
    "author": "cheetahing",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2019-03-22T10:03:31Z",
        "body": "Multiple databases in one instance is not supported"
      },
      {
        "user": "cheetahing",
        "created_at": "2019-03-22T11:03:40Z",
        "body": "1.我需要支持多个sql server我该从哪里入手，如何进行改造，有什么建议，我有时间可以贡献代码\r\n2.我的事务性的业务放在sql server里，非事务(历史数据)通过消息总线进行同步，他们会处于同一个微服务中，有什么建议"
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2019-03-22T11:23:56Z",
        "body": "@cheetahing  你的思路可能有点问题，我帮你理一下。\r\n\r\n你想的是事务消息写SQL Server， 其他不重要的历史消息写入其他数据库，这样分工职责比较明确，场景比较清晰，你的想法大概是这样吧？\r\n\r\n那么我们可以从两方面来分析。\r\n1、假如你们业务量很大，消息数量可能达到每秒几千或者几万，那么为什么还要使用数据库或者在内存中做一次存储呢，这么大的吞吐量应该直接连到消息队列，不经过任何处理发送即可，使消息队列达到最大峰值，使用CAP反而会降低吞吐量，因为CAP需要处理以及存储。\r\n2、假如你们业务量很小，消息数量可能就每秒几十或者几百甚至可能还要更少一些，那么使用SQL Server存储（包括历史数据消息）又有什么关系呢，CAP会定期清理这些成功的数据，这些事件数据仅仅是为了保证数据一致性的临时存储介质而已，你可以把过期事件设置小一点，这样CAP就会更加积极的清理这些数据。\r\n3、需要事务的场景在发消息的时候开启事务就行了，像历史数据这种直接发就行了，这是我能够告诉你的解决方案。\r\n\r\n以上，希望你能明白我想表达意思的核心思想。\r\n\r\n\r\n"
      },
      {
        "user": "cheetahing",
        "created_at": "2019-03-22T11:44:23Z",
        "body": "完全理解了，非常，非常感谢！\r\n我上面上表达的意思是，sql server存储的业务数据是实时事务性的数据，例如订单数据。\r\n当订单关闭后，通过消息总线把关闭的订单的业务数据推到mongodb的历史数据微服务里，我原来的想法是这件事要全部完成。\r\n\r\n经过您的提示，我发现我的想法是错的，我完全可以在mongodb的微服务里，写完历史数据，再去删sql server里的数据。\r\n\r\n还是非常感谢您！\r\n\r\n### 我还是有一个疑惑，sql server如果自已做水平分库，能否解决分库的问题，\r\n业务场景：\r\n我们公司做的酒店saas系统，完全可以按门店进行水平切分\r\nid为1-100的门店的所有数据放在db1\r\n101-200的门店的数据放在db2\r\n这种场景能否处理，由于历史原因，现在只能用sql server\r\n\r\n我们现在单体asp.net mvc站点的做法是，业务层把门店的id传进来，跟据门店id映射连接字符串，生成不同连接串的connection，如果改为微服务，回到刚才多库的问题了"
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2019-03-22T11:49:05Z",
        "body": "不好意思，这里只会讨论和CAP有关的话题，你的问题已经超出此范围了。"
      },
      {
        "user": "d4ilys",
        "created_at": "2021-03-08T01:28:13Z",
        "body": "@cheetahing 你好，我也遇到saas系统，根据每次的请求动态生成不同连接串的connection，现在无奈只能改成按表隔离租户，请问你这个问题解决了吗"
      }
    ]
  },
  {
    "number": 279,
    "title": "Transaction question about EF DbContext ",
    "created_at": "2019-01-23T02:27:28Z",
    "closed_at": "2019-01-24T08:21:05Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/279",
    "body": "我有个疑问就是既然集成了EF,为什么还需要这样呢?\r\n```\r\nusing (var trans = dbContext.Database.BeginTransaction(_capBus, autoCommit: true))\r\n        {\r\n            //业务代码\r\n\r\n            _capBus.Publish(\"xxx.services.show.time\", DateTime.Now);\r\n        }\r\n```\r\n为什么不集成在await ct.SaveChangesAsync();一并提交呢?",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/279/comments",
    "author": "bao2314483",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2019-01-23T03:34:04Z",
        "body": "Because the underlying CAP is not a database operation using EF, EF needs to provide an ADO.NET transaction context to merge the two operation."
      },
      {
        "user": "bao2314483",
        "created_at": "2019-01-23T05:49:33Z",
        "body": "我发现dbContext.Database.BeginTransaction期间会把表死锁直到事务执行完毕才释放,连查询相关表都会阻塞,这样非常不好"
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2019-01-24T01:02:06Z",
        "body": "The default transaction isolation level does not block the query. Can you render your test report?"
      },
      {
        "user": "bao2314483",
        "created_at": "2019-01-24T01:21:29Z",
        "body": "DbContext我是注入方式(非单例)获取\r\n```\r\nusing (var tran =ct.Database.BeginTransaction(CapBus, true)){\r\n                if (await ct.Set<UserDriveLicense>().CountAsync(x => x.DriveFileNo == ReqData.DriveFileNo && x.UserId != ReqData.User_Id) > 0)\r\n                    return (null, \"此驾驶证不能多次绑定\");\r\n                var user = await ct.Set<UserBasicInfo>()\r\n                    .Include(x => x.UserDriveLicenseApply)\r\n                    .FirstOrDefaultAsync(x => x.Id == ReqData.User_Id);\r\n                if (user == null)\r\n                    return (null, \"查无此用户信息\");\r\n                var add = new UserDriveLicenseApply()\r\n                {\r\n                    //省略\r\n                };\r\n                await ct.Set<UserDriveLicenseApply>().AddAsync(add);\r\n                await ct.SaveChangesAsync();\r\n                await CapBus.PublishAsync(CapQueueConfig.BusinessService.Backstage.UserBase.UserDriveLicenseApplyAdd, add.Id);//**此处我做了断点**\r\n                return (add, \"添加成功\");\r\n            }\r\n```\r\n我做了断点,事务没有完全执行完毕对吧?这时候我去数据库查询UserDriveLicenseApply表的时候发现查询不了,全表给锁住了,知道我取消了断点或者让执行完毕之后才能查询"
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2019-01-24T03:38:41Z",
        "body": "What database are you using?  Whether your query and operation are the same record？"
      },
      {
        "user": "bao2314483",
        "created_at": "2019-01-24T04:09:39Z",
        "body": "sqlserver2016  我是select * form UserDriveLicenseApply"
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2019-01-24T08:21:05Z",
        "body": "> sqlserver2016 我是select * form UserDriveLicenseApply\r\n\r\nThis is expected!  If you want to query the affected records, you need to use with the `nolock` :\r\n```\r\nSELECT * FROM UserDriveLicenseApply WITH(NOLOCK);\r\n```"
      }
    ]
  },
  {
    "number": 268,
    "title": "Why is the consumer side not using transactions?",
    "created_at": "2019-01-07T03:17:15Z",
    "closed_at": "2019-01-08T01:24:56Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/268",
    "body": "我看发布端业务处理和发送消息可以使用事务，为什么订阅端消费消息和处理业务没有使用事务呢？",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/268/comments",
    "author": "TheSlow1989",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2019-01-07T03:45:31Z",
        "body": "Because the consumer side does not need to use transactions, we can ensure that the message is persisted"
      },
      {
        "user": "TheSlow1989",
        "created_at": "2019-01-07T06:56:44Z",
        "body": "这样订阅端可能会出现业务代码执行成功后，因为网络或者程序异常消息等原因消息却被标记为失败的情况，不能完全指望消息实现幂等吧。我现在想的办法是加入一个消息执行成功记录表，消费消息时候判断消息是否被成功消费过，但感觉这样有点不对，如果订阅端支持事务的话不是就更简单了么。\r\n或者我的思路有问题？"
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2019-01-07T06:59:46Z",
        "body": "关键业务消费端都要保证幂等，和用不用事务没有关系，任何框架都保证不了幂等。\r\n\r\n具体可查看 #29 "
      },
      {
        "user": "TheSlow1989",
        "created_at": "2019-01-08T02:54:55Z",
        "body": "OK,Thanks!"
      }
    ]
  },
  {
    "number": 264,
    "title": "How to configure RabbitMQ Cluster?",
    "created_at": "2019-01-03T02:11:13Z",
    "closed_at": "2019-01-03T02:14:20Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/264",
    "body": "- [√] Question or discussion\r\n___\r\n### Question\r\n- 如果RabbitMQ集群，在UseRabbitMQ的时候应该怎么配置呢？\r\n___",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/264/comments",
    "author": "fayuanliu",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2019-01-03T02:14:20Z",
        "body": "You can set the `HostName` like `192.168.1.111,192.168.1.112`"
      },
      {
        "user": "fayuanliu",
        "created_at": "2019-01-03T02:14:51Z",
        "body": "ok"
      }
    ]
  },
  {
    "number": 248,
    "title": "Two services with only one dashboard enabled.An unenabled dashboard service could fail to register at consul because cap/health failed.",
    "created_at": "2018-12-05T10:15:19Z",
    "closed_at": "2018-12-05T10:35:55Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/248",
    "body": "如题",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/248/comments",
    "author": "Shinetaku",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2018-12-05T10:17:13Z",
        "body": "yes, It's an expect desgin"
      },
      {
        "user": "Shinetaku",
        "created_at": "2018-12-05T12:03:44Z",
        "body": "那和之前去中心化的设计不一致了。多个服务多个dashboard。每个服务都有自己的dashboard，切换目标实例的意义就不大了啊。"
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2018-12-05T12:50:39Z",
        "body": "Dashboard 提供路由中间件API接口查询数据，要不然数据从哪里来？配置一下Dashboard并不会带来额外的性能开销"
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2018-12-05T12:55:21Z",
        "body": "为什么没有意义？ 在集群环境下，通过反向代理暴漏一个地址到外网，然后通过这个地址就可以看所有的了，要不然你每个实例配置一个地址，挨个点开看?"
      },
      {
        "user": "Shinetaku",
        "created_at": "2018-12-07T02:43:38Z",
        "body": "就是因为在某一个服务下可以看到所有的信息，所以不需要每个服务都开启dashboard了。各服务只需要开启discovery就可以了。具体指定哪个服务开启dashboard就ok了。现在是dashboard和discovery绑在一起，要开discovery就必须要开dashboard。感觉这样不是很合理。"
      }
    ]
  },
  {
    "number": 239,
    "title": "How to prevent messages from being sent repeatedly after load balancing?",
    "created_at": "2018-11-15T13:49:29Z",
    "closed_at": "2018-11-18T12:40:03Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/239",
    "body": "负载均衡之后如何防止消息被重复发送？以前的版本我记得是用的是一个数据库队列，还是说对于本来需要轮询发送的消息本来就少，重复发送这点消耗被忽略掉？",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/239/comments",
    "author": "BennetWang",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2018-11-16T07:13:07Z",
        "body": "What did you mean about load balancing publish message repeated? You means failed message ?"
      },
      {
        "user": "BennetWang",
        "created_at": "2018-11-16T07:15:38Z",
        "body": "是的，当消息失败重试时，由于部署多台机子，可能会对消息进行重复发送，没看到锁或者其它协调机制存在"
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2018-11-16T07:19:52Z",
        "body": "This leads to additional complexity, such as distributed lock or database lock, so we didn't consider about it. Because consumers need to ensure idempotency"
      },
      {
        "user": "zjlhope",
        "created_at": "2018-11-16T08:14:15Z",
        "body": "我认为，只要使用消息中间件，应用如果对重复消费敏感，就需要应用自己做幂等，没有消息中间件会做仅发送一次的保证。消费重复可能和生产端有关，也可能和消费端有关，但集中在消费端做幂等会简单很多"
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2018-11-16T08:18:09Z",
        "body": "Yes, I agree with you"
      },
      {
        "user": "BennetWang",
        "created_at": "2018-11-16T08:19:19Z",
        "body": "非常感谢。。明白了。。"
      }
    ]
  },
  {
    "number": 229,
    "title": " [Question] how can we config CAP with multi RabbitMQ server in one ASPNETCORE application ",
    "created_at": "2018-11-08T00:51:19Z",
    "closed_at": "2018-11-08T07:09:14Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/229",
    "body": "\r\n### Question\r\n- How can we config CAP with RabbitMQ, we will pub/sub from multi MQ server that have different mq server endpoint(maybe different server, different virtual host or exchange, etc.). \r\nSo how can we config in one ASPNETCORE application?\r\n***CAP如何配置RabbitMQ的选项？我们需要和多个MQ服务器进行订阅/发布操作，可能这些服务器有不同的地址或则VHost、exchange不一样. 所以想知道如何在一个ASPNETCORE的启动应用中配置CAP呢？***\r\n",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/229/comments",
    "author": "joeiren",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2018-11-08T02:37:46Z",
        "body": "If you want connect to the rabbitmq  cluster, you can set `HostName` like “192.168.1.111,192.168.1.112”.\r\n\r\nIf you want to connect different rabbitmq servers , we does not support. In microservices, you need to keep the message bus server unified.\r\n"
      },
      {
        "user": "joeiren",
        "created_at": "2018-11-08T04:14:43Z",
        "body": "If config different virtual host on one rabbitmq server,  can it  be supported?"
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2018-11-08T07:09:14Z",
        "body": "No, different virtual host is same as different servers"
      },
      {
        "user": "joeiren",
        "created_at": "2018-11-08T07:19:16Z",
        "body": "opps, it's so bad"
      }
    ]
  },
  {
    "number": 211,
    "title": "Dashboard can't open",
    "created_at": "2018-09-19T09:36:07Z",
    "closed_at": "2018-09-21T04:00:25Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/211",
    "body": "采用的Net core 控制台，使用的通用Host，并没有采用webhost作为宿主，这种情况下仪表盘还能支持本地通过URL打开不？",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/211/comments",
    "author": "beefsteak",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2018-09-19T09:38:59Z",
        "body": "No, CAP Dashboard it is a asp.net core middleware, can't run without asp.net core host"
      }
    ]
  },
  {
    "number": 202,
    "title": "Does CAP support ASP.NET MVC？",
    "created_at": "2018-09-10T02:32:03Z",
    "closed_at": "2018-09-10T02:45:52Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/202",
    "body": "我现在有个项目是用 传统的asp.net mvc 框架进行开发的，框架是 netframework 4.6 。cap提供了像支持asp.net core 那样对 asp.net mvc 框架提供了支持了吗？\r\n PS:我们项目用kafka作为了消息队列",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/202/comments",
    "author": "bluetianx",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2018-09-10T02:37:18Z",
        "body": "Because CAP depends on DI container , so it does not support .net framework asp.net mvc."
      },
      {
        "user": "bluetianx",
        "created_at": "2018-09-10T02:44:13Z",
        "body": "alright ，thanks"
      }
    ]
  },
  {
    "number": 193,
    "title": "同一个组内的订阅者订阅的消息只能被消费一次",
    "created_at": "2018-08-31T13:36:21Z",
    "closed_at": "2018-09-04T07:00:04Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/193",
    "body": "如题，同一个组内的订阅者订阅的消息只能被消费一次，当同一组内存在多个订阅者时，始终选取第一个消费者？能否实现轮询？",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/193/comments",
    "author": "yshbchenlie",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2018-09-01T01:08:27Z",
        "body": "No, this is accord with the expected design, we have no reason to change it to polling"
      }
    ]
  },
  {
    "number": 185,
    "title": "Is there any plan to support more .net platforms",
    "created_at": "2018-08-20T11:48:46Z",
    "closed_at": "2018-08-28T03:47:37Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/185",
    "body": "我在官方文档中只看到了MVC的支持与示例，请问是否支持Console、WinForm、WPF、WebForm、Windows Service等其他类型的程序？我的项目中没有MVC。\r\n如果支持，请补充一下示例代码。如果暂时还不支持，请考虑新增对以上类型程序的支持。\r\n谢谢！",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/185/comments",
    "author": "fanruinet",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2018-08-21T00:55:25Z",
        "body": "Now we can support webapi, webmvc and console app(#111)\r\n\r\nCan you tell me why you need this component in WinForm, WPF?"
      },
      {
        "user": "fanruinet",
        "created_at": "2018-08-21T03:02:30Z",
        "body": "For WebForm, it has the same reason to support mvc.\r\nFor WinForm/WPF, our client app is an internal application which uses the queue as RPC. I'm not aware of the current support of console app (no sample code provided). In most cases if console is supported, WinForm/WPF can be supported too. I'll try it later."
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2018-08-22T06:10:54Z",
        "body": "We didn't more test for .net framework, let me konw if you have any question"
      }
    ]
  },
  {
    "number": 183,
    "title": "How does the PublishAsync method in the ICapPublisher interface specify the GroupName",
    "created_at": "2018-08-20T06:14:27Z",
    "closed_at": "2018-08-21T01:00:24Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/183",
    "body": "如果在订阅的时候申明当前订阅的名字归属到User组，那当发送消息的时候如果指定发送给User组呢？",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/183/comments",
    "author": "beefsteak",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2018-08-20T08:41:51Z",
        "body": "GroupName is the concept of the consumer side, Maybe you need to learn about the Topic pattern of message queue first."
      }
    ]
  },
  {
    "number": 175,
    "title": "能不能开放一些internal的接口",
    "created_at": "2018-08-06T04:17:04Z",
    "closed_at": "2018-08-17T10:25:41Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/175",
    "body": "### Question\r\n- DotNetCore.CAP.Internal 的接口和实现很多是Internal，是不是写成public的比较好，这样更容易扩 \r\n  展。至少可以把接口开放出来。",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/175/comments",
    "author": "DillonHuang",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2018-08-06T06:36:42Z",
        "body": "What interface are you referring to, and how do you want to extend it?"
      },
      {
        "user": "DillonHuang",
        "created_at": "2018-08-09T09:43:47Z",
        "body": "比如说可以通过接口 IConsumerServiceSelector找到事件处理的方法，类必须继承ICapSubscribe，方法必须打上TopicAttribute。我想用自己的接口IEventHandler(IEventHandler在抽象层并不依赖第三方库)，\r\n这样每个EventHandler必须同时实现IEventHandler，ICapSubscribe，感觉不太舒服。\r\n"
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2018-08-10T11:50:09Z",
        "body": "你的这个需求好像和是否开放internal并无关系啊"
      }
    ]
  },
  {
    "number": 173,
    "title": "How to send a message correctly in a logic that needs to be executed sequentially?",
    "created_at": "2018-08-03T02:34:18Z",
    "closed_at": "2018-08-13T02:01:21Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/173",
    "body": "逐层发布，如果最后一步订阅业务错误怎么回滚前面步骤？",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/173/comments",
    "author": "xruihu",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2018-08-03T03:09:40Z",
        "body": "In a project that using the microservice, if your business context is closely related and heavily dependent, as you call this sequential dependency, you should not break them up into many services to handle, but rather they should be aggregated into one service.\r\n\r\nEvent messages are the medium through which services communicate with each other,  the expected outcome of this service communication should be consistent with the final consistency."
      },
      {
        "user": "xruihu",
        "created_at": "2018-08-03T03:35:01Z",
        "body": "简单举例：比如订单业务，需要分别发布修改库存和修改金额的事件消息\r\n那么如果修改库存成功，修改金额失败，我只能callback发布者（订单回滚），库存怎么解决？"
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2018-08-03T03:44:49Z",
        "body": "After the order is created, the amount of the order should not be modified. The inventory is pre-deducted when the order is placed, so I cannot explain your example"
      },
      {
        "user": "xruihu",
        "created_at": "2018-08-03T04:01:09Z",
        "body": "这里扣金额指的是用户账户的金额，当然这个举例确实不恰当，扣库存应该是发货的时候，我只是想说明一种需要同时做两种业务动作的业务时应该怎么操作，因为阿里云的消息队列里面有这种顺序队列的实例"
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2018-08-04T01:57:17Z",
        "body": "Making business process sequential execution or broadcast mode based on your business needs. CAP does not limit the way you perform business logic.\r\nYou need to make an assessment based on your business scenario."
      },
      {
        "user": "xruihu",
        "created_at": "2018-08-06T02:50:06Z",
        "body": "非常感谢您的耐心回复，顺序执行的话，如果用顺序队列我需要一级一级的发布再一级一级往上callback我这个理解对吗？"
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2018-08-06T03:10:55Z",
        "body": "Yes"
      }
    ]
  },
  {
    "number": 170,
    "title": "several instances with a single table",
    "created_at": "2018-07-26T10:34:21Z",
    "closed_at": "2018-07-31T03:40:54Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/170",
    "body": "### Question\r\nI'm planning to deploy several instances of web service.\r\nEach instance will store events in a single Table.\r\nOne table for all instances.\r\n\r\nAnother microservice will read messages from this table and push them to the Message Queue.\r\n\r\nIs it posible with CAP?",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/170/comments",
    "author": "darkspring1",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2018-07-26T13:01:13Z",
        "body": "Yes.\r\n\r\nThe same microservice instance can use the same database table when deploying multiple replication.\r\n\r\nAnother scenario is that different microservice instances need to use different table names if they use the same database table to store messages."
      }
    ]
  },
  {
    "number": 169,
    "title": "Could I configure connectionStrings one times to use anywhere",
    "created_at": "2018-07-26T09:45:39Z",
    "closed_at": "2018-07-31T03:40:31Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/169",
    "body": "Please answer these questions before submitting your issue.\r\n\r\n- Why do you submit this issue?\r\n- [x] Question or discussion\r\n- [ ] Bug\r\n- [ ] Requirement\r\n- [ ] Feature or performance improvement\r\n___\r\n### Question\r\n- What do you want to know?\r\n\r\nCould I configure connectionStrings one times to use anywhere?\r\nI user mysql +dapper  and configure like this \r\n\r\n```\r\nservices.AddCap(x =>\r\n{     \r\n    x.UseMySql(Configuration.GetConnectionString(\"hn_datasync\"));\r\n}\r\n\r\n//then In my controller I must to use like this\r\nusing (var connection = new MySqlConnection(_configuration.GetConnectionString(\"hn_datasync\")))\r\n{\r\n    connection.Open();\r\n    using (var transaction = connection.BeginTransaction())\r\n    {\r\n        await _publisher.PublishAsync(CapEventKeys.GA_RY_CSDJXXBAddEvent, Datas, transaction);\r\n        transaction.Commit();\r\n    }\r\n}\r\n\r\n```\r\n\r\nso I use 'Configuration.GetConnectionString(\"hn_datasync\"))' two times, could I configure connectionStrings one times to use In up two ways.",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/169/comments",
    "author": "yilezhu",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2018-07-26T13:33:09Z",
        "body": "You can completely encapsulation the code to your liking. CAP only provides a piece of demo code that uses the simplest logic to tell you that it needs an `IDbTransaction` object to send the message."
      }
    ]
  },
  {
    "number": 168,
    "title": "Multiple subscribers consume messages, always the first subscriber to consume",
    "created_at": "2018-07-25T10:17:19Z",
    "closed_at": "2018-07-31T03:40:10Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/168",
    "body": "Multiple subscribers consume messages, which are always the first subscribers to consume. I want to do load balancing in the group, implement polling, and reduce the pressure on subscribers. What should I do?\r\n```\r\n[CapSubscribe(\"tibos.services.test\", Group = \"tibos\")]\r\n        public void BarMessageProcessor(Users user)\r\n        {\r\n\r\n        }\r\n\r\n        [CapSubscribe(\"Test666\", Group = \"tibos\")]\r\n        public void Test()\r\n        {\r\n\r\n        }\r\n\r\n        [CapSubscribe(\"tibos.services.test\", Group = \"tibos\")]\r\n        public void BarMessageProcessorA(Users user)\r\n        {\r\n\r\n        }\r\n\r\n        [CapSubscribe(\"Test666\", Group = \"tibos\")]\r\n        public void TestB()\r\n        {\r\n\r\n        }\r\n```",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/168/comments",
    "author": "wmowm",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2018-07-26T02:07:20Z",
        "body": "if you want use broadcast mode, you need to assign the different group name to the subscribe consumer."
      }
    ]
  },
  {
    "number": 124,
    "title": "Problems with multiple subscriptions",
    "created_at": "2018-04-29T08:49:42Z",
    "closed_at": "2018-04-29T14:48:08Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/124",
    "body": "```\r\npublic void ConfigureServices(IServiceCollection services)\r\n{\r\n    ...\r\n    services.AddTransient<ITestMessage, TestMessage>();\r\n    //services.AddTransient<ITestMessage2, TestMessage2>();\r\n    services.AddCap(x => {  });\r\n}\r\n```\r\n\r\nThe above code works well after commenting out one subscription. However,  there is a puzzling problem when I try to open two subscriptions. Publishers can publish successfully, but subscribers can't receive any messages, I'm very confused. Is it the wrong way I use it? \r\nSee the code below：\r\n```\r\nprivate async Task SendRequest()\r\n{\r\n    using (var trans = context.Database.BeginTransaction())\r\n    {\r\n        await publisher.PublishAsync(\"Test.Message\", \"\");\r\n        ...\r\n        trans.Commit();\r\n    }\r\n}\r\n\r\npublic interface ITestMessage\r\n{\r\n    void TestSubscriber(string text); \r\n}\r\n\r\npublic class TestMessage : ITestMessage, ICapSubscribe\r\n{\r\n    [CapSubscribe(\"Test.Message\")]\r\n    public void TestSubscriber(string text)\r\n    {\r\n    }\r\n}\r\n```",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/124/comments",
    "author": "szlee",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2018-04-29T10:30:51Z",
        "body": "@szlee  Hello,\r\nIf you have multiple subscribers you need to set up different groups like `CapSubscribe(\"Test.Message\", Group = \"test1\")` and `CapSubscribe(\"Test.Message\", Group = \"test2\")` , do you do that?"
      },
      {
        "user": "szlee",
        "created_at": "2018-04-29T13:09:49Z",
        "body": "How do I set up the different groups for the subscriptions. Is it in the Cap Option. Can you put a sample code? Thanks"
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2018-04-29T13:44:20Z",
        "body": "```\r\npublic interface ITestMessage\r\n{\r\n    void TestSubscriber(string text); \r\n}\r\n\r\npublic class TestMessage : ITestMessage, ICapSubscribe\r\n{\r\n    [CapSubscribe(\"Test.Message\", Group = \"test1\")]\r\n    public void TestSubscriber(string text)\r\n    {\r\n    }\r\n}\r\n```\r\nand \r\n\r\n```\r\npublic interface ITestMessage2\r\n{\r\n    void TestSubscriber(string text); \r\n}\r\n\r\npublic class TestMessage2: ITestMessage2, ICapSubscribe\r\n{\r\n    [CapSubscribe(\"Test.Message\", Group = \"test2\")]\r\n    public void TestSubscriber(string text)\r\n    {\r\n    }\r\n}\r\n```"
      },
      {
        "user": "szlee",
        "created_at": "2018-04-29T13:58:32Z",
        "body": "Thanks for your reply. I tried the above methods, it seems that still can not... But I added the following line of Italic code, which works fine...\r\npublic void ConfigureMotionServices(IServiceCollection services)\r\n{\r\n    services.AddTransient<ITestMessage, TestMessage>();\r\n    services.AddTransient<ITestMessage2, TestMessage2>();\r\n    _services.AddCap(x => { x.DefaultGroup = \"Test\"; });_\r\n}\r\n\r\nI have a question, the above code only uses one group, if I need more than one group, how to set the options? Like this?\r\npublic void ConfigureMotionServices(IServiceCollection services)\r\n{\r\n    services.AddTransient<ITestMessage, TestMessage>();\r\n    services.AddTransient<ITestMessage2, TestMessage2>();\r\n    _services.AddCap(x => { x.DefaultGroup = \"Test\"; });_\r\n    services.AddTransient<ITestMessage3, TestMessage3>();\r\n    services.AddTransient<ITestMessage4, TestMessage4>();\r\n    _services.AddCap(x => { x.DefaultGroup = \"Test2\"; });_\r\n}"
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2018-04-29T14:09:32Z",
        "body": "No, You can't configuration like this. The `DefaultGroup ` represents a group in Kafka or a queue in RabbitMQ.\r\n\r\nIf you follow what I'm saying and it not works , please provide your environment and configuration.\r\n"
      },
      {
        "user": "szlee",
        "created_at": "2018-04-29T14:20:16Z",
        "body": "```\r\npublic void ConfigureMotionServices(IServiceCollection services)\r\n{\r\n    services.AddMvc();\r\n    services.AddDbContext<McsDbContext>(option => option.UseSqlServer(Configuration.GetConnectionString(\"DefaultConnection\")));\r\n    services.AddCap(x => { x.UseEntityFramework<McsDbContext>(); x.UseRabbitMQ(\"localhost\"); });\r\n    services.AddTransient<ITestMessage, TestMessage>();\r\n    services.AddTransient<ITestMessage2, TestMessage2>();\r\n    services.AddCap(x => { x.DefaultGroup = \"Test\"; });\r\n    services.AddTransient<ITestMessage3, TestMessage3>();\r\n    services.AddTransient<ITestMessage4, TestMessage4>();\r\n    services.AddCap(x => { x.DefaultGroup = \"Test2\"; });\r\n}\r\npublic void Configure(IApplicationBuilder app, IHostingEnvironment env)\r\n{\r\n    if (env.IsDevelopment()) app.UseDeveloperExceptionPage();\r\n    app.UseCap();  \r\n    app.UseMvc();\r\n}\r\n```"
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2018-04-29T14:27:51Z",
        "body": "There are too many mistakes in your configuration.\r\n\r\n**Startup.cs**\r\n\r\n```cs\r\npublic void ConfigureMotionServices(IServiceCollection services)\r\n{\r\n    services.AddDbContext<McsDbContext>(option => option.UseSqlServer(Configuration.GetConnectionString(\"DefaultConnection\")));\r\n\r\n    services.AddTransient<ITestMessage, TestMessage>();\r\n    services.AddTransient<ITestMessage2, TestMessage2>();\r\n\r\n    services.AddCap(x => { \r\n        x.UseEntityFramework<McsDbContext>();\r\n        x.UseRabbitMQ(\"localhost\");\r\n    });\r\n\r\n    services.AddMvc();\r\n}\r\n\r\npublic void Configure(IApplicationBuilder app, IHostingEnvironment env)\r\n{\r\n    if (env.IsDevelopment()) \r\n        app.UseDeveloperExceptionPage();\r\n    \r\n    app.UseMvc();\r\n\r\n    app.UseCap(); \r\n}\r\n\r\n```\r\n\r\n**ITestMessage.cs** and **TestMessage.cs**\r\n\r\n```cs\r\npublic interface ITestMessage\r\n{\r\n    void TestSubscriber(string text); \r\n}\r\n\r\npublic class TestMessage : ITestMessage, ICapSubscribe\r\n{\r\n    [CapSubscribe(\"Test.Message\", Group = \"test1\")]\r\n    public void TestSubscriber(string text)\r\n    {\r\n    }\r\n}\r\n```\r\n\r\n\r\n**ITestMessage2.cs** and **TestMessage2.cs**\r\n\r\n```cs\r\npublic interface ITestMessage2\r\n{\r\n    void TestSubscriber(string text); \r\n}\r\n\r\npublic class TestMessage2: ITestMessage2, ICapSubscribe\r\n{\r\n    [CapSubscribe(\"Test.Message\", Group = \"test2\")]\r\n    public void TestSubscriber(string text)\r\n    {\r\n    }\r\n}\r\n```"
      },
      {
        "user": "szlee",
        "created_at": "2018-04-29T14:44:36Z",
        "body": "Yes, the above code can run perfectly. You solved my problem. Thanks a lot！"
      }
    ]
  },
  {
    "number": 123,
    "title": "bad question",
    "created_at": "2018-04-29T06:22:00Z",
    "closed_at": "2018-04-29T07:55:19Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/123",
    "body": "",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/123/comments",
    "author": "tiandao-dongguan",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2018-04-29T06:34:06Z",
        "body": "首先，纠正一个问题，CAP不是微服务框架，而是微服务架构中的一个基础设施。\r\n然后我开始回答你的问题：\r\n1、我没有看明白实时订阅是什么意思？ 如果指的是动态增加消费者的话，CAP没有提供支持，因为在微服务中我想不需要。\r\n\r\n2,3 问题属于Kafka或者RabbitMQ C#客户端驱动的范畴了，可以去相应客户端驱动查找相关资料，我们更应该专注CAP所提供的功能。\r\n"
      }
    ]
  },
  {
    "number": 111,
    "title": "Question about using CAP in the console application",
    "created_at": "2018-04-17T02:04:14Z",
    "closed_at": "2018-04-18T06:09:33Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/111",
    "body": "我在core控制台使用时遇到一个奇怪问题，数据能够写入数据库但是不能推送到消息队列（kafka），回调函数也没有执行。\r\n获取Publisher代码：\r\n\r\n```c#\r\n            var services = new ServiceCollection();\r\n            services.AddLogging();\r\n\r\n            services.AddCap(x =>\r\n            {\r\n                x.UseSqlServer(ConnectionString);\r\n                x.UseKafka(ServerList);\r\n            });\r\n\r\n            var provider = services.BuildServiceProvider();\r\n            return provider.GetService<ICapPublisher>();\r\n```\r\n\r\n执行代码：\r\n\r\n```c#\r\n                //发布数据修改\r\n                using (SqlConnection conn = new SqlConnection(ConnectionString))\r\n                {\r\n                    conn.Open();\r\n                    using (var tran = conn.BeginTransaction())\r\n                    {\r\n                        publisher.Publish(“mytopicname”, postData, tran,\"SuccessCallBack\");\r\n                        tran.Commit();\r\n                    }\r\n\r\n                }\r\n```\r\n\r\n回调函数：\r\n\r\n```c#\r\n        [CapSubscribe(\"SuccessCallBack\")]\r\n        public void KafkaTestCallback(Person p)\r\n        {\r\n            Console.WriteLine(\"0\");\r\n        }\r\n```",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/111/comments",
    "author": "dlancerzz",
    "comments": [
      {
        "user": "dlancerzz",
        "created_at": "2018-04-17T02:26:25Z",
        "body": "然后我使用一个aspdotnet web站点几乎相同的代码，消息能够正确推送到消息队列，沉积的消息也同步推送了，那么新问题是，我怎样使用控制台来使cap能够正确运行呢？"
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2018-04-17T04:26:11Z",
        "body": "Have you startup CAP using `IBootStrapper` ? see #75 "
      },
      {
        "user": "dlancerzz",
        "created_at": "2018-04-17T09:30:40Z",
        "body": "谢谢@yuleyule66 thanks，进行如下修改我发送成功了\r\n\r\n```c#\r\n            var services = new ServiceCollection();\r\n            services.AddTransient<ISubscriberService, Program>();\r\n            services.AddSingleton<IApplicationLifetime, ApplicationLifetime>();//添加\r\n            services.AddLogging();\r\n            services.AddCap(x =>\r\n            {\r\n                x.UseSqlServer(ConnectionString);\r\n                x.UseKafka(ServerList);\r\n            });\r\n            var provider = services.BuildServiceProvider();\r\n            provider.GetRequiredService<IBootstrapper>().BootstrapAsync();//添加\r\n            return provider.GetService<ICapPublisher>();\r\n```\r\n\r\n，但是callback方法没有被调用。"
      },
      {
        "user": "chaiziqi",
        "created_at": "2018-04-17T10:01:27Z",
        "body": "请问ApplicationLifetime 从哪里定义的？谢谢。 @yuleyule66 @dlancerzz "
      },
      {
        "user": "dlancerzz",
        "created_at": "2018-04-18T00:28:03Z",
        "body": "@chaiziqi  在程序集 Microsoft.AspNetCore.Hosting.Abstractions，通过nuget下载就可以了。"
      },
      {
        "user": "chaiziqi",
        "created_at": "2018-04-18T01:17:26Z",
        "body": "但我是在Microsoft.AspNetCore.Hosting.Abstractions中只有定义接口IApplicationLifetime，但是没有找到ApplicationLifetime 的实现 @dlancerzz "
      },
      {
        "user": "dlancerzz",
        "created_at": "2018-04-18T01:31:57Z",
        "body": "ApplicationLifetime 通过安装Microsoft.AspNetCore.Hosting，在命名空间 Microsoft.AspNetCore.Hosting.Internal;"
      }
    ]
  },
  {
    "number": 110,
    "title": "按照指导示例，在SubscriberService 中进行消息处理",
    "created_at": "2018-04-16T03:05:34Z",
    "closed_at": "2018-04-16T03:19:32Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/110",
    "body": "  public interface ISubscriberService\r\n    {\r\n        void CheckReceivedMessage(dynamic model);\r\n    }\r\n\r\n\r\n    public class SubscriberService : ISubscriberService, ICapSubscribe\r\n    {\r\n        [CapSubscribe(\"capdemo.values.getmethodevent\")]\r\n        public void CheckReceivedMessage(dynamic model)\r\n        {\r\n            Console.WriteLine($\"[capdemo.values.getmethodevent] message received: Id:{model.Id}  Time:{model.Time}  Message:{model.Message} \");\r\n        }\r\n    }\r\n     services.AddTransient<ISubscriberService, SubscriberService>();\r\n     消费者不会获取不到消息呢？\r\n同样的代码，如果放在Controller中，就能够执行\r\n     ///// <summary>\r\n        ///// 定义消息消费者\r\n        ///// </summary>\r\n        ///// <param name=\"model\"></param>\r\n        [NonAction]\r\n        [CapSubscribe(\"capdemo.values.getmethodevent\")]\r\n        public void ReceiveMessage(dynamic model)\r\n        {\r\n          Console.WriteLine($\"[capdemo.values.getmethodevent] message received: Id:{model.Id}  Time:{model.Time}  Message:{model.Message} \");\r\n       }\r\n\r\n请问是我哪里设置没对么？\r\n",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/110/comments",
    "author": "crashsol",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2018-04-16T03:15:45Z",
        "body": "` services.AddTransient<ISubscriberService, SubscriberService>();` 的顺序，需要在 services.AddCap之前，请检查"
      },
      {
        "user": "crashsol",
        "created_at": "2018-04-16T03:19:32Z",
        "body": "谢谢大佬，已经解决！建议把这个加入到MD中"
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2018-04-16T03:26:27Z",
        "body": "注意事项已添加到 readme，谢谢"
      }
    ]
  },
  {
    "number": 109,
    "title": "给个例子和试用场景 能具体点吗",
    "created_at": "2018-04-14T04:30:14Z",
    "closed_at": "2018-04-16T12:55:15Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/109",
    "body": "比如订单 和库存和积分 怎么处理",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/109/comments",
    "author": "yangliangguang",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2018-04-16T12:55:15Z",
        "body": "你好，CAP 只是一个中间件，不属于业务框架。具体业务怎么处理需要按照业务人员规定的处理方式，没有固定的规则"
      }
    ]
  },
  {
    "number": 101,
    "title": "How to use dapper overloaded method with IDbConnection and IDbTransaction?",
    "created_at": "2018-03-27T02:54:11Z",
    "closed_at": "2018-03-27T14:33:12Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/101",
    "body": "How to use dapper overloaded method with IDbConnection and IDbTransaction?\r\n\r\nCan you provider a demo?",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/101/comments",
    "author": "pbzyy",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2018-03-27T03:50:22Z",
        "body": "```cs\r\n       var connectionString = \"\";\r\n        using (var sqlConnection = new SqlConnection(connectionString))\r\n        {\r\n            sqlConnection.Open();\r\n            using (var sqlTransaction = sqlConnection.BeginTransaction())\r\n            {\r\n                // your business code\r\n\r\n                publisher.Publish(\"xxx.services.account.check\", new Person { Name = \"Foo\", Age = 11 }, sqlTransaction);\r\n\r\n                sqlTransaction.Commit();\r\n            }\r\n        }\r\n```"
      }
    ]
  },
  {
    "number": 99,
    "title": "Question aboutt message reception and consumption",
    "created_at": "2018-03-20T02:07:05Z",
    "closed_at": "2018-03-21T12:12:59Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/99",
    "body": "services.AddCap(x =>\r\n            {\r\n                x.UseEntityFramework<AppDbContext>();\r\n                x.UseKafka(\"localhost:9092\");\r\n                x.UseDashboard();\r\n                _x.DefaultGroup = \"test3\";_\r\n                \r\n                //x.UseDiscovery(d =>\r\n                //{\r\n                //    d.DiscoveryServerHostName = \"localhost\";\r\n                //    d.DiscoveryServerPort = 8500;\r\n                //    d.CurrentNodeHostName = \"localhost\";\r\n                //    d.CurrentNodePort = 5820;\r\n                //    d.NodeName = \"CAP 2号节点\";\r\n                //});\r\n            }).AddMessagePacker<MyMessagePacker>();\r\n            services.AddMvc();\r\n\r\n\r\n斜体处，当改成默认组也就是不赋值的时候，再重起应用就会收到重复已经处理的消息，而改成test4或者其他自定义组名就不会",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/99/comments",
    "author": "hzr1348",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2018-03-20T02:16:04Z",
        "body": "\"当默认组转向自定义组时，会重复收到消息\" This is expectantly!\r\n\r\n\"而自定义组1改成自定义组2就不会\" Maybe you didn't send some messages to \"自定义组1\".\r\n\r\nYou need to see if the data in the Kafka is in line with expectations."
      },
      {
        "user": "hzr1348",
        "created_at": "2018-03-20T12:49:01Z",
        "body": "@yuleyule66 详细测试了下，确实如你所说，但是现在有一个问题就是kafka产生的临时数据很多(tmp\\kafka-logs)，测试短短几个用例就1G多了。这在实际生产环境中也是这种暴涨速度的话，估计服务器很难撑得住,请问有什么好的解决方式吗\r\n\r\n"
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2018-03-21T02:27:56Z",
        "body": "windows上的kafka不太清楚，我在linux上使用的，感觉还好不会有那么多。 另外你是 logs 目录占用空间大还是 kafka-logs 目录占用空间大？"
      },
      {
        "user": "hzr1348",
        "created_at": "2018-03-21T03:18:57Z",
        "body": "是kafka-logs\r\n我在测试时，当我发布消息的时候日志基本都是暴涨，基本几个消息就瞬间几十M了，后续会有回落，不知道后续并发高的情况下日志的增长情况如何\r\n后续我使用压测工具看下\r\n现在日志量在1个G多一点"
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2018-03-21T12:12:59Z",
        "body": "ok，关闭issue。 如果发现是cap的问题，可以 reopen "
      }
    ]
  },
  {
    "number": 88,
    "title": "Questions about UseEntityFramework",
    "created_at": "2018-02-23T09:30:39Z",
    "closed_at": "2018-02-23T09:32:24Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/88",
    "body": " MySql PostgreSql SqlServer的库中对CapOptions都进行了EntityFramework的扩展，\r\n扩展方法都是`UseEntityFramework`\r\n命名空间都是` Microsoft.Extensions.DependencyInjection`\r\n当同时应用 MySql PostgreSql SqlServer库，UseEntityFramework就无法使用\r\n\r\n\r\n",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/88/comments",
    "author": "DillonHuang",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2018-02-23T09:32:24Z",
        "body": "设计如此，没有考虑一个应用多个CAP库的情况"
      },
      {
        "user": "DillonHuang",
        "created_at": "2018-02-23T09:34:28Z",
        "body": "UseEntityFramework<TContext>如果直接改成 UseMySql<TContext>、UsePostgreSql<TContext>、UseSqlServer<TContext>，我觉得也挺清楚的，毕竟有TContext的约束就能知道是用EF"
      },
      {
        "user": "DillonHuang",
        "created_at": "2018-02-23T09:36:44Z",
        "body": "我开发的应用需要同时支持SQL Server和MySQL，虽然可以绕着解决，不过也是比较痛苦的"
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2018-02-23T09:37:02Z",
        "body": "@tirongaws 正常情况下，不会有人这么用啊。。。"
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2018-02-23T09:38:44Z",
        "body": "同使支持并不代表会同时使用两个库， 你们是同时使用两个数据库？"
      },
      {
        "user": "DillonHuang",
        "created_at": "2018-02-23T09:48:44Z",
        "body": "不会同时用两个库，是想通过配置来做的  \r\n可能通过代码分支来做更好，我也有点犹豫\r\n\r\n"
      },
      {
        "user": "DillonHuang",
        "created_at": "2018-02-23T10:01:31Z",
        "body": "如果用配置的方式，虽然不会同时用，但是库都是引用了，这样就比较头疼了\r\n"
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2018-02-23T10:02:16Z",
        "body": "做成两个项目呀，提供nuget出去就行了"
      },
      {
        "user": "DillonHuang",
        "created_at": "2018-02-23T13:08:02Z",
        "body": "不管设计如何，从代码角度讲 UseEntityFramework这个扩展方法命名还是有瑕疵的\r\n使用UseXXXEntityFramework似乎更好"
      }
    ]
  },
  {
    "number": 79,
    "title": "Can we use CAP without storing messages to Database?",
    "created_at": "2018-01-21T15:40:50Z",
    "closed_at": "2018-01-22T15:43:33Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/79",
    "body": "I can see it takes benefits store messages to database, but will it make the process slower since we want to use RabbitMQ to fire&forget in many cases?",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/79/comments",
    "author": "trumhemcut",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2018-01-22T01:48:28Z",
        "body": "CAP is designed to maintain data consistency across Microservice or SOA, it depending on the ACID nature of the database to ensure message reliability. If you leave the database, then this solution is only a message queue client encapsulation, it does not make sense, maybe your scene does not require CAP, just send and receive messages only"
      },
      {
        "user": "trumhemcut",
        "created_at": "2018-01-22T15:43:28Z",
        "body": "Agree, storage is needed for enterprise level. Thanks"
      }
    ]
  },
  {
    "number": 76,
    "title": "Kafka cluster can't published message",
    "created_at": "2018-01-12T09:48:05Z",
    "closed_at": "2018-01-24T02:48:50Z",
    "labels": [
      "question",
      "kafka"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/76",
    "body": "配置了3台kafka集群  x.UseKafka(\"x.x.x.x:9092,x.x.x.x:9093,x.x.x.x:9094\");  生产者和消费者都是一样的kafka配置 不同的程序 链接的数据库也不同 关闭其中一台kafka后 生产者有时候发送消息会失败 cap.published表里状态为 Processing 当启动刚刚关闭的Kafka后  消息能重新发送出去  但是 消费者接收不到..\r\n1.生产者偶尔不能正常发送消息出去\r\n2.重启服务后 消息发送成功后  不能监听到消息",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/76/comments",
    "author": "a641545621",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2018-01-13T02:50:51Z",
        "body": "如果生产者和消费者都是一个实例的话，你可以遇到了我最近刚发现的之前对Kafka一个概念理解错误的一个潜在bug。\r\n\r\n手动提交模式，假如消息队列里有10条消息，拉取第一条后存数据库失败，第二次拉取会拉取到第二条消息，只要你的consumer没有触发rebalance，即使你没有ACK提交，第一条消息再也拉不到了。\r\n\r\n你这里的情况应该是在先ACK到了后面的消息，导致之前的消息取不到了。你可以对应看一下是不是我说的这种情况呢？\r\n\r\n如果是这个问题，稍后我会想办法处理这种情况。。\r\n\r\n发消息发布出去的问题，我需要检查确认一下\r\n"
      },
      {
        "user": "a641545621",
        "created_at": "2018-01-15T09:02:12Z",
        "body": "嗯 是你说的这样子 只是有点疑问就是 消息第一次发送失败 后面重新以新的消息再发送出去 应该是按最新消息来处理把？这样接收最新消息的话应该就正常了."
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2018-01-20T01:48:38Z",
        "body": "如果是发送端新发出去，是按照新消息处理的，所以消费端一般要保证幂等性"
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2018-01-24T02:48:50Z",
        "body": "Closed!\r\nv2.1.3 has fixed kafka consumer database store failed may caused message loss bug. "
      }
    ]
  },
  {
    "number": 73,
    "title": "Can not use the database and message queue, the use of memory for event bus and cross-module transactions",
    "created_at": "2017-12-21T13:24:02Z",
    "closed_at": "2017-12-25T05:51:58Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/73",
    "body": "",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/73/comments",
    "author": "lfzm",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2017-12-25T05:51:58Z",
        "body": "That's not CAP design goal."
      }
    ]
  },
  {
    "number": 72,
    "title": "Can this be a stand-alone version of the event bus and transaction processing?",
    "created_at": "2017-12-19T15:25:38Z",
    "closed_at": "2017-12-21T01:09:45Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/72",
    "body": "因为公司项目的前期不大，所以不需要进行分布式部署，但是我希望使用里面的事件总线，如果后期需要扩展就可以直接增加分布式基础设施就可以了，不知道这个行不行",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/72/comments",
    "author": "lfzm",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2017-12-20T02:45:52Z",
        "body": "你好，可以的。"
      },
      {
        "user": "lfzm",
        "created_at": "2017-12-20T13:25:50Z",
        "body": "@yuleyule66 现在好像没有实现吧？\r\n"
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2017-12-21T01:09:45Z",
        "body": "我想我应该对这个项目更加了解。 建议你先看一下wiki。\r\n\r\n关闭此issue，如果还有其他问题，可以reopn."
      },
      {
        "user": "lfzm",
        "created_at": "2017-12-21T13:20:50Z",
        "body": "@yuleyule66 这个可以不使用数据库和消息队列，如果实现单机版"
      }
    ]
  },
  {
    "number": 70,
    "title": "CAP can be used with other programming languages?",
    "created_at": "2017-12-18T02:21:00Z",
    "closed_at": "2017-12-18T02:52:41Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/70",
    "body": "你好，CAP能否跨语言使用？\r\n因为我看到是用rabbitmq和kafka的，java应该能互动吧",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/70/comments",
    "author": "VictorShadow89",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2017-12-18T02:52:41Z",
        "body": "你好，基于消息队列的通讯是可以跨语言的，但是CAP目前并没有Java版本，如果Java要使用的话，需要自己写一套。\r\n我们之前公司项目就是 .NET 和 Java 跨语言使用的， .NET 使用的CAP，但是Java那边的CAP并未开源。\r\n\r\n关闭issue，如果还有其他问题，可以reopen\r\n\r\n"
      },
      {
        "user": "VictorShadow89",
        "created_at": "2017-12-18T07:57:48Z",
        "body": "嗯，那这个实用性就不是特别大了，因为现在项目基本都是跨语言平台的。如果用存粹的消息通信，是无所谓的，但是因为CAP封装了一层，导致消息解析的时候可能难度会加大，这就要对CAP内部消息处理机制要很清楚了"
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2017-12-19T01:34:00Z",
        "body": "为什么解析消息会复杂呢？ 就是包装了一层而已。 而且编程语言那么多，如果要实现，也是先做golang，Java不会是最优先级。"
      }
    ]
  },
  {
    "number": 52,
    "title": "how dapper user works?",
    "created_at": "2017-10-20T03:15:52Z",
    "closed_at": "2017-10-21T04:49:17Z",
    "labels": [
      "help wanted",
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/52",
    "body": "   \r\n```\r\n        [Route(\"publish\")]\r\n        public async Task<IActionResult> PublishMessage()\r\n        {\r\n            const string cstr = \"Data Source=192.168.0.250;Initial Catalog=CapDemo;User ID=sa;Password=123123;\";\r\n\r\n            var sql1 = new System.Data.SqlClient.SqlConnection(cstr);\r\n            await _publisher.PublishAsync(\"CapDemo\", new Person { Name = \"老张\", Age = 30 }, sql1);\r\n\r\n            var sql2 = new System.Data.SqlClient.SqlConnection(cstr);\r\n            await _publisher.PublishAsync(\"CapDemo.Service\", new Person { Name = \"老李\", Age = 40 }, sql2);\r\n\r\n            return Ok();\r\n        }\r\n```\r\n\r\nshould I create a instance of SqlConnection when publish a message ? ",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/52/comments",
    "author": "zanpen2000",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2017-10-20T10:12:54Z",
        "body": "No, just create one SqlConnection in an action."
      },
      {
        "user": "zanpen2000",
        "created_at": "2017-10-31T11:22:29Z",
        "body": "@yuleyule66 But When I use one SqlConnection , I got a \"NullReferenceException\", code like below:\r\n```\r\n        [Route(\"publish\")]\r\n        public async Task<IActionResult> PublishMessage()\r\n        {\r\n            const string cstr = \"Data Source=192.168.0.250;Initial Catalog=CapDemo;User ID=sa;Password=123123;\";\r\n\r\n            var sql1 = new System.Data.SqlClient.SqlConnection(cstr);\r\n            await _publisher.PublishAsync(\"CapDemo\", new Person { Name = \"老张\", Age = 30 }, sql1);\r\n\r\n            // var sql2 = new System.Data.SqlClient.SqlConnection(cstr);\r\n            await _publisher.PublishAsync(\"CapDemo.Service\", new Person { Name = \"老李\", Age = 40 }, sql1);\r\n\r\n            return Ok();\r\n        }\r\n```\r\n\r\nThen I got:\r\n```\r\nNullReferenceException: Object reference not set to an instance of an object.\r\nSystem.Data.SqlClient.SqlConnection.TryOpen(TaskCompletionSource<DbConnectionInternal> retry)\r\nSystem.Data.SqlClient.SqlConnection.Open()\r\nDotNetCore.CAP.Abstractions.CapPublisherBase.PrepareConnectionForAdo(IDbConnection dbConnection, IDbTransaction dbTransaction) in CapPublisherBase.cs\r\n-\r\n        private void PrepareConnectionForAdo(IDbConnection dbConnection, IDbTransaction dbTransaction)\r\n        {\r\n            DbConnection = dbConnection ?? throw new ArgumentNullException(nameof(dbConnection));\r\n            if (DbConnection.State != ConnectionState.Open)\r\n            {\r\n                IsCapOpenedConn = true;\r\n                DbConnection.Open();\r\n            }\r\n            DbTransaction = dbTransaction;\r\n            if (DbTransaction == null)\r\n            {\r\n                IsCapOpenedTrans = true;\r\n                DbTransaction = dbConnection.BeginTransaction(IsolationLevel.ReadCommitted);\r\nDotNetCore.CAP.Abstractions.CapPublisherBase.PublishAsync<T>(string name, T contentObj, IDbConnection dbConnection, string callbackName, IDbTransaction dbTransaction) in CapPublisherBase.cs\r\n-\r\n        }\r\n        public Task PublishAsync<T>(string name, T contentObj, IDbConnection dbConnection,\r\n            string callbackName = null, IDbTransaction dbTransaction = null)\r\n        {\r\n            CheckIsAdoNet(name);\r\n            PrepareConnectionForAdo(dbConnection, dbTransaction);\r\n            var content = Serialize(contentObj, callbackName);\r\n            return PublishWithTransAsync(name, content);\r\n        }\r\nDemoA.Controllers.ValuesController+<PublishMessage>d__2.MoveNext() in ValuesController.cs\r\n-\r\n            const string cstr = \"Data Source=192.168.0.250;Initial Catalog=CapDemo;User ID=sa;Password=123123;\";\r\n            var sql1 = new System.Data.SqlClient.SqlConnection(cstr);\r\n            await _publisher.PublishAsync(\"CapDemo\", new Person { Name = \"老张\", Age = 30 }, sql1);\r\n            // var sql2 = new System.Data.SqlClient.SqlConnection(cstr);\r\n            await _publisher.PublishAsync(\"CapDemo.Service\", new Person { Name = \"老李\", Age = 40 }, sql1);\r\n            return Ok();\r\n        }\r\n        [NonAction]\r\n        [CapSubscribe(\"CapDemo\")]\r\nSystem.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()\r\nSystem.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\r\nSystem.Runtime.CompilerServices.TaskAwaiter.GetResult()\r\nMicrosoft.AspNetCore.Mvc.Internal.ControllerActionInvoker+<InvokeActionMethodAsync>d__12.MoveNext()\r\nSystem.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()\r\nSystem.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\r\nMicrosoft.AspNetCore.Mvc.Internal.ControllerActionInvoker+<InvokeNextActionFilterAsync>d__10.MoveNext()\r\nSystem.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()\r\nMicrosoft.AspNetCore.Mvc.Internal.ControllerActionInvoker.Rethrow(ActionExecutedContext context)\r\nMicrosoft.AspNetCore.Mvc.Internal.ControllerActionInvoker.Next(ref State next, ref Scope scope, ref object state, ref bool isCompleted)\r\nMicrosoft.AspNetCore.Mvc.Internal.ControllerActionInvoker+<InvokeInnerFilterAsync>d__14.MoveNext()\r\nSystem.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()\r\nSystem.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\r\nMicrosoft.AspNetCore.Mvc.Internal.ResourceInvoker+<InvokeNextResourceFilter>d__22.MoveNext()\r\nSystem.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()\r\nMicrosoft.AspNetCore.Mvc.Internal.ResourceInvoker.Rethrow(ResourceExecutedContext context)\r\nMicrosoft.AspNetCore.Mvc.Internal.ResourceInvoker.Next(ref State next, ref Scope scope, ref object state, ref bool isCompleted)\r\nMicrosoft.AspNetCore.Mvc.Internal.ResourceInvoker+<InvokeFilterPipelineAsync>d__17.MoveNext()\r\nSystem.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()\r\nSystem.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\r\nMicrosoft.AspNetCore.Mvc.Internal.ResourceInvoker+<InvokeAsync>d__15.MoveNext()\r\nSystem.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()\r\nSystem.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\r\nMicrosoft.AspNetCore.Builder.RouterMiddleware+<Invoke>d__4.MoveNext()\r\nSystem.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()\r\nSystem.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\r\nMicrosoft.AspNetCore.Diagnostics.DeveloperExceptionPageMiddleware+<Invoke>d__7.MoveNext()\r\n```\r\n"
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2017-10-31T14:45:12Z",
        "body": "Upgrading CAP version to `2.1.0-preview-26231671`, I modified part of the `ICapPublish` interface about publishing message with ADO.NET , and here is a sample code :\r\n\r\n```\r\n    [Route(\"~/publishWithTransactionUsingAdonet\")]\r\n    public async Task<IActionResult> PublishMessageWithTransactionUsingAdonet([FromServices]ICapPublisher publisher)\r\n    {\r\n        var connectionString = \"\";\r\n        using (var sqlConnection = new SqlConnection(connectionString))\r\n        {\r\n            sqlConnection.Open();\r\n            using (var sqlTransaction = sqlConnection.BeginTransaction())\r\n            {\r\n                // 此处填写你的业务代码，通常情况下，你可以将业务代码使用一个委托传递进来进行封装该区域代码。\r\n\r\n                publisher.Publish(\"xxx.services.account.check\", new Person { Name = \"Foo\", Age = 11 }, sqlTransaction);\r\n\r\n                sqlTransaction.Commit();\r\n            }\r\n        }\r\n        return Ok();\r\n    }\r\n```"
      },
      {
        "user": "zanpen2000",
        "created_at": "2017-10-31T23:31:17Z",
        "body": "En, Thank you for your time, It's very helpful!"
      }
    ]
  },
  {
    "number": 37,
    "title": "How to ensure the consumer method will not be executed twice when the consumer method succeeded but IFetchedMessage.RemoveFromQueue failed?",
    "created_at": "2017-08-18T05:03:09Z",
    "closed_at": "2017-09-09T13:20:41Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/37",
    "body": "IFetchedMessage looks like using a transaction that independent of the consumer method. Here is a situation may happen : IFetchedMessage.RemoveFromQueue (commit transaction) has been failed and rolling back after consumer method succeeded (this record in the cap.queue has not been deleted). When next round began, a same consumer method will be execute. \r\n",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/37/comments",
    "author": "ah-its-andy",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2017-08-18T08:40:38Z",
        "body": "I have thought about this problem in the issue #29 , this scenario is only one of you say, because of we can not guarantee 100% will not be repeated processing a message, so we want message consumer  can support idempotent operation at their needed scenario, such as repetitive operation does not cause side effects. Other frameworks based MQ all are so."
      }
    ]
  },
  {
    "number": 32,
    "title": "asp.net core 2.0 not compatibility",
    "created_at": "2017-08-16T03:27:24Z",
    "closed_at": "2017-08-18T03:26:10Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/32",
    "body": "when in asp.net core 2.0\r\nin ConfigureServices AddCap -- UseEntityFramework, UseRabbitMQ\r\nin Configure UseCap\r\n\r\nruntime throw\r\n\r\nMethod not found: 'System.IServiceProvider Microsoft.Extensions.DependencyInjection.ServiceCollectionContainerBuilderExtensions.BuildServiceProvider(Microsoft.Extensions.DependencyInjection.IServiceCollection)'.\r\n\r\n\r\nStackTrace:\r\n   at DotNetCore.CAP.SqlServerCapOptionsExtension.TempBuildService(IServiceCollection services)\r\n   at DotNetCore.CAP.SqlServerCapOptionsExtension.AddServices(IServiceCollection services)\r\n   at Microsoft.Extensions.DependencyInjection.ServiceCollectionExtensions.AddCap(IServiceCollection services, Action`1 setupAction)\r\n   at namespace.Startup.ConfigureServices(IServiceCollection services)\r\n",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/32/comments",
    "author": "SimTsai",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2017-08-16T07:43:01Z",
        "body": "An official version of 2.0 has yet to be released, you can use the preview version now."
      },
      {
        "user": "SimTsai",
        "created_at": "2017-08-17T03:51:01Z",
        "body": "Thank you for your prompt reply. wish 2.0 final version faster."
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2017-08-18T03:26:10Z",
        "body": "@simhgd \r\nversion 2.0 preview published, it used .net standard 2.0 also support .net core 2.0 and asp.net core 2.0."
      }
    ]
  },
  {
    "number": 1603,
    "title": "Does CAP support sending messages to oneself?",
    "created_at": "2024-10-29T09:24:47Z",
    "closed_at": "2024-11-05T03:58:31Z",
    "labels": [
      "help wanted"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/1603",
    "body": "Does CAP support sending messages to oneself? \r\nThat is, a service that published a message and it can reveive this message too\r\nI remember earlier versions didn't seem to support it，there were some issues",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/1603/comments",
    "author": "jrlygdsj",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2024-10-30T01:07:47Z",
        "body": "Of course, why don't you do a test?"
      },
      {
        "user": "jrlygdsj",
        "created_at": "2024-12-06T11:16:08Z",
        "body": "> Of course, why don't you do a test?\r\n\r\nYes, i have done,\r\nthe number of received messages is less than the number of published messages，I have encountered it twice\r\n\r\n@yang-xiaodong "
      }
    ]
  },
  {
    "number": 1602,
    "title": "期待当配置RabbitMQ时cap.published支持至少消费指定1个或多个订阅服务后才能定时清除",
    "created_at": "2024-10-28T08:49:43Z",
    "closed_at": "2024-10-29T01:09:05Z",
    "labels": [
      "help wanted"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/1602",
    "body": "以保证消费端异常或延迟未启动成功且发布者发送Exchange时没有队列，当消息过多或超出清楚时间后，相当于消费白发送了也就是没有达到CAP；\r\n或者支持配置不通过Exchange发送消息，可以配置指定队列发送。\n```[tasklist]\n### Tasks\n```\n",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/1602/comments",
    "author": "rocleegithub",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2024-10-29T01:08:16Z",
        "body": "There are no plans for this.\r\nBroker-based senders usually follow the Fire-and-forget guideline, and if you need to know the result of consumption to do something, it's better to use rpc instead of messages!"
      },
      {
        "user": "rocleegithub",
        "created_at": "2024-10-29T01:25:12Z",
        "body": "那我的临时解决方案：\r\n\r\n1. 根据实体状态手动或定时扫描补偿发送消息事件。\r\n\r\n2. 首次使用应用前得提前启动消费端（创建队列queue `durable:true` （持久的）)保证异常情况下重启消费端后这个队列还在（生产者继续发送消息到这个队列），当再次启动后继续消费这个队列。"
      }
    ]
  },
  {
    "number": 1546,
    "title": "一个程序进程会操作多个不同的业务数据库，参考#998创建多个发布者进行对应处理，消费者应该如何处理消息？",
    "created_at": "2024-06-17T10:06:38Z",
    "closed_at": "2024-06-19T12:03:06Z",
    "labels": [
      "help wanted"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/1546",
    "body": "杨老师你好，我已经查看#998 的沟通讨论，仍旧有些场景不知如何处理。我的场景及问题如下。\r\n\r\n场景：一个程序进程会操作多个不同的业务数据库dbA、dbB，传输层共用消息放在内存中(使用Savorboard.CAP.InMemoryMessageQueue)，使用#998的方式给每个数据库创建对应的发布者。\r\n\r\n问题：发布消息是ok的，对应的发布者可以正常的将消息发布到对应的数据库及数据表中，但是无法正常消费消息：比如业务模块A发布消息，想要由业务模块B订阅；但是我像正常的方式使用消费者，发现消息会被业务模块A消费了(dbA的cap.received表收到了消息)；而无法由业务模块B消费并将接收到的消息存储到dbB的接收表(cap.received)中。针对这种情况我应该如何处理呢？",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/1546/comments",
    "author": "ngala-hjw",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2024-06-17T13:22:19Z",
        "body": "不支持，建议不同库拆分服务。"
      }
    ]
  },
  {
    "number": 1525,
    "title": "How to Handle Multiple Instances Receiving Messages",
    "created_at": "2024-05-09T01:22:18Z",
    "closed_at": "2024-05-10T01:17:29Z",
    "labels": [
      "help wanted"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/1525",
    "body": "在集群部署时2套一样的程序如何配置，看文档说是配置不同的group就可以了，同一套代码如何配置不同的group，group参数必须是常量，也没办法通过读取当前机器标识生成\r\n",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/1525/comments",
    "author": "JavaScript-zt",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2024-05-09T03:10:29Z",
        "body": "You can use `DefaultGroupName`  option to configure it globally.\r\n\r\n```\r\nx.DefaultGroupName = Helper.GetInstanceHostname();\r\n```"
      }
    ]
  },
  {
    "number": 1515,
    "title": "Scheduling freezes on large number of delayed messages",
    "created_at": "2024-04-12T01:36:09Z",
    "closed_at": "2024-04-16T06:08:19Z",
    "labels": [
      "help wanted"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/1515",
    "body": "Setup: CAP 8.1 RabbitMq + Postgres\r\nGiven: A large number of delayed messages (>20000 in my case)\r\n\r\nWhen `IDataStorage.ScheduleMessagesOfDelayedAsync` fetches all messages from the DB and schedules them for processing, entire operation is executed inside a DB transaction and with `FOR UPDATE SKIP LOCKED` instruction that locks all selected rows for the duration of the transaction.\r\n\r\nNext, the following happens:\r\n\r\n1. Transaction (**T1**) starts in `ScheduleMessagesOfDelayedAsync`\r\n2. Pending messages are read and enqueued via `_dispatcher.EnqueueToScheduler()` (IProcessor.Delayed.cs)\r\n3. Messages are added to the `_schedulerQueue` priority queue for async processing by a background task. (Dispatcher.cs)\r\n4. The BG task picks the next available message from the priority queue: `_schedulerQueue.TryPeek(out _, out _nextSendTime)`\r\n5. The message is sent to transport (`await _sender.SendAsync(_schedulerQueue.Dequeue());`) and `SetSuccessfulState` is called (IMessageSender.Default.cs)\r\n6. An update statement is executed in `ChangeMessageStateAsync()` (IDataStorage.PostgreSql.cs) against the DB **while the T1 transaction is still not committed**. Thus, the update statement times out and fails as the affected row is still locked by **T1**.\r\n7. The `while (_schedulerQueue.TryPeek(out _, out _nextSendTime))` loop freezes forever. (IDispatcher.Default.cs)\r\n\r\n\r\n",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/1515/comments",
    "author": "eubelov",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2024-04-12T02:16:58Z",
        "body": "It looks similar to #1429. It is caused by ScheduleMessagesOfDelayedAsync triggering again during the execution of T1 transaction. Please refer to the solution in #1429. If there are a large number of delayed messages at the same time, you may need to override the QueuedMessageFetchTime method."
      }
    ]
  },
  {
    "number": 1460,
    "title": "CapFilter AsyncLocal",
    "created_at": "2023-12-21T08:52:28Z",
    "closed_at": "2023-12-29T09:48:35Z",
    "labels": [
      "help wanted"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/1460",
    "body": "Hello Guys,\r\n\r\n## Issue Description\r\n\r\n### Problem\r\nIn the `CapFilter` class, when using `LogContext.PushProperty` within the `SetLogCorrelationIdProperty` method during asynchronous execution, it seems that the context is not properly captured due to changes in the behavior of `AsyncLocal` after version 7. \r\n\r\nPreviously, before version 7, when `CapFilter` was synchronous, this issue did not occur.\r\n\r\n### Expected Behavior\r\nThe `LogContext.PushProperty` operation should capture the context correctly even in an asynchronous environment.\r\n\r\n### Steps to Reproduce\r\n1. Implement a `CapFilter` class similar to the provided code.\r\n2. Use `LogContext.PushProperty` within an asynchronous method, such as `OnSubscribeExecutingAsync`.\r\n3. Observe that the context is not properly captured when using Cap version 7 or later.\r\n\r\n\r\n## Code Samples\r\n\r\nPlease find the relevant code samples below:\r\n\r\n```csharp\r\n// CapFilter class\r\npublic class CapFilter : SubscribeFilter\r\n    {\r\n        public CapFilter()\r\n        {\r\n\r\n        }\r\n\r\n        public override Task OnSubscribeExecutingAsync(ExecutingContext context)\r\n        {\r\n            SetLogCorrelationIdProperty(context.DeliverMessage.Headers);\r\n\r\n            return Task.CompletedTask;\r\n        }\r\n        private void SetLogCorrelationIdProperty(IDictionary<string, string> headers)\r\n        {\r\n            if (headers.TryGetValue(AppConstants.HeaderKeys.CorrelationIdHeaderKey, out string correlationId))\r\n            {\r\n                LogContext.PushProperty(\"CorrelationId\", correlationId);\r\n            }\r\n        }\r\n    }\r\n\r\n// TestCapHandler class\r\npublic class TestCapHandler : ICapSubscribe\r\n{\r\n    private readonly ILogger<TestCapHandler> _logger;\r\n\r\n    public TestCapHandler(ILogger<TestCapHandler> logger)\r\n    {\r\n        _logger = logger;\r\n    }\r\n\r\n    [CapSubscribe(nameof(TestCap))]\r\n    public async Task Handler(TestCap testCap, [FromCap] CapHeader headers)\r\n    {\r\n        _logger.LogInformation(\"Hello\");\r\n    }\r\n}",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/1460/comments",
    "author": "mertigdir",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2023-12-22T05:00:28Z",
        "body": "Hi, \r\n\r\nWhat's `LogContext` ?  \r\n\r\nAsyncLocal cannot be propagated up within an async context, so you cannot use AsyncLocal to save the value"
      },
      {
        "user": "mertigdir",
        "created_at": "2023-12-23T14:18:18Z",
        "body": "Hi,\r\nIn Serilog, LogContext is a feature that provides a context mechanism for carrying logging-related information within the Serilog library. It allows you to associate additional contextual information with log events. This information is often related to a specific operation or request and can be useful for tracing and debugging.\r\n\r\nFor example, you can use LogContext to attach properties like user information, request IDs, or any other context-specific data to log events. This makes it easier to understand and analyze logs, especially in complex systems with multiple components.\r\n\r\nLogContext internally uses AsyncLocal, and what I want to convey here is that AsyncLocal cannot be applied to an object like CapFilter, which diminishes the functionality of CapFilter.\r\n"
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2023-12-24T13:41:01Z",
        "body": "This is the remark in the LogContext.\r\n> The PushProperty must be popped from the same thread/logical call context\r\n\r\nWe cannot solve the problem of AsyncLocal, and CAP does not intend to provide synchronous filters.\r\n\r\nYou may need to customize ISubscribeInvoker to implement synchronized filters"
      }
    ]
  },
  {
    "number": 1358,
    "title": "Hot update of sqlserver connection string",
    "created_at": "2023-06-06T03:06:55Z",
    "closed_at": "2023-06-07T12:25:28Z",
    "labels": [
      "help wanted"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/1358",
    "body": "Hello, we use the sqlserver database in the CAP framework. If the connection string of sqlserver changes during the running of the program, how do we update the CAP to the latest connection string? Thanks.",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/1358/comments",
    "author": "zaoantest",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2023-06-06T09:59:31Z",
        "body": "You can just set ConnectionString in SqlServerOptions"
      }
    ]
  },
  {
    "number": 1352,
    "title": "Send message to specific Kafka partition",
    "created_at": "2023-06-03T11:03:38Z",
    "closed_at": "2023-06-05T13:02:11Z",
    "labels": [
      "help wanted"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/1352",
    "body": "Hello!\r\nIs there any way to send a specific message to a specific partition in Kafka?",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/1352/comments",
    "author": "SAhmadvand",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2023-06-03T13:32:28Z",
        "body": "Hi,\r\nYou can customize the `ITransport` interface, then read the partition ID you want to set from the Header, and use the overload of `ProduceAsync(TopicPartition topicPartition, Message<TKey, TValue> message, CancellationToken cancellationToken)` to send."
      }
    ]
  },
  {
    "number": 1299,
    "title": "Kafka partitioning and consumer Client Id property.",
    "created_at": "2023-03-22T14:53:01Z",
    "closed_at": "2023-03-28T04:10:49Z",
    "labels": [
      "help wanted"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/1299",
    "body": "Hi,\r\nWe are using this great library heavily in our projects. And our projects require heavy message processing. So we need multi-core processing. It is known that if you need concurrent processing you need to have partitions in kafka. When you set `ConsumerThreadCount` greater than 1 it will have no effect on the concurrency. As the topics will have just 1 partition created by the CAP. This part is manageable you can of course set the partition count manually via kafka command line tools. But when you do this you need to set the `client.id` for each thread that is consuming. Currently, the library only allows for passing config only in the startup stage, and this config is shared by all the consumers. So we need to be able to configure each consumer id individually. If you can provide a callback (it would be better if an async callback) kind of setting which will determine the client id of the consumer it will super useful. \r\nIf anyone has the same issue as us, we are currently using a workaround that requires setting the `ConsumerThreadCount` to 1 and setting the client id at startup. Instead of having multi-threading in a single app, we are using multiple apps to consume concurrently. This is easy to implement in a k8s environment you can easily increase the pod count. But I don't know about self-hosted applications (In IIS you can also increase the worker process count.). Also, I don't know if it is as efficient as having multiple threads.\r\n",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/1299/comments",
    "author": "3ldar",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2023-03-24T08:42:09Z",
        "body": "Hi  @3ldar \r\n\r\nThanks for your feedback, I think this is a feature that can be improved, but I need further clarification from you.\r\n\r\nDo you mean that you manually changed the number of kafka partitions by the following command\r\n```\r\nkafka-topics.sh --bootstrap-server localhost:9092 --alter --topic first_topic --partitions 5\r\n```\r\n\r\nAnd you want to change the consumer thread corresponding to the topic partition at runtime ?\r\n\r\n> But when you do this you need to set the `client.id` for each thread that is consuming\r\n\r\nI know that Kafka specifies consumer thread strategies through `partition.assignment.strategy` configuration. How to specify at runtime by command?  \r\n\r\n\r\n"
      },
      {
        "user": "3ldar",
        "created_at": "2023-03-25T22:54:08Z",
        "body": "Hi again,\r\n\r\n\r\n>  kafka-topics.sh --bootstrap-server localhost:9092 --alter --topic first_topic --partitions 5\r\n\r\nThis is the exact command I have used. Setting this according to the consumer thread count (or providing another config, which would be way better if it was per-topic configurable) is nice. But the crucial part is `client.id`. The `partition.assignment.strategy` will determine how the clients in the same group will pick or rotate the partitions (and it is ok to set it once at the application startup) but when all the clients have the same id they will share the same offsets and no efficient concurrency will be applied here. (Concurrency would work for different topics well, but not on the same topic. There are many benchmarks about this for kafka.) `client.id` should be set before the consuming starts and it is not necessary to change it at runtime (maybe it should not it might mess up some offsets). \r\n\r\nA singleton service that implements the below interface would work here I think.\r\n```\r\npublic interface IKafkaClientIdProvider {\r\n    Task<string> GetClientId();\r\n    Task<string> GetClientId(string groupId); //one of them can be pick here\r\n}\r\n```\r\n\r\n A default implementation like the one below would work :\r\n```\r\npublic class DefaultKafkaClientIdProvider {\r\n    int clientIdCounter = 0; // consider this is thread-safe\r\n    Task<string> GetClientId() => Task.FromResult($\"fancyClient_{i++}\");\r\n    Task<string> GetClientId(string groupId) => Task.FromResult($\"{groupId}_client_{i++}\");\r\n}\r\n```\r\nMe personally will use some state store like redis to determine the clientId for the related group. Because I have a distributed environment, and have many instances accros the kubernetes clusters for the same service."
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2023-03-26T13:24:43Z",
        "body": "Hello,\r\n\r\nI did a test.\r\n\r\nThe `client.id` is not specified and set `ConsumerThreadCount = 3` and set 3 partitions for the test topic, the 3 consumer threads will automatically correspond to the 3 partitions, and the messages will be in concurrent consumption by 3 consumer threads within 3 partitions.\r\n\r\n\r\n```cs\r\n[CapSubscribe(\"sample.kafka.postgrsql\")]\r\npublic void Test2(DateTime value, [FromCap] CapHeader header)\r\n{\r\n    var offset = header[\"my.kafka.offset\"];\r\n    var partition = header[\"my.kafka.partition\"];\r\n    var consumerId = header[\"ConsumerId\"][^2..];\r\n    Console.ForegroundColor = ConsoleColor.Red;\r\n    Console.WriteLine(\"Subscriber output message: \" + value);\r\n    Console.WriteLine(\"ConsumerId: \" + consumerId + \", Offset: \" + offset + \", Partition: \" + partition);\r\n}\r\n```\r\n> header[\"ConsumerId\"]  generated when the `KafkaConsumerClient` created and add to the header when received message.\r\n\r\nThe consumer output:\r\n```\r\nSubscriber output message: 2023/3/26 21:07:20\r\nConsumerId: 92, Offset: 28, Partition: [1]\r\nSubscriber output message: 2023/3/26 21:07:20\r\nConsumerId: 92, Offset: 29, Partition: [1]\r\nSubscriber output message: 2023/3/26 21:07:37\r\nConsumerId: 91, Offset: 22, Partition: [0]\r\nSubscriber output message: 2023/3/26 21:07:38\r\nConsumerId: 91, Offset: 23, Partition: [0]\r\nSubscriber output message: 2023/3/26 21:07:38\r\nConsumerId: 90, Offset: 14, Partition: [2]\r\nSubscriber output message: 2023/3/26 21:07:38\r\nConsumerId: 92, Offset: 30, Partition: [1]\r\nSubscriber output message: 2023/3/26 21:07:38\r\nConsumerId: 92, Offset: 31, Partition: [1]\r\nSubscriber output message: 2023/3/26 21:07:38\r\nConsumerId: 92, Offset: 32, Partition: [1]\r\nSubscriber output message: 2023/3/26 21:07:38\r\nConsumerId: 91, Offset: 24, Partition: [0]\r\nSubscriber output message: 2023/3/26 21:07:39\r\nConsumerId: 90, Offset: 15, Partition: [2]\r\nSubscriber output message: 2023/3/26 21:07:39\r\nConsumerId: 92, Offset: 33, Partition: [1]\r\n```\r\n\r\n\r\nWhen tha app startup and connect to the kafka server, the kafka server will create a new member id for the new consumer , the new consumer (dynamic member) will auto join the group and the server remove the old consumer.\r\n\r\nBelow is the kafka server log when app connect the the server.\r\n\r\n```\r\n2023-03-26 21:06:12 [2023-03-26 13:06:12,156] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group cap.queue.sample.kafka.postgresql.v1 in Stable state. Created a new member id rdkafka-cc98ba5e-bd87-4a17-bd22-5f7df8fbbe6b and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)\r\n2023-03-26 21:06:12 [2023-03-26 13:06:12,161] INFO [GroupCoordinator 1]: Preparing to rebalance group cap.queue.sample.kafka.postgresql.v1 in state PreparingRebalance with old generation 11 (__consumer_offsets-8) (reason: Adding new member rdkafka-cc98ba5e-bd87-4a17-bd22-5f7df8fbbe6b with group instance id None) (kafka.coordinator.group.GroupCoordinator)\r\n2023-03-26 21:06:12 [2023-03-26 13:06:12,204] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group cap.queue.sample.kafka.postgresql.v1 in PreparingRebalance state. Created a new member id rdkafka-a8e28383-146d-4a72-8a22-2ed2b3f87120 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)\r\n2023-03-26 21:06:12 [2023-03-26 13:06:12,204] INFO [GroupCoordinator 1]: Dynamic member with unknown member id joins group cap.queue.sample.kafka.postgresql.v1 in PreparingRebalance state. Created a new member id rdkafka-b742d5ad-39cf-492c-949d-31172acbe275 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)\r\n2023-03-26 21:06:37 [2023-03-26 13:06:37,223] INFO [GroupCoordinator 1]: Member rdkafka-22d4cb6a-592a-417b-b8e6-132346f96937 in group cap.queue.sample.kafka.postgresql.v1 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)\r\n2023-03-26 21:06:37 [2023-03-26 13:06:37,304] INFO [GroupCoordinator 1]: Member rdkafka-49cc36c8-51ce-43bb-b6e4-1c973e3ad508 in group cap.queue.sample.kafka.postgresql.v1 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)\r\n2023-03-26 21:06:37 [2023-03-26 13:06:37,304] INFO [GroupCoordinator 1]: Member rdkafka-fdaa4e1b-25f2-421e-b1e0-2bc43e780109 in group cap.queue.sample.kafka.postgresql.v1 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)\r\n2023-03-26 21:06:37 [2023-03-26 13:06:37,305] INFO [GroupCoordinator 1]: Stabilized group cap.queue.sample.kafka.postgresql.v1 generation 12 (__consumer_offsets-8) with 3 members (kafka.coordinator.group.GroupCoordinator)\r\n```\r\n\r\nThis seems to be exactly what you want, I don't know why you want to specifying the `client.id` ?\r\n"
      },
      {
        "user": "3ldar",
        "created_at": "2023-03-26T21:40:16Z",
        "body": "Thanks for all the effort you have done. The first mistake I made is: it should be `consumer.id` not the `client.id`. For the second one; you are right when you did not set a consumer id, the connector assigns a random consumer id and it solves the \"consumer id must be unique among the group members\". I probably misinterpreted the error I had before and started to overthink it.  The last question remains in my mind and not being so sure. When your consumer which has a randomly generated id is restarted an auto-reset offset situation happens because the new id will be different from the previous depending on the setting your consumer will process all the data again. Like I said I am not so sure about it, I might be messing the `group.id` with the `consumer.id`. If I can have some spare time in the morning I will try to simulate the behavior to prove myself wrong 😃 "
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2023-03-28T04:10:49Z",
        "body": "#1303 as the subsequent for current issue."
      }
    ]
  },
  {
    "number": 1247,
    "title": "Add ability to support configurable  subscriber",
    "created_at": "2022-11-30T03:33:06Z",
    "closed_at": "2022-12-01T01:01:03Z",
    "labels": [
      "help wanted"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/1247",
    "body": "If we have multiple workers in a swarm or Kubernetes,  is it possible to change the subscriber in a config file , case as below:\r\n\r\nin normal Dotnet.Cap mode\r\n`[CapSubscribe(\"store.**.data\")]\r\nPublic Task StoreData(object data){...}`\r\n\r\nIn dynamic mode, add a subscriber dynamically in a config file when load the host app in appsetting.json:\r\n`\r\n{\r\n    \"subscribers\":\r\n    [\r\n       {\r\n            \"topic\" : \"store.data1\", \r\n            \"group\" : \"v1\",\r\n            \"bind-method\" : \"Namespace.SampleClass.StoreData\"\r\n       }\r\n    ]\r\n}\r\n`",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/1247/comments",
    "author": "charleypeng",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2022-11-30T05:36:09Z",
        "body": "We're not suppot it directly, but your can impl your own `IConsumerServiceSelector`  to find the subscriber from configuration file."
      }
    ]
  },
  {
    "number": 1153,
    "title": "Received表中的数据比Published中的数据足足晚了将近一天",
    "created_at": "2022-06-10T12:13:16Z",
    "closed_at": "2022-06-13T07:39:03Z",
    "labels": [
      "help wanted"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/1153",
    "body": "你好，最近遇到这样一个问题，Received表中数据的Added时间比Published中的数据足足晚了将近一天，导致用户昨天提交的数据今天才收到，能否帮忙分析一下这种情况是怎么发生的呢？我暂时没有想明白这种情况是怎么发生的。谢谢！",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/1153/comments",
    "author": "pwm812",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2022-06-12T08:45:16Z",
        "body": "Please provide your version and configuration and logs"
      },
      {
        "user": "pwm812",
        "created_at": "2022-06-13T07:18:59Z",
        "body": "你好，CAP版本号是5.1.0，我发现情况大概是这样：有可能是中途rabbitmq服务挂过，然后重启之后，其他服务重新连接到rabbitmq，rabbimq中的connection中也可以看到连接，连接这里没有问题，问题出在队列中的consumer是空的，按理说connection都连上了，consumer应该不会为空呢。目前发现大概就是这样，不知道CAP有没有重连机制呢？谢谢。"
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2022-06-13T07:39:03Z",
        "body": "你好，有自动重连。 \r\n\r\n调查这类问题需要大量上下文信息，所以除非有可复现的步骤，否则我们无法进行调查。\r\n\r\n现在我关闭这个issue。"
      }
    ]
  },
  {
    "number": 974,
    "title": "DotNetCore.CAP.Dashboard类库在5.x中能否支持netstandard2.1呢",
    "created_at": "2021-08-13T03:44:34Z",
    "closed_at": "2021-08-13T03:46:23Z",
    "labels": [
      "help wanted",
      "wontfix"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/974",
    "body": "现在DotNetCore.CAP.Dashboard在5.x只支持net5.0能否支持netstandard2.1呢,因为现在有很多项目还在使用netcoreapp3.1\r\n",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/974/comments",
    "author": "jakey188",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2021-08-13T03:46:23Z",
        "body": "No, Dashboard is implemented based on ASP.NET Core middleware\r\n\r\nYou can use version 3.1.2 for  .net core 3.1"
      },
      {
        "user": "jakey188",
        "created_at": "2021-08-13T05:48:56Z",
        "body": "如果是使用了nginx或者其他代理之后Dashboard对于资源资源请求文件(js,css)的路径不支持,而且是使用的绝对路径/,我看了5.x之后是支持配置的。"
      }
    ]
  },
  {
    "number": 890,
    "title": "Cap library help",
    "created_at": "2021-05-25T15:04:24Z",
    "closed_at": "2021-05-28T10:09:45Z",
    "labels": [
      "help wanted"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/890",
    "body": "Sorry if i am asking dumb questions.\r\n\r\nAfter going through docs i understand that CAP is used in some service which produces events, cap will store the events in the \r\ndatabase and publishes the message to Message Broker and consume the events from Message Broker.\r\n\r\nAll the code(Storage, publishing and subscribing) is included in one service which might not need all the functionality.\r\n\r\nIn my case, service will just produce events, it will not use subscription part.\r\n\r\nCan anyone suggest me on the below structure.\r\n\r\nServiceA - produces events and stores in db.\r\nConsoleApp1(background) - Reads the events from db and publishes to Message Broker.\r\nConsoleApp2(background) - Subscribes to Message Broker and consumes the events.\r\n\r\nNow if i want to use CAP here, I will need \r\n           1.  CAP.Storage package to save data in **ServiceA**\r\n           2.  CAP.Publisher package to only read the events table and publishes to Message Broker in **ConsoleApp1**\r\n           3.  CAP.Subscriber package to consume events from Message Broker in **ConsoleApp2**\r\n\r\nIs this kind of approach is good ? If yes how can i use CAP to achieve it ?\r\n",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/890/comments",
    "author": "BBanoth",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2021-05-26T06:28:32Z",
        "body": "Hello,\r\n\r\nAfter the CAP is stored in the DB, the message will be placed in the buffer area instead of being read from the DB again, so why not put the behavior of ConsoleApp1 directly in ServiceA ?\r\n\r\n"
      }
    ]
  },
  {
    "number": 683,
    "title": "Possible to keep messages ordered when received",
    "created_at": "2020-10-06T10:15:33Z",
    "closed_at": "2020-10-10T06:15:28Z",
    "labels": [
      "help wanted"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/683",
    "body": "Is there any in built mechanism, setting or way to make sure messages are received in order, FIFO.\r\nIf messages are published very close to each other it seems they can be received in incorrect order.\r\nThanks",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/683/comments",
    "author": "cog-ab",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2020-10-07T10:51:36Z",
        "body": "This is true for any message-based architecture. It depends on how you consume your messages. If there is a single consumer instance, the messages are sequential. If there are multiple consumers, the order cannot be strictly guaranteed."
      }
    ]
  },
  {
    "number": 369,
    "title": "Working with multiple instances of one service",
    "created_at": "2019-07-17T13:13:38Z",
    "closed_at": "2019-07-18T13:10:12Z",
    "labels": [
      "help wanted"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/369",
    "body": "Hello, i'm using kafka transport with postgres persistence in my service.\r\nI have 3 instance of my service (in kubernetes) and one database for persistence (one table for all instances).  Instances subscribes for one topic in one subscriber group. One of instance crushes when process message. What is behavior of other instances? Is one or both take this message to proccess? \r\nWhat cases should pay attention with multiple instance of service?",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/369/comments",
    "author": "cruisade",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2019-07-17T13:53:50Z",
        "body": "Hello @cruisade ,\r\n\r\nWhen using Kafka as a Transport, the message consumed by the consumer instance depends on the number of Kafka partitions and the consumer group.\r\n\r\nIf you have three service instances, then ideally your Kafka partition should be greater than or equal to three to ensure that all instances are working.\r\n\r\nAs you said, one of the instances crashed. Can you provide a log so that we can check it out?"
      },
      {
        "user": "cruisade",
        "created_at": "2019-07-18T08:03:45Z",
        "body": "Thank you for your answer. \r\nAll instance in one consumer group. \r\n Should i use 3 partition of topics for 3 instances? And why one partition is not an option?\r\nAnd, my question not about crush instance, it's about fault tolerance, and behavior of other instances. \r\nAs i understand, every instance have scheduler that monitor \"received\" table. Is it possible that two other instances start process message (of crushed instance) in same time, and will process one message two times?\r\n\r\nIs Kafka offset commited, when message appears in \"received\" table, or it is commited when subscriber finish his work?"
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2019-07-18T08:30:41Z",
        "body": "> Should i use 3 partition of topics for 3 instances?   \r\n\r\nYes, it's best practice\r\n\r\n> Why one partition is not an option?\r\n\r\nI can't get your point.\r\n\r\n> Will process one message two times\r\n\r\nYes, there is this possibility, but only for failed messages. At this time, the idempotency of the consumer will work.\r\n\r\n> or it is commited when subscriber finish his work?\r\n\r\nCommited after the message is stored in the table, before executing the consumer\r\n"
      }
    ]
  },
  {
    "number": 352,
    "title": "Only READPAST locks can be specified at the READ COMMITTED or REPEATABLE READ isolation level.",
    "created_at": "2019-06-20T03:31:01Z",
    "closed_at": "2019-06-20T05:41:15Z",
    "labels": [
      "help wanted"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/352",
    "body": "2019-06-20 08:03:12.5425servicename=ShipMainService--Processor 'DotNetCore.CAP.Processor.NeedRetryMessageProcessor' failed. Retrying...System.Data.SqlClient.SqlException (0x80131904): Only READPAST locks can be specified at the READ COMMITTED or REPEATABLE READ isolation level.\r\n   at System.Data.SqlClient.SqlConnection.OnError(SqlException exception, Boolean breakConnection, Action`1 wrapCloseInAction)\r\n   at System.Data.SqlClient.TdsParser.ThrowExceptionAndWarning(TdsParserStateObject stateObj, Boolean callerHasConnectionLock, Boolean asyncClose)\r\n   at System.Data.SqlClient.TdsParser.TryRun(RunBehavior runBehavior, SqlCommand cmdHandler, SqlDataReader dataStream, BulkCopySimpleResultSet bulkCopyHandler, TdsParserStateObject stateObj, Boolean& dataReady)\r\n   at System.Data.SqlClient.SqlDataReader.TryHasMoreRows(Boolean& moreRows)\r\n   at System.Data.SqlClient.SqlDataReader.TryReadInternal(Boolean setTimeout, Boolean& more)\r\n   at System.Data.SqlClient.SqlDataReader.<>c__DisplayClass190_0.<ReadAsync>b__1(Task t)\r\n   at System.Data.SqlClient.SqlDataReader.InvokeRetryable[T](Func`2 moreFunc, TaskCompletionSource`1 source, IDisposable objectToDispose)\r\n--- End of stack trace from previous location where exception was thrown ---\r\n   at Dapper.SqlMapper.QueryAsync[T](IDbConnection cnn, Type effectiveType, CommandDefinition command) in C:\\projects\\dapper\\Dapper\\SqlMapper.Async.cs:line 437\r\n   at DotNetCore.CAP.SqlServer.SqlServerStorageConnection.GetPublishedMessagesOfNeedRetry() in C:\\projects\\cap\\src\\DotNetCore.CAP.SqlServer\\IStorageConnection.SqlServer.cs:line 49\r\n   at DotNetCore.CAP.Processor.NeedRetryMessageProcessor.ProcessPublishedAsync(IStorageConnection connection, ProcessingContext context) in C:\\projects\\cap\\src\\DotNetCore.CAP\\Processor\\IProcessor.NeedRetry.cs:line 45\r\n   at DotNetCore.CAP.Processor.NeedRetryMessageProcessor.ProcessAsync(ProcessingContext context) in C:\\projects\\cap\\src\\DotNetCore.CAP\\Processor\\IProcessor.NeedRetry.cs:line 40\r\n   at DotNetCore.CAP.Processor.InfiniteRetryProcessor.ProcessAsync(ProcessingContext context) in C:\\projects\\cap\\src\\DotNetCore.CAP\\Processor\\IProcessor.InfiniteRetry.cs:line 29\r\nClientConnectionId:7d2faa60-9da9-4008-ae58-d39d7345c59a\r\nError Number:650,State:1,Class:16",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/352/comments",
    "author": "CacoCode-zz",
    "comments": [
      {
        "user": "CacoCode-zz",
        "created_at": "2019-06-20T03:31:50Z",
        "body": "Action<CapOptions> capOptions = option =>\r\n            {\r\n                option.UseEntityFramework<AdminDbContext>();\r\n                //option.UseSqlServer(_appConfiguration.GetConnectionString(\"Default\"));\r\n                option.UseRabbitMQ(\"localhost\");\r\n                option.UseDashboard();\r\n                if (Convert.ToBoolean(_appConfiguration[\"Cap:UseConsul\"]))\r\n                {\r\n                    option.UseDiscovery(discovery =>\r\n                    {\r\n                        discovery.DiscoveryServerHostName = _appConfiguration[\"Cap:DiscoveryServerHostName\"];\r\n                        discovery.DiscoveryServerPort = Convert.ToInt32(_appConfiguration[\"Cap:DiscoveryServerPort\"]);\r\n                        discovery.CurrentNodeHostName = _appConfiguration[\"Cap:CurrentNodeHostName\"];\r\n                        discovery.CurrentNodePort = Convert.ToInt32(_appConfiguration[\"Cap:CurrentNodePort\"]);\r\n                        discovery.NodeId = Convert.ToInt32(_appConfiguration[\"Cap:NodeId\"]);\r\n                        discovery.NodeName = _appConfiguration[\"Cap:NodeName\"];\r\n                        discovery.MatchPath = _appConfiguration[\"Cap:MatchPath\"];\r\n                    });\r\n                }\r\n\r\n            };"
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2019-06-20T05:38:18Z",
        "body": "To resolve this problem, configure to use the READ COMMITTED or REPEATABLE READ isolation level in Microsoft SQL Server instead of the SERIALIZABLE isolation level."
      },
      {
        "user": "CacoCode-zz",
        "created_at": "2020-03-10T02:38:27Z",
        "body": "> To resolve this problem, configure to use the READ COMMITTED or REPEATABLE READ isolation level in Microsoft SQL Server instead of the SERIALIZABLE isolation level.\r\n \r\nsql server has set ‘set transaction isolation level read committed;’, but this problem still occurs"
      },
      {
        "user": "tohkinzhu",
        "created_at": "2020-05-19T02:12:04Z",
        "body": "Have you solved this issue?\r\nWe have the same one, we are using Aliyun SQL SERVER2016 WEB\r\n@CacoCode "
      }
    ]
  },
  {
    "number": 262,
    "title": "Is there an api to compress content data",
    "created_at": "2018-12-29T07:03:55Z",
    "closed_at": "2018-12-29T11:17:59Z",
    "labels": [
      "help wanted"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/262",
    "body": "Please answer these questions before submitting your issue.\r\n\r\n- Why do you submit this issue?\r\n- [ ] Question or discussion\r\n- [ ] Bug\r\n- [ x] Requirement\r\n- [ ] Feature or performance improvement\r\n\r\n___\r\n### Requirement or improvement\r\n- whether you can consider adding compressed data API in the transmission of big data, ex: gzip\r\n能否加入数据压缩的API，或自定义Provider的入口，如Gzip",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/262/comments",
    "author": "Shinetaku",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2018-12-29T07:45:38Z",
        "body": "Sorry, I can't catch your point."
      },
      {
        "user": "Shinetaku",
        "created_at": "2018-12-29T08:04:46Z",
        "body": "传输过程中的数据较大，能否启用压缩进行数据传输。比如使用gzip协议。"
      },
      {
        "user": "yang-xiaodong",
        "created_at": "2018-12-29T08:11:18Z",
        "body": "Sure, you can customize `IContentSerializer` interface at `DotNetCore.CAP.Abstractions` namespace.\r\n\r\nThen, configure like this:\r\n```\r\nservices.AddCap(x => { }).AddContentSerializer<MyContentSerializer>();\r\n```"
      },
      {
        "user": "Shinetaku",
        "created_at": "2019-01-01T09:23:57Z",
        "body": "ok.thanks"
      }
    ]
  },
  {
    "number": 252,
    "title": "Warning logs appear daily during the run",
    "created_at": "2018-12-14T06:50:15Z",
    "closed_at": "2018-12-14T12:51:41Z",
    "labels": [
      "help wanted"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/252",
    "body": "`warn: DotNetCore.CAP.Processor.InfiniteRetryProcessor[1]\r\nProcessor 'DotNetCore.CAP.Processor.NeedRetryMessageProcessor' failed. Retrying...\r\nSystem.InvalidOperationException: Invalid operation. The connection is closed.\r\nat System.Data.SqlClient.SqlCommand.<>c.<ExecuteDbDataReaderAsync>b__122_0(Task`1 result)\r\nat System.Threading.Tasks.ContinuationResultTaskFromResultTask`2.InnerInvoke()\r\nat System.Threading.ExecutionContext.RunInternal(ExecutionContext executionContext, ContextCallback callback, Object state)\r\n--- End of stack trace from previous location where exception was thrown ---\r\nat System.Threading.Tasks.Task.ExecuteWithThreadLocal(Task& currentTaskSlot)\r\n--- End of stack trace from previous location where exception was thrown ---\r\nat Dapper.SqlMapper.QueryAsync[T](IDbConnection cnn, Type effectiveType, CommandDefinition command) in C:\\projects\\dapper\\Dapper\\SqlMapper.Async.cs:line 419\r\nat DotNetCore.CAP.SqlServer.SqlServerStorageConnection.GetPublishedMessagesOfNeedRetry()\r\nat DotNetCore.CAP.Processor.NeedRetryMessageProcessor.ProcessPublishedAsync(IStorageConnection connection, ProcessingContext context)\r\nat DotNetCore.CAP.Processor.NeedRetryMessageProcessor.ProcessAsync(ProcessingContext context)\r\nat DotNetCore.CAP.Processor.InfiniteRetryProcessor.ProcessAsync(ProcessingContext context)\r\nwarn: DotNetCore.CAP.Processor.InfiniteRetryProcessor[1]\r\nProcessor 'DotNetCore.CAP.Processor.NeedRetryMessageProcessor' failed. Retrying...\r\nSystem.Data.SqlClient.SqlException (0x80131904): Timeout expired. The timeout period elapsed prior to completion of the operation or the server is not responding. ---> System.ComponentModel.Win32Exception (258): Unknown error 258\r\nat System.Data.SqlClient.SqlCommand.<>c.<ExecuteDbDataReaderAsync>b__122_0(Task`1 result)\r\nat System.Threading.Tasks.ContinuationResultTaskFromResultTask`2.InnerInvoke()\r\nat System.Threading.ExecutionContext.RunInternal(ExecutionContext executionContext, ContextCallback callback, Object state)\r\n--- End of stack trace from previous location where exception was thrown ---\r\nat System.Threading.Tasks.Task.ExecuteWithThreadLocal(Task& currentTaskSlot)\r\n--- End of stack trace from previous location where exception was thrown ---\r\nat Dapper.SqlMapper.QueryAsync[T](IDbConnection cnn, Type effectiveType, CommandDefinition command) in C:\\projects\\dapper\\Dapper\\SqlMapper.Async.cs:line 419\r\nat DotNetCore.CAP.SqlServer.SqlServerStorageConnection.GetPublishedMessagesOfNeedRetry()\r\nat DotNetCore.CAP.Processor.NeedRetryMessageProcessor.ProcessPublishedAsync(IStorageConnection connection, ProcessingContext context)\r\nat DotNetCore.CAP.Processor.NeedRetryMessageProcessor.ProcessAsync(ProcessingContext context)\r\nat DotNetCore.CAP.Processor.InfiniteRetryProcessor.ProcessAsync(ProcessingContext context)\r\nClientConnectionId:e7116280-df02-4fff-b910-7a389c255083\r\nError Number:-2,State:0,Class:11`\r\n\r\n每天都会出现一次，之前我也提问过因为sql2008原因，这次我改用了sql2016也同样出现这个问题",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/252/comments",
    "author": "bao2314483",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2018-12-14T06:55:10Z",
        "body": "`The connection is closed.  Timeout expired. The timeout period elapsed prior to completion of the operation or the server is not responding `\r\n\r\n似乎是网络问题造成的数据库连接不稳定，这个需要你自己排查下。\r\n\r\n我们使用的 MySql，生产环境跑了很长的时间了，没有过遇到类似的问题。\r\n\r\n由于CAP具有重试机制，所以这个异常应该没有造成什么影响？"
      }
    ]
  },
  {
    "number": 244,
    "title": "About authorization for the public IP access policies ",
    "created_at": "2018-12-02T14:56:42Z",
    "closed_at": "2018-12-03T05:40:49Z",
    "labels": [
      "help wanted"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/244",
    "body": "目前发现部署在公网ip上，没办法开启dashboard跟踪消息。看了一下dashboard的Authorization，应该是可以开启用户密码验证的。只是这块没有实现，是否可以考虑下参考下hangfire的认证。结构也比较像。",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/244/comments",
    "author": "Shinetaku",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2018-12-03T04:01:41Z",
        "body": "For security CAP only allows local IP access by default, you can allow other access policies by customizing authorization filters.\r\n\r\n```cs\r\nservices.AddCap(\r\n    x => x.UseDashboard(d => d.Authorization =\r\n        new List<DotNetCore.CAP.Dashboard.IDashboardAuthorizationFilter>\r\n        {\r\n            new YourAuthorizationFilter();   // customizing your authorization filters from `IDashboardAuthorizationFilter`\r\n        }\r\n    )\r\n);\r\n```"
      },
      {
        "user": "Shinetaku",
        "created_at": "2018-12-03T05:40:49Z",
        "body": "明白。谢谢了。"
      },
      {
        "user": "Shinetaku",
        "created_at": "2018-12-03T06:08:13Z",
        "body": "实现了，顺手贴一下代码，以便有需要的参考下。正好项目中有hangfire的引用，顺便就稍微利用了hangfire的验证方法。\r\n\r\n\r\n```\r\nservices.AddCap(x =>\r\n{\r\n\t//Retry 3\r\n\tx.FailedRetryCount = 3;\r\n\t//Retry Interval 600s\r\n\tx.FailedRetryInterval = 600;\r\n\t//Dashboard\r\n\tx.UseDashboard(y => y.Authorization = new List<IDashboardAuthorizationFilter>()\r\n\t{\r\n\t\tnew CapAuthorizationFilter()\r\n\t\t{\r\n\t\t\tLoginCaseSensitive = true,\r\n\t\t\tUsers = new []\r\n\t\t\t{\r\n\t\t\t\tnew BasicAuthAuthorizationUser\r\n\t\t\t\t{\r\n\t\t\t\t\tLogin = Configuration[\"DefaultAuthorizationUser:UserName\"],\r\n\t\t\t\t\tPasswordClear =  Configuration[\"DefaultAuthorizationUser:Password\"],\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t});\r\n\r\ninternal class CapAuthorizationFilter : IDashboardAuthorizationFilter\r\n{\r\n\tpublic bool LoginCaseSensitive { get; set; }\r\n\tpublic IEnumerable<BasicAuthAuthorizationUser> Users { get; set; }\r\n\r\n\tpublic bool Authorize(DashboardContext context)\r\n\t{\r\n\t\tif (context is CapDashboardContext capContext)\r\n\t\t{\r\n\t\t\tstring header = capContext.HttpContext.Request.Headers[\"Authorization\"];\r\n\t\t\tif (!string.IsNullOrWhiteSpace(header))\r\n\t\t\t{\r\n\t\t\t\tAuthenticationHeaderValue authenticationHeaderValue = AuthenticationHeaderValue.Parse(header);\r\n\r\n\t\t\t\tif (\"Basic\".Equals(authenticationHeaderValue.Scheme, StringComparison.OrdinalIgnoreCase))\r\n\t\t\t\t{\r\n\t\t\t\t\tstring[] strArray = Encoding.UTF8.GetString(Convert.FromBase64String(authenticationHeaderValue.Parameter)).Split(':');\r\n\t\t\t\t\tif (strArray.Length > 1)\r\n\t\t\t\t\t{\r\n\t\t\t\t\t\tstring login = strArray[0];\r\n\t\t\t\t\t\tstring password = strArray[1];\r\n\t\t\t\t\t\tif (!string.IsNullOrWhiteSpace(login) && !string.IsNullOrWhiteSpace(password) && Users.Any(user => user.Validate(login, password, LoginCaseSensitive)))\r\n\t\t\t\t\t\t\treturn true;\r\n\t\t\t\t\t}\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\treturn Challenge(capContext.HttpContext);\r\n\t\t}\r\n\r\n\t\treturn false;\r\n\t}\r\n\r\n\tprivate bool Challenge(HttpContext context)\r\n\t{\r\n\t\tcontext.Response.StatusCode = 401;\r\n\t\tcontext.Response.Headers.Append(\"WWW-Authenticate\", \"Basic realm=\\\"CAP Dashboard\\\"\");\r\n\t\treturn false;\r\n\t}\r\n}\r\n```"
      },
      {
        "user": "Shinetaku",
        "created_at": "2018-12-03T06:08:21Z",
        "body": "```\r\npublic class BasicAuthAuthorizationUser\r\n  {\r\n    public string Login { get; set; }\r\n\r\n    public byte[] Password { get; set; }\r\n\r\n    public string PasswordClear\r\n    {\r\n      set\r\n      {\r\n        using (SHA1 shA1 = SHA1.Create())\r\n          this.Password = shA1.ComputeHash(Encoding.UTF8.GetBytes(value));\r\n      }\r\n    }\r\n\r\n    public bool Validate(string login, string password, bool loginCaseSensitive)\r\n    {\r\n      if (string.IsNullOrWhiteSpace(login))\r\n        throw new ArgumentNullException(nameof (login));\r\n      if (string.IsNullOrWhiteSpace(password))\r\n        throw new ArgumentNullException(nameof (password));\r\n      if (!login.Equals(this.Login, loginCaseSensitive ? StringComparison.CurrentCulture : StringComparison.OrdinalIgnoreCase))\r\n        return false;\r\n      using (SHA1 shA1 = SHA1.Create())\r\n        return StructuralComparisons.StructuralEqualityComparer.Equals((object) shA1.ComputeHash(Encoding.UTF8.GetBytes(password)), (object) this.Password);\r\n    }\r\n  }\r\n```"
      }
    ]
  },
  {
    "number": 120,
    "title": "dashboard主页报错",
    "created_at": "2018-04-23T08:19:02Z",
    "closed_at": "2018-04-26T11:47:26Z",
    "labels": [
      "help wanted"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/120",
    "body": "环境：\r\nasp.net core 2.0\r\nrabbitmq\r\nmssqlserver\r\n\r\n\r\n发布订阅功能正常，进入dashboard提示：\r\nAn unhandled exception occurred while processing the request.\r\n\r\nSqlException: 'FORMAT' 不是可以识别的 内置函数名称。\r\nSystem.Data.SqlClient.SqlConnection.OnError(SqlException exception, bool breakConnection, Action<Action> wrapCloseInAction)\r\n\r\nSystem.Data.SqlClient.SqlConnection.OnError(SqlException exception, bool breakConnection, Action<Action> wrapCloseInAction)\r\nSystem.Data.SqlClient.SqlInternalConnection.OnError(SqlException exception, bool breakConnection, Action<Action> wrapCloseInAction)\r\nSystem.Data.SqlClient.TdsParser.ThrowExceptionAndWarning(TdsParserStateObject stateObj, bool callerHasConnectionLock, bool asyncClose)\r\nSystem.Data.SqlClient.TdsParser.TryRun(RunBehavior runBehavior, SqlCommand cmdHandler, SqlDataReader dataStream, BulkCopySimpleResultSet bulkCopyHandler, TdsParserStateObject stateObj, out bool dataReady)\r\nSystem.Data.SqlClient.SqlDataReader.TryConsumeMetaData()\r\nSystem.Data.SqlClient.SqlDataReader.get_MetaData()\r\nSystem.Data.SqlClient.SqlCommand.FinishExecuteReader(SqlDataReader ds, RunBehavior runBehavior, string resetOptionsString)\r\nSystem.Data.SqlClient.SqlCommand.RunExecuteReaderTds(CommandBehavior cmdBehavior, RunBehavior runBehavior, bool returnStream, bool async, int timeout, out Task task, bool asyncWrite, SqlDataReader ds)\r\nSystem.Data.SqlClient.SqlCommand.RunExecuteReader(CommandBehavior cmdBehavior, RunBehavior runBehavior, bool returnStream, TaskCompletionSource<object> completion, int timeout, out Task task, bool asyncWrite, string method)\r\nSystem.Data.SqlClient.SqlCommand.ExecuteReader(CommandBehavior behavior)\r\nSystem.Data.SqlClient.SqlCommand.ExecuteDbDataReader(CommandBehavior behavior)\r\nSystem.Data.Common.DbCommand.System.Data.IDbCommand.ExecuteReader(CommandBehavior behavior)\r\nDapper.SqlMapper.ExecuteReaderWithFlagsFallback(IDbCommand cmd, bool wasClosed, CommandBehavior behavior) in SqlMapper.cs\r\nDapper.SqlMapper+<QueryImpl>d__136.MoveNext() in SqlMapper.cs\r\nSystem.Collections.Generic.List.AddEnumerable(IEnumerable<T> enumerable)\r\nSystem.Linq.Enumerable.ToList<TSource>(IEnumerable<TSource> source)\r\nDapper.SqlMapper.Query<T>(IDbConnection cnn, string sql, object param, IDbTransaction transaction, bool buffered, Nullable<int> commandTimeout, Nullable<CommandType> commandType) in SqlMapper.cs\r\nDotNetCore.CAP.SqlServer.SqlServerMonitoringApi.GetTimelineStats(IDbConnection connection, string tableName, string statusName, IDictionary<string, DateTime> keyMaps)\r\nDotNetCore.CAP.SqlServer.SqlServerMonitoringApi.GetHourlyTimelineStats(IDbConnection connection, string tableName, string statusName)\r\nDotNetCore.CAP.SqlServer.SqlServerStorage.UseConnection<T>(Func<IDbConnection, T> func)\r\nDotNetCore.CAP.Dashboard.Pages.HomePage.Execute()\r\nDotNetCore.CAP.Dashboard.RazorPage.TransformText(string body)\r\nDotNetCore.CAP.Dashboard.RazorPageDispatcher.Dispatch(DashboardContext context)\r\nDotNetCore.CAP.DashboardMiddleware.Invoke(HttpContext context)\r\nMicrosoft.AspNetCore.Builder.RouterMiddleware+<Invoke>d__4.MoveNext()\r\nSystem.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()\r\nSystem.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\r\nMicrosoft.AspNetCore.Diagnostics.DeveloperExceptionPageMiddleware+<Invoke>d__7.MoveNext()",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/120/comments",
    "author": "daimeiquan",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2018-04-23T10:12:06Z",
        "body": "需要SQL Server 2012+ 版本"
      }
    ]
  },
  {
    "number": 49,
    "title": "How to setting of only publish or receive message ? ",
    "created_at": "2017-09-20T02:38:05Z",
    "closed_at": "2017-09-26T15:20:39Z",
    "labels": [
      "help wanted",
      "wontfix"
    ],
    "url": "https://github.com/dotnetcore/CAP/issues/49",
    "body": "比如两个mvc项目，共同引用service项目，但第一个项目我只想要发送消息，第二个才开启SubscribeService。\r\n是不是第一个项目不UseCap就可以了？",
    "comments_url": "https://api.github.com/repos/dotnetcore/CAP/issues/49/comments",
    "author": "kulend",
    "comments": [
      {
        "user": "yang-xiaodong",
        "created_at": "2017-09-20T07:42:53Z",
        "body": "两个 MVC 项目引用同一个Service类库，在发布后，还是相当于Service两个副本同时在两个项目中啊。\r\n\r\n不 UseCap 消息就发不出去了。"
      }
    ]
  }
]