[
  {
    "number": 5925,
    "title": "Can ML.NET be used in .Net Framework 4.8?",
    "created_at": "2021-09-06T14:18:46Z",
    "closed_at": "2022-10-07T17:01:42Z",
    "labels": [
      "question",
      "onnx"
    ],
    "url": "https://github.com/dotnet/machinelearning/issues/5925",
    "body": "Can ML.NET be used in .Net Framework 4.8?\r\n\r\nI add all the required NuGet packages and then a link to google.Protobuf 3.11.4.0 is added.\r\nBut at runtime an error occurs: FileLoadException Google.Protobuf, Version = 3.10.1.0\r\nI can't figure out where version 3.10 came from.\r\n\r\nBy the way, if generate an example of a console application in ModelBuilder, then there will be a link Google.Protobuf, Version = 3.10.1.0.\r\n\r\n\r\nSystem.Reflection.TargetInvocationException: Адресат вызова создал исключение. ---> System.Reflection.TargetInvocationException: Адресат вызова создал исключение. ---> System.IO.**FileLoadException**: Не удалось загрузить файл или сборку \"**Google.Protobuf, Version=3.10.1.0**, Culture=neutral, PublicKeyToken=a7d26565bac4d604\" либо одну из их зависимостей. Найденное определение манифеста сборки не соответствует ссылке на сборку. (Исключение из HRESULT: 0x80131040)\r\n   в Microsoft.ML.Transforms.Onnx.OnnxModel..ctor(String modelFile, Nullable`1 gpuDeviceId, Boolean fallbackToCpu, Boolean ownModelFile, IDictionary`2 shapeDictionary, Int32 recursionLimit)\r\n   в Microsoft.ML.Transforms.Onnx.OnnxModel.CreateFromBytes(Byte[] modelBytes, IHostEnvironment env, Nullable`1 gpuDeviceId, Boolean fallbackToCpu, IDictionary`2 shapeDictionary, Int32 recursionLimit)\r\n   в Microsoft.ML.Transforms.Onnx.OnnxTransformer..ctor(IHostEnvironment env, Options options, Byte[] modelBytes)\r\n   в Microsoft.ML.Transforms.Onnx.OnnxTransformer.Create(IHostEnvironment env, ModelLoadContext ctx)\r\n   --- Конец трассировки внутреннего стека исключений ---\r\n   в System.RuntimeMethodHandle.InvokeMethod(Object target, Object[] arguments, Signature sig, Boolean constructor)\r\n   в System.Reflection.RuntimeMethodInfo.UnsafeInvokeInternal(Object obj, Object[] parameters, Object[] arguments)\r\n   в System.Reflection.RuntimeMethodInfo.Invoke(Object obj, BindingFlags invokeAttr, Binder binder, Object[] parameters, CultureInfo culture)\r\n   в Microsoft.ML.Runtime.ComponentCatalog.LoadableClassInfo.CreateInstanceCore(Object[] ctorArgs)\r\n   в Microsoft.ML.Runtime.ComponentCatalog.TryCreateInstance[TRes](IHostEnvironment env, Type signatureType, TRes& result, String name, String options, Object[] extra)\r\n   в Microsoft.ML.Runtime.ComponentCatalog.TryCreateInstance[TRes,TSig](IHostEnvironment env, TRes& result, String name, String options, Object[] extra)\r\n   в Microsoft.ML.ModelLoadContext.TryLoadModelCore[TRes,TSig](IHostEnvironment env, TRes& result, Object[] extra)\r\n   в Microsoft.ML.ModelLoadContext.TryLoadModel[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, Entry ent, String dir, Object[] extra)\r\n   в Microsoft.ML.ModelLoadContext.LoadModel[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, Entry ent, String dir, Object[] extra)\r\n   в Microsoft.ML.ModelLoadContext.LoadModelOrNull[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, String dir, Object[] extra)\r\n   в Microsoft.ML.ModelLoadContext.LoadModel[TRes,TSig](IHostEnvironment env, TRes& result, String name, Object[] extra)\r\n   в Microsoft.ML.Data.TransformerChain`1..ctor(IHostEnvironment env, ModelLoadContext ctx)\r\n   в Microsoft.ML.Data.TransformerChain.Create(IHostEnvironment env, ModelLoadContext ctx)\r\n   --- Конец трассировки внутреннего стека исключений ---\r\n   в System.RuntimeMethodHandle.InvokeMethod(Object target, Object[] arguments, Signature sig, Boolean constructor)\r\n   в System.Reflection.RuntimeMethodInfo.UnsafeInvokeInternal(Object obj, Object[] parameters, Object[] arguments)\r\n   в System.Reflection.RuntimeMethodInfo.Invoke(Object obj, BindingFlags invokeAttr, Binder binder, Object[] parameters, CultureInfo culture)\r\n   в Microsoft.ML.Runtime.ComponentCatalog.LoadableClassInfo.CreateInstanceCore(Object[] ctorArgs)\r\n   в Microsoft.ML.Runtime.ComponentCatalog.TryCreateInstance[TRes](IHostEnvironment env, Type signatureType, TRes& result, String name, String options, Object[] extra)\r\n   в Microsoft.ML.Runtime.ComponentCatalog.TryCreateInstance[TRes,TSig](IHostEnvironment env, TRes& result, String name, String options, Object[] extra)\r\n   в Microsoft.ML.ModelLoadContext.TryLoadModelCore[TRes,TSig](IHostEnvironment env, TRes& result, Object[] extra)\r\n   в Microsoft.ML.ModelLoadContext.TryLoadModel[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, Entry ent, String dir, Object[] extra)\r\n   в Microsoft.ML.ModelLoadContext.LoadModel[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, Entry ent, String dir, Object[] extra)\r\n   в Microsoft.ML.ModelLoadContext.LoadModelOrNull[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, String dir, Object[] extra)\r\n   в Microsoft.ML.ModelLoadContext.LoadModel[TRes,TSig](IHostEnvironment env, TRes& result, RepositoryReader rep, String dir, Object[] extra)\r\n   в Microsoft.ML.ModelOperationsCatalog.Load(Stream stream, DataViewSchema& inputSchema)\r\n   в Microsoft.ML.ModelOperationsCatalog.Load(String filePath, DataViewSchema& inputSchema)",
    "comments_url": "https://api.github.com/repos/dotnet/machinelearning/issues/5925/comments",
    "author": "dmamel",
    "comments": [
      {
        "user": "michaelgsharp",
        "created_at": "2021-09-23T22:14:24Z",
        "body": "It should work just fine. Can you send a sample repro project so we can take a look?"
      },
      {
        "user": "luisquintanilla",
        "created_at": "2022-10-07T17:01:42Z",
        "body": "Closing this issue due to lack of activity and an answer was provided to the original question."
      }
    ]
  },
  {
    "number": 5843,
    "title": "image classification detect false result ",
    "created_at": "2021-06-15T13:10:52Z",
    "closed_at": "2021-06-17T21:59:36Z",
    "labels": [
      "question",
      "P3",
      "image"
    ],
    "url": "https://github.com/dotnet/machinelearning/issues/5843",
    "body": "i use my image classification model  but \r\nif image was not in classes , system detect it wrongs . \r\nwhy ???",
    "comments_url": "https://api.github.com/repos/dotnet/machinelearning/issues/5843/comments",
    "author": "masgh021",
    "comments": [
      {
        "user": "michaelgsharp",
        "created_at": "2021-06-17T21:59:36Z",
        "body": "Your model can only classify images based on what it was trained on. If you didn't train a model on a type of image, than it won't be able to predict on it either.\r\n\r\nIf you want to classify your image, make sure you train on other images of that same class."
      }
    ]
  },
  {
    "number": 5841,
    "title": "Exponential Curve Fitting",
    "created_at": "2021-06-15T04:39:10Z",
    "closed_at": "2023-05-03T06:18:11Z",
    "labels": [
      "question",
      "P3",
      "regression"
    ],
    "url": "https://github.com/dotnet/machinelearning/issues/5841",
    "body": "Have a set of XY data and would like to fit them on an exponential curve as below\r\n\r\na + b * Math.Exp(-x / c)\r\n\r\nWhich regression trainer class can be used to get the value of a,b,c ?",
    "comments_url": "https://api.github.com/repos/dotnet/machinelearning/issues/5841/comments",
    "author": "absinghal",
    "comments": [
      {
        "user": "absinghal",
        "created_at": "2023-05-03T06:18:11Z",
        "body": "Solved by #ChatGPT"
      },
      {
        "user": "xiaomao0o0o0o",
        "created_at": "2023-05-09T07:17:34Z",
        "body": "Is it complex to solve the problem ?I meet the problem recently and hardly find answer with google . I just know GSL can solve it but the source code is too long and difficult to learn."
      }
    ]
  },
  {
    "number": 5793,
    "title": "IDataView for experiments with AutoML",
    "created_at": "2021-05-12T12:33:04Z",
    "closed_at": "2021-06-09T04:36:44Z",
    "labels": [
      "question",
      "AutoML.NET",
      "P3"
    ],
    "url": "https://github.com/dotnet/machinelearning/issues/5793",
    "body": "### System information\r\n\r\n- **OS version/distro**: Win10\r\n- **.NET Version (eg., dotnet --info)**:  .NET Core 3.1\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nI am adapting the AutoML sample to fit my purpose. Everything works fine if I place my data in a CSV file, but in case, the data is already in memory as a List<DataPoint> because I am calculating Features. So instead of saving that to a CSV file and loading it back in again, I replaced this line:\r\n**TrainDataView = textLoader.Load(TrainDataPath);**\r\nwith:\r\n**TrainDataView = mlContext.Data.LoadFromEnumerable<DataPoint>(Data);**\r\n\r\nBoth are IDataViews, so I am guessing it should work. For the time being, I kept the ColumnInference working from the CSV file. But the regression fails.\r\n\r\nIs there a way to avoid saving/loading data?\r\n\r\n- **What happened?**\r\n=============== Running AutoML experiment ===============\r\n#########################################################\r\nRunning AutoML regression experiment...\r\nPress any key to stop the experiment run...\r\n|     Trainer                             RSquared Absolute-loss Squared-loss RMS-loss  Duration                 |\r\n|1    SdcaRegression                           NaN          0.00         0.00     0.00      15.8                 |\r\n1 models were returned after 15.92 seconds\r\n\r\n- **What did you expect?**\r\n=============== Running AutoML experiment ===============\r\n#########################################################\r\nRunning AutoML regression experiment...\r\nPress any key to stop the experiment run...\r\n|     Trainer                             RSquared Absolute-loss Squared-loss RMS-loss  Duration                 |\r\n|1    SdcaRegression                      -554.7830        460.07    368733.51   588.39       3.0                |\r\n|2    LightGbmRegression                  -151.0080        436.38    625374.63   702.75       1.3                |\r\n|3    FastTreeRegression                  -54.9780        267.71    287578.01   484.74       2.7                 |\r\n|4    FastTreeTweedieRegression            -1.6479        215.75    278471.13   450.67       1.2                 |\r\n|5    FastForestRegression                -32.4529        343.83    540098.80   627.91       1.8                 |\r\n|6    LbfgsPoissonRegression              -20.8898       1102.84  50035704.04  3150.17       0.9\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n",
    "comments_url": "https://api.github.com/repos/dotnet/machinelearning/issues/5793/comments",
    "author": "ndgroth",
    "comments": [
      {
        "user": "michaelgsharp",
        "created_at": "2021-06-03T22:15:19Z",
        "body": "Have you compared the schema of the 2 data frames?"
      },
      {
        "user": "ndgroth",
        "created_at": "2021-06-09T04:36:44Z",
        "body": "> \r\n> \r\n> Have you compared the schema of the 2 data frames?\r\n\r\nThank you @michaelgsharp, I had an issue with the schema. All good now."
      }
    ]
  },
  {
    "number": 5792,
    "title": "System.AccessViolationException' occurred in TensorFlow.NET.dll when calling predictionEngine.Predict()",
    "created_at": "2021-05-12T04:25:00Z",
    "closed_at": "2021-07-21T00:58:26Z",
    "labels": [
      "question",
      "P3",
      "image"
    ],
    "url": "https://github.com/dotnet/machinelearning/issues/5792",
    "body": "\r\n### System information\r\n\r\n- **OS version/distro**:\r\n- **.NET Version (eg., dotnet --info)**: \r\n\r\n.NET SDK (reflecting any global.json):\r\n Version:   5.0.103\r\n Commit:    72dec52dbd\r\n\r\nRuntime Environment:\r\n OS Name:     Windows\r\n OS Version:  10.0.19042\r\n OS Platform: Windows\r\n RID:         win10-x64\r\n Base Path:   C:\\Program Files\\dotnet\\sdk\\5.0.103\\\r\n\r\nHost (useful for support):\r\n  Version: 5.0.3\r\n  Commit:  c636bbdc8a\r\n\r\n.NET SDKs installed:\r\n  5.0.101 [C:\\Program Files\\dotnet\\sdk]\r\n  5.0.103 [C:\\Program Files\\dotnet\\sdk]\r\n\r\n.NET runtimes installed:\r\n  Microsoft.AspNetCore.All 2.1.25 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.All]\r\n  Microsoft.AspNetCore.App 2.1.25 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.AspNetCore.App 3.1.12 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.AspNetCore.App 5.0.1 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.AspNetCore.App 5.0.3 [C:\\Program Files\\dotnet\\shared\\Microsoft.AspNetCore.App]\r\n  Microsoft.NETCore.App 2.1.25 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 3.1.12 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 5.0.1 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.NETCore.App 5.0.3 [C:\\Program Files\\dotnet\\shared\\Microsoft.NETCore.App]\r\n  Microsoft.WindowsDesktop.App 3.1.12 [C:\\Program Files\\dotnet\\shared\\Microsoft.WindowsDesktop.App]\r\n  Microsoft.WindowsDesktop.App 5.0.1 [C:\\Program Files\\dotnet\\shared\\Microsoft.WindowsDesktop.App]\r\n  Microsoft.WindowsDesktop.App 5.0.3 [C:\\Program Files\\dotnet\\shared\\Microsoft.WindowsDesktop.App]\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nTrying to create a prediction engine and then calling Predict() after loading a tensorflow model. The error is thrown when trying to call Predict().\r\n\r\nLatest nugets are referenced:\r\nMicrosoft.ML - 1.5.5\r\nMicrosoft.ML.TensorFlow - 1.5.5\r\nTensorFlow.NET - 0.40.1\r\n\r\n- **What happened?**\r\n\r\nEncounter this error:\r\n\r\nAn unhandled exception of type 'System.AccessViolationException' occurred in TensorFlow.NET.dll\r\nAttempted to read or write protected memory. This is often an indication that other memory is corrupt.\r\n\r\n- **What did you expect?**\r\nNo error. Ability to call Predict()\r\n\r\n### Source code / logs\r\n\r\nx64 is selected for building.\r\n\r\n`\r\nTensorFlowModel tensorFlowModel = mlContext.Model.LoadTensorFlowModel(modelLocation);\r\n\r\nIEstimator<ITransformer> pipeline = tensorFlowModel.ScoreTensorFlowModel(\"sequential_1/dense_1/BiasAdd\", \"inputs\", false)\r\n    .Append(mlContext.Transforms.CopyColumns(\"Prediction\", \"sequential_1/dense_1/BiasAdd\"));\r\n\r\nvar engine = mlContext.Model.CreatePredictionEngine<TensorData, PricePrediction>(model);\r\nvar prediction = engine.Predict(data); // error thrown on this line\r\n`",
    "comments_url": "https://api.github.com/repos/dotnet/machinelearning/issues/5792/comments",
    "author": "hexate",
    "comments": [
      {
        "user": "michaelgsharp",
        "created_at": "2021-06-03T22:13:29Z",
        "body": "What version of tensorflow was used to create the model you are loading?"
      },
      {
        "user": "afust003",
        "created_at": "2021-07-20T15:09:18Z",
        "body": "Running into a similar issue, any updates on this?"
      },
      {
        "user": "afust003",
        "created_at": "2021-07-20T17:20:48Z",
        "body": "> Running into a similar issue, any updates on this?\r\n\r\nSolution suggestion: @hexate We had a similar issue loading a custom TensorFlow \"frozen_model\" .pb file.\r\nThe problem was that one of the \"input\" elements was an float[] decorated with Vector(1) but the array was being initialized to an array of 0 elements via new float[] (for testing purposes) and we were receiving the above-mentioned AccessViolationException. I believe this to be the root cause of our problem. Hope this helps.\r\n"
      },
      {
        "user": "michaelgsharp",
        "created_at": "2021-07-20T19:47:54Z",
        "body": "So the issue was resolved when you fixed the issue with your input then?"
      },
      {
        "user": "afust003",
        "created_at": "2021-07-20T22:07:49Z",
        "body": "> So the issue was resolved when you fixed the issue with your input then?\r\n\r\nYes @michaelgsharp. We are using TensorFlow 2.x. I wasn't the original issue creator but it's been opened for over 1 month. We ran into this issue yesterday and were able to resolve it within ~4 hours of trial/error."
      },
      {
        "user": "michaelgsharp",
        "created_at": "2021-07-21T00:58:26Z",
        "body": "Well I'm going to close this as resolved then as the root cause of the problem has been figured out."
      }
    ]
  },
  {
    "number": 5369,
    "title": "Enable access to preloaded data in primitive data types",
    "created_at": "2020-08-28T17:20:19Z",
    "closed_at": "2020-08-28T23:22:53Z",
    "labels": [
      "question",
      "API",
      "documentation"
    ],
    "url": "https://github.com/dotnet/machinelearning/issues/5369",
    "body": "I have been using the Accord.Net framework for some time and would like to run it side-by-side with ML.NET in my application. In my application the data exists in memory as a 2D array ```double[,]```. Headings are kept as a separate 1D string array. It would be easy enough to convert to a jagged array or to a .NET DataTable (which I do in various instances for Accord). \r\n\r\nHowever, there does not appear to be any easy way to load the data to ML.NET this way. I've looked at ```mlContext.Data.LoadFromEnumerable``` but it appears that is looking for objects not raw data. It would be massively inefficient to convert the raw data to this approach.\r\n\r\nI'm a newbie to ML.NET so if I'm missing something, my apologies. \r\n\r\n\r\n",
    "comments_url": "https://api.github.com/repos/dotnet/machinelearning/issues/5369/comments",
    "author": "barrybriggs",
    "comments": [
      {
        "user": "michaelgsharp",
        "created_at": "2020-08-28T21:22:46Z",
        "body": "Currently there is no built in way to do this. Have you tried creating objects for it and seeing if there really is a big performance hit (time/memory/cpu)? If your training is not being done in parallel, you should be able to use the same object memory for all the data (I'll put an example of what I mean) so it shouldn't impact memory basically at all. If you are doing training in parallel, then you will have to create 1 object for each row, but it would still be good to see what the actual performance impact would be.\r\n\r\nIf you really want to use the raw data directly, the only way would be to write a custom `IDataLoader` and `IDataView`. This would be more memory efficient, but would require a lot more developer effort than just making objects to use the built in methods. So unless the performance impact is noticeable, its probably not worth the extra effort.\r\n\r\nSample\r\n```\r\n// Class to hold the raw data.\r\npublic class Data\r\n{\r\n        public double Col1;\r\n        public double Col2;\r\n        public double Col3;\r\n        public double Col4;\r\n        public double Col5;\r\n}\r\n\r\n// Make sure your data is accessible to the method so you don't need to pass it.\r\ndouble[,] rawData;\r\n\r\n// Generator to turn raw data into object\r\nIEnumerable<Data> GetData()\r\n{\r\n    // Create new object outside the loop so its only created once.\r\n    // This works because ML.Net \"streams\" in the data 1 row at a time (unless running in parallel),\r\n    // so we are safe to reuse the object.\r\n    Data data = new Data();\r\n    for (int i = 0; i < 100000; i++)\r\n    {\r\n        data.Col1 = rawData[i, 0];\r\n        data.Col2 = rawData[i, 1];\r\n        data.Col3 = rawData[i, 2];\r\n        data.Col4 = rawData[i, 3];\r\n        data.Col5 = rawData[i, 4];\r\n        yield return data;\r\n    }\r\n}\r\n\r\n// Then in your main function do the normal stuff.\r\nvar mlContext = new MLContext(0);\r\n// An IDataView is lazy evaluated. It will only pull in the rows when it needs them, one at a time.\r\nvar dataview = mlContext.Data.LoadFromEnumerable<Data>(GetData());\r\n```\r\n\r\nDoing it like this should let you use the data as you have it already, with only a very small amount of extrahead.\r\n\r\nWill that work for you?"
      },
      {
        "user": "barrybriggs",
        "created_at": "2020-08-28T23:03:43Z",
        "body": "Yes, this is helpful, thanks. It's a little more complicated because I have to synthesize the class definitions at runtime, but this is doable. "
      },
      {
        "user": "michaelgsharp",
        "created_at": "2020-08-28T23:22:52Z",
        "body": "Awesome, I'm glad it was able to work for you. I will go ahead and close the ticket for now then. If you have any further problems with this please feel free to re-open the ticket as needed."
      }
    ]
  },
  {
    "number": 5270,
    "title": "CreateEnumerable from key column",
    "created_at": "2020-07-01T00:11:10Z",
    "closed_at": "2020-07-01T09:09:15Z",
    "labels": [
      "question",
      "P3"
    ],
    "url": "https://github.com/dotnet/machinelearning/issues/5270",
    "body": "### System information\r\n\r\n- **OS version/distro**: Windows 10\r\n- **.NET Version (eg., dotnet --info)**: 4.7\r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\nTrying to create Enumerable from IDataView which contains Column with Type Key<UInt32, 0-1059>, into a uint type.\r\n- **What happened?**\r\nEncountered error:\r\n\"Can't bind the IDataView column 'ImpressionIdKey' of type 'Key<UInt32, 0-1059>' to field or property 'ImpressionIdKey' of type 'System.UInt32'.\"\r\n- **What did you expect?**\r\nI want to be able to export key value in its uint format as enumerable\r\n\r\n### Source code / logs\r\n\r\n```\r\n        var a = mlContext.Data.CreateEnumerable<ProcessedData>(\r\n            colSelTrainingData, reuseRowObject: false);\r\n\r\n...\r\n\r\n        private class ProcessedData\r\n        {\r\n            public float[] Feature { get; set; }\r\n\r\n            public float BackProClick { get; set; }\r\n\r\n            public uint ImpressionIdKey { get; set; }\r\n        }\r\n```\r\n",
    "comments_url": "https://api.github.com/repos/dotnet/machinelearning/issues/5270/comments",
    "author": "go2ready",
    "comments": [
      {
        "user": "antoniovs1029",
        "created_at": "2020-07-01T07:04:03Z",
        "body": "Hi, @go2ready . It should be possible for you to create an enumerable from a key column. I don't know why you're getting that exception. Can you please provide a full stacktrace, and also a .zip containing code and data to reproduce your error so I can look closer? Thanks.\r\n\r\nFor reference, I've just ran this toy example, and it worked as expected, showing you can create enumerables from key columns:\r\n<details>\r\n<summary> Click to toggle toy example </summary>\r\n<p>\r\n\r\n```C#\r\n\r\nusing System;\r\nusing Microsoft.ML;\r\nusing Microsoft.ML.Data;\r\nusing System.Linq;\r\n\r\nnamespace TextLoaderSample\r\n{\r\n    class Program\r\n    {\r\n        public class ModelInput\r\n        {\r\n            public int Id { get; set; }\r\n\r\n            public string Description { get; set; }\r\n\r\n            public float Num1 { get; set; }\r\n\r\n            public float Num2 { get; set; }\r\n\r\n        }\r\n\r\n        public class ModelOutput\r\n        {\r\n            public uint KeyDescription { get; set; }\r\n        }\r\n\r\n        static void Main(string[] args)\r\n        {\r\n            MLContext mlContext = new MLContext(seed: 1);\r\n\r\n            var inputList = new[]\r\n            {\r\n                new ModelInput(){Id = 0, Description = \"lion\", Num1 = 12.333f, Num2 = 13.44f},\r\n                new ModelInput(){Id = 1, Description = \"house\", Num1 = 12.333f, Num2 = 13.44f},\r\n            };\r\n\r\n            IDataView inputDV = mlContext.Data.LoadFromEnumerable(inputList);\r\n\r\n            var pipeline = mlContext.Transforms.Conversion.Hash(\"KeyDescription\", \"Description\");\r\n            var outputDV = pipeline.Fit(inputDV).Transform(inputDV); // \"KeyDescription\" column is type \"Key<UInt32, 0-2147483647>\"\r\n\r\n            var outputEnum = mlContext.Data.CreateEnumerable<ModelOutput>(outputDV, reuseRowObject: false);\r\n            var outputArray = outputEnum.ToArray();\r\n        }\r\n    }\r\n}\r\n\r\n```\r\n\r\n</p>\r\n\r\n</details>"
      },
      {
        "user": "go2ready",
        "created_at": "2020-07-01T09:09:15Z",
        "body": "Thanks @antoniovs1029 for providing the code snippet, I tired this morning it worked, must be something I have been doing wrong on the pipeline :) Really appreciated"
      }
    ]
  },
  {
    "number": 5208,
    "title": "Use the model designed by myself.",
    "created_at": "2020-06-04T15:37:24Z",
    "closed_at": "2020-06-04T19:05:04Z",
    "labels": [
      "question",
      "P3"
    ],
    "url": "https://github.com/dotnet/machinelearning/issues/5208",
    "body": "Hi\r\n\r\nI am new to ML, so this might seem like a stupid question, may be it is wrong, but when I learn the ML.NET, I found that all of the models or the way training data in ML.NET have been designed, or you should import it from tensorflow or OXXN.  However, is it possible use the model that the structure of the neural network is designed by myself which has the pooling layers , convolutional layers and so on, just like Tensorflow and Pytorch to trainging the model? Also, could I change the  loss function which designed by myself?",
    "comments_url": "https://api.github.com/repos/dotnet/machinelearning/issues/5208/comments",
    "author": "Color-Dark",
    "comments": [
      {
        "user": "Lynx1820",
        "created_at": "2020-06-04T19:05:04Z",
        "body": "Hi @Lucifer-Morning-Star, \r\n\r\nNo. We don't support CNN training within ML.NET at this point. The way to circumvent that is by creating your model/ training in another framework like tensorflow and then consuming the model in ML.NET to use for **inferencing** only. Closing this issue, feel free to reopen if you have additional questions. "
      },
      {
        "user": "Color-Dark",
        "created_at": "2020-06-06T02:41:36Z",
        "body": "Thanks for your answer. So, is there a plan that would be support in the future? @Lynx1820 \r\n\r\n> Hi @Lucifer-Morning-Star,\r\n> \r\n> No. We don't support CNN training within ML.NET at this point. The way to circumvent that is by creating your model/ training in another framework like tensorflow and then consuming the model in ML.NET to use for **inferencing** only. Closing this issue, feel free to reopen if you have additional questions.\r\n\r\n"
      },
      {
        "user": "Lynx1820",
        "created_at": "2020-06-12T15:20:49Z",
        "body": "Not at the moment. "
      }
    ]
  },
  {
    "number": 4915,
    "title": "how we can show confusion matrix of Permutation Feature Importance so end user easily identify?",
    "created_at": "2020-03-04T10:08:58Z",
    "closed_at": "2020-03-09T22:07:10Z",
    "labels": [
      "question",
      "P3"
    ],
    "url": "https://github.com/dotnet/machinelearning/issues/4915",
    "body": "@yaeldekel,@eerhardt,@najeeb-kazmi,@justinormont,@CESARDELATORRE\r\n\r\nhow we can show score,probability,confusion matrix of Permutation Feature Importance?",
    "comments_url": "https://api.github.com/repos/dotnet/machinelearning/issues/4915/comments",
    "author": "nighotatul",
    "comments": [
      {
        "user": "najeeb-kazmi",
        "created_at": "2020-03-09T22:07:10Z",
        "body": "Subset of #4912 "
      }
    ]
  },
  {
    "number": 4712,
    "title": "DllNotFoundException: Unable to load DLL 'tensorflow': The specified module could not be found. (Exception from HRESULT: 0x8007007E)",
    "created_at": "2020-01-27T06:24:13Z",
    "closed_at": "2020-02-18T20:24:34Z",
    "labels": [
      "question",
      "P3"
    ],
    "url": "https://github.com/dotnet/machinelearning/issues/4712",
    "body": "I am trying to Consume the ML.NET model to predict the results via following code \r\n\r\n\r\npublic static ModelOutput Predict(ModelInput input)\r\n        {\r\n\r\n\r\n            // Create new MLContext\r\n            MLContext mlContext = new MLContext();\r\n            ModelOutput result = new ModelOutput();\r\n            try\r\n            {\r\n\r\n\r\n                Load model &create prediction engine\r\n                string modelPath = AppDomain.CurrentDomain.BaseDirectory + \"MLModel.zip\";\r\n                ITransformer mlModel = mlContext.Model.Load(modelPath, out var modelInputSchema);\r\n                var predEngine = mlContext.Model.CreatePredictionEngine<ModelInput, ModelOutput>(mlModel);\r\n\r\n                Use model to make prediction on input dataDllNotFoundException: Unable to load DLL 'tensorflow': The specified module could not be found. (Exception from HRESULT: 0x8007007E)\r\n\r\n                result = predEngine.Predict(input);\r\n                Console.WriteLine(result);\r\n\r\n            }\r\n            catch (Exception e)\r\n            {\r\n                Console.WriteLine(e.ToString());\r\n            }\r\n            return result;\r\n        }\r\n\r\n\r\n\r\nI am having tensorflow.dll error while it is installed and present in respective folder too. ",
    "comments_url": "https://api.github.com/repos/dotnet/machinelearning/issues/4712/comments",
    "author": "yasir9624",
    "comments": [
      {
        "user": "mstfbl",
        "created_at": "2020-01-27T12:44:45Z",
        "body": "Hi @yasir9624 , are you importing the TensorFlow libraries by adding `using Microsoft.ML.TensorFlow` before you declare your namespace?"
      },
      {
        "user": "mstfbl",
        "created_at": "2020-02-18T20:24:34Z",
        "body": "Closing this issue as no response was received."
      }
    ]
  },
  {
    "number": 4257,
    "title": "What is the input format required by the LDA transform?",
    "created_at": "2019-09-27T13:35:46Z",
    "closed_at": "2019-12-19T23:49:56Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnet/machinelearning/issues/4257",
    "body": "Ideally I would like the output of ApplyWordEmbedding transform as input to LDA for topic modeling but apparently that is not the case.\r\n\r\nSo I am not sure how to format the input to LDA.\r\n\r\nDocumentation says it should be a vector of single - which it is with after applying the embedding transform but then I see an error message when running LDA:\r\n\r\nThe specified documents are all empty in column 'Features'.\r\n\r\nWhere \"Features\" is the output of the embedding.\r\n\r\n",
    "comments_url": "https://api.github.com/repos/dotnet/machinelearning/issues/4257/comments",
    "author": "fwaris",
    "comments": [
      {
        "user": "yaeldekel",
        "created_at": "2019-10-02T12:11:24Z",
        "body": "Hi @fwaris, thank you for opening this issue. The LDA transformer in ML.NET can be applied to the output of n-gram transformer, or bag of words (so even though the input is a vector of floats, it checks that the values are integers). Please see this related issue: #4178."
      },
      {
        "user": "antoniovs1029",
        "created_at": "2019-12-19T23:49:56Z",
        "body": "Since it seems this was answered, I am going to close it."
      }
    ]
  },
  {
    "number": 3897,
    "title": "Guidance on simple binaryclassification",
    "created_at": "2019-06-21T21:43:46Z",
    "closed_at": "2020-01-18T00:09:08Z",
    "labels": [
      "question",
      "need info",
      "P3"
    ],
    "url": "https://github.com/dotnet/machinelearning/issues/3897",
    "body": "Trying to get a very simple binary classification to work. And while I feel I am just touching on the ABC's I am running into various issues. This shouldn't be rocket science.\r\n\r\nThe issue I get is \"Schema mismatch for feature column 'Features': expected Vector<Single>, got Vector<String>\r\nParameter name: inputSchema\"\r\n\r\nTo make sure the classification would work I made sure the Label column that I want to eventually predict is a boolean type. (I couldn't find clear docs on why the label column was needed but I assumed the training requires a single potential target for predictions which is the label, and if you want to predict other properties you need to train a model specifically for that property).\r\n\r\nI also made sure I transformed the string property first. \r\n\r\n```csharp\r\n        public class Employee\r\n        {\r\n            [LoadColumn(0)]\r\n            public float Age { get; set; }\r\n            [LoadColumn(1), ColumnName(\"Label\")]\r\n            public bool Attrition { get; set; }\r\n            [LoadColumn(2)]\r\n            public string BusinessTravel { get; set; }\r\n            [LoadColumn(3)]\r\n            public float DailyRate { get; set; }\r\n        }\r\n\r\n        public ActionResult Turnover()\r\n        {\r\n            MLContext mlContext = new MLContext();\r\n\r\n            var _appPath = AppDomain.CurrentDomain.BaseDirectory;\r\n            var _dataPath = Path.Combine(_appPath, \"Datasets\", \"attrition_small_dataset.csv\");\r\n            IDataView dataView = mlContext.Data.LoadFromTextFile<Employee2>(_dataPath, separatorChar: ',', hasHeader: true);\r\n\r\n            var categoricalEstimator = mlContext.Transforms.Categorical.OneHotEncoding(\"BusinessTravel\");\r\n            IDataView transformedData = categoricalEstimator.Fit(dataView).Transform(dataView);\r\n            \r\n            string[] featureColumnNames =\r\n                dataView.Schema\r\n                    .Select(column => column.Name)\r\n                    .Where(columnName => columnName != \"Label\").ToArray();\r\n\r\n            IEstimator<ITransformer> dataPrepEstimator = mlContext.Transforms.Concatenate(\"Features\", featureColumnNames);\r\n            IDataView preprocessedTrainData = dataPrepEstimator.Fit(dataView).Transform(dataView);\r\n\r\n            var sdcaEstimator = mlContext.BinaryClassification.Trainers.SdcaLogisticRegression();\r\n            var sdcaModel = sdcaEstimator.Fit(preprocessedTrainData);\r\n\r\n            return View(\"Turnover\");\r\n        }\r\n```",
    "comments_url": "https://api.github.com/repos/dotnet/machinelearning/issues/3897/comments",
    "author": "famschopman",
    "comments": [
      {
        "user": "wschin",
        "created_at": "2019-06-26T19:52:05Z",
        "body": "Could you please find which line threw that error?"
      },
      {
        "user": "najeeb-kazmi",
        "created_at": "2020-01-18T00:05:07Z",
        "body": "@famschopman you are seeing this because you are fitting `dataPrepEstimator` on `dataView`, which has the schema of the original data, specifically \"BusinessTravel\" is still a string. So you are trying to concatenate \"Age\" (float), \"BusinessTravel\" (string), and \"DailyRate\" (float) into one column \"Features\". \r\n\r\nYou should instead fit this on `transformedData`, where \"BusinessTravel\" has been correctly featurized with the `OneHotEncoding` transform.\r\n\r\nAlso, it would be a good idea to get `featureColumnNames` from `transformedData` rather than `dataView`. Not that it would make a difference here. It's just good practice just in case you had renamed a column in an earlier transformation (so the next transformation would not have that feature name)."
      },
      {
        "user": "najeeb-kazmi",
        "created_at": "2020-01-18T00:09:08Z",
        "body": "@famschopman I'm closing this issue. Please feel free to reopen if you are still getting this error."
      }
    ]
  },
  {
    "number": 3816,
    "title": "System.ArgumentException: 'Length of memory  must match product of dimensions.",
    "created_at": "2019-06-04T11:37:53Z",
    "closed_at": "2019-06-10T09:47:39Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnet/machinelearning/issues/3816",
    "body": "- windows 10\r\n- 4.7.NET Version  \r\n- ML dotnet 1.0\r\n- Visual Studio 15.9.12\r\n\r\nIssue:\r\n\r\nI'm quite new to .net, however I'm trying to replicate CRNN model developed on keras to ML dotnet. I successfully converted the model to onnx format. But when I try to make a prediction I'm getting this:\r\n _System.ArgumentException: 'Length of memory (9600) must match product of dimensions (3200).'_\r\nI didn't find any issue or something so that is way I'm writing here.\r\n\r\nI can assume that the problem might be somewhere in image transformation. My model is built for grayscale images with the shape of (1, 1, 32, 100) and there I have this conflict between:\r\n1x32x100 = 3200 (should be)  vs  3x32x100 = 9600 (actually is)\r\n\r\nI've tried to transform images to grayscale, but it doesn't work (perhaps I do it in a wrong way).\r\n\r\nThis is my snipped code for building the pipeline:\r\n\r\n`\r\n\r\n        int imageHeight = 32;\r\n        int imageWidth = 100;\r\n        bool ChannelsLast = false;\r\n        string ModelInput = \"conv2d_1_input_01\";\r\n        string ModelOutput = \"dense_1_add_0\";\r\n\r\n\r\n        var pipeline = mLContext.Transforms.LoadImages(outputColumnName: \"conv2d_1_input_01\",\r\n                                                           imageFolder: imagesLocation,\r\n                                                           inputColumnName: nameof(ImageData.ImagePath))\r\n            .Append(mLContext.Transforms.ResizeImages(outputColumnName: \"conv2d_1_input_01\",\r\n                                                            imageWidth: imageWidth,\r\n                                                            imageHeight: imageHeight))\r\n            .Append(mLContext.Transforms.ConvertToGrayscale(outputColumnName:\r\n                                                            \"conv2d_1_input_01\"))\r\n            .Append(mLContext.Transforms.ExtractPixels(outputColumnName: \"conv2d_1_input_01\", interleavePixelColors: ImageSettings.ChannelsLast))\r\n            .Append(mLContext.Transforms.ApplyOnnxModel(modelFile: modelLocation,\r\n                                                            outputColumnNames: new[] { ModelOutput },\r\n                                                            inputColumnNames: new[] { ModelInput }));\r\n`\r\n\r\nI would appreciate any help or comments.",
    "comments_url": "https://api.github.com/repos/dotnet/machinelearning/issues/3816/comments",
    "author": "cemicel",
    "comments": [
      {
        "user": "cemicel",
        "created_at": "2019-06-06T12:36:45Z",
        "body": "I was able to omit the problem by changing model's input shape to consume 3-channel images.\r\nIt is not the solution."
      },
      {
        "user": "yaeldekel",
        "created_at": "2019-06-07T20:08:51Z",
        "body": "Hi @cemicel, thank you for your question. The `ConvetToGrayscale` transform converts the image to gray scale, but it keeps all the channels (alpha, R, G and B). the `ExtractPixels` transform has an option called `colorsToExtract`, where you can specify that you would only like to extract the alpha channel:\r\n```\r\nmLContext.Transforms.ExtractPixels(outputColumnName: \"conv2d_1_input_01\", colorsToExtract: ImagePixelExtractingEstimator.ColorBits.Alpha)\r\n```\r\n"
      },
      {
        "user": "cemicel",
        "created_at": "2019-06-10T09:47:38Z",
        "body": "Hello @yaeldekel,\r\nThank you for your explanation, now it make sense for me.\r\n"
      }
    ]
  },
  {
    "number": 3743,
    "title": "Question: Deep Learning and Doc2Vec",
    "created_at": "2019-05-17T10:01:39Z",
    "closed_at": "2019-05-22T06:24:56Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnet/machinelearning/issues/3743",
    "body": "Hi, \r\n\r\nI was wondering if there are any plans to allow modeling deep neural networks. I know that it is possible to consume Tensorflow models. I am interested in creating and training models directly in ml.net\r\n\r\nUnrelated to the first question: Are there any plans to implement Doc2vec as an alternative to the current FeaturizeText feature.\r\n\r\nIn case this issue tracker is the wrong place to ask questions, please point me to the site you might be using for questions.\r\n\r\nThanks, \r\n\r\nLars",
    "comments_url": "https://api.github.com/repos/dotnet/machinelearning/issues/3743/comments",
    "author": "larsbeck",
    "comments": [
      {
        "user": "yaeldekel",
        "created_at": "2019-05-22T03:06:24Z",
        "body": "Hi Lars,\r\nThank you for your interest in ML.NET. We do have plans to support training of deep neural networks. Currently, we have partial support of re-training an existing Tensorflow model, and we plan to expand this capability in the future.\r\n\r\nRegarding Doc2vec, I am not aware of any plans regarding this, but I will open a new issue for this so it can be tracked separately.\r\n\r\n"
      },
      {
        "user": "larsbeck",
        "created_at": "2019-05-22T06:24:56Z",
        "body": "Thanks! I'll check out new versions then. Keep up the great work!"
      }
    ]
  },
  {
    "number": 3673,
    "title": "Restore trainer code from model.zip ",
    "created_at": "2019-05-07T09:25:34Z",
    "closed_at": "2019-05-14T20:22:47Z",
    "labels": [
      "enhancement",
      "question",
      "wontfix"
    ],
    "url": "https://github.com/dotnet/machinelearning/issues/3673",
    "body": "How can I restore the code that was used to create `model.zip`? Is model archive is self-containing?\r\n\r\n### Use case:\r\nLet's say I have 10 models in production, created by few engineers. \r\nAfter some time (1 year) I find out that one model does not perform as good as it was before and I want to retrain it using the same algorithms but with more training data.\r\n\r\nShould I maintain all version of trainers (code & params) and their relationships with generated model files separately or I will be able to restore code in the future?\r\n\r\nSomething like\r\n```\r\nmlnet gen-proj \"model.zip\" --lang C#\r\n```   \r\n\r\n### Note\r\n\r\nAlso may be useful to have AutoML logs packed inside (optionally)\r\nIf model is trained and saved by Azure ML it may be useful to know how many minutes was spend on training and what models was tried...",
    "comments_url": "https://api.github.com/repos/dotnet/machinelearning/issues/3673/comments",
    "author": "sergey-tihon",
    "comments": [
      {
        "user": "zeahmed",
        "created_at": "2019-05-08T22:56:04Z",
        "body": "@sergey-tihon, Thanks for bringing up this issue.\r\n\r\nCurrently, the trainer Code cannot be regenerated/retrieved from model.zip. This is inline with ML.NET model management philosophy. Trainer code and model.zip should be maintained together for future consumption.\r\n\r\nIt's not confirmed if there will be any such feature available in near future. I am currently tagging it as an `enhancement` for further discussion."
      },
      {
        "user": "glebuk",
        "created_at": "2019-05-09T07:06:38Z",
        "body": "The general issue is that the transitive closure of the training code is hard to capture in general, as a result, the proper way to deal with this is to integrate the traning into the CI pipeline, and store the code in the source  code management system such as git repo and associate the model with the source code version hash.  \r\nFor example, imagine that you have the actual training code recorded with the model, however, some 3rd-degree dependency such as ADO.NET got updated and now your code behaves slightly differently despite being unchanged."
      },
      {
        "user": "najeeb-kazmi",
        "created_at": "2019-05-14T20:22:47Z",
        "body": "Closing since this is a won't fix. "
      }
    ]
  },
  {
    "number": 3155,
    "title": "Beginner: 'Schema mismatch for label column '': expected R4, got Key<U4>' exception thrown.",
    "created_at": "2019-04-01T19:04:29Z",
    "closed_at": "2019-04-01T20:15:57Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnet/machinelearning/issues/3155",
    "body": "- **Windows 10**:\r\n\r\n\r\n\r\nTrying to create my first regression in ML.NET\r\nI get an exception thrown:\r\nSchema mismatch for label column '': expected R4, got Key<U4>\r\nI was expecting to get \r\n\"Predicted 6 + 3 is: 9\"\r\nprinted to the console.\r\n\r\nI wrote a python script to create training data with 3 columns :\r\nfirst, second, result.\r\nfirst and second are random values.\r\nresult is first+second.\r\n\r\nI expect the machine to get first and second and predict the result. \r\n\r\nnumbers.cvs:\r\n```\r\n35,74,109\r\n69,36,105\r\n75,3,78\r\n19,44,63\r\n65,93,158\r\n40,15,55\r\n2,67,69\r\n27,63,90 ... X1000 times\r\n```\r\nCode that matters:\r\n```\r\n\r\n    public class NumberData\r\n    {\r\n        [LoadColumn(0)]\r\n        public float first;\r\n        [LoadColumn(1)]\r\n        public float second;\r\n        [LoadColumn(2)]\r\n        public float result;\r\n    }\r\n    public class NumberPrediction\r\n    {\r\n        [ColumnName(\"PredictedNumber\")]\r\n        public float PredictedNumber;\r\n    }\r\n.\r\n.\r\n.\r\nusing Microsoft.Data.DataView;\r\nusing Microsoft.ML;\r\nusing Microsoft.ML.Data;\r\n.\r\n.\r\n.\r\nMLContext mlContext = new MLContext();          \r\nIDataView trainingDataView = \r\nmlContext.Data.LoadFromTextFile<NumberData>(\r\n\"numbers.csv\",',',false);\r\nConsole.WriteLine(\"Loaded Data\");\r\nvar trainingPipeline =\r\nmlContext.Transforms.Conversion.MapValueToKey(nameof(NumberData.result))\r\n.Append(mlContext.Transforms.Concatenate(\r\nDefaultColumnNames.Features,\r\nnameof(NumberData.first),\r\nnameof(NumberData.second)))\r\n.Append(mlContext.Regression.Trainers.StochasticDualCoordinateAscent(\r\nlabelColumnName: \"result\",\r\nfeatureColumnName: DefaultColumnNames.Features))\r\n.Append(mlContext.Transforms.Conversion.MapKeyToValue(\"PredictedNumber\"));\r\nConsole.WriteLine(\"Created Trainer\");\r\nvar model = trainingPipeline.Fit(trainingDataView);//**RELEVANT** exception thrown here\r\nConsole.WriteLine(\"Trained The Model\");\r\nvar prediction =\r\nmodel.CreatePredictionEngine<NumberData, NumberPrediction>(mlContext).Predict(\r\nnew NumberData()\r\n{\r\nfirst = 6f,\r\nsecond = 3f,\r\nresult = 0// To be predicted\r\n});\r\nConsole.WriteLine($\"Predicted 6 + 3 is: {prediction.PredictedNumber}\");\r\n```\r\n",
    "comments_url": "https://api.github.com/repos/dotnet/machinelearning/issues/3155/comments",
    "author": "tomerze",
    "comments": [
      {
        "user": "singlis",
        "created_at": "2019-04-01T20:09:04Z",
        "body": "Hi @TomerZeitune  - \r\n\r\nSorry that error message could be better. With 0.12 it should say \"expected float, got Key\". You are getting the exception , because there is a MapValueToKey transform for the result column which should not be needed as result is already a float. \r\n\r\nIf you remove this transformer, you will get another error Argument out of range exception and that  PredictedResult column is not found. So if you also take out the MapKeyToValue for PredictedResult, you will have a working pipeline, however the predicted result is 0. This is because the NumberPrediction class that you are using to store the prediction needs to pull from the Score column. So if you change the attribute for PredictedNumber to be:\r\n`[ColumnName(\"Score\")]\r\n`\r\nYou will get a better result:\r\n```\r\n        {\r\n            int maxIterations = 100;\r\n            MLContext mlContext = new MLContext();\r\n            IDataView trainingDataView =\r\n            mlContext.Data.LoadFromTextFile<NumberData>(\r\n            \"numbers.csv\", ',', false);\r\n            Console.WriteLine(\"Loaded Data\");\r\n            var trainingPipeline =\r\n            //mlContext.Transforms.Conversion.MapValueToKey(nameof(NumberData.result))\r\n            mlContext.Transforms.Concatenate(\r\n            DefaultColumnNames.Features,\r\n            nameof(NumberData.first),\r\n            nameof(NumberData.second))\r\n            .Append(mlContext.Regression.Trainers.StochasticDualCoordinateAscent(\r\n            labelColumnName: \"result\",\r\n            featureColumnName: DefaultColumnNames.Features,\r\n            maxIterations: maxIterations));\r\n            //.Append(mlContext.Transforms.Conversion.MapKeyToValue(\"PredictedNumber\"));\r\n            Console.WriteLine(\"Created Trainer\");\r\n            var model = trainingPipeline.Fit(trainingDataView);//**RELEVANT** exception thrown here\r\n            Console.WriteLine(\"Trained The Model\");\r\n            var prediction =\r\n            model.CreatePredictionEngine<NumberData, NumberPrediction>(mlContext).Predict(\r\n            new NumberData()\r\n            {\r\n                first = 6f,\r\n                second = 3f,\r\n                result = 0// To be predicted\r\n            });\r\n            Console.WriteLine($\"Predicted 6 + 3 is: {prediction.PredictedNumber}\");\r\n        }\r\n```\r\n\r\nHere is the class:\r\n```\r\n    public class NumberPrediction\r\n    {\r\n        [ColumnName(\"Score\")]\r\n        public float PredictedNumber;\r\n    }\r\n```\r\n"
      },
      {
        "user": "tomerze",
        "created_at": "2019-04-01T20:14:24Z",
        "body": "Thank you a lot for your help. You solved the problem. \r\nI get \r\n\r\n```\r\nLoaded Data\r\nCreated Trainer\r\nTrained The Model\r\nPredicted 6 + 3 is: 9.004125\r\n\r\n```\r\nprinted as expected."
      }
    ]
  },
  {
    "number": 3145,
    "title": "LinearSupportVectorMachines trained Model not working",
    "created_at": "2019-03-31T14:38:30Z",
    "closed_at": "2020-01-10T00:30:47Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnet/machinelearning/issues/3145",
    "body": "### System information\r\n\r\n- **OS windows 10**:\r\n- **.NET Version (Microsoft.NETCore.App 2.2.3)**: \r\n\r\n### Issue\r\n\r\n- **What did you do?**\r\ntrained a model using LinearSupportVectorMachines\r\n- **What happened?**\r\nThe model was created then i load the model and tried to predict on the model but it shows exception\r\n```\r\nUnhandled Exception: System.ArgumentOutOfRangeException: Could not find input column 'IdPreservationColumn'\r\nParameter name: inputSchema\r\n   at Microsoft.ML.Data.ColumnConcatenatingTransformer.Mapper.MakeColumn(DataViewSchema inputSchema, Int32 iinfo)\r\n   at Microsoft.ML.Data.ColumnConcatenatingTransformer.Mapper..ctor(ColumnConcatenatingTransformer parent, DataViewSchema inputSchema)\r\n   at Microsoft.ML.Data.ColumnConcatenatingTransformer.MakeRowMapper(DataViewSchema inputSchema)\r\n   at Microsoft.ML.Data.RowToRowTransformerBase.Microsoft.ML.ITransformer.GetRowToRowMapper(DataViewSchema inputSchema)\r\n   at Microsoft.ML.Data.TransformerChain`1.Microsoft.ML.ITransformer.GetRowToRowMapper(DataViewSchema inputSchema)\r\n   at Microsoft.ML.Data.TransformerChain`1.Microsoft.ML.ITransformer.GetRowToRowMapper(DataViewSchema inputSchema)\r\n   at Microsoft.ML.PredictionEngineBase`2..ctor(IHostEnvironment env, ITransformer transformer, Boolean ignoreMissingColumns, SchemaDefinition inputSchemaDefinition, SchemaDefinition outputSchemaDefinition)\r\n```\r\n- **What did you expect?**\r\nI expected to predict based on loaded trained model\r\n### Source code / logs\r\n\r\nIdPreservationColumn i don't know what this is and i can't find any document about it\r\n",
    "comments_url": "https://api.github.com/repos/dotnet/machinelearning/issues/3145/comments",
    "author": "amirjalali1",
    "comments": [
      {
        "user": "sfilipi",
        "created_at": "2019-04-01T06:54:20Z",
        "body": "@1amirjalai Is there any column on your dataset with name \"IdPreservationColumn\" ?\r\nCan you post your full pipeline, and one row of your data?"
      },
      {
        "user": "ganik",
        "created_at": "2020-01-10T00:30:47Z",
        "body": "closing this as author has not replied for request for more info since March 2019"
      }
    ]
  },
  {
    "number": 2836,
    "title": "Question : When 0.11 expected to be released",
    "created_at": "2019-03-04T20:53:13Z",
    "closed_at": "2019-03-04T21:25:08Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnet/machinelearning/issues/2836",
    "body": "Question : When 0.11 expected to be released\r\n\r\nbest regards",
    "comments_url": "https://api.github.com/repos/dotnet/machinelearning/issues/2836/comments",
    "author": "DevLob-zz",
    "comments": [
      {
        "user": "shauheen",
        "created_at": "2019-03-04T21:20:23Z",
        "body": "Thanks @DevLob-zz for the question. We are on track to release 0.11 this week. Hope that answers your question."
      },
      {
        "user": "DevLob-zz",
        "created_at": "2019-03-04T21:25:08Z",
        "body": "thanks best luck "
      }
    ]
  },
  {
    "number": 2554,
    "title": "ColumnInfo as an API parameter",
    "created_at": "2019-02-14T20:45:00Z",
    "closed_at": "2019-02-27T04:03:35Z",
    "labels": [
      "question",
      "API"
    ],
    "url": "https://github.com/dotnet/machinelearning/issues/2554",
    "body": "The use of `ColumnInfo` in the public API can be rather jarring. I'd like to clarify when we should use it in the catalog API, and if the parameter name could be made to be more consistent with the API, such as `ColumnOptions` or `Options`.",
    "comments_url": "https://api.github.com/repos/dotnet/machinelearning/issues/2554/comments",
    "author": "rogancarr",
    "comments": [
      {
        "user": "Ivanidzo4ka",
        "created_at": "2019-02-15T22:24:25Z",
        "body": "Whatever we decide to call it, we also have `MeanVarColumn`, `LogMeanVarColumn`, `BinningColumn`, `SupervisedBinningColumn` and `MinMaxColumn` in `NormalizingEstimator` so they should be renamed to same thing. (Easy to miss if we sweep just ColumnInfo).\r\n\r\nWe also have `SimpleColumnInfo` which we need to address as well."
      },
      {
        "user": "artidoro",
        "created_at": "2019-02-21T01:11:58Z",
        "body": "I think the suggestion `ColumnOptions` could work. It relates to the naming convention that we use for trainers, and it also indicates that this is column-specific compared to the trainers.\r\n\r\nI would like however to hear @TomFinley 's opinion on this."
      },
      {
        "user": "TomFinley",
        "created_at": "2019-02-22T00:34:33Z",
        "body": "I could definitely get behind `ColumnOptions`. It seems a far superior choice, so, let me say I agree wholeheartedly."
      }
    ]
  },
  {
    "number": 2068,
    "title": "Word embedding output dimensions",
    "created_at": "2019-01-08T07:33:46Z",
    "closed_at": "2019-02-01T01:12:58Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnet/machinelearning/issues/2068",
    "body": "### System information\r\n\r\n- **OS version/distro**: windows 64bit 10.0.17134\r\n- **.NET Version (eg., dotnet --info)**: 2.1.502\r\n\r\n### Issue\r\nI am having trouble understanding the output of the WordEmbeddings function. Using a model with 50 dimensionality output, I would expect the embedding dimensions to match that output in some way. It only just multiplies the expected output dimension by 3.\r\n\r\nI have checked the model files, and they have the correct output for each word for each model.\r\n\r\n- **What did you do?** \r\nCreated wordEmbedding using several different preprocessed models. Both default and downloaded elsewhere\r\n- **What happened?**\r\nFor GloVe50D the output dimensions were 150.\r\nFor FastTextWikipedia300D the output was 900\r\n- **What did you expect?**\r\nI expected the output to match the embedding size in the models.\r\nFor GloVe50D to output dimensions 50 * input size, or [inputsize][50].\r\nFor FastTextWikipedia300D to output dimensions 300 * input size, or [inputsize][300].\r\n\r\n### Source code / logs\r\n\r\nPlease paste or attach the code or logs or traces that would be helpful to diagnose the issue you are reporting.\r\n\r\nThis code illustrates my issue. I would assume the output to be of variable size, but all outputs have dimensionality of 150, which I have trouble grasping. I have tried forcing the output to a variable vector output but it changes nothing.\r\n\r\nWhat worries me most, is what happens, when the input is a single word sentence, as I can not fathom or figure out what the extra 100 values are.\r\n\r\n```\r\n\r\nusing System;\r\nusing System.Linq;\r\nusing Microsoft.ML;\r\nusing Microsoft.ML.Runtime.Api;\r\nusing Microsoft.ML.Runtime.Data;\r\nusing Microsoft.ML.StaticPipe;\r\nusing Microsoft.ML.Transforms.Text;\r\n\r\nnamespace ConsoleApp1\r\n{\r\n    class DataEntry\r\n    {\r\n        public DataEntry(string message, int label)\r\n        {\r\n            Message = message;\r\n            Label = label;\r\n        }\r\n        public string Message { get; set; }\r\n        public int Label { get; set; }\r\n    }\r\n\r\n    class ModelOutput\r\n    {\r\n        public int Label;\r\n        public float[] Embedding;\r\n    }\r\n\r\n    class Program\r\n    {\r\n        private static MLContext mLContext = new MLContext();\r\n        private static PredictionFunction<DataEntry, ModelOutput> wordEmbedder;\r\n\r\n        static void Main()\r\n        {\r\n            var dataEntries = new[]\r\n            {\r\n                \"I am a horse\",\r\n                \"cow\",\r\n                \"The cat is norse\",\r\n                \"Don't ask me how\",\r\n                \"This is a sentence that is very long, and should have a different dimension than the other ones?\"\r\n            };\r\n            var labels = dataEntries.Select((_, i) => i).ToArray();\r\n\r\n            TokenizeData(dataEntries, labels, out  var data);\r\n            \r\n            Console.WriteLine($\"{data.Length} {data[0].Length}\");\r\n            foreach (var d in data)\r\n            {\r\n                Console.WriteLine($\"{d.Length}\");\r\n            }\r\n\r\n            Console.Read();\r\n        }\r\n        \r\n\r\n        private static void TokenizeData(string[] dataEntries, int[] labels, out double[][] dataVectors)\r\n        {\r\n            var dataEnum = dataEntries.Select((s, i) => new DataEntry(s, labels[i])).ToArray();\r\n            var reader = mLContext.CreateDataView(dataEnum).AssertStatic(\r\n                mLContext, c =>\r\n                (\r\n                    Message: c.Text.Scalar,\r\n                    Label: c.I4.Scalar));\r\n\r\n            // Inspect the message texts that are read from the file.\r\n            var pipeline = reader.MakeNewEstimator()\r\n                    .Append(r => (\r\n                        LabelMid: r.Label,\r\n                        Embedding: r.Message\r\n                            .NormalizeText()\r\n                            .TokenizeText()\r\n                            .RemoveStopwords()\r\n                            .WordEmbeddings(\r\n                                WordEmbeddingsExtractingTransformer\r\n                                    .PretrainedModelKind\r\n                                    .GloVe50D)\r\n                    ))\r\n                ;\r\n\r\n            var modelFit = pipeline.Fit(reader);\r\n\r\n            wordEmbedder = modelFit.AsDynamic.MakePredictionFunction<DataEntry, ModelOutput>(mLContext);\r\n\r\n            dataVectors = dataEntries.Select((s, i) => NameToTfVector(s, labels[i])).ToArray();\r\n        }\r\n        \r\n        private static double[] SentenceFromWordEmbedding(ModelOutput embedding)\r\n        {\r\n            return embedding.Embedding.Select(f => (double) f).ToArray();\r\n        }\r\n\r\n        private static double[] NameToTfVector(string inputText, int label)\r\n        {\r\n            return SentenceFromWordEmbedding(wordEmbedder.Predict(new DataEntry(inputText, label)));\r\n        }\r\n    }\r\n}\r\n```\r\nOutput:\r\n`5 150\r\n150\r\n150\r\n150\r\n150\r\n150`",
    "comments_url": "https://api.github.com/repos/dotnet/machinelearning/issues/2068/comments",
    "author": "cmollgaard",
    "comments": [
      {
        "user": "justinormont",
        "created_at": "2019-01-08T13:53:58Z",
        "body": "Greetings @stunax! \r\n\r\nThe WordEmbedding transform produces an output consisting of the average, min, and max of the words in the phrase. The min/max provide a bounding hyper-rectangle for the words in the word embedding space. This can assist for longer phrases where the average of many words drowns out the useful signal and your label is reasonable correlated with a dimension of the embedding space. \r\n\r\nFor instance, if you're trying to classify ( trucks vs. dogs ), a dimension of the pretrained embedding space may reasonably represent \"mechanical-ness\" or \"softness\"; and any word in your phrase peaking these dimensions would push the min/max outwards even when the average is overwhelmed by other words.\r\n\r\nIf you want to experiment, you can try to select the first/middle/last 3rd of the output vector as your Features column and see the impact of the average/min/max on your dataset.\r\n\r\nLet us know if you find the WordEmbedding valuable on your dataset, and if any of the pretrained custom embeddings which you're trying turn out to be useful useful. \r\n "
      },
      {
        "user": "cmollgaard",
        "created_at": "2019-01-08T15:09:31Z",
        "body": "Thank you very much! \r\n\r\nThis was what I needed to understand the output. I was unable to find any documentation for the output, but this makes sense.\r\n\r\nI ended up just loading the model manually, but glove50 improved model performance, by reducing test error by 2/3.\r\n\r\nI am abit curious as how your FastText model works? As far as i understand, the benefit of FastText comes from the subword information, but I miss an example as how it should be combined with the ngram transformer."
      },
      {
        "user": "justinormont",
        "created_at": "2019-01-08T23:16:17Z",
        "body": "FastText uses the sub-words (often 3 to 6 length charactergrams) plus ngrams (often length ~2 ngrams) to train the model. When they flatten the model to a lookup table, they include only the unigrams. We use the unigrams as the key to the lookup table. \r\n\r\nI believe the binary format of FastText embeddings (.bin files) retains the full neural net includes inputs for the charactergrams. We haven't investigated the gains by using the binary format vs. the flattened (.vec) format. I expect this would mainly help when there are words which are telling of the label, but not in the pre-trained word embedding file, as it can lookup the chargrams even without the full word existing. \r\n\r\nFor handling the case of out-of-vocabulary words, the trichargram portion of the TextTransform provides similar gains. Using bigrams+trichargrams as a feature gives you a pseudo-stemming ability from the trichargrams. I tend to use a word embedding in parallel with these ngrams+chargrams. "
      },
      {
        "user": "Ivanidzo4ka",
        "created_at": "2019-01-31T01:10:24Z",
        "body": "This is clear sign what we need better documentation."
      }
    ]
  },
  {
    "number": 1843,
    "title": "Schema.Metadata needs a better name",
    "created_at": "2018-12-06T19:36:59Z",
    "closed_at": "2019-02-26T18:16:56Z",
    "labels": [
      "question",
      "API",
      "need info"
    ],
    "url": "https://github.com/dotnet/machinelearning/issues/1843",
    "body": "\"Metadata\" is perhaps not the best name for what we currently call metadata.\r\n\r\nFirst, what is it: what we call Metadata is meant to suggest not just any metadata, but that data that we consider auxiliary, or at *most* ancillary. (So for example, slot names are in metadata, because not everything will have names for each slot. But sometimes they will, and we need a place to keep that.)\r\n\r\nThe trouble with the name \"metadata\" is that it means literally everything but the data. But this is inaccurate: there are lots of things that are data about the data (e.g., the types, the vector sizes, the names of columns) that we definitely do not want to keep in the metadata structure (since they're absolutely required information), but that is \"metadata\" in the strict linguistic sense of the word.\r\n\r\nThe only name suggested as an alternative that I am aware of is \"annotations.\" I am fine with the name annotations. Perhaps we could come up with a better name. I'll leave this open for a bit, and unless people object we can rename metadata annotations.",
    "comments_url": "https://api.github.com/repos/dotnet/machinelearning/issues/1843/comments",
    "author": "TomFinley",
    "comments": [
      {
        "user": "Zruty0",
        "created_at": "2018-12-18T22:38:22Z",
        "body": "I am fine with 'annotations' as a property name (as in, `schema[column].Annotations.GetValue(\"foo\", ref foo)`).\r\n\r\nAs for the class name, I think neither `Metadata` nor `Annotations` are good names: they reflect what the object is **used for**, not what it **is**. And the metadata is, essentially, 'almost a row', or 'a property bag'.\r\n\r\nSo, maybe `PropertyBag`, or `ValueCollection` or something like that?.."
      }
    ]
  },
  {
    "number": 1827,
    "title": "The trainer API for MLContext is inconsistent for learner in external nugets",
    "created_at": "2018-12-05T02:00:19Z",
    "closed_at": "2019-06-30T08:47:47Z",
    "labels": [
      "question",
      "API"
    ],
    "url": "https://github.com/dotnet/machinelearning/issues/1827",
    "body": "APIs are discoverable via the MLContext. There are some learners that are declared on the MLContext where other learners define an MLContext extension in cases where the learner is in a separate nuget package. \r\n\r\nThis results inconsistent API calls when accessing APIs, for example BinaryClassification vs Recommendation():\r\n```\r\nvar foo_bar = mlContext.BinaryClassification.Trainers;\r\nvar foo_moo_bar = mlContext.Recommendation().Trainers;\r\n```\r\n\r\nThe API discover ability should be consistent and work across nuget pakages.\r\nOriginal issue: #1806 \r\n\r\nThis issue may be the solution #1319 as it creates extensions for the trainers. ",
    "comments_url": "https://api.github.com/repos/dotnet/machinelearning/issues/1827/comments",
    "author": "singlis",
    "comments": [
      {
        "user": "Zruty0",
        "created_at": "2018-12-05T19:57:55Z",
        "body": "This inconsistency was expected by design from the first day: we planned to have **properties** for 'standard' tasks (available in `Microsoft.ML` NuGet) and **methods** for tasks that are added in separate NuGets (time series, recommendation, etc.) \r\n\r\nIf you have any suggestion on how to make them consistent, please make it. The only way I see that we can reconcile the calls is to make all existing properties into methods:\r\n```csharp\r\nvar foo1 = mlContext.BinaryClassification().Trainers().LogisticRegression();\r\nvar foo2 = mlContext.Transforms().Categorical().OneHotEncoding();\r\n```\r\netc.\r\n\r\nI do not like this solution: a natural way to represent catalogs is by making them properties. I think sacrificing this natural design in order to make the calls to common and less-common parts of the API more similar is not a good idea."
      },
      {
        "user": "Zruty0",
        "created_at": "2018-12-18T22:33:35Z",
        "body": "@singlis or anyone else: if we do not have a good suggestion for an alternative, I propose leaving the code as is."
      },
      {
        "user": "glebuk",
        "created_at": "2019-01-08T00:05:50Z",
        "body": "@singlis please review Pete's feedback. If agree with him, close."
      },
      {
        "user": "CESARDELATORRE",
        "created_at": "2019-02-20T19:29:39Z",
        "body": "I think it should be consistent so if some of the learners have to be methods because they are extension methods, then let's make all of them methods. \r\n\r\nFrom a user's point of view looks strange why some of them are methods and some of them are properties. We are propagating the way it is internally implemented to the way the API is designed (property vs. method) ... \r\n\r\nAlso, if something is a method, it should have a verb as part of the name... \r\n\r\nI'm adding @eerhardt in case these approaches are changing due to his work on the catalog and removing MEF.\r\n\r\n"
      },
      {
        "user": "singlis",
        "created_at": "2019-03-29T00:54:10Z",
        "body": "Very sorry for the late reply, I know I am well overdue.\r\n\r\nI would rather not have an MLContext along with these discover-able methods for APIs and instead use namespaces. This problem would be solved across assemblies if the APIs were scoped by namespaces rather than within members of a class. This could then simply be \r\n```\r\nfoo1 = Microsoft.ML.BinaryClassification.LogisticRegression();\r\nvar foo2 = Microsoft.ML.Transforms.OneHotEncoding();\r\n```\r\n\r\nBut I know, I know, then we would have to pass MLContext around. That is a whole other discussion... that has been talked about a lot and I don't want to re-hash it here. \r\n\r\nSince we are not there and we have mlContext, then I agree with @CESARDELATORRE in that we should always use parenthesis and be consistent. This would allow us to have MLContext extensions defined in their respective assembly and therefore the category would only show on mlContext if its available.\r\n\r\nFor example when I type `mlContext.Ranking.Trainers` -- nothing shows up in the pop-up window (with the exception of the defaults Equals, ToString). I then have to install a nuget that contains a Ranking  trainer -- so if I install `Microsoft.ML.LightGBM`, Trainers then gets populated with LightGbm. This is a very disconnected experience -- how do I know I need to install a nuget? Why do I see Ranking at all when I dont have the proper assemblies yet?\r\n\r\nRecommendation works more like how I would expect: if the `Microsoft.ML.Recommender` nuget is installed, I can now see Recommendation on mlContext (it is a function) and when I type `mlContext.Recommendation().Trainers` I can see a list of trainers to choose from. \r\n"
      }
    ]
  },
  {
    "number": 1819,
    "title": "CreatePredictionEngine<TSrc, TDst> is internal now. What is replacement?",
    "created_at": "2018-12-04T15:55:16Z",
    "closed_at": "2018-12-19T17:55:13Z",
    "labels": [
      "bug",
      "question"
    ],
    "url": "https://github.com/dotnet/machinelearning/issues/1819",
    "body": "The CreatePredictionEngine method is internal now. What is replacement for trainedModel (ITransfomer) and scheme (SchemaDefinition)? MakePredictionFunction can't use SchemaDefinition and makes exception for me.\r\n\r\n",
    "comments_url": "https://api.github.com/repos/dotnet/machinelearning/issues/1819/comments",
    "author": "NektoDron",
    "comments": [
      {
        "user": "singlis",
        "created_at": "2018-12-04T19:01:59Z",
        "body": "Thank you for the question. \r\n\r\nMakePredictionFunction is a generic extension on ITransformer -- so you should be able to call trainedModel.MakePredictionFunction. The schema for the input and output is determined from the generic arguments <TSrc, TDst>. These should be classes that have the format for the input (TSrc) and output (TDst). \r\n\r\nCan you show an example of how you are using this now?\r\n"
      },
      {
        "user": "NektoDron",
        "created_at": "2018-12-05T05:02:41Z",
        "body": "I can't define scheme in the TSrc's attributes because I have a VBuffer<float> Feature field with a dynamic size. I make data and scheme definition on run-time and it was possible in the 0.7 and not possible in the 0.8+ versions. To be more exact I can make DataView with a dynamic scheme and train model with it, but I can't use its model for prediction because it makes exception like \"Incompatible features column type: 'Vec<R4>' vs 'Vec<R4, 9>'\"."
      },
      {
        "user": "Zruty0",
        "created_at": "2018-12-06T01:27:24Z",
        "body": "@NektoDron , thank you for reporting this issue. It looks like we have a gap in capabilities: there is no overload to `MakePredictionFunction` that takes `schemaDefinition` of input and output, like `CreatePredictionEngine` did.\r\n\r\nIt is a minor bug, we should be able to fix it quickly."
      }
    ]
  },
  {
    "number": 1806,
    "title": "Usage of Matrix Factorization Trainer for Recommendation ",
    "created_at": "2018-12-03T02:41:46Z",
    "closed_at": "2018-12-07T18:43:52Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnet/machinelearning/issues/1806",
    "body": "When using Matrix Factorization Trainer:\r\n\r\n ```csharp\r\nvar trainer = mlcontext.Recommendation().Trainers.MatrixFactorization\r\n                                                     (\"userIdEncoded\", \"movieIdEncoded\", \"rating\"));\r\n```\r\nWhen using other trainers:\r\n\r\n ```csharp\r\nvar trainer = mlContext.Regression.Trainers.StochasticDualCoordinateAscent\r\n                                                       (label: \"Label\", features: \"Features\");\r\n``` \r\n\r\nIs the difference in usage prop vs. method by design? Also there is a difference in the order of parameters being passed. First parameter is Label vs. Features being used. \r\n",
    "comments_url": "https://api.github.com/repos/dotnet/machinelearning/issues/1806/comments",
    "author": "asthana86",
    "comments": [
      {
        "user": "wschin",
        "created_at": "2018-12-03T19:07:14Z",
        "body": "```csharp\r\nvar trainer = mlcontext.Recommendation().Trainers.MatrixFactorization\r\n                                                    (\"userIdEncoded\", \"movieIdEncoded\", \"rating\"));\r\n```\r\nis equivalent to\r\n```csharp\r\nvar trainer = mlcontext.Recommendation().Trainers.MatrixFactorization\r\n                                                    (matrixColumnIndexColumnName: \"userIdEncoded\", matrixRowIndexColumnName: \"movieIdEncoded\", labelColumn: \"rating\"));\r\n```\r\naccording to its signature\r\n```csharp\r\n        /// <summary>\r\n        /// Initializing a new instance of <see cref=\"MatrixFactorizationTrainer\"/>.\r\n        /// </summary>\r\n        /// <param name=\"env\">The private instance of <see cref=\"IHostEnvironment\"/>.</param>\r\n        /// <param name=\"matrixColumnIndexColumnName\">The name of the column hosting the matrix's column IDs.</param>\r\n        /// <param name=\"matrixRowIndexColumnName\">The name of the column hosting the matrix's row IDs.</param>\r\n        /// <param name=\"labelColumn\">The name of the label column.</param>\r\n        /// <param name=\"advancedSettings\">A delegate to apply all the advanced arguments to the algorithm.</param>\r\n        public MatrixFactorizationTrainer(IHostEnvironment env,\r\n            string matrixColumnIndexColumnName,\r\n            string matrixRowIndexColumnName,\r\n            string labelColumn = DefaultColumnNames.Label,\r\n            Action<Arguments> advancedSettings = null)\r\n            : base(env, LoadNameValue)\r\n```\r\n\r\nInstead of a single feature `Column` and a label `Column`, matrix factorization requires row index `Column`, column index `Column`, and label `Column`. For example, assume that\r\n```\r\nrow index column = [0, 3, 1]\r\ncolumn index column = [2, 1, 0]\r\nlabel column = [7, 7, 8]\r\n```\r\nthe 4-by-3 rating matrix being factorized may be\r\n```\r\n[? ? 7]\r\n|8 ? ? |\r\n|? ? ? |\r\n[? 7 ?]\r\n```\r\nwhere `?` happens at row `u` and column `v` means user `u` never rates `v` in your training data. Note that I assume those IDs are 0-based indexes."
      },
      {
        "user": "asthana86",
        "created_at": "2018-12-03T20:11:25Z",
        "body": "Two questions still: \r\n\r\nWhy are these different:\r\n            var foo = mlContext.Regression.Trainers;\r\n            var foo_bar = mlContext.BinaryClassification.Trainers;\r\n            var foo_moo_bar = mlContext.Recommendation().Trainers;\r\n\r\nvs \r\n           var foo_moo_bar = mlContext.Recommendation.Trainers\r\n\r\nand then the order of parameters again for consistency? other trainers seem to take Label as the first parameter for input. so this instead. \r\n\r\nvar trainer = mlcontext.Recommendation().Trainers.MatrixFactorization\r\n                                                    (labelColumn: \"rating\", matrixColumnIndexColumnName: \"userIdEncoded\", matrixRowIndexColumnName: \"movieIdEncoded\"));\r\n\r\n\r\n\r\n\r\n\r\n\r\n"
      },
      {
        "user": "wschin",
        "created_at": "2018-12-03T22:31:53Z",
        "body": "@assafi, for your second question, matrix factorization is a special problem. It's not standard regression/classification which maps a feature vector to a label, so it looks not very bad to have label as the last argument. Of course, you can submit a PR if this doesn't look good enough for you. It should be a minor change."
      },
      {
        "user": "singlis",
        "created_at": "2018-12-04T01:06:46Z",
        "body": "Hi @asthana86, \r\n\r\nFor the question about the differences in the mlContext api calls, please  see issue #1770 as this addresses your question. It is because Recommendation is not part of the core nuget package and therefore is defined as an extension rather than a property of MLContext. \r\n\r\nFor the ordering of label columns in the matrix factorization, we can create an issue on this or use this as an the issue for tracking. \r\n"
      },
      {
        "user": "asthana86",
        "created_at": "2018-12-04T01:14:04Z",
        "body": "I am not sure if #1770 addresses my issue. #1770 is about discoverability, the fix we came up for that was one needs to acquire the MatrixFactorization Nuget for now. I do agree with @GalOshri its not the best experience but even with that nuget acquisition the usage pattern should remain the same.  \r\n\r\nGiven the need to acquire an additional NuGet is there no way to have the API be consistent like the one that follows? It just looks a bit odd from a user perspective. \r\n\r\nmlcontext.Recommendation.Trainers.MatrixFactorization\r\n\r\ninstead of\r\n\r\nmlcontext.Recommendation().Trainers.MatrixFactorization\r\n\r\nIn terms of the other issue, it might be worth it creating a list of all learners on order of input parameters /output parameters and follow it across. I have been working on exporting these samples to 0.8 and after playing with Regression, Classification the recommendation ML task is a bit less consistent to other MLTasks. \r\n\r\n\r\n\r\n"
      },
      {
        "user": "singlis",
        "created_at": "2018-12-04T02:26:08Z",
        "body": "I agree with you @asthana86 it is odd from the user's perspective and I think we could do better here - The current implementation has the trainers declared as properties on MLContext. This current implementation does not work when the code lives in a different nuget package (i.e. we can't add a RecommendationContext property on MLContext since we aren't guaranteed the nuget is installed). \r\n\r\nI would like to see if there are other ways where this could be more flexible based on what nugets are installed by the user. It would need some investigation - but your main point is that the api needs to be consistent, right?\r\n\r\nAlso we are in talks with the .net core team regarding API changes. I think this is something worth discussing with them. @TomFinley, @Zruty0, @eerhardt\r\n\r\nI want to separate the issues to get more specific, here are the issues as I understand:\r\nIssue 1 - The trainer API for MLContext is inconsistent for learner in external nugets\r\nIssue 2 - MatrixFactorization construction parameters are not consistent with other learners.\r\n\r\nI also like the idea of having consistent parameter usage and confirming if this is consistent across the board. Looking through our existing issues, there is a number of issues titled \"Final Public API *\" for learners and transforms. For example there is #1703.  While they do mention public constructor, they do not mention consistent parameter usage so I added a note to the issue."
      },
      {
        "user": "asthana86",
        "created_at": "2018-12-04T03:38:06Z",
        "body": "Sounds great. Thanks for capturing this. \r\n\r\n"
      },
      {
        "user": "singlis",
        "created_at": "2018-12-05T02:02:06Z",
        "body": "Thanks @asthana86.  For reference, I filed the two issues\r\n#1827 The trainer API for MLContext is inconsistent for learner in external nugets\r\n#1826 - MatrixFactorization construction parameters are not consistent with other learners.\r\n\r\nI will keep this issue open for a few days in case there is any other things to discuss."
      },
      {
        "user": "singlis",
        "created_at": "2018-12-07T18:43:52Z",
        "body": "Closing as we have the other two issues filed."
      }
    ]
  },
  {
    "number": 1713,
    "title": "How to use Feature selection ",
    "created_at": "2018-11-22T13:11:20Z",
    "closed_at": "2019-01-14T22:09:10Z",
    "labels": [
      "question",
      "documentation"
    ],
    "url": "https://github.com/dotnet/machinelearning/issues/1713",
    "body": "I want to use FeatureSelectorByMutualInformation feature selection, can you please provide me a sample code snippet how to use it with a dataset,  i could not able find in the samples provided. ",
    "comments_url": "https://api.github.com/repos/dotnet/machinelearning/issues/1713/comments",
    "author": "Vijay27anand",
    "comments": [
      {
        "user": "shmoradims",
        "created_at": "2018-11-26T23:14:10Z",
        "body": "That transform is changed to MutualInformationFeatureSelector. The documentation for is not rendering properly. I've added issue #1725 to fix it."
      },
      {
        "user": "glebuk",
        "created_at": "2019-01-14T22:09:10Z",
        "body": "@Vijay27anand,\r\nThanks for reporting this issue!\r\nPlease track it via #1725 \r\nclosing."
      }
    ]
  },
  {
    "number": 1693,
    "title": "QUESTION: The \"pipeline\" is immutable; sometimes a chain of Estimators, sometimes a single Estimator. Easy to understand?",
    "created_at": "2018-11-21T01:41:01Z",
    "closed_at": "2018-11-28T01:19:57Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnet/machinelearning/issues/1693",
    "body": "This is just an observation of a possible risk. I'm not saying that my hypothetical proposal below is better, since it is probably less flexible. I just would like to get feedback from the community about our current approach to double-check we're on the right path.\r\n\r\nThe fact that a \"pipeline\" sometimes is a \"chain of estimators\", but sometimes \"it can be\" a single estimator could be confusing for developers. For instance:\r\n\r\nIn this case \"dataProcessPipeline\" is a single Estimator of type `TextFeaturizingEstimator`:\r\n\r\n`var dataProcessPipeline = mlContext.Transforms.Categorical.MapValueToKey(\"Area\", \"Label\")\r\n;`\r\n\r\nIn this other case below, \"dataProcessPipeline\" is a chain of estimators of type `EstimatorChain<TTrans>`, as soon as you call the first `Append()`:\r\n\r\n```\r\nvar dataProcessPipeline = mlContext.Transforms.Categorical.MapValueToKey(\"Area\", \"Label\")\r\n                .Append(mlContext.Transforms.Text.FeaturizeText(\"Title\", \"TitleFeaturized\"))\r\n                .Append(mlContext.Transforms.Text.FeaturizeText(\"Description\", \"DescriptionFeaturized\"))\r\n                .Append(mlContext.Transforms.Concatenate(\"Features\", \"TitleFeaturized\", \"DescriptionFeaturized\"));\r\n```\r\n\r\nAlso, the fact that an EstimatorChain pipeline is created from its first element might also be confusing?\r\n\r\nSimplifying and in comparison, when you create a List or collection in C# you first create the List (the box) then add things/elements  into it. You usually don't create a collection of items from the first item but you create the \"box\" first, then add items. But that is for mutable collections. Not the same! :)\r\n\r\nIn the case of our current EstimatorChain it is using a more advanced pattern based on fluent API and immutable objects. Since each estimator and estimator-chain is immutable, when you append another estimator in reality you are creating a new estimator-chain and returning that new pipeline (estimator-chain).\r\n\r\n**QUESTION: Is this pattern clear or confusing for you?**\r\n\r\nA different approach based on a typical **mutable** collection could be something like the following (This is NOT how ML.NET currently works and might require different types):\r\n\r\n```\r\n//DataView with dataset\r\nIDataView trainingDataView = textLoader.Read(TrainDataPath);\r\n\t\t\r\n// Create an \"empty\" EstimatorChain, the \"box\", which would be mutable, as it'll be growing with items:\r\nvar dataProcessPipeline = MLContext.CreateEstimatorChain();\r\n\r\n// Add Estimators to the same chain/pipeline\r\ndataProcessPipeline.Append(mlContext.Transforms.CopyColumns(\"FareAmount\", \"Label\");\r\ndataProcessPipeline.Append(mlContext.Transforms.Categorical.OneHotEncoding(\"VendorId\", \"VendorIdEncoded\"));\r\ndataProcessPipeline.Append(mlContext.Transforms.Normalize(inputName: \"TripTime\", mode: NormalizerMode.MeanVariance));\r\ndataProcessPipeline.Append(mlContext.Transforms.Concatenate(\"Features\", \"VendorIdEncoded\", \"TripTime\"));\r\n\r\n//... Peek data into the DataView, etc. if you want\r\n\r\n//Optional - Clone the pipeline with data transformations in case you want to reuse the dataProcessPipeline for parallel executions of additional trainers\r\nvar trainingPipeline = dataProcessPipeline.Clone();\r\n\r\n//Add trainer to the training pipeline\r\nvar sdcaTrainer = mlContext.Regression.Trainers.StochasticDualCoordinateAscent(label: \"Label\", features: \"Features\");\r\ntrainingPipeline.Append(sdcaTrainer);\r\n\r\n//Train the model fitting to the dataSet\r\nvar trainedModel = trainingPipeline.Fit(trainingDataView);\r\n```\r\nIn this last code, when you execute dataProcessPipeline.Append(estimator) it is really appending an estimator into that current pipeline. \r\n\r\nIn comparison and shown below, with our current API, when adding a trainer, you have to \"catch\" the returned pipeline, as the estimator/trainer was added only to the returned new pipeline, not to the pipeline owning the method Append() you run.\r\n\r\n```\r\n//Add trainer to the training pipeline\r\nvar sdcaTrainer = mlContext.Regression.Trainers.StochasticDualCoordinateAscent(label: \"Label\", features: \"Features\");\r\nvar trainingPipeline = dataProcessPipeline.Append(sdcaTrainer);\r\n\r\n//Train the model fitting to the dataSet\r\nvar trainedModel = trainingPipeline.Fit(trainingDataView);\r\n```\r\nThat's also why you don't need to clone the pipeline if you want to \"fork\" it, since every time you call Append() you are creating a new pipeline, so you could \"fork\" whenever you call .Append().\r\n\r\nAs summary, in our current API, .Append() is not appending anything into the current pipeline, but creating and returning a new pipeline (EstimatorChain) with that new estimator appended.\r\n\r\nOur current approach is probably more flexible based on immutable EstimatorChains but I'd like to double check if our current approach is clear for anyone learning the API.\r\n\r\n What are your thoughts about it?\r\nCan you provide your feedback? 👍 \r\nThanks, \r\n \r\n\r\n",
    "comments_url": "https://api.github.com/repos/dotnet/machinelearning/issues/1693/comments",
    "author": "CESARDELATORRE",
    "comments": [
      {
        "user": "Zruty0",
        "created_at": "2018-11-21T18:34:02Z",
        "body": "I will not comment on the user adoption / likability of the API, I would like to point out more of an architectural concern: we expect 'estimators' to be passed to some (potentially lazy) methods that will fit them (maybe repeatedly) at their convenience. \r\n\r\nHaving estimator pipelines (that are estimators) mutable looks dangerous in this case: it will immediately compromise thread-safety, and introduce a potential for confusion.\r\n\r\nI also pinged folks on Gitter to provide more user feedback on this."
      },
      {
        "user": "lobrien",
        "created_at": "2018-11-22T00:24:20Z",
        "body": "I'm +1 on such a pattern. Developers likely to engage with ML.NET are likely to be familiar with the benefits of immutability. Even if they're not, the pattern is not confusing. My only question would be whether `Append` is the best name. Might `Concat` lead to better intuitions? "
      },
      {
        "user": "mariuszwojcik",
        "created_at": "2018-11-22T06:26:59Z",
        "body": "I do not think it is confusing at all. Even when you look at the *List* example, now most likely you will find people using collection initialisers, like:\r\n```csharp\r\nList<Cat> cats = new List<Cat>\r\n{\r\n    new Cat(){ Name = \"Sylvester\", Age=8 },\r\n    new Cat(){ Name = \"Whiskers\", Age=2 },\r\n    new Cat(){ Name = \"Sasha\", Age=14 }\r\n};\r\n```\r\nwhich is very similar to the append sample above. Less flexible though. And, as mentioned before, immutability brings plenty of benefits, like thread-safety."
      },
      {
        "user": "rauhs",
        "created_at": "2018-11-22T06:30:06Z",
        "body": "I also very much like the immutable API (I'm mostly doing Clojure so this is very natural). Forgetting to \"catch\" the return value of `.Append` can certainly be source of bugs. It seems that tagging the method as `[Pure]` would at least tell visual studio to give a wiggly line if you don't assign it a value. But then: The method isn't really pure, is it?"
      },
      {
        "user": "MarcoZama",
        "created_at": "2018-11-22T21:43:33Z",
        "body": "Personally i like pattern. I agree with @lobrien that probably the name misleading. "
      },
      {
        "user": "shmoradims",
        "created_at": "2018-11-26T23:26:07Z",
        "body": "@CESARDELATORRE , seems like everybody is in favor of immutable pipelines. If you're happy with the results, could you please close the issue?"
      },
      {
        "user": "CESARDELATORRE",
        "created_at": "2018-11-26T23:31:39Z",
        "body": "Right, sounds great that folks like our current approach, but we just had four comments. It would be good to keep it some more time to gather more feedback? :)"
      },
      {
        "user": "TomFinley",
        "created_at": "2018-11-28T00:00:20Z",
        "body": "That's fine @CESARDELATORRE , but as @Zruty0 already pointed out we simply *cannot* have `IEstimator`s be mutable. If we lived in a world where `SchemaShape GetOutputSchema(SchemaShape inputSchema)` could potentially return different results at different times depending on the state of the estimator, it would be practically impossible to compose chains of estimators. This composability of estimators is a core aspect of this software, and it absolutely relies on immutability to work at all. You'll note also that `IEstimator`'s return a transformer type -- mutability would wreak havoc with that as well.\r\n\r\nNote that this reasoning would hold even in the hypothetical world where, say, you'd received one thousand people noisily agreeing with you that having the basis of our data pipelines be objects with constantly mutating state was somehow a less confusing situation. Good software architecture must be a more deliberative process than merely holding loose straw polls."
      },
      {
        "user": "CESARDELATORRE",
        "created_at": "2018-11-28T01:19:57Z",
        "body": "I agree on that but the API usage experience can usually be improved that's why we also ask for feedback.\r\nIn any case, we all agree that our current approach is good and folks providing feedback in this thread also like it, so let's close the issue. If there's related feedback in the future we can correlate the issues. 👍  "
      },
      {
        "user": "jcapellman",
        "created_at": "2019-01-06T06:05:40Z",
        "body": "Creating a generic method like this:\r\nvoid TrainModel<T>(MLContext mlContext, string trainDataPath, string modelPath)\r\n\r\nGetting the Column property for my TextReader was trivial to enumerate over T with Reflection.\r\n\r\nIn addition, getting my Label with Reflection was also obtainable.\r\n\r\nThe problem came after:\r\nvar dataProcessPipeline = mlContext.Transforms.CopyColumns(label.Name, \"Label\");\r\n\r\nIn the examples where the OneHotEncoding and/or Normalize get chained works well, but in my case iterating through and appending to my dataProcessPipeline doesn't work with this API.\r\n\r\nI guess I may be one of the few devs making 100% dynamic methods compared to dedicated methods for a given model, but wanted to chime in."
      }
    ]
  },
  {
    "number": 1380,
    "title": "Need predictedLabel in binary classification as original string value (not bool)",
    "created_at": "2018-10-25T18:35:11Z",
    "closed_at": "2019-03-29T05:24:51Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnet/machinelearning/issues/1380",
    "body": "Using ML.NET NuGet 0.7.0-preview-27025-1.\r\n\r\nI have a binary classification dataset with string labels: \"Spam\", \"Not Spam\". \r\nI need to use the TermEstimator to turn the label into a key for the training to work. \r\nOne output in the prediction from the binary classifier (let's say SDCA), is predictedLabel, which is a bool. \r\n\r\nHow do I map the bool back to \"Spam\" or \"Not Spam\"? \r\n\r\nThank you!",
    "comments_url": "https://api.github.com/repos/dotnet/machinelearning/issues/1380/comments",
    "author": "GalOshri",
    "comments": [
      {
        "user": "artidoro",
        "created_at": "2018-10-26T23:31:47Z",
        "body": "@TomFinley should the predictedLabel in the output of a binary classifier be a bool, or should it be a key?"
      },
      {
        "user": "Ivanidzo4ka",
        "created_at": "2019-03-29T05:24:51Z",
        "body": "You should use MapKeyToValue on \"PredictedLabelColumn\""
      }
    ]
  },
  {
    "number": 948,
    "title": "Public space such as Wiki for accumulating knowledge about ML.NET",
    "created_at": "2018-09-19T18:40:39Z",
    "closed_at": "2019-06-30T06:44:22Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnet/machinelearning/issues/948",
    "body": "Do we have any places like a Wiki? I'd like to have a place to share some small knowledge related to ML.NET. Here is an example.\r\nToday, I changed the signature of SaveOnnx and then got two tests failed, TestGeneratedCSharpAPI and EntryPointCatalog. The solution is very straightforward, when you know the answer.\r\n\r\nSolution:\r\n\r\n1. Open Microsoft.ML.sln under Visual Studio\r\n2. Go to Test Explorer\r\n3. Find the test code of `RegenerateEntryPointCatalog()` in TestEntryPoints.cs and change its `[Fact(Skip = \".....\")]` to `[Fact()]`' and then run it. Then, you will see (via `git diff`) core_mainfest.json gets changed. Include those changes into your commit. Note that with the existence of `Skip =`, Test Explorer may not execute your test anyway.\r\n4. Find the test code of `RegenerateCSharpApi()` in CSharpCodeGen.cs and change its `[Fact(skip = \".....\")]` to `[Fact()]` and also commit the changes (CSharpApi.cs) induced by running this test.\r\n\r\nI personally like GitHub issues with a better tag name such as \"knowledge\" so that we have one place for all.",
    "comments_url": "https://api.github.com/repos/dotnet/machinelearning/issues/948/comments",
    "author": "wschin",
    "comments": [
      {
        "user": "wschin",
        "created_at": "2018-11-08T17:31:17Z",
        "body": "Another trick when your changes modify the output files produced by some tests and therefore those tests fail. It's pretty annoying when I am trying to locate those touched files. My solution is\r\n1. Go to `BaseTestBaseline.cs` and set up a break point inside `protected bool CheckEqualityCore(string dir, string name, string nameBase, bool normalize, int digitsOfPrecision = DigitsOfPrecision)`\r\n2. In `CheckEqualityCore`, you can find all the paths: `basePath` is the expected output file while `outPath` is the result produced by your code.\r\n3. A broken test can be fixed by copying the `outPath` file to `basePath`."
      },
      {
        "user": "codemzs",
        "created_at": "2019-06-30T06:44:22Z",
        "body": "we have dot.net/ml and docs."
      }
    ]
  },
  {
    "number": 915,
    "title": "Trying to left-outer join two datasets using a PK/FK",
    "created_at": "2018-09-14T17:15:37Z",
    "closed_at": "2018-10-03T17:58:09Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnet/machinelearning/issues/915",
    "body": "Is there any way to manipulate the input data in order to join two distinct datasets using a primary key/foreign key?  Is the expectation that the input from the TextLoader is always partially pre-processed?",
    "comments_url": "https://api.github.com/repos/dotnet/machinelearning/issues/915/comments",
    "author": "ftdube",
    "comments": [
      {
        "user": "Zruty0",
        "created_at": "2018-09-17T18:08:37Z",
        "body": "Generally, in ML.NET we tried to move away from relational operations, and assume that the input data is already a single 'view' (think SQL view).\r\n\r\nThe reasoning was that there has been a lot of research and a lot of work already done for relational operations, and we'd rather not make a mediocre effort at that.\r\n\r\nSo, yes, the expectation is that any JOINs and other relational operations are conducted prior to loading the data into ML.NET"
      },
      {
        "user": "ftdube",
        "created_at": "2018-10-03T17:58:09Z",
        "body": "Got it, makes total sense, thank you :)"
      }
    ]
  },
  {
    "number": 908,
    "title": "Command Line Usages",
    "created_at": "2018-09-13T23:38:45Z",
    "closed_at": "2018-10-22T20:59:08Z",
    "labels": [
      "question",
      "documentation"
    ],
    "url": "https://github.com/dotnet/machinelearning/issues/908",
    "body": "Are command line tool exposed to users with some docs? It looks it's not straightforward for external users to use command line to train a model. Thanks.",
    "comments_url": "https://api.github.com/repos/dotnet/machinelearning/issues/908/comments",
    "author": "wschin",
    "comments": [
      {
        "user": "Zruty0",
        "created_at": "2018-10-22T20:59:08Z",
        "body": "I'm going to close it in favor of its duplicate, #1203 "
      }
    ]
  },
  {
    "number": 498,
    "title": "Which model type should I use for financial price prediction?",
    "created_at": "2018-07-05T16:27:16Z",
    "closed_at": "2018-10-22T16:28:29Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnet/machinelearning/issues/498",
    "body": "First of all thank you for the great library!\r\nMy question is simple: I want to predict next period price with pre-computed history values.\r\nI have over 30 rows data for each price.\r\nPrice and datas are decimal.\r\n\r\nFor example history:\r\nIndicator1 - Indicator 2 - Indicator 3 - Price - **Trend**\r\n10,01121 - 23,56540 - 12.00001 - 12,23321 - UP\r\n9,00001 - 3,00040 - 2.00001 - 1,23300 - DOWN\r\n...\r\n...\r\nAnd data to predict coming like\r\n8,11211 - 1,00020 - 0.00021 - 3,5555 - ?\r\nI want to get **TREND** field.\r\n\r\nWhich model should I use? Any example will be perfect?\r\nRegards!",
    "comments_url": "https://api.github.com/repos/dotnet/machinelearning/issues/498/comments",
    "author": "ErcinDedeoglu",
    "comments": [
      {
        "user": "justinormont",
        "created_at": "2018-07-05T16:54:06Z",
        "body": "You turned this into a binary classification problem (UP vs. DOWN), so any of the binary classifiers should give you a working model. \r\n\r\nI'm unsure which are exposed w/ a nice ML.NET interface, but the repo has code for these:\r\n\r\n-   AveragedPerceptron: Averaged Perceptron\r\n-   BinaryClassificationGamTrainer: Generalized Additive Model for Binary Classification\r\n-   BinarySGD: Hogwild SGD (binary)\r\n-   FastForestClassification: Fast Forest Classification\r\n-   FastTreeBinaryClassification: FastTree (Boosted Trees) Classification\r\n-   FieldAwareFactorizationMachine: Field-aware Factorization Machine\r\n-   LightGBMBinary: LightGBM Binary Classifier\r\n-   LinearSVM: SVM (Pegasos-Linear)\r\n-   LogisticRegression: Logistic Regression\r\n-   PriorPredictor: Prior Predictor\r\n-   RandomPredictor: Random Predictor\r\n-   SDCA: Fast Linear (SA-SDCA)\r\n-   WeightedEnsemble: Parallel Ensemble (bagging, stacking, etc)\r\n\r\nAlso, of notable importance, you'll want to ensure that your Train & Test datasets are split on time (all newer rows are in the test set). Splitting on company (train & test dataset don't have any companies in common) is almost as good, but will still leak some information like raising tide effects."
      },
      {
        "user": "abgoswam",
        "created_at": "2018-10-18T18:49:56Z",
        "body": "DRI RESPONSE : Looks like question has been answered. Plan to close this issue in the next 1-2 days"
      }
    ]
  },
  {
    "number": 495,
    "title": "Time Series support",
    "created_at": "2018-07-05T13:52:10Z",
    "closed_at": "2018-10-22T16:28:18Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnet/machinelearning/issues/495",
    "body": "Quick question: I know that right now there is no real support for time series.... ( both on the data input side as well as in the implemented Learners ) \r\n\r\nHowever before i could often solve my case by windowing over the sequential stream of events i wanted to base my prediction on e.g \r\n\r\nFor this i would need Collection support for columns... is this possible right now ? \r\n\r\nE.g \r\n\r\nclass MeasurementTick  {\r\n\r\n   DateTime TimeStamp { get; set; }\r\n   float Temperature { get; set; }\r\n   float Pressure { get; set; }\r\n}\r\n\r\nclass FixedSizeMeasureMentWindow {\r\n   IList<MeasurementTick> Ticks { get; set; }\r\n}\r\n\r\nUsing FixedSizeMeasureMentWindow as my input data type.... \r\n\r\n",
    "comments_url": "https://api.github.com/repos/dotnet/machinelearning/issues/495/comments",
    "author": "BernhardGlueck",
    "comments": [
      {
        "user": "abgoswam",
        "created_at": "2018-10-18T18:48:04Z",
        "body": "DRI RESPONSE : Adding support for time series is being tracked using issue #978. Planning to close this issue (duplicate of #978)"
      }
    ]
  },
  {
    "number": 283,
    "title": "When will 0.2.0 be released?",
    "created_at": "2018-06-01T09:07:20Z",
    "closed_at": "2018-06-06T07:57:55Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnet/machinelearning/issues/283",
    "body": "I'm champing at the bit to open packaging.",
    "comments_url": "https://api.github.com/repos/dotnet/machinelearning/issues/283/comments",
    "author": "ecofee",
    "comments": [
      {
        "user": "shauheen",
        "created_at": "2018-06-01T17:01:07Z",
        "body": "We are planning for release on Tuesday June 5th."
      },
      {
        "user": "glebuk",
        "created_at": "2018-06-05T17:34:14Z",
        "body": "@ecofee,\r\nGlad you asked, 0.2 has just been released.  Please take a look!"
      }
    ]
  },
  {
    "number": 257,
    "title": "Is it possible update model without retraining?",
    "created_at": "2018-05-29T03:08:28Z",
    "closed_at": "2018-10-22T16:26:36Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnet/machinelearning/issues/257",
    "body": "Hello.\r\n\r\n1, I want to update stored model after read it. I don't want to retrain whole data. How can I do this?\r\n2. Can I load data from c# collection or just string for generate model, not file or stream?",
    "comments_url": "https://api.github.com/repos/dotnet/machinelearning/issues/257/comments",
    "author": "ecofee",
    "comments": [
      {
        "user": "TomFinley",
        "created_at": "2018-05-31T00:28:48Z",
        "body": "Hi @ecofee just clarifying, are you talking about online learning? Or some other scenario?"
      },
      {
        "user": "ecofee",
        "created_at": "2018-05-31T02:33:36Z",
        "body": "Hi~ @TomFinley \r\nYes. It could be one of the scenarios. I want to update model with newly inserted records in database, not whole records every time when I try to retrain sometimes. It could be real time or not. So, I want to know how can I do this.\r\n\r\nAnd I convert records from database into text file for training. I think this is inefficient. So, I hope I had another options like training from String, Collections. Maybe I could be mistaken about that."
      },
      {
        "user": "TomFinley",
        "created_at": "2018-06-01T05:34:40Z",
        "body": "Regarding the first question, no, sorry. The underlying code supports it for a few learners, but this sort of graph composition layer does not. So we're somewhat out of luck at the moment.\r\n\r\nRegarding the second question, about working over stuff in memory vs. materializing to disk, do you think #106 helps? Or is that insufficient?"
      },
      {
        "user": "ecofee",
        "created_at": "2018-06-01T10:19:48Z",
        "body": "OK. I understand. Thanks. @TomFinley "
      },
      {
        "user": "abgoswam",
        "created_at": "2018-10-18T18:10:44Z",
        "body": "DRI RESPONSE: Issue seems to have been answered. I plan to close the issue withing the next few days."
      }
    ]
  },
  {
    "number": 246,
    "title": "Question about \"Unknown\" classification",
    "created_at": "2018-05-27T06:51:31Z",
    "closed_at": "2018-12-07T23:52:10Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnet/machinelearning/issues/246",
    "body": "Hello,\r\n\r\nWhen using a multiclass classifier, eg ``StochasticDualCoordinateAscentClassifier``, the scores are all relative to 1.\r\n\r\nWhat is the best way to detect when there are no suitable matches, rather than the classifier leaning towards one of them?\r\n\r\nthanks",
    "comments_url": "https://api.github.com/repos/dotnet/machinelearning/issues/246/comments",
    "author": "Plasma",
    "comments": [
      {
        "user": "codemzs",
        "created_at": "2018-05-28T14:47:38Z",
        "body": "Hi @Plasma ,\r\n\r\nFor a given feature array every label is scored and the one with highest score is selected as \"PredictedLabel\". Every label is a match or no match up to a certain magnitude. Does that answer your question?"
      },
      {
        "user": "Plasma",
        "created_at": "2018-05-29T01:20:34Z",
        "body": "Hey @codemzs ,\r\n\r\nI think it confirms my understanding, but to give a more concrete example:\r\n\r\nSay I have a multi-class classifier that has been trained to match against Red, Green and Blue colors.\r\n\r\nIf I then present a Yellow color, something it has never seen before, in my testing I will still get back scores that add up to 1.0, eg  0.1 red, 0.7 green, 0.2 blue (0.1 + 0.7 + 0.2 == 1.0) and thus are all just a ratio between each other. If I were to have an internal cutoff of at least 70% score for a predicted label to be correct, I'd incorrectly pick Green here, instead of the score being too low to match.\r\n\r\nI'd ideally expect, having not seen Yellow before, the scores returned are more likely say 0.1, 0.1, 0.2 -- or something that is very low score for all known classifications. But it seems all scores returned always add up to 1.0, so for an unknown class being classified, it can still strongly appear as a known class.\r\n\r\nIf my understanding is correct, that all scores from the classifier add up to 1.0 and are just ratios between each other, then I can't easily tell when the classifier has no idea what the presented color was."
      },
      {
        "user": "TomFinley",
        "created_at": "2018-05-30T20:12:21Z",
        "body": "The trouble though is, typical machine learning methods don't attempt to model unknown classes -- machine learning methods are trained on labeled data, they simultaneously make an IID assumption about their test data being similarly distributed. With typical loss functions for classification being softmax, they aren't even *trying* to model the problem of encountering data that looks different. It just isn't part of what they're trying to do, at all.\r\n\r\nThat said, the problem you've described is important, but the solution is actually to introduce a different method. Sometimes called one-class methods or more frequently nowadays anomaly detection models. The one we've migrated so-far is PcaAnomalyDetector (not in ML.NET v0.1, but surfaced AFAIK in #221 so will be in v0.2)."
      },
      {
        "user": "Plasma",
        "created_at": "2018-06-04T04:15:30Z",
        "body": "Thank you @TomFinley for the explanation. Looking forward to seeing more developments in ML.NET"
      },
      {
        "user": "sfilipi",
        "created_at": "2018-12-07T23:52:10Z",
        "body": "Closing since the question seems answered. "
      }
    ]
  },
  {
    "number": 237,
    "title": "Natural language generation from structured data",
    "created_at": "2018-05-24T18:25:11Z",
    "closed_at": "2019-06-30T02:42:17Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnet/machinelearning/issues/237",
    "body": "does ML.NET have a capability to extract text out of structured data ? Say for example , we have a stock data of a company over some years. I want to generate text based on a template for YoY Analysis.",
    "comments_url": "https://api.github.com/repos/dotnet/machinelearning/issues/237/comments",
    "author": "as-ghub",
    "comments": [
      {
        "user": "zeahmed",
        "created_at": "2018-05-24T19:12:03Z",
        "body": "Thanks for the question. Can you please elaborate more on this?\r\nI don't understand if you want to do text extraction or generation?\r\n\r\n"
      },
      {
        "user": "as-ghub",
        "created_at": "2018-05-24T20:14:16Z",
        "body": "Its text generation, I am talking about. Say I have sales for 2017 as 4M $ and 2018 its 5M$. I want to be able to generate text based on a template some think like this. \" The sales increased from 4M $ to 5M $ by xyz percentage.\". "
      },
      {
        "user": "zeahmed",
        "created_at": "2018-05-29T17:51:15Z",
        "body": "As far as I understand from the example above, this problem can be solved without using machine learning at all.\r\n\r\nCan you explain bit more why this problem would need machine learning?\r\n"
      },
      {
        "user": "codemzs",
        "created_at": "2019-06-30T02:42:17Z",
        "body": "closing as more info has not been provided since last year. Also as @zeahmed points this does not need ML. You seem to want to do some intelligent text generation using ML which can be achieved by using our transforms, trainers and some custom code that uses predictions results to generate text."
      }
    ]
  },
  {
    "number": 184,
    "title": "Feature type, input, and output validation should happen much earlier",
    "created_at": "2018-05-17T22:42:52Z",
    "closed_at": "2018-10-27T02:25:34Z",
    "labels": [
      "bug",
      "question"
    ],
    "url": "https://github.com/dotnet/machinelearning/issues/184",
    "body": "Validation of feature vector types, inputs, and outputs seems to happen randomly throughout the learning pipeline - sometimes after a few minutes, sometimes after an hour.  It would really be great if this happened up front so that errors could be corrected faster.  It would also be great if some of these were documented.\r\n\r\nFor example:\r\n```cs\r\npublic class InputData\r\n{\r\n    [Column(\"0\")]\r\n    public double input0;\r\n\r\n    [Column(\"1\")]\r\n    public double input1;\r\n\r\n    [Column(\"2\", name: \"Label\")]\r\n    public double output0;\r\n}\r\n\r\npublic class OutputData\r\n{\r\n    [ColumnName(\"Score\")]\r\n    public double output0;\r\n}\r\n\r\npublic class Program\r\n{\r\n    static void Main(string[] args)\r\n    {\r\n        var pipeline = new LearningPipeline();\r\n        pipeline.Add(new TextLoader<InputData>(\"mydata.txt\", separator: \"comma\"));\r\n        pipeline.Add(new ColumnConcatenator(\"Features\", \"input0\", \"input1\");\r\n        pipeline.Add(new FastTreeRegressor());\r\n        var model = pipeline.Train<InputData, OutputData>();\r\n    }\r\n}\r\n```\r\n\r\nRunning this with a very large \"mydata.txt\" gives output of:\r\n```\r\nNot adding a normalizer.\r\nMaking per-feature arrays\r\nChanging data from row-wise to column-wise\r\nWarning: We seem to be processing a lot of data. Consider using the FastTree diskTranspose+ (or dt+) option, for slower but more memory efficient transposition.\r\nProcessed 1112251 instances\r\nBinning and forming Feature objects\r\nReserved memory for tree learner: 10301148 bytes\r\nStarting to train ...\r\nNot training a calibrator because it is not needed.\r\n```\r\n\r\nAnd then about 15 minutes later, an exception occurs:\r\n```\r\nIncompatible features column type item type: 'R8' vs 'R4'\r\n\r\n   at Microsoft.ML.Runtime.Data.SchemaBindablePredictorWrapperBase.Bind(IHostEnvironment env, RoleMappedSchema schema)\r\n   at Microsoft.ML.Runtime.Data.GenericScorer.Bindings.Create(IHostEnvironment env, ISchemaBindableMapper bindable, ISchema input, IEnumerable`1 roles, String suffix, Boolean user)\r\n   at Microsoft.ML.Runtime.Data.GenericScorer..ctor(IHost host, ModelLoadContext ctx, IDataView input)\r\n   at Microsoft.ML.Runtime.Data.GenericScorer.<>c__DisplayClass15_0.<Create>b__0(IChannel ch)\r\n   at Microsoft.ML.Runtime.HostExtensions.Apply[T](IHost host, String channelName, Func`2 func)\r\n   at Microsoft.ML.Runtime.Data.GenericScorer.Create(IHostEnvironment env, ModelLoadContext ctx, IDataView input)\r\n```\r\n\r\nAfter lots of digging through code, it turns out only float types are supported - not doubles. Why didn't the docs say this and why wasn't I told almost immediately when I called Train()?",
    "comments_url": "https://api.github.com/repos/dotnet/machinelearning/issues/184/comments",
    "author": "shaunco",
    "comments": [
      {
        "user": "glebuk",
        "created_at": "2018-05-17T23:50:30Z",
        "body": "Thanks for reporting the issue.  Indeed, we should document that input and output fields for the pipeline should be float.   IT would be also good to validate input/output types first.\r\n\r\nThe actual reason for the observed behavior is that we automatically convert doubles to floats for training, however, the scoring code does not.  Scoring only fires after training is complete, in your case after 15 minutes.  "
      },
      {
        "user": "anneomcl",
        "created_at": "2018-06-08T21:36:49Z",
        "body": "Just ran into this as well, adding my +1 for documenting and validating inputs."
      },
      {
        "user": "jwood803",
        "created_at": "2018-06-19T12:51:15Z",
        "body": "Also, this error message `Incompatible features column type item type: 'R8' vs 'R4'` seems a bit vague. Would it be worthwhile to try to also make a more understandable error message as part of this?"
      },
      {
        "user": "artidoro",
        "created_at": "2018-10-27T02:25:34Z",
        "body": "We have implemented schema validation for pipelines as part of the new API. The schema is propagated through the pipeline before beginning training. I think this should solve the error that you were encountering.\r\n\r\nIn terms of documentation there is an active effort to improve what we currently have, please let us know if there are any specific parts that we should be developing further."
      }
    ]
  },
  {
    "number": 164,
    "title": "VectorType attribute with dynamic dimension",
    "created_at": "2018-05-15T22:41:23Z",
    "closed_at": "2019-06-30T02:32:09Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnet/machinelearning/issues/164",
    "body": "The `VectorType` attribute can be added to an array-valued field when the length of the array is known at compile time, e.g.,\r\n```\r\n        public class Data\r\n        {\r\n            [ColumnName(\"Features\")]\r\n            [VectorType(2)]\r\n            public float[] Features;\r\n\r\n            [ColumnName(\"Label\")]\r\n            public bool Label;\r\n        }\r\n```\r\n\r\nHowever, what if the length of the array is only known at run time?\r\n\r\nFor example, given `IEnumerable<Data> data` where the length of the `Features` array is given by `int numFeatures`, I need to be able to pass `numFeatures` to `CollectionDataSource.Create(data)` somehow, and remove the static `2` argument to the `VectorType` attribute on the `Features` field.",
    "comments_url": "https://api.github.com/repos/dotnet/machinelearning/issues/164/comments",
    "author": "mjmckp",
    "comments": [
      {
        "user": "zeahmed",
        "created_at": "2018-05-16T03:22:50Z",
        "body": "Can you please elaborate your `IEnumerable<Data>` example bit more? Usually, feature vector size is known and fixed for all the examples in the dataset. I would like to know what is your scenario in more detail?"
      },
      {
        "user": "mjmckp",
        "created_at": "2018-05-16T03:33:02Z",
        "body": "Features may be extracted from a data source in a way that is specified at runtime.  A simple example is the last `N` values from a time series, where `N` is configurable at runtime."
      },
      {
        "user": "zeahmed",
        "created_at": "2018-05-16T04:11:37Z",
        "body": "Thanks for the explanation. Yes, this can done through a`'Transform` in the pipeline (may be call it `WindowTransform`) which can turn last `N` values of column(s) into a feature vector. This transform is not currently available in ML.Net. "
      },
      {
        "user": "mjmckp",
        "created_at": "2018-05-16T04:29:12Z",
        "body": "Thanks, however that particular transform was just an example.\r\n\r\nIn general, the transforms done on the source data to extract features may be parameterised in countless ways.  ML.Net should not be attempting to implement every conceivable transform, and should instead allow pre-processed arrays of features as an input..."
      },
      {
        "user": "zeahmed",
        "created_at": "2018-05-16T05:33:02Z",
        "body": "Thanks @mjmckp for the suggestion. ML.NET does support pre-processed arrays of feature as input. Your concern is only regarding setting VectorType dimension at runtime. I am adding @TomFinley and @Ivanidzo4ka if they have more info in this regard."
      },
      {
        "user": "mjmckp",
        "created_at": "2018-05-16T05:59:09Z",
        "body": "That's right, thanks a lot @zeahmed "
      },
      {
        "user": "mjmckp",
        "created_at": "2018-05-23T22:45:53Z",
        "body": "Any update on this?"
      },
      {
        "user": "chitsaw",
        "created_at": "2018-06-02T00:05:01Z",
        "body": "Support for this would also be very useful for our scenario. We are trying to integrate ML.NET into our framework, which generates training data with feature vectors as float[] arrays. The number of features is not known a priori and can vary across runs.\r\n\r\nGiven a set of float[] feature vectors and labels, we would like to be able to instantiate a LearningPipeline and train a model. However as various stages of the pipeline rely on the VectorTypeAttribute to determine the input schema, we are currently unable to do this. Internally the ML.NET framework supports passing explicit schema definitions such as:\r\n\r\n```\r\nComponentCreation.CreateDataView<TRow>(this IHostEnvironment env, IList<TRow> data, SchemaDefinition schemaDefinition)\r\nComponentCreation.CreatePredictionEngine<TSrc, TDst>(this IHostEnvironment env, Stream modelStream, bool ignoreMissingColumns, SchemaDefinition inputSchemaDefinition, SchemaDefinition outputSchemaDefinition)\r\n```\r\n\r\nCould this be surfaced in the pipeline APIs to support variable feature vector dimensions?"
      },
      {
        "user": "Ivanidzo4ka",
        "created_at": "2018-06-28T23:13:55Z",
        "body": "Sorry for delay.\r\nWe definitely can let you setup vector size during runtime.\r\nSo far I can see two ways to do that. \r\nFirst is let you pass dictionary of field/property (property not yet supported, but we working on this) name and dimension for it. \r\n```\r\n            var vectorSizes = new Dictionary<string, int[]>();\r\n            vectorSizes.Add(\"Features\", new int[1] { 2 });\r\n            pipeline.Add(CollectionDataSource.Create(data, vectorSizes));\r\n```\r\nsomething like this.\r\nAnother option is to inspect first element in your collection and infer vector sizes from it.\r\n```\r\npipeline.Add(CollectionDataSource.Create(data, inferVectorSizesFromCollection:true));\r\n```\r\ndownside of second approach is fact what you need to start two enumerators, and in some cases like SQL data extraction it can be quite costly.\r\n\r\nDoes this sound reasonable for you?"
      },
      {
        "user": "mjmckp",
        "created_at": "2018-06-28T23:35:22Z",
        "body": "Either way sounds fine to me, thanks a lot"
      },
      {
        "user": "chitsaw",
        "created_at": "2018-06-29T00:24:24Z",
        "body": "Thanks for looking into this. While either would work, the first approach is more explicit and may provide users more flexibility (e.g. specifying a vector size that is smaller than the underlying collection)."
      },
      {
        "user": "Anaschouihdi",
        "created_at": "2019-05-09T16:25:19Z",
        "body": "Hello Guys,\r\n\r\nI am a new to ML.net and I don't really get your solution. I am using the 0.11.0 version and I try to keep the following architecture: \r\n\r\nclass Data\r\n{ \r\n    public string ID{ get; set; }\r\n\r\n    [VectorType(5)] //I do not know the if the data will contain 5 or more features\r\n    public float[] Features { get; set; }   \r\n}\r\n\r\n\r\nInputData row = new InputData { AssetID = Data[0, i + 1].ToString(), Features = features };\r\n\r\nvar context = new MLContext();\r\nvar DataView = context.Data.LoadFromEnumerable(dataArray);\r\nstring featuresColumnName = \"Features\";\r\nvar pipeline=context.Transforms.Concatenate(featuresColumnName,\"Features\")             .Append(context.Clustering.Trainers.KMeans(featuresColumnName, clustersCount: NumberClusters));\r\n\r\nvar model = pipeline.Fit(DataView);\r\n\r\nCould you help me ?\r\n"
      },
      {
        "user": "drake7707",
        "created_at": "2019-05-16T06:41:28Z",
        "body": "@Anaschouihdi \r\n\r\nCreate a schema definition and pass it as the 2nd parameter in the LoadFromEnumerable method:\r\n```\r\nvar schemaDef = SchemaDefinition.Create(typeof(Data));\r\nschemaDef[\"Features\"].ColumnType = new VectorDataViewType(NumberDataViewType.Single, 5);\r\nvar trainingDataView = mlContext.Data.LoadFromEnumerable(dataArray, schemaDef);\r\n```"
      },
      {
        "user": "ehsanasgarian",
        "created_at": "2019-05-16T08:10:57Z",
        "body": "That's right, thanks a lot @drake7707\r\n\r\n"
      },
      {
        "user": "drake7707",
        "created_at": "2019-05-16T08:33:03Z",
        "body": "One thing I forgot to mention is that you'll also need to pass the same schema definition as an additional parameter `inputSchemaDefinition` in the prediction engine:\r\n\r\n```\r\nvar predEngine = mlContext.Model.CreatePredictionEngine<IrisData, IrisPrediction>(trainedModel, inputSchemaDefinition: schemaDef);\r\n```"
      },
      {
        "user": "Anaschouihdi",
        "created_at": "2019-05-30T12:50:17Z",
        "body": "@drake7707  Thank you very much for your answer. It works perfectly fine !\r\n\r\n"
      },
      {
        "user": "codemzs",
        "created_at": "2019-06-30T02:32:09Z",
        "body": "closing this since this can be achieved by passing input schema and overriding column property with the dimensions at runtime. "
      },
      {
        "user": "ScubaAddict1",
        "created_at": "2019-07-11T03:40:45Z",
        "body": "Hi, can someone please post and example passing input schema and overriding column property with the dimensions at runtime.\r\n\r\nI tried, the following in vb.net. but get an error \"ballhist is a class type and cannot be used as an espression.\r\n\r\nvar schemaDef = SchemaDefinition.Create(typeof(BallHist));\r\nschemaDef[\"Features\"].ColumnType = new VectorDataViewType(NumberDataViewType.Single, 5);\r\nvar trainingDataView = mlContext.Data.LoadFromEnumerable(dataArray, schemaDef);\r\n\r\nmy class is as follows\r\n    Public Class BallHist\r\n        <LoadColumn(0)>\r\n        <ColumnName(\"Sequence\")>\r\n        Public Sequence As Single\r\n\r\n        <LoadColumn(1)>\r\n        <ColumnName(\"Day\")>\r\n        Public Day As Single\r\n\r\n        <LoadColumn(2)>\r\n        <ColumnName(\"Month\")>\r\n        Public Month As Single\r\n\r\n        <LoadColumn(3)>\r\n        <ColumnName(\"Year\")>\r\n        Public Year As Single\r\n\r\n        <LoadColumn(4)>\r\n        <VectorType(9)> ' want this to be dynamic at runtime.\r\n        <ColumnName(\"PreviousBalls\")>\r\n        Public PreviousBalls As Single()\r\n\r\n\r\n        <LoadColumn(5)>\r\n        <ColumnName(\"BallNo\")>\r\n        Public BallNo As Single\r\n\r\n\r\n    End Class\r\n\r\n\r\nThank you in advance."
      },
      {
        "user": "ScubaAddict1",
        "created_at": "2019-07-16T06:55:58Z",
        "body": "For any reference the code in vb.net is\r\n\r\n\r\n\r\n   Dim featureDimension As Integer = Data(0).PreviousBalls.Count - 1\r\n            Dim schemaDef = SchemaDefinition.Create(GetType(BallHist))\r\n            schemaDef(\"PreviousBalls\").ColumnType = New VectorDataViewType(NumberDataViewType.Single, featureDimension)\r\n            trainData = mlContext.Data.LoadFromEnumerable((GetTrainDataBallHist(records, NumRecordsForTrain)), schemaDef)"
      },
      {
        "user": "lionelquirynen",
        "created_at": "2020-03-27T09:15:59Z",
        "body": "Hello Guys,\r\n\r\nBut how do this when the size of the vector changes for each row? \r\nFor instance if I have a dataset with 10 000 movies, each movies contains two arrays of string, one for the actors and the other for the crew members. For each movie the number of actors and crew members are not the same... How to handle this?\r\n\r\nBest regards,\r\n\r\nLionel Quirynen"
      }
    ]
  },
  {
    "number": 70,
    "title": "ML.Net and Azure ML Relationship",
    "created_at": "2018-05-08T06:58:54Z",
    "closed_at": "2019-06-30T02:18:13Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnet/machinelearning/issues/70",
    "body": "It would be beneficial for potential users to understand the relationship between ml.net and azure ML. \r\n\r\nIs ml.net the lib behind azure ml? Is ml.net going to be a block inside azure ml? How do those things.work together, is it going to be possible to seamlessly move models, flows, etc between the two?",
    "comments_url": "https://api.github.com/repos/dotnet/machinelearning/issues/70/comments",
    "author": "voltcode",
    "comments": [
      {
        "user": "sfilipi",
        "created_at": "2018-11-27T20:44:29Z",
        "body": "@GalOshri is there any plans we can share about this?"
      },
      {
        "user": "codemzs",
        "created_at": "2019-06-30T02:18:13Z",
        "body": "Currently ML.NET is not a backend for Azure ML. "
      }
    ]
  },
  {
    "number": 53,
    "title": "Simple example using House Pricing Scenario",
    "created_at": "2018-05-07T20:00:50Z",
    "closed_at": "2018-05-16T13:47:11Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/dotnet/machinelearning/issues/53",
    "body": "This is the first time I've looked into machine learning but I have a use case I'd like to test with it.\r\n\r\nTo get started I've created a simple example from the house pricing scenario which somewhat closely matches my use case but the results I'm getting are not at all close to what I expected. The data I'm providing is simply linear in terms of just the `SqftLiving` input parameter to the `Price` where `Price = SqftLiving * 100`. The `SqftLot` is held constant for training and prediction so it should be a non-factor.\r\n\r\nI'm just trying to predict the Price when the `SqftLiving` is 1500 which with the linear model created by the provided data should make it about $150,000.\r\n\r\nHowever, the results I get vary wildly from the negative to the postive 10's of millions every time I run the program which is unexpected. Could someone look into this simple example and let me know what if anything I'm doing is causing these poor results?\r\n\r\n```c#\r\nclass Program\r\n{\r\n    static void Main(string[] args)\r\n    {\r\n        var filePath = \"C://Temp/kc_house_data.csv\";\r\n\r\n        File.WriteAllText(filePath, @\"100000,1000,8000\r\n200000,2000,8000\r\n400000,4000,8000\");\r\n\r\n        var pipeline = new LearningPipeline\r\n        {\r\n            new TextLoader<HousePriceData>(filePath, separator: \",\"),\r\n            new ColumnConcatenator(\"Features\", \"SqftLiving\", \"SqftLot\"),\r\n            new StochasticDualCoordinateAscentRegressor()\r\n        };\r\n\r\n        var model = pipeline.Train<HousePriceData, HousePricePrediction>();\r\n\r\n        var prediction = model.Predict(new HousePriceData { SqftLiving = 1500, SqftLot = 8000 });\r\n\r\n        Console.WriteLine(prediction.Price);\r\n        Console.ReadLine();\r\n    }\r\n}\r\n\r\npublic class HousePriceData\r\n{\r\n    [Column(ordinal: \"0\", name: \"Label\")]\r\n    public float Price;\r\n\r\n    [Column(ordinal: \"1\")]\r\n    public float SqftLiving;\r\n\r\n    [Column(ordinal: \"2\")]\r\n    public float SqftLot;\r\n}\r\n\r\npublic class HousePricePrediction\r\n{\r\n    [ColumnName(\"Score\")]\r\n    public float Price;\r\n}\r\n```",
    "comments_url": "https://api.github.com/repos/dotnet/machinelearning/issues/53/comments",
    "author": "TylerBrinkley",
    "comments": [
      {
        "user": "Ivanidzo4ka",
        "created_at": "2018-05-07T21:31:21Z",
        "body": "Hello Tyler.\r\nLet me point on the fact what you have only 3 data points, and our algorithms expected to be worked on millions of data points, with huge feature vector. For you as a person. it's obvious what formula states behind this 3 points, but from machine point of view, 3 points is not enough.\r\n\r\nI've made following change in your code:\r\n\r\n            Random random = new Random();\r\n            StringBuilder sb = new StringBuilder();\r\n            for ( int i = 0; i < n; i++)\r\n            {\r\n                var sqft = random.NextDouble();\r\n                sb.AppendLine(string.Format(\"{0},{1},8000\", sqft*10, sqft ));\r\n            }\r\n            File.WriteAllText(filePath, sb.ToString());\r\n\r\nAnd I played with different values for n.\r\nn=100 gives me prediction for your example around 141 000 which is about 6% error.\r\nn=1000 gives me prediction 14910 which 0.6% error\r\nn=100000 gives me 14992 which is 0.06% error\r\nSo the more data you give to algorithm, the better it performs.\r\n\r\nYou can also play with different learning models. For example if I modify my generating code to make \r\n`var sqft = random.NextDouble() *10_000;`\r\nto reflect real values for square foots I can use FastTreeRegressor, and it will give me reasonable prediction (2% error) even with 100 examples."
      },
      {
        "user": "TylerBrinkley",
        "created_at": "2018-05-07T21:57:12Z",
        "body": "@Ivanidzo4ka Thanks for the insight and the follow up with more data point results. I look forward to playing with this some more where I'll have a much larger data set."
      }
    ]
  }
]