[
  {
    "number": 11575,
    "title": "Analizing website with an user and an googlebot version",
    "created_at": "2020-10-19T04:18:26Z",
    "closed_at": "2020-11-10T20:38:24Z",
    "labels": [
      "question",
      "pending-close",
      "needs-priority"
    ],
    "url": "https://github.com/GoogleChrome/lighthouse/issues/11575",
    "body": "Hello! \r\n\r\nMy website has a conditional accessing rule: if the access is being made by the Googlebot I deliver a page fully rendered by the server (**server-side** rendering). \r\n\r\nOtherwise, if the access is being made by a human being I deliver a page with SPA features (**client-side** rendering). \r\n\r\n**My question is:** In my last analysis using PageSpeed Insights (Lighthouse) I noticed that the results were based on the **client-side** rendering version. In this case, should I consider that the website performance result will be judged by Google by the **client-side** version? \r\n\r\nI'm a little bit confused about this behavior. \r\n\r\nThanks :)\r\n",
    "comments_url": "https://api.github.com/repos/GoogleChrome/lighthouse/issues/11575/comments",
    "author": "wagnermeyer",
    "comments": [
      {
        "user": "Lofesa",
        "created_at": "2020-10-19T10:06:55Z",
        "body": "Hi\r\nMaybe you test it with the UA? PSI don¬¥t have a UA GoogleBot related.\r\n\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4143.7 Safari/537.36 Chrome-Lighthouse\"\r\n"
      },
      {
        "user": "patrickhulce",
        "created_at": "2020-10-19T14:29:29Z",
        "body": "Thanks for filing @wagnermeyer! We don't really discuss explicit ranking signals here though, sorry! You can try official search communication channels if that's your primary concern.\r\n\r\nFrom our perspective though, you should absolutely optimize the site that your end-users actually use, which is what PSI is already measuring :)"
      }
    ]
  },
  {
    "number": 11159,
    "title": "Is there any step necesary for getting Field Data and Origin Summary to show stats",
    "created_at": "2020-07-25T00:58:48Z",
    "closed_at": "2020-09-29T20:07:02Z",
    "labels": [
      "question",
      "needs-priority"
    ],
    "url": "https://github.com/GoogleChrome/lighthouse/issues/11159",
    "body": "I already have search console  and google analytics, is there an additional step in order to display in the future those indicators?",
    "comments_url": "https://api.github.com/repos/GoogleChrome/lighthouse/issues/11159/comments",
    "author": "tomasts248",
    "comments": [
      {
        "user": "patrickhulce",
        "created_at": "2020-07-25T03:05:50Z",
        "body": "I assume you're referring to Page Speed Insights showing the field data for your URL and origin? AFAIK, there are no steps for you to take other than increase the traffic to the page as only pages with enough data to anonymize are included in the Chrome UX report."
      },
      {
        "user": "tomasts248",
        "created_at": "2020-07-25T04:07:42Z",
        "body": "Alright understood! Thanks for explaining :)"
      },
      {
        "user": "exterkamp",
        "created_at": "2020-09-29T20:07:02Z",
        "body": "Thanks @patrickhulce for answering üéâ "
      }
    ]
  },
  {
    "number": 11060,
    "title": "Time to Interactive - Impact due to 3rd party scripts though invoked after onload event",
    "created_at": "2020-07-06T16:53:14Z",
    "closed_at": "2020-07-06T17:14:08Z",
    "labels": [
      "question",
      "pending-close",
      "needs-priority"
    ],
    "url": "https://github.com/GoogleChrome/lighthouse/issues/11060",
    "body": "Time To interactive (TTI):\r\n1.\tIt is highly effected by third party scripts. \r\n2.\tThere are many third party scripts on the pages (which many sites do), so TTI gets pushed way out. In some cases it‚Äôs almost close to full page load. \r\n3.\tAs TTI is used in page speed score calculation, score does not improve much, especially for mobile device browsers.\r\n\r\nFor lighthouse 6.xx version, Total Blocking Time is introduced which calculates total amount of time for long tasks between FCP and TTI. So here also, due to 3rd party scripts even loaded after onload event has the impact on page speed score calculation. \r\n\r\nFew queries:\r\n1.\tWere there any changes to TTI metric in past 1 year?\r\n2.\tIs there a way to improve calculation of TTI metric?\r\n",
    "comments_url": "https://api.github.com/repos/GoogleChrome/lighthouse/issues/11060/comments",
    "author": "sgaurav7867",
    "comments": [
      {
        "user": "patrickhulce",
        "created_at": "2020-07-06T17:01:59Z",
        "body": "> Were there any changes to TTI metric in past 1 year?\r\n\r\nNope.\r\n\r\n> Is there a way to improve calculation of TTI metric?\r\n\r\nI think our definitions of \"improve\" will be different ;) The issues you describe are features of TTI that are working as intended.\r\n\r\n> There are many third party scripts on the pages (which many sites do), so TTI gets pushed way out.\r\n\r\nThis is intentional. Third-party scripts have a significant impact on the user's ability to interact with the page. TTI captures this.\r\n\r\n> In some cases it‚Äôs almost close to full page load.\r\n\r\nThis is also intentional. If every resource causes a longtask when it loads, then TTI will be the same as full page load time by design.\r\n\r\n> So here also, due to 3rd party scripts even loaded after onload event has the impact on page speed score calculation.\r\n\r\nDeferring to `onload` won't do much for either of these metrics. True deferral here requires not loading the third-party at all for some subset of users (examples: only load the chat widget when they've clicked the chat button, show a still of a YouTube image and only load YouTube when the user clicks play, etc). Don't do the work at all instead of just reordering the work :)"
      },
      {
        "user": "sgaurav7867",
        "created_at": "2020-07-06T17:14:08Z",
        "body": "Thanks @patrickhulce for swift response and detailed inputs :)"
      }
    ]
  },
  {
    "number": 10639,
    "title": "What custom config can allow me to run audits for mobile and desktop simultaneously",
    "created_at": "2020-04-26T20:40:51Z",
    "closed_at": "2020-04-28T20:30:09Z",
    "labels": [
      "question",
      "pending-close",
      "needs-priority"
    ],
    "url": "https://github.com/GoogleChrome/lighthouse/issues/10639",
    "body": "**Summary**\r\nHi,\r\n\r\nIs there a way to run audits for mobile and desktop simultaneously?\r\nCan the \"passes\" be used to run a pass for mobile, and pass for desktop in the same audit?\r\nOr is there any other workaround?\r\n",
    "comments_url": "https://api.github.com/repos/GoogleChrome/lighthouse/issues/10639/comments",
    "author": "moerazem",
    "comments": [
      {
        "user": "patrickhulce",
        "created_at": "2020-04-26T20:46:39Z",
        "body": "It is not possible. You'll need to run Lighthouse twice."
      }
    ]
  },
  {
    "number": 9656,
    "title": "Why the change from 3G to 4G? Add possibility to pick?",
    "created_at": "2019-09-11T11:51:32Z",
    "closed_at": "2019-09-12T07:27:58Z",
    "labels": [
      "question",
      "pending-close"
    ],
    "url": "https://github.com/GoogleChrome/lighthouse/issues/9656",
    "body": "Before creating an feature request please make sure you are using the latest: \r\n‚úÖ \r\n\r\n**Feature request summary**\r\nAdd also 3G in Audit\r\n\r\n**Describe what you want to be added:**\r\nOption to use 3G as before OR 4G or a fair explanation of why it changed.\r\n\r\nAre you willing to work on this yourself?\r\n‚õîÔ∏è \r\n\r\n**What is the motivation or use case for changing this?**\r\nEnd-customers having 3G, measure their performance\r\n\r\n**How is this beneficial to Lighthouse?**\r\nü§∑‚Äç‚ôÇ \r\n",
    "comments_url": "https://api.github.com/repos/GoogleChrome/lighthouse/issues/9656/comments",
    "author": "OZZlE",
    "comments": [
      {
        "user": "patrickhulce",
        "created_at": "2019-09-11T15:15:03Z",
        "body": "Thanks for filing!\r\n\r\nIf you're referring to the default throttling settings, the change from \"Fast 3G\" to \"Slow 4G\" was in name only and no throttling settings under the hood were actually changed. The observed percentile latency and bandwidth in Chrome data between ~85th percentile 4G and ~25th percentile 3G are quite similar.\r\n\r\nWe've discussed offering multiple throttling profiles in the past, but it's not on our radar for the near future at this time."
      },
      {
        "user": "OZZlE",
        "created_at": "2019-09-12T07:27:58Z",
        "body": "Big thank you for the fast response!! Not sure why it needed to change name but good to know! :)\r\n\r\nI think the industry standard has been to measure Fast 3G since a couple of years back but yeah then this is the same with another name :D "
      }
    ]
  },
  {
    "number": 9381,
    "title": "Site Audit: lherror: no_fcp Page load time too high",
    "created_at": "2019-07-16T12:17:44Z",
    "closed_at": "2019-07-23T19:35:43Z",
    "labels": [
      "question",
      "pending-close"
    ],
    "url": "https://github.com/GoogleChrome/lighthouse/issues/9381",
    "body": "Our site ico.ambcrypto.com is loading very slow. So i tried to run a site audit on it. But it shows LHerror: No_FCP\r\nPlease help me figure out this issue. How can i run the audit?",
    "comments_url": "https://api.github.com/repos/GoogleChrome/lighthouse/issues/9381/comments",
    "author": "startupflux",
    "comments": [
      {
        "user": "patrickhulce",
        "created_at": "2019-07-16T15:11:54Z",
        "body": "If the page is loading so slowly that it passes the Lighthouse default timeout, you can manually increase the paint timer by running with the CLI.\r\n\r\n```bash\r\nnpm install -g lighthouse\r\nlighthouse <url> --max-wait-for-fcp=45000 # wait up to 45s for the page to paint instead of just 15s"
      },
      {
        "user": "exterkamp",
        "created_at": "2019-07-23T19:35:43Z",
        "body": "Reopen if you are still having issues!"
      }
    ]
  },
  {
    "number": 8992,
    "title": "Measure load time from A to B",
    "created_at": "2019-05-18T14:36:01Z",
    "closed_at": "2019-05-18T17:06:45Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/GoogleChrome/lighthouse/issues/8992",
    "body": "First off, I love lighthouse. \r\n\r\nHowever, I don't just want to measure the time it takes to load page B; I would like to measure how long it takes to load page B, **provided I am already on page A**.\r\n\r\nIdeally I'd fire a click event on the link to page B.\r\n\r\nFrom all I see, this can't be done with Lighthouse && Node ?",
    "comments_url": "https://api.github.com/repos/GoogleChrome/lighthouse/issues/8992/comments",
    "author": "m0-n",
    "comments": [
      {
        "user": "patrickhulce",
        "created_at": "2019-05-18T15:59:49Z",
        "body": "You're mostly correct it's not really possible to do exactly what you've described, but you can get kinda close.\r\n\r\n1. Open Chrome yourself with remote debugging enabled.\r\n2. Navigate to Page A\r\n3. Run Lighthouse on Page B by passing the port of your opened Chrome and `disableStorageReset: true`.\r\n\r\nLighthouse will still create a new tab and navigate to Page B separately, but at least your cache state/cookies/localStorage/etc will be as if the user just came from Page A. Note that `sessionStorage` will be different though.\r\n\r\n\r\nRelated discussions you might find helpful #1418, #3837"
      },
      {
        "user": "m0-n",
        "created_at": "2019-05-18T17:06:45Z",
        "body": "Thanks Patrick,\r\n\r\nI chose to implement against the Performance Web API and then simulate things like clicks with RobotJS."
      }
    ]
  },
  {
    "number": 7253,
    "title": "PWA in chrome Beta version not reporting score",
    "created_at": "2019-02-15T05:31:16Z",
    "closed_at": "2019-04-01T02:53:47Z",
    "labels": [
      "question",
      "pending-close"
    ],
    "url": "https://github.com/GoogleChrome/lighthouse/issues/7253",
    "body": "Not an issue, rather a question requesting clarification.\r\n\r\n**Summary**\r\nI have just noticed that my chrome beta version app is not reporting the PWA score, only the recommendations are displayed. \r\nI tried to search for the beta release change-list manual as to the reason this change was made.\r\n\r\nMy question is:\r\n- Is there any reason as to why the PWA score value has been removed from the lighthouse dev-tools (in chrome beta version)?\r\n\r\nüòï ",
    "comments_url": "https://api.github.com/repos/GoogleChrome/lighthouse/issues/7253/comments",
    "author": "dryleaf",
    "comments": [
      {
        "user": "exterkamp",
        "created_at": "2019-02-15T05:55:27Z",
        "body": "Hi, thanks for the question!\r\n\r\nThe PWA section was refactored, so I assume you are talking about the features found in #6486 and #6526 tracked by #6395.  These refactors are starting to hit beta versions of Chrome, and should be the norm moving forward.  \r\n\r\nThe PWA section still has a numeric score underlying it and can be seen if you run the CLI tool and generate JSON reports, or download the devtools report and look at the JSON.\r\n\r\n@brendankenny correct me if I'm lying here."
      }
    ]
  },
  {
    "number": 6727,
    "title": "Lighthouse  network-requests audit results are not same for every run ",
    "created_at": "2018-12-05T12:44:23Z",
    "closed_at": "2018-12-07T15:39:31Z",
    "labels": [
      "question",
      "pending-close",
      "needs-more-info"
    ],
    "url": "https://github.com/GoogleChrome/lighthouse/issues/6727",
    "body": "I am using lighthouse CLI to monitor some set of URLs in my product. The results of \"Network-requests\" are not the same for every run, even there is no code change those pages.  \r\n\r\nSome network requests are missing and for some N/w requests,  getting size as 0 Bytes. (these are random issues for the next run I am getting the size and request also available)\r\n",
    "comments_url": "https://api.github.com/repos/GoogleChrome/lighthouse/issues/6727/comments",
    "author": "ssivanatarajan",
    "comments": [
      {
        "user": "patrickhulce",
        "created_at": "2018-12-05T15:31:12Z",
        "body": "We'll need more specifics here to be able to help. What URLs are you monitoring? What requests are missing?\r\n\r\nIf a request isn't in the `network-requests` audit that means that Chrome never issued it (unless it was inside a crossorigin iframe that was out of process, see #6337)."
      },
      {
        "user": "ssivanatarajan",
        "created_at": "2018-12-06T10:22:26Z",
        "body": "@patrickhulce  I am using Lighthouse API for monitoring our product in the test environment. so it can't be accessible outside.  Those requests are not inside an iframe. This issue happening in the random run.  \r\n"
      },
      {
        "user": "patrickhulce",
        "created_at": "2018-12-06T15:08:03Z",
        "body": "OK, well without more information and repro steps I'm afraid we can't really do anything about it :/"
      },
      {
        "user": "ssivanatarajan",
        "created_at": "2018-12-07T09:20:07Z",
        "body": "@patrickhulce  ,Below is the JSON result of network-request audit of that request . This may helps. why it's status is \"-1\" and mimeType is empty.\r\nmimeType: \"\"\r\nresourceType: \"Stylesheet\"\r\nstartTime: 28583.233000710607\r\nstatusCode: -1\r\ntransferSize: 0"
      },
      {
        "user": "patrickhulce",
        "created_at": "2018-12-07T15:39:31Z",
        "body": "That just means Chrome never got a response. It didn't know the status code/mime type/transfer size because there was no response :)"
      }
    ]
  },
  {
    "number": 5622,
    "title": "Minimum chrome version",
    "created_at": "2018-07-05T15:31:22Z",
    "closed_at": "2018-07-06T15:36:14Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/GoogleChrome/lighthouse/issues/5622",
    "body": "**Summary**\r\nI haven't seen any documentation about a minimum chrome version to run Lighthouse programmatically or through CLI, so I'm wondering if there is one. Apologies if I simply missed it somewhere. Thanks!",
    "comments_url": "https://api.github.com/repos/GoogleChrome/lighthouse/issues/5622/comments",
    "author": "nfaltermeier",
    "comments": [
      {
        "user": "patrickhulce",
        "created_at": "2018-07-06T15:36:14Z",
        "body": "It's in the output of the CLI `--help` and on our readme ;)\r\n\r\nCurrently you can get away with 66 or later, but our policy is to just support current stable + canary, so any environment where you are updating LH regularly, you should be sure to be updating Chrome regularly as well."
      }
    ]
  },
  {
    "number": 5604,
    "title": "How can I generate HTML report at the end using LightCrawler",
    "created_at": "2018-07-02T09:08:39Z",
    "closed_at": "2018-08-10T18:23:58Z",
    "labels": [
      "question",
      "pending-close"
    ],
    "url": "https://github.com/GoogleChrome/lighthouse/issues/5604",
    "body": "I have done with terminal output, But I need HTML report for CI process. Is it possible to generate HTML report or else any other options to create a HTML report using LightCrawler",
    "comments_url": "https://api.github.com/repos/GoogleChrome/lighthouse/issues/5604/comments",
    "author": "MohamedRasool786",
    "comments": [
      {
        "user": "patrickhulce",
        "created_at": "2018-07-02T14:08:41Z",
        "body": "Sounds like this issue belongs in the lightcrawler repo ;)"
      }
    ]
  },
  {
    "number": 5531,
    "title": "How to grab/pass the 5 audit score categories",
    "created_at": "2018-06-20T20:36:42Z",
    "closed_at": "2018-06-21T22:07:44Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/GoogleChrome/lighthouse/issues/5531",
    "body": "<!-- We would love to hear anything on your mind about Lighthouse -->\r\n**Summary**\r\nIm trying to find the code related to audit scores of the following categories:\r\n\"id\": \"performance\"\r\n\"id\": \"pwa\"\r\n\"id\": \"accessibility\"\r\n\"id\": \"Best-Practices\"\r\n\"id\": \"seo\"\r\nI need to grab these audit score results and return them similarly to how the following metrics have functions to return their results. \r\n - `ttfcp` - First Contentful Paint\r\n - `ttfmp` - First Meaningful Paint\r\n - `psi` - Perceptual Speed Index\r\n - `fv` - First Visual Change\r\n - `vc` - Visually Complete 100%\r\n - `ttfi` - First Interactive (vBeta)\r\n - `ttci` - Time to Consistently Interactive (vBeta)\r\n - `vc85` - Visually Complete 85%\r\n\r\nIs there any existing code within the project that will help me accomplish this? Any recommendations on how I could accomplish this otherwise? I would like to get the five audit scores I mentioned above, in addition to the available metrics, and update a google spreadsheet with the scores after running the lighthouse test.\r\n",
    "comments_url": "https://api.github.com/repos/GoogleChrome/lighthouse/issues/5531/comments",
    "author": "gsemfield",
    "comments": [
      {
        "user": "patrickhulce",
        "created_at": "2018-06-21T16:23:13Z",
        "body": "Not 100% sure what you mean, but you can grab the category scores directly from the category objects.\r\n\r\nv2\r\n```js\r\nconst results = await lighthouse(...)\r\nfor (const category of results.reportCategories) {\r\n  console.log(category.id, category.score)\r\n}\r\n```\r\n\r\nv3\r\n```js\r\nconst {lhr} = await lighthouse(...)\r\nfor (const [categoryId, category] of Object.entires(lhr.categories) {\r\n  console.log(categoryId, category.score)\r\n}\r\n```\r\n\r\nThe `results` and `lhr` variables above are roughly the same as if you were saving the `lighthouse --output=json` to a file and reading that."
      },
      {
        "user": "gsemfield",
        "created_at": "2018-06-21T22:07:44Z",
        "body": "Thanks for clarifying that! Was having trouble finding them in the project code."
      }
    ]
  },
  {
    "number": 5478,
    "title": "How to get HTML page size in kb? ",
    "created_at": "2018-06-12T12:20:38Z",
    "closed_at": "2018-06-14T05:00:35Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/GoogleChrome/lighthouse/issues/5478",
    "body": "I don't see any existing artifacts or audits for this. `TotalByteWeight` audit returns kilobytes from network requests. `DOMSize` audit  and `DOMStats` gatherer returns number of nodes right? ",
    "comments_url": "https://api.github.com/repos/GoogleChrome/lighthouse/issues/5478/comments",
    "author": "rustanacexd",
    "comments": [
      {
        "user": "patrickhulce",
        "created_at": "2018-06-12T21:50:59Z",
        "body": "If the HTML page is in the top 10 heaviest requests you can use the details of the `total-byte-weight` audit to get the size in bytes. Alternatively, you can use the details of the `network-requests` audit to get the transferSize. \r\n\r\n\r\n```js\r\n// DISCLAIMER: untested, fresh from üí≠ \r\naudits['network-requests'].details.items.find(request => request.mimeType === 'text/html' || request.resourceType === 'document').transferSize\r\n```"
      },
      {
        "user": "rustanacexd",
        "created_at": "2018-06-13T07:54:59Z",
        "body": "thanks a lot for this snippet btw. I got it with slight modification on where to find\r\n```\r\nconst NetworkRequests = require('lighthouse/lighthouse-core/audits/network-requests');\r\n\r\nconst {extendedInfo} = await NetworkRequests.audit(artifacts);\r\nconst kb = extendedInfo.value.find(request => request.mimeType === 'text/html' || request.resourceType === 'document').transferSize;\r\n```\r\n\r\n"
      },
      {
        "user": "walmello",
        "created_at": "2022-04-29T17:28:45Z",
        "body": "Hello. I'm really stuck in this part of the solution. \r\nwhat the artifacts part of the script is?\r\n\r\nI tried to run it but I got an error"
      }
    ]
  },
  {
    "number": 5477,
    "title": "Lighthouse logs everything as error",
    "created_at": "2018-06-12T11:23:20Z",
    "closed_at": "2018-08-10T18:42:24Z",
    "labels": [
      "question",
      "needs-more-info"
    ],
    "url": "https://github.com/GoogleChrome/lighthouse/issues/5477",
    "body": "Hi all,\r\n\r\nI have added lighthouse + puppeteer into my Jenkins pipeline. I've noticed that all logs from lighthouse have ERROR level. This is how my logs look like:\r\n\r\n```\r\n10:45:58 [ERROR] Tue, 12 Jun 2018 10:45:58 GMT status Initializing‚Ä¶\r\n10:45:59 [ERROR] Tue, 12 Jun 2018 10:45:59 GMT status Loading page & waiting for onload Accessibility\r\n10:46:17 [ERROR] Tue, 12 Jun 2018 10:46:17 GMT statusEnd Loading page & waiting for onload\r\n10:46:17 [ERROR] Tue, 12 Jun 2018 10:46:17 GMT status Retrieving devtoolsLog and network records\r\n10:46:17 [ERROR] Tue, 12 Jun 2018 10:46:17 GMT status Retrieving: Accessibility\r\n10:46:18 [ERROR] Tue, 12 Jun 2018 10:46:18 GMT status Disconnecting from browser...\r\n10:46:18 [ERROR] Tue, 12 Jun 2018 10:46:18 GMT status Analyzing and running audits...\r\n10:46:18 [ERROR] Tue, 12 Jun 2018 10:46:18 GMT status Evaluating: `[accesskey]` values are unique\r\n10:46:18 [ERROR] Tue, 12 Jun 2018 10:46:18 GMT status Evaluating: `[aria-*]` attributes match their roles\r\n```\r\n\r\nI've checked how logging are implemented in lighthouse. It looks that all 'status' logs should be saved with 'debug' level. It's worth mentioning that I'm getting expected lighthouse scan result and all my tests passes. Does anyone have idea why all lighthouse logs are read in my case?",
    "comments_url": "https://api.github.com/repos/GoogleChrome/lighthouse/issues/5477/comments",
    "author": "pmajcher",
    "comments": [
      {
        "user": "patrickhulce",
        "created_at": "2018-06-12T21:42:05Z",
        "body": "the `debug` package we use for logging outputs to stderr so you can do things like `lighthouse --output=json > report.json`\r\n\r\nis your pipeline interpreting all stderr output as error level? the double timestamp makes it look like our raw logs are being reinterpreted by something else"
      },
      {
        "user": "brendankenny",
        "created_at": "2018-08-10T18:42:24Z",
        "body": "Without more info, closing for now. If this is still an issue for you, please comment and we can reopen!"
      }
    ]
  },
  {
    "number": 5466,
    "title": "how to use existing audits inside a custom audit?",
    "created_at": "2018-06-11T08:54:10Z",
    "closed_at": "2018-06-23T13:28:26Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/GoogleChrome/lighthouse/issues/5466",
    "body": "So I am using lighthouse for custom audits by extending the audits class. I am wondering if its possible to use another existing audits inside my custom audit class? or I have to rely only on gatherers.",
    "comments_url": "https://api.github.com/repos/GoogleChrome/lighthouse/issues/5466/comments",
    "author": "rustanacexd",
    "comments": [
      {
        "user": "patrickhulce",
        "created_at": "2018-06-11T16:19:22Z",
        "body": "There's not really a blessed way to do this. Our strategy for reusing logic between audits is mostly using computed artifacts. Is there a particular audit you're wanting to use that we should consider a computed artifact?\r\n\r\nAs a workaround we've used in the past, you could require in the audit class and invoke the audit yourself. DISCLAIMER: the paths/impls might be brittle and aren't guaranteed between minor version bumps.\r\n\r\n```js\r\nconst SpeedIndexAudit = require('lighthouse/lighthouse-core/audits/speed-index.js')\r\n\r\nclass MyAudit extends Audit {\r\n  static async audit(artifacts, context) {\r\n    const {rawValue} = await SpeedIndexAudit.audit(artifacts, context)\r\n    ...\r\n  }\r\n}\r\n```"
      },
      {
        "user": "rustanacexd",
        "created_at": "2018-06-12T09:17:19Z",
        "body": "@patrickhulce thank you for this, definitely will help a lot!! awesome thanks. \r\n\r\n\r\n"
      }
    ]
  },
  {
    "number": 4874,
    "title": "Changes in Section 508 compliance",
    "created_at": "2018-03-26T22:18:42Z",
    "closed_at": "2018-08-29T21:34:55Z",
    "labels": [
      "question",
      "needs-priority"
    ],
    "url": "https://github.com/GoogleChrome/lighthouse/issues/4874",
    "body": "We run reports with Lighthouse regularly. Recently, we've noticed a shift in compliance scores. Websites that once got compliant scores are now showing up as deficient. Has the algorithm been shifted, and if so, why?",
    "comments_url": "https://api.github.com/repos/GoogleChrome/lighthouse/issues/4874/comments",
    "author": "jeandion",
    "comments": [
      {
        "user": "patrickhulce",
        "created_at": "2018-03-27T16:52:06Z",
        "body": "A few versions ago the weights of accessibility category were adjusted to more accurately reflect importance. Additionally, scores of 100 were no longer averaged in to your score when they were not applicable i.e. you don't get credit for having no image violations if your page didn't have any images to begin with. Both of these changes could impact overall scores quite significantly."
      },
      {
        "user": "paulirish",
        "created_at": "2018-08-29T21:34:55Z",
        "body": "Yup it was the change of introducing Not Applicable."
      }
    ]
  },
  {
    "number": 2342,
    "title": "Improve cache start_url gatherer (strategy)",
    "created_at": "2017-05-23T19:44:25Z",
    "closed_at": "2019-04-25T21:57:21Z",
    "labels": [
      "question",
      "gatherers",
      "needs-priority"
    ],
    "url": "https://github.com/GoogleChrome/lighthouse/issues/2342",
    "body": "There are a few issues with start_url being cached. \r\n1) of them is that the manifest is not cached and can not be retrieved.\r\n2) Another is that the start_url is not yet cached by the service worker.\r\n\r\nThere are a couple of solutions that we went over\r\n\r\n1) Cache manifest inside driver.js (getAppManifest). We cache the manifest during the main pass. And get it in the offline pass.\r\n-- Downside is that we always need another pass (which is not ideal).\r\n2) Offline pass should navigate to start_url instead of the current url. We fix both issues with this fix. -- lighthouse needs to know about the manifest inside the runner which makes lighthouse smarter than we probably want to know\r\n3) Monitor the service worker and see what requests it caches\r\n-- tricky to do as we need to use the SW as our debug target.\r\n4) Read the requests inside the cache api.\r\n-- Not sure if this will work\r\n\r\nIf anyone has more ideas please let me know\r\n\r\n",
    "comments_url": "https://api.github.com/repos/GoogleChrome/lighthouse/issues/2342/comments",
    "author": "wardpeet",
    "comments": [
      {
        "user": "paulirish",
        "created_at": "2019-04-25T21:57:21Z",
        "body": "Mostly outdated, but merging into #709"
      }
    ]
  },
  {
    "number": 1719,
    "title": "README: add note that testing and results are done locally (no remote servers)",
    "created_at": "2017-02-14T14:19:41Z",
    "closed_at": "2017-02-15T18:21:26Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/GoogleChrome/lighthouse/issues/1719",
    "body": "I searched the docs on this extension and couldn't find a clear answer.\r\n\r\nI regularly want to use tools like lighthouse to test content loaded in the browser from a in internal (Intranet) site that contains high security information that should not ever leave my offices walls.\r\n\r\nAre all of the tests run locally in the browser? or is some of it processed externally?\r\n\r\nIf this is all run locally in the browser, can the documentation be updated to indicate as such?",
    "comments_url": "https://api.github.com/repos/GoogleChrome/lighthouse/issues/1719/comments",
    "author": "scunliffe",
    "comments": [
      {
        "user": "ebidel",
        "created_at": "2017-02-14T17:19:32Z",
        "body": "> Are all of the tests run locally in the browser? or is some of it processed externally?\r\n\r\nYes. Lighthouse runs its audits locally in a Chrome browser installed on your machine. Nothing is beaconed or processed on a remote server.\r\n\r\nBTW, if you're only interested in that one metric, may I suggest the performance timing api. You could log DCL after page load:\r\n\r\n    const DCL = performance.timing.domContentLoadedEventStart - performance.timing.navigationStart;\r\n\r\n(or `performance.timing.domContentLoadedEventStart - performance.timing.domLoading;` if you only care about the time after the main page bytes are rev'd. IOW, how long it takes for the browser to parse the document.\r\n\r\nWe'll update the docs. Let us know if you have any other questions."
      }
    ]
  },
  {
    "number": 1098,
    "title": "document.write() audit may be too strict",
    "created_at": "2016-12-02T01:28:23Z",
    "closed_at": "2017-01-20T06:38:47Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/GoogleChrome/lighthouse/issues/1098",
    "body": "The Chrome intervention against `document.write()` is specifically against dynamically-injected, render-blocking scripts. But the Lighthouse audit calls out all uses of `document.write()`.",
    "comments_url": "https://api.github.com/repos/GoogleChrome/lighthouse/issues/1098/comments",
    "author": "kaycebasques",
    "comments": [
      {
        "user": "ebidel",
        "created_at": "2016-12-02T01:38:09Z",
        "body": "I'd have to look at the message chrome shows, but I suspect these may be one and the same.\r\n\r\n`document.write('<script>...</script>');` is \"dynamically injected\" and rendering blocking. That's what the audit cover."
      },
      {
        "user": "ebidel",
        "created_at": "2017-01-20T06:38:47Z",
        "body": "@kaycebasques I think we can close this. Right now, LH is specifically warning on all uses of `document.write` because we want to discourage using that API. It's ok if Chrome's intervention is slightly different. In the future, we'll have an audit that shows intervention warnings sent to the console (similar to the new deprecations audit.)"
      }
    ]
  },
  {
    "number": 11026,
    "title": "Remove ambiguous words from link text disallow list",
    "created_at": "2020-06-25T17:40:06Z",
    "closed_at": "2020-07-09T21:59:36Z",
    "labels": [
      "help wanted",
      "good first issue",
      "bug",
      "P1.5"
    ],
    "url": "https://github.com/GoogleChrome/lighthouse/issues/11026",
    "body": "I'm receiving this warning about a link not being descriptive enough. The weird thing is it only happens on some pages, but that same link is everywhere on the site.\r\n\r\nOn the other hand the text is \"Inicio\" which translates to \"Homepage/Home\", I wonder how is that not descriptive enough? ü§î ",
    "comments_url": "https://api.github.com/repos/GoogleChrome/lighthouse/issues/11026/comments",
    "author": "devngl",
    "comments": [
      {
        "user": "patrickhulce",
        "created_at": "2020-06-25T18:28:56Z",
        "body": "Thanks for filing @devngl! The non-English words were contributed from the community, so there could definitely be room for improvement, and I'm certainly not much of an expert. \r\n\r\nIs it possible the connotation is different between spanish and portugese? I see they were added to add Portuguese support but were left out of spanish, but we didn't consider words that have different *web* meanings in different languages :/ Probably best to remove it either way?"
      },
      {
        "user": "devngl",
        "created_at": "2020-06-28T15:08:56Z",
        "body": "Hello,\r\n\r\nI think the main problem with the word is the multiple connotations you can give to it depending on the context. \"Inicio\" could translate to: start, home, the beginning, and probably more. The most common use I've seen in spanish sites is for \"Home\" or \"Homepage\", not sure about portuguese.\r\n\r\nMaybe it should use one set of words depending on the lang attribute of the html tag?"
      },
      {
        "user": "IgorWilbert",
        "created_at": "2020-06-30T11:21:04Z",
        "body": "@devngl @patrickhulce as a native Portuguese speaker, I think the main usage of the word \"In√≠cio\" is to make reference to \"Home\"  or \"Homepage\" of the website. I think the idea of using a set of words depending on the language would be better. I would like to take this issue if nobody is willing to work on it, but I think I'll need some guidance since I don't know the codebase very well."
      },
      {
        "user": "patrickhulce",
        "created_at": "2020-06-30T13:13:36Z",
        "body": "> Maybe it should use one set of words depending on the lang attribute of the html tag?\r\n\r\nThat's a neat idea! For now though, let's just remove `In√≠cio` from the audit as it sounds like it's not following the purpose of the audit in *any* language (Home links are fine, we don't want \"Click here\" style links)."
      }
    ]
  },
  {
    "number": 599,
    "title": "Wait for SW to finish installing",
    "created_at": "2016-08-17T10:25:00Z",
    "closed_at": "2017-02-27T21:55:25Z",
    "labels": [
      "help wanted",
      "architecture",
      "gatherers"
    ],
    "url": "https://github.com/GoogleChrome/lighthouse/issues/599",
    "body": "Today we assume that a SW, if there is one, will have installed by the time the first pass finishes. For a large SW install that may not be the case.\n\nI think we need something that watches for a SW to start installing and causes the pass to wait for it before moving to the next one.\n\nAny takers?\n",
    "comments_url": "https://api.github.com/repos/GoogleChrome/lighthouse/issues/599/comments",
    "author": "paullewis",
    "comments": [
      {
        "user": "wardpeet",
        "created_at": "2016-08-18T05:02:31Z",
        "body": "Would this be enough to listen to the activate event of the sw? If no takers I could give it a spin \n"
      },
      {
        "user": "sendilkumarn",
        "created_at": "2016-10-17T10:21:50Z",
        "body": "Can we have it in once the page loading completed. To check and wait till SW is activated. \nI would like to give it a shot. \n"
      },
      {
        "user": "byronigoe",
        "created_at": "2017-02-01T21:08:27Z",
        "body": "With the LH extension I'm getting a checkmark for \"Has a registered Service Worker\" (I'm using sw-precache), but a false-positive failure for \"URL responds with a 200 when offline\". When I test manually, use Developer Tools and enable \"Offline\", all the network requests show a 200, and the page loads completely.\r\n\r\nThe URL is veggietables.org/app, and this is a decent size AngularJS webapp. My minified JS file is 580K, and I get a \"First meaningful paint\" of between 4 and 6 seconds. When running the test with version 1.4.1 of the LH extension, the page refreshes a bunch of times quite quickly. So, my hypothesis is that the SW is not done installing/precaching.\r\n\r\nAny help would be appreciated."
      },
      {
        "user": "patrickhulce",
        "created_at": "2017-02-01T21:20:32Z",
        "body": "@byronigoe your situation might also be an artifact of #1296 which has been fixed in master but yet to be released in the extension, do you get the same problem running with a git checkout from command line?"
      },
      {
        "user": "byronigoe",
        "created_at": "2017-02-01T22:58:06Z",
        "body": "Thanks for the tip, @patrickhulce \r\nThe first time running the CLI from master it gave the same false positive. Subsequent runs correctly reported that it works offline. So, it seems that the recent fix (almost completely) solves the issue."
      },
      {
        "user": "wardpeet",
        "created_at": "2017-02-20T22:07:55Z",
        "body": "@byronigoe @patrickhulce should  I close this issue?"
      },
      {
        "user": "byronigoe",
        "created_at": "2017-02-21T15:24:13Z",
        "body": "@wardpeet Yes, I think that's fine."
      },
      {
        "user": "patrickhulce",
        "created_at": "2017-02-21T18:20:17Z",
        "body": "@wardpeet do you happen to have a working example of this issue from before? I would assume that the waitForLoad logic that waits for network idle (introduced after this issue was created) has rendered it obsolete, but I'm not sure."
      },
      {
        "user": "wardpeet",
        "created_at": "2017-02-27T08:22:06Z",
        "body": "@patrickhulce no I did not, maybe ask @paullewis or @jakearchibald üòõ \r\n\r\nI only asked the question if it would be a workable fix. I could create an example though where it might give an issue"
      },
      {
        "user": "paulirish",
        "created_at": "2017-02-27T21:55:25Z",
        "body": "I believe this is fixed as our second pass (where we do the sw gatherer) has a navigation to about:blank inbetween which gives the SW a chance to not only finish installing but activate\r\n\r\nlet's close, unless someone can repro this."
      }
    ]
  },
  {
    "number": 475,
    "title": "Travis: enable testing of node v4 + --harmony",
    "created_at": "2016-06-27T21:50:13Z",
    "closed_at": "2016-07-12T19:09:29Z",
    "labels": [
      "help wanted"
    ],
    "url": "https://github.com/GoogleChrome/lighthouse/issues/475",
    "body": "Thus bringing our test matrix to:\n- v4 + harmony\n- v5\n- v6\n\nAny takers?\n",
    "comments_url": "https://api.github.com/repos/GoogleChrome/lighthouse/issues/475/comments",
    "author": "paulirish",
    "comments": [
      {
        "user": "brendankenny",
        "created_at": "2016-06-27T21:57:08Z",
        "body": "emphasizing _not_ running v5 with `--harmony`, which makes this a bit harder, but ensures we really do run on vanilla v5.\n"
      },
      {
        "user": "michaelgerakis",
        "created_at": "2016-06-27T23:23:42Z",
        "body": "One solution that comes to mind would be to move the npm scripts into a Makefile. The scripts then become `make lint/smoke/etc`. Inside the Makefile, we can check the version of node and if that version matches 4 we run files through node with the `--harmony` flag\n"
      },
      {
        "user": "wardpeet",
        "created_at": "2016-06-29T20:32:25Z",
        "body": "make or any other helper is probably much easier but you could do something like this\n`$(test $(node -v) =~ \"^v5.*\" && echo $(npm bin)\"/mocha --harmony\" || echo $(npm bin)\"/mocha\") $(find lighthouse-core/test -name '*.js') --timeout 60000` inside your package.json. Of course it's not really pretty, i suppose it can be written a bit shorter.\n\nIf you are looking for something like this rather than a \"make\" or \"bash\" file I can cook up a PR.\n"
      },
      {
        "user": "wardpeet",
        "created_at": "2016-07-02T21:10:20Z",
        "body": "@paulirish @brendankenny what do you guys think? Do it native with bash or rather have something in between? I could do a pr with just a one liner and see what you guys think?\n"
      },
      {
        "user": "brendankenny",
        "created_at": "2016-07-06T21:26:29Z",
        "body": "what about passing an argument into the npm scripts and let the `travis.yml` handle the node version detection part?\n"
      },
      {
        "user": "wardpeet",
        "created_at": "2016-07-06T22:04:51Z",
        "body": "sounds better but no idea how to do that :)\n"
      },
      {
        "user": "avegancafe",
        "created_at": "2016-07-10T01:13:13Z",
        "body": "What about using a more node friendly task runner like gulp or grunt? Might help with the node versioning as well\n"
      },
      {
        "user": "paulirish",
        "created_at": "2016-07-12T19:09:27Z",
        "body": "fixed by #501 \n"
      }
    ]
  }
]