[
  {
    "number": 2717,
    "title": "The `watch-files` suspended during `/run` command",
    "created_at": "2024-12-28T08:50:12Z",
    "closed_at": "2025-01-02T23:36:04Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/2717",
    "body": "### Issue\r\nIt seems like Aider ignores file changes if they're made during a `/run` command\r\n\r\n### Reproduce steps\r\n- Create a file with a valid Aider comment (e.x. `-- ai?`)\r\n- Start up Aider with `--watch-files` (after comment creation)\r\n- Run in Aider `/run touch <path with ai comment>` (in-order to trigger Aider to process the comment)\r\n\r\nAider will never process the AI comment. Although if you run the same command in a another terminal, Aider does process the comment as expected.\r\n\r\n### Version and model info\r\n\r\nAider v0.69.1\r\nModel: gemini/gemini-exp-1206 with whole edit format\r\nGit repo: .git with 19 files\r\nRepo-map: using 1024 tokens, files refresh",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/2717/comments",
    "author": "aweis89",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-12-28T13:01:31Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nYes, aider only watches for changes when it is waiting for your input at the aider > prompt. "
      }
    ]
  },
  {
    "number": 2713,
    "title": "/read-only doesn't abide .aiderignore / .gitignore",
    "created_at": "2024-12-27T07:04:09Z",
    "closed_at": "2025-01-05T12:51:28Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/2713",
    "body": "### Issue\r\n\r\nRunning `/read-only **/*.cs` includes files from ignored directories that `/add` doesn't. (files from obj/ and bin/ folders)\r\nExpected behavior is that both `/add` and `/read-only` reach same files / ignore the same files.\r\nPresumably because `/read-only` does take into account `.aiderignore` / `.gitignore`\r\n\r\n### Version and model info\r\n\r\nAider v0.69",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/2713/comments",
    "author": "Nucs",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-12-28T15:02:11Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nThe `/read-only` command intentionally does not respect gitignore and aiderignore. It allows you to read in any file from anywhere in the file system."
      }
    ]
  },
  {
    "number": 2624,
    "title": "--watch-files doesn't work with Scala files",
    "created_at": "2024-12-14T00:24:48Z",
    "closed_at": "2024-12-16T18:37:18Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/2624",
    "body": "### Issue\r\n\r\nScala supports '//' style comments just like Java so it could be added to the corresponding list of file extensions so that \"Aider in your IDE\" works.\r\n\r\n### Version and model info\r\n\r\naider-chat                           0.68.0",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/2624/comments",
    "author": "pkozikow",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-12-14T00:58:11Z",
        "body": "This should be fixed in the latest version. You can get it like this:\r\n\r\n```\r\naider --upgrade\r\n\r\n# or...\r\n\r\npython -m pip install --upgrade --upgrade-strategy only-if-needed aider-chat\r\n```\r\n\r\nIf you have a chance to try it, let me know if it works better for you."
      },
      {
        "user": "lockmeister",
        "created_at": "2024-12-16T06:12:07Z",
        "body": "See #2586\r\n@paul-gauthier  I recommend allowing a user-defined trigger. Or something like `@aider` anywhere within the file."
      },
      {
        "user": "pkozikow",
        "created_at": "2024-12-16T18:37:19Z",
        "body": "That was fast! It works in 0.69.0. Thanks."
      }
    ]
  },
  {
    "number": 2514,
    "title": "Watch files AI! command not being detected when at the start of comment",
    "created_at": "2024-12-02T15:24:05Z",
    "closed_at": "2024-12-03T14:04:59Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/2514",
    "body": "### Issue\n\nUsing this snippet of code testing out the watch-files expt feature \r\n```python\r\nfrom whoosh import index\r\nfrom whoosh.fields import Schema, TEXT, ID\r\nfrom whoosh.qparser import QueryParser\r\nimport os\r\nfrom typing import List\r\n\r\n\r\nclass WhooshSearcher:\r\n    def __init__(self):\r\n        self.index_dir = \"whoosh_index\"\r\n        self.schema = Schema(id=ID(stored=True), content=TEXT(stored=True))\r\n        self.ix = None\r\n        self.initialize_index()\r\n\r\n    def initialize_index(self):\r\n        if not os.path.exists(self.index_dir):\r\n            os.makedirs(self.index_dir)\r\n            self.ix = index.create_in(self.index_dir, self.schema)\r\n        else:\r\n            self.ix = index.open_dir(self.index_dir)\r\n\r\n    def index_documents(self, documents: List[dict]):\r\n        writer = self.ix.writer()\r\n        # AI\r\n        # Diagnostics:\r\n        # 1. \"writer\" is not a known attribute of \"None\" [reportOptionalMemberAccess]\r\n        for doc in documents:\r\n            writer.add_document(id=str(doc[\"id\"]), content=doc[\"content\"])\r\n        writer.commit()\r\n\r\n    def search(self, query_str: str, limit: int = 10) -> List[dict]:\r\n        with self.ix.searcher() as searcher:\r\n            # AI\r\n            # Diagnostics:\r\n            # 1. \"searcher\" is not a known attribute of \"None\" [reportOptionalMemberAccess]\r\n            query = QueryParser(\"content\", self.ix.schema).parse(query_str)\r\n            # AI! please fix this\r\n            # Diagnostics:\r\n            # 1. \"schema\" is not a known attribute of \"None\" [reportOptionalMemberAccess]\r\n            results = searcher.search(query, limit=limit)\r\n            return [{\"id\": hit[\"id\"], \"content\": hit[\"content\"]} for hit in results]\r\n\r\n```\r\n\r\nthe comment line \r\n`# AI! please fix this`\r\nDoes not trigger aider but \r\n`# please fix this AI!` does\r\n\r\n\n\n### Version and model info\n\nAider v0.66.1.dev215+g75d24974\r\nMain model: claude-3-5-sonnet-20241022 with architect edit format, infinite output\r\nEditor model: claude-3-5-sonnet-20241022 with editor-diff edit format\r\nWeak model: claude-3-5-haiku-20241022\r\nGit repo: .git with 13 files\r\nRepo-map: using 1024 tokens, auto refresh\r\nAdded signs_rag_lambda/main.py to the chat.\r\nAdded signs_rag_lambda/routers/query_router.py to the chat.\r\nAdded signs_rag_lambda/services/whoosh_service.py to the chat.\r\nRestored previous conversation history.\r\nCommand Line Args:   --watch-files --no-auto-commit --no-auto-lint --no-suggest-shell-commands\r\n--env-file /Users/gem/.env.aider --sonnet --architect --editor-model claude-3-5-sonnet-20241022\r\n--verbose\r\n\r\nEnvironment Variables:\r\n  OPENAI_API_KEY:    ...uTUA\r\n  ANTHROPIC_API_KEY: ...uQAA\r\n\r\nDefaults:\r\n  --model-settings-file:.aider.model.settings.yml\r\n  --model-metadata-file:.aider.model.metadata.json\r\n  --cache-keepalive-pings:0\r\n  --map-refresh:     auto\r\n  --map-multiplier-no-files:2\r\n  --input-history-file:/Users/gem/git/sevron/signs-rag-lambda/.aider.input.history\r\n  --chat-history-file:/Users/gem/git/sevron/signs-rag-lambda/.aider.chat.history.md\r\n  --user-input-color:#00cc00\r\n  --tool-error-color:#FF2222\r\n  --tool-warning-color:#FFA500\r\n  --assistant-output-color:#0088ff\r\n  --code-theme:      default\r\n  --aiderignore:     /Users/gem/git/sevron/signs-rag-lambda/.aiderignore\r\n  --lint-cmd:        []\r\n  --test-cmd:        []\r\n  --encoding:        utf-8\r\n  --voice-format:    wav\r\n  --voice-language:  en\r\n\r\nOption settings:\r\n  - aiderignore: /Users/gem/git/sevron/signs-rag-lambda/.aiderignore\r\n  - alias: None\r\n  - analytics: None\r\n  - analytics_disable: False\r\n  - analytics_log: None\r\n  - anthropic_api_key: ...uQAA\r\n  - apply: None\r\n  - apply_clipboard_edits: False\r\n  - assistant_output_color: #0088ff\r\n  - attribute_author: True\r\n  - attribute_commit_message_author: False\r\n  - attribute_commit_message_committer: False\r\n  - attribute_committer: True\r\n  - auto_commits: False\r\n  - auto_lint: False\r\n  - auto_test: False\r\n  - cache_keepalive_pings: 0\r\n  - cache_prompts: False\r\n  - chat_history_file: /Users/gem/git/sevron/signs-rag-lambda/.aider.chat.history.md\r\n  - chat_language: None\r\n  - check_update: True\r\n  - code_theme: default\r\n  - commit: False\r\n  - commit_prompt: None\r\n  - completion_menu_bg_color: None\r\n  - completion_menu_color: None\r\n  - completion_menu_current_bg_color: None\r\n  - completion_menu_current_color: None\r\n  - config: None\r\n  - dark_mode: False\r\n  - detect_urls: True\r\n  - dirty_commits: True\r\n  - dry_run: False\r\n  - edit_format: architect\r\n  - editor: None\r\n  - editor_edit_format: None\r\n  - editor_model: claude-3-5-sonnet-20241022\r\n  - encoding: utf-8\r\n  - env_file: /Users/gem/.env.aider\r\n  - exit: False\r\n  - fancy_input: True\r\n  - file: None\r\n  - files: []\r\n  - git: True\r\n  - gitignore: True\r\n  - gui: False\r\n  - input_history_file: /Users/gem/git/sevron/signs-rag-lambda/.aider.input.history\r\n  - install_main_branch: False\r\n  - just_check_update: False\r\n  - light_mode: False\r\n  - lint: False\r\n  - lint_cmd: []\r\n  - list_models: None\r\n  - llm_history_file: None\r\n  - load: None\r\n  - map_multiplier_no_files: 2\r\n  - map_refresh: auto\r\n  - map_tokens: None\r\n  - max_chat_history_tokens: None\r\n  - message: None\r\n  - message_file: None\r\n  - model: claude-3-5-sonnet-20241022\r\n  - model_metadata_file: .aider.model.metadata.json\r\n  - model_settings_file: .aider.model.settings.yml\r\n  - openai_api_base: None\r\n  - openai_api_deployment_id: None\r\n  - openai_api_key: ...uTUA\r\n  - openai_api_type: None\r\n  - openai_api_version: None\r\n  - openai_organization_id: None\r\n  - pretty: True\r\n  - read: None\r\n  - restore_chat_history: False\r\n  - show_diffs: False\r\n  - show_model_warnings: True\r\n  - show_prompts: False\r\n  - show_release_notes: None\r\n  - show_repo_map: False\r\n  - skip_sanity_check_repo: False\r\n  - stream: True\r\n  - subtree_only: False\r\n  - suggest_shell_commands: False\r\n  - test: False\r\n  - test_cmd: []\r\n  - timeout: None\r\n  - tool_error_color: #FF2222\r\n  - tool_output_color: None\r\n  - tool_warning_color: #FFA500\r\n  - upgrade: False\r\n  - user_input_color: #00cc00\r\n  - verbose: True\r\n  - verify_ssl: True\r\n  - vim: False\r\n  - voice_format: wav\r\n  - voice_input_device: None\r\n  - voice_language: en\r\n  - watch_files: True\r\n  - weak_model: None\r\n  - yes_always: None\r\n",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/2514/comments",
    "author": "gembancud",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-12-02T16:59:10Z",
        "body": "Thanks, this should be fixed in the main branch."
      }
    ]
  },
  {
    "number": 2471,
    "title": "Feature Request: \"Refine Plan\" Option in Architect Mode",
    "created_at": "2024-11-27T08:25:15Z",
    "closed_at": "2024-11-30T08:27:57Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/2471",
    "body": "### Issue\n\nArchitect mode is a valuable tool, but I often want to make minor/major adjustments to its proposed plans. Currently, the only options available once a plan is prepared are \"Edit the files? (Y)es/(N)o [Yes]:\".\r\n\r\nI propose adding a third option, \"Refine Plan,\" which would allow users to request modifications to the plan to the architect model before editing the files. This would streamline workflows by reducing the need for multiple file edits and LLM calls. My current workaround involves editing files and then requesting further changes from the architect, which is inefficient and time-consuming.\r\n\r\nThank you for considering this improvement to enhance the user experience.\n\n### Version and model info\n\nAider v0.64.1\r\nMain model: o1-preview with architect edit format\r\nEditor model: anthropic/claude-3-5-sonnet-20241022 with editor-diff edit format\r\nWeak model: gpt-4o-mini\r\nGit repo: .git with 45 files\r\nRepo-map: using 1024 tokens, files refresh",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/2471/comments",
    "author": "rubik",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-11-27T15:41:45Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nYou can just answer \"No\" and then send a message like \"Please refine the plan to ...\"."
      },
      {
        "user": "rubik",
        "created_at": "2024-11-30T08:27:57Z",
        "body": "@paul-gauthier Thank you for the quick reply. It makes sense; for some reason I thought that answering \"No\" would discard the plan."
      }
    ]
  },
  {
    "number": 2439,
    "title": "Bug Aider with VertexAI anthorophic last version",
    "created_at": "2024-11-23T13:32:15Z",
    "closed_at": "2024-12-10T17:19:19Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/2439",
    "body": "### Issue\r\n\r\nI am using vertexai anthophic last version and I get this error when trying to talk with claude 3.5 last version when I add an image to the chat (.png file).\r\nlitellm.InternalServerError: VertexAIException InternalServerError - b'{\"type\":\"error\",\"error\":{\"type\":\"invalid_request_error\",\"message\":\"Unexpected value(s) `pdfs-2024-09-25` for \r\nthe `anthropic-beta` header. Please consult our documentation at docs.anthropic.com or try again without the header.\"}}'\r\nThe API provider's servers are down or overloaded.\r\nRetrying in 0.2 seconds...\r\nlitellm.InternalServerError: VertexAIException InternalServerError - b'{\"type\":\"error\",\"error\":{\"type\":\"invalid_request_error\",\"message\":\"Unexpected value(s) `pdfs-2024-09-25` for \r\nthe `anthropic-beta` header. Please consult our documentation at docs.anthropic.com or try again without the header.\"}}'\r\nThe API provider's servers are down or overloaded.\r\nRetrying in 0.5 seconds...\r\nlitellm.InternalServerError: VertexAIException InternalServerError - b'{\"type\":\"error\",\"error\":{\"type\":\"invalid_request_error\",\"message\":\"Unexpected value(s) `pdfs-2024-09-25` for \r\nthe `anthropic-beta` header. Please consult our documentation at docs.anthropic.com or try again without the header.\"}}'\r\nThe API provider's servers are down or overloaded.\r\nRetrying in 1.0 seconds...\r\n\r\n\r\nI started having this problem since Aider 0.61.0\r\n\r\n### Version and model info\r\n\r\nAider 0.64.0\r\nVersion: vertexai anthrophic claude3.5 last version.",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/2439/comments",
    "author": "xavitg",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-12-03T15:52:29Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nAider isn't configured to send the BETA headers to Vertex. How have you configured aider with vertex? Do you still see this with the latest v0.66 aider?"
      },
      {
        "user": "wottpal",
        "created_at": "2024-12-10T17:16:26Z",
        "body": "Did you manage to resolve this, @xavitg?"
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-12-10T17:19:19Z",
        "body": "This looks like a duplicate of #2447. Please see the comments there for more information, and feel free to continue the discussion within that issue.\r\n\r\nI'm going to close this issue for now. But please let me know if you think this is actually a distinct issue and I will reopen this issue."
      }
    ]
  },
  {
    "number": 2418,
    "title": "Feature: allow ad hoc chat mode for `/editor`",
    "created_at": "2024-11-21T19:04:27Z",
    "closed_at": "2024-11-22T03:27:50Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/2418",
    "body": "Currently, `/editor` operates in the selected chat mode. Similar to using `/ask` when in code mode, it would be nice if the `/editor` command could be invoked with an ad hoc chat mode.\r\n\r\nI see a couple of ways to attack this, each with trade offs:\r\n\r\n1. **Allow chat mode commands inside the editor:** Similar to how the main interface works, if the text in the editor starts with a chat mode command (like `/ask`), then switch to that mode for that input. This would be most familiar to people, but from my look, I think it would require a substantial refactor, because you'd essentially be running a command inside a command.\r\n2. **Pass chat mode as an arg to `/editor`:** Less familiar syntax, but more straightforward to implement. Validation of the argument should be pretty straightforward.\r\n\r\nI'm happy to take a crack at the PR for this, but do not want to start until we've decided on a best approach.\r\n\r\n@paul-gauthier thoughts?",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/2418/comments",
    "author": "thehunmonkgroup",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-11-21T19:50:53Z",
        "body": "Ya, neither approach is super attractive. I probably think this is best left as something to be done in 2 commands."
      },
      {
        "user": "thehunmonkgroup",
        "created_at": "2024-11-22T02:25:45Z",
        "body": "> Ya, neither approach is super attractive. I probably think this is best left as something to be done in 2 commands.\r\n\r\nI can let this go. Sadly, it's currently three commands (switch to new mode, run editor, switch back to original mode), and that adds up over time."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-11-22T02:36:50Z",
        "body": "Give the main branch a try. Now when you exit the editor, it simply prefills the text into the prompt. You press enter to submit it. So now it can contain /commands which will run.\r\n\r\nThis allows you to make a file like:\r\n\r\n```\r\n/ask \r\n\r\nFor something...\r\n...long and complicated\r\n```\r\n"
      },
      {
        "user": "thehunmonkgroup",
        "created_at": "2024-11-22T03:27:50Z",
        "body": "You nailed it, that's the perfect solution."
      }
    ]
  },
  {
    "number": 2370,
    "title": "x",
    "created_at": "2024-11-14T17:14:35Z",
    "closed_at": "2024-12-10T00:30:31Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/2370",
    "body": null,
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/2370/comments",
    "author": "ghost",
    "comments": [
      {
        "user": "SanderVocke",
        "created_at": "2024-12-03T02:44:27Z",
        "body": "Seconding this. At the moment I am doing lots of changes that add methods to existing Rust classes. Aider keeps coming up with search/replace blocks like:\r\n\r\n```\r\n<<<<<<< SEARCH                                                                               \r\n     }                                                                                        \r\n =======                                                                                      \r\n     }                                                                                        \r\n                                                                                              \r\n     pub fn available(&self) -> bool {                                                        \r\n         !self.obj.lock().unwrap().is_null()                                                  \r\n     }                                                                                        \r\n                                                                                              \r\n     pub fn set_visible(&self, visible: bool) {                                               \r\n         if self.available() {                                                                \r\n             unsafe {                                                                         \r\n                 ffi::fx_chain_set_ui_visible(*self.obj.lock().unwrap(), visible as u32);     \r\n             }                                                                                \r\n         }                                                                                    \r\n     }\r\n}\r\n >>>>>>> REPLACE \r\n ```\r\n\r\n This is not just incidental, but happens all the time with these kinds of changes (which makes sense)."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-12-03T16:30:40Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nBoth approaches have problems. I've tested this both ways, and benchmarks do better this way. "
      },
      {
        "user": "SanderVocke",
        "created_at": "2024-12-04T11:58:35Z",
        "body": "Thanks for the reply. Maybe there is another solution or improvement possible?\n\nI don't know how these search/replace blocks are built, but it seems to me like in my example, if there was a bit more context in the \"search\" part, the new code would not be misplaced.\n\nThanks for this lovely tool! For me this is just a minor issue."
      },
      {
        "user": "ghost",
        "created_at": "2024-12-04T14:17:02Z",
        "body": "w"
      },
      {
        "user": "SanderVocke",
        "created_at": "2024-12-21T16:20:55Z",
        "body": "Could someone elaborate what happened here? It seems the topic was erased and renamed so that now it is unclear what it was originally about. I don't  understand whether it is discarded, solved or otherwise."
      }
    ]
  },
  {
    "number": 2215,
    "title": "Q?: Why is the cache being warmed with 23K when I have no files loaded?",
    "created_at": "2024-10-31T21:07:13Z",
    "closed_at": "2024-11-01T13:13:43Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/2215",
    "body": "### Issue\r\n\r\nI was using aider for a few minutes and then the phone rang.  I knew it might be a longer call so I decided to drop my files from the chat, thinking that if I was sitting idle at the prompt with no files loaded, it wouldn't need anything warm in the cache.  \r\n\r\nThen I came back to this on the console, which lead to some questions:\r\n\r\n```\r\n> /drop aider/coders/chat_chunks.py                                                                                                                                                                              \r\n\r\nRemoved aider/coders/chat_chunks.py from the chat\r\n─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n> Warmed 21k cached tokens.\r\nWarmed 21k cached tokens.\r\nWarmed 0 cached tokens.\r\nWarmed 21k cached tokens.                                                                                                                                                                                        \r\nWarmed 21k cached tokens.\r\nWarmed 21k cached tokens.\r\nWarmed 21k cached tokens.\r\nWarmed 21k cached tokens.\r\nWarmed 21k cached tokens.\r\nWarmed 21k cached tokens.\r\nWarmed 21k cached tokens.\r\nWarmed 21k cached tokens.\r\nWarmed 21k cached tokens.\r\nWarmed 21k cached tokens.\r\nWarmed 21k cached tokens.\r\nWarmed 21k cached tokens.\r\nWarmed 21k cached tokens.\r\nWarmed 21k cached tokens.\r\nWarmed 21k cached tokens.\r\nWarmed 21k cached tokens.\r\nWarmed 21k cached tokens.\r\n```\r\nDoes it make sense to be keeping the cache warm when there are no files?  I am assuming the 21K must be chat history and other hidden prompt things and the repo-map?\r\n\r\nAlso, this sequence jumped out at me, any idea what is happening here?\r\n\r\n```\r\nWarmed 21k cached tokens.\r\nWarmed 0 cached tokens.\r\nWarmed 21k cached tokens. \r\n```  \r\n\r\n### Version and model info\r\n\r\nAider v0.60.1\r\nMain model: claude-3-5-sonnet-20241022 with diff edit format, prompt cache, infinite output\r\nWeak model: claude-3-haiku-20240307\r\nGit repo: .git with 361 files\r\nRepo-map: using 1024 tokens, files refresh",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/2215/comments",
    "author": "5ocworkshop",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-10-31T21:19:23Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nAider keeps the existing cache warm, whatever it last sent to the API."
      },
      {
        "user": "5ocworkshop",
        "created_at": "2024-11-01T13:13:43Z",
        "body": "Thank you, good to know."
      }
    ]
  },
  {
    "number": 2194,
    "title": "aider read-only doesn't accept wildcard but add does?",
    "created_at": "2024-10-30T04:21:16Z",
    "closed_at": "2024-11-14T18:04:45Z",
    "labels": [
      "question",
      "stale"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/2194",
    "body": "### Issue\n\n```\r\n> /read-only src/core/*.hpp                                                                                                \r\n\r\nNo matches found for: src/core/*.hpp\r\n───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n> /read-only src/core/*                                                                                                    \r\n\r\nNo matches found for: src/core/*\r\n───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n> /read-only src/core/                                                                                                     \r\n\r\nNo matches found for: src/core/\r\n───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n> /add src/core/*.hpp                                                                                                      \r\n\r\nAdded src/core/IObjectConfigurator.hpp to the chat\r\nAdded src/core/IObjectInformation.hpp to the chat\r\nAdded src/core/IVideoSource.hpp to the chat\r\nAdded src/core/IVideoSourceListener.hpp to the chat\r\nAdded src/core/XError.hpp to the chat\r\nAdded src/core/XImage.hpp to the chat\r\nAdded src/core/XImageDrawing.hpp to the chat\r\nAdded src/core/XInterfaces.hpp to the chat\r\nAdded src/core/XJpegEncoder.hpp to the chat\r\nAdded src/core/XManualResetEvent.hpp to the chat\r\nAdded src/core/XObjectConfigurationRequestHandler.hpp to the chat\r\nAdded src/core/XObjectConfigurationSerializer.hpp to the chat\r\nAdded src/core/XSimpleJsonParser.hpp to the chat\r\nAdded src/core/XStringTools.hpp to the chat\r\nAdded src/core/XVideoFrameDecorator.hpp to the chat\r\nAdded src/core/XVideoSourceToWeb.hpp to the chat\r\nAdded src/core/XWebServer.hpp to the chat\r\n```\n\n### Version and model info\n\nAider v0.60.1\r\nMain model: gpt-4o-2024-08-06 with diff edit format\r\nWeak model: gpt-4o-mini",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/2194/comments",
    "author": "Kreijstal",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-10-30T13:35:40Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nI am unable to reproduce this?\r\n\r\n```\r\nAider v0.60.2.dev13+g9e7995b7\r\nModel: claude-3-5-sonnet-20241022 with diff edit format, prompt cache, infinite output\r\nGit repo: .git with 351 files\r\nRepo-map: using 1024 tokens, files refresh\r\nUse /help <question> for help, run \"aider --help\" to see cmd line args\r\n──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n> /read aider/*.py\r\n\r\nAdded /Users/gauthier/Projects/aider/aider/__init__.py to read-only files.\r\nAdded /Users/gauthier/Projects/aider/aider/__main__.py to read-only files.\r\nAdded /Users/gauthier/Projects/aider/aider/__version__.py to read-only files.\r\nAdded /Users/gauthier/Projects/aider/aider/args.py to read-only files.\r\n```\r\n\r\n"
      },
      {
        "user": "Kreijstal",
        "created_at": "2024-10-30T14:51:04Z",
        "body": "Interesting.... I'll try with another computer"
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-10-30T16:45:28Z",
        "body": "Did you launch aider in a subdir? See #2200."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-11-14T14:50:11Z",
        "body": "I'm labeling this issue as stale because it has been open for 2 weeks with no activity. If there are no additional comments, it will be closed in 7 days."
      },
      {
        "user": "Kreijstal",
        "created_at": "2024-11-14T18:04:45Z",
        "body": "It's solved"
      }
    ]
  },
  {
    "number": 2181,
    "title": "Vertex AI: Missing module 'google'",
    "created_at": "2024-10-29T02:16:59Z",
    "closed_at": "2024-11-01T07:11:00Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/2181",
    "body": "### Issue\r\n\r\nHello!\r\n\r\nJust a small thing, using Aider v0.60.1 with Vertex AI, the authentication fails:\r\n\r\n```\r\nlitellm.APIConnectionError: No module named 'google'\r\nTraceback (most recent call last):\r\n  File \"/home/jasmin/.local/share/pipx/venvs/aider-chat/lib/python3.12/site-packages/litellm/main.py\", line 2171, in \r\ncompletion\r\n    model_response = vertex_chat_completion.completion(  # type: ignore\r\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \r\n\"/home/jasmin/.local/share/pipx/venvs/aider-chat/lib/python3.12/site-packages/litellm/llms/vertex_ai_and_google_ai_stu\r\ndio/gemini/vertex_and_google_ai_studio_gemini.py\", line 1325, in completion\r\n    _auth_header, vertex_project = self._ensure_access_token(\r\n                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \r\n\"/home/jasmin/.local/share/pipx/venvs/aider-chat/lib/python3.12/site-packages/litellm/llms/vertex_ai_and_google_ai_stu\r\ndio/vertex_llm_base.py\", line 137, in _ensure_access_token\r\n    self._credentials, cred_project_id = self.load_auth(\r\n                                         ^^^^^^^^^^^^^^^\r\n  File \r\n\"/home/jasmin/.local/share/pipx/venvs/aider-chat/lib/python3.12/site-packages/litellm/llms/vertex_ai_and_google_ai_stu\r\ndio/vertex_llm_base.py\", line 45, in load_auth\r\n    import google.auth as google_auth\r\nModuleNotFoundError: No module named 'google'\r\n```\r\n\r\nAs you can see, I am using a `pipx` installation.\r\n\r\nAs a workaround, I can use `pipx inject aider-chat google-auth` for now.\r\n\r\nMaybe it would be better to add `google-auth` as a dependency.\r\n\r\nThank you!\r\n\r\n### Version and model info\r\n\r\nAider v0.60.1, Model: any Vertex AI",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/2181/comments",
    "author": "Jasmin68k",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-10-31T22:44:41Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nIt's a big dependency, so aider leaves it the user to install if they use vertex."
      },
      {
        "user": "Jasmin68k",
        "created_at": "2024-11-01T07:11:01Z",
        "body": "I see, no worries then, thank you!"
      }
    ]
  },
  {
    "number": 2147,
    "title": "Specify model name like \"claude-sonnet-latest\"",
    "created_at": "2024-10-24T23:28:37Z",
    "closed_at": "2024-10-31T21:58:52Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/2147",
    "body": "### Issue\n\nI have these options in my config file to use o1-preview as my architect and claude-sonnet as my editor, \r\n\r\no1-preview: true\r\narchitect: true\r\neditor-model: claude-3-5-sonnet-20241022\r\n\r\nthis works, but it'd be great if I could say something like \"claude-sonnet-latest\" instead of that specific date version.  for example, it appears I can use the more generic model name \"gpt-4o\".  I'm guessing this is really just an artifact of how these api's work, but still it'd be nice if aider would abstract over that for me and let me just say somehow in my config \"use the latest, whatever that may be\".  \n\n### Version and model info\n\n_No response_",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/2147/comments",
    "author": "jubishop",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-10-31T21:53:59Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nYou can use `anthropic/claude-3-5-sonnet-latest`."
      },
      {
        "user": "jubishop",
        "created_at": "2024-10-31T21:58:52Z",
        "body": "oh thanks!  I missed that. "
      }
    ]
  },
  {
    "number": 2128,
    "title": "Feature request: Refresh / update / add locally modified files",
    "created_at": "2024-10-23T12:36:41Z",
    "closed_at": "2024-10-23T15:43:17Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/2128",
    "body": "### Issue\n\nFor complicated changes, I often find that it makes the most sense to make a few simple changes on top of what `aider` has done, and then ask it to pick up from there, rather than trying to explain in words what I want to be done.  But then `aider`'s idea of the state of then file has diverged from mine. `/add file.ext` refuses to add the file again, since it's already been added; this probably makes sense to avoid duplication, but it seems like having a `/refresh file.ext` command to re-upload the new version of the file would make sense.  (Or maybe some sort of diff from the previous version that aider sent?)\r\n\r\nIf there's an appropriate command that I missed, please let me know!\n\n### Version and model info\n\nAider v0.59.1\r\nMain model: claude-3-5-sonnet-20240620 with diff edit format, infinite output\r\nGit repo: .git with 220 files\r\nauto-commit: false\r\n",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/2128/comments",
    "author": "gwd",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-10-23T14:51:20Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nAider always reads the latest copy of the files from the file system when sending them to the LLM. "
      },
      {
        "user": "gwd",
        "created_at": "2024-10-23T15:43:17Z",
        "body": "You're right -- I thought it didn't because at some point it tried to edit something I'd already edited; that must have been an LLM quirk.  Thanks for the quick response, and sorry for the noise!"
      }
    ]
  },
  {
    "number": 2124,
    "title": "Uncaught KeyError in models.py line 1039",
    "created_at": "2024-10-23T02:26:44Z",
    "closed_at": "2024-10-26T17:15:44Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/2124",
    "body": "Aider version: 0.60.0\r\nPython version: 3.12.7\r\nPlatform: macOS-15.1-arm64-arm-64bit\r\nPython implementation: CPython\r\nVirtual environment: Yes\r\nOS: Darwin 24.1.0 (64bit)\r\nGit version: git version 2.46.1\r\n\r\nAn uncaught exception occurred:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"aider\", line 8, in <module>\r\n    sys.exit(main())\r\n             ^^^^^^\r\n  File \"main.py\", line 601, in main\r\n    problem = models.sanity_check_models(io, main_model)\r\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"models.py\", line 975, in sanity_check_models\r\n    problem_main = sanity_check_model(io, main_model)\r\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"models.py\", line 1019, in sanity_check_model\r\n    possible_matches = fuzzy_match_models(model.name)\r\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"models.py\", line 1039, in fuzzy_match_models\r\n    provider = (attrs[\"litellm_provider\"] + \"/\").lower()\r\n                ~~~~~^^^^^^^^^^^^^^^^^^^^\r\nKeyError: 'litellm_provider'\r\n\r\n```",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/2124/comments",
    "author": "lenohard",
    "comments": [
      {
        "user": "lenohard",
        "created_at": "2024-10-23T02:35:00Z",
        "body": "I use a openai compatiable endpoint by settting the `OPENAI_API_BASE` and `OPENAI_API_KEY`. This service support anthropic's model, and I include the following settting in `~/.aider.model.settings.yml`: \r\n\r\n```\r\n> - accepts_images: true\r\n>   cache_control: true\r\n>   caches_by_default: false\r\n>   edit_format: diff\r\n>   editor_edit_format: editor-diff\r\n>   editor_model_name: openai/claude-3-5-sonnet-20240620\r\n>   examples_as_sys_msg: true\r\n>   extra_params:\r\n>     extra_headers:\r\n>       anthropic-beta: prompt-caching-2024-07-31\r\n>   lazy: false\r\n>   name: openai/claude-3-5-sonnet-20240620\r\n>   reminder: user\r\n>   send_undo_reply: false\r\n>   streaming: true\r\n>   use_repo_map: true\r\n>   use_system_prompt: true\r\n>   use_temperature: true\r\n>   weak_model_name: openai/gpt-4o-mini\r\n> - accepts_images: true\r\n>   cache_control: true\r\n>   caches_by_default: false\r\n>   edit_format: diff\r\n>   editor_edit_format: editor-diff\r\n>   editor_model_name: openai/claude-3-5-sonnet-20241022\r\n>   examples_as_sys_msg: true\r\n>   extra_params:\r\n>     extra_headers:\r\n>       anthropic-beta: prompt-caching-2024-07-31\r\n>   lazy: false\r\n>   name: openai/claude-3-5-sonnet-20241022\r\n>   reminder: user\r\n>   send_undo_reply: false\r\n>   streaming: true\r\n>   use_repo_map: true\r\n>   use_system_prompt: true\r\n>   use_temperature: true\r\n>   weak_model_name: openai/gpt-4o-mini\r\n> - accepts_images: false\r\n>   cache_control: false\r\n>   caches_by_default: false\r\n>   edit_format: whole\r\n>   editor_edit_format: editor-diff\r\n>   editor_model_name: openai/gpt-4o\r\n>   examples_as_sys_msg: false\r\n>   extra_params: null\r\n>   lazy: false\r\n>   name: openai/o1-mini\r\n>   reminder: user\r\n>   send_undo_reply: false\r\n>   streaming: false\r\n>   use_repo_map: true\r\n>   use_system_prompt: false\r\n>   use_temperature: false\r\n>   weak_model_name: openai/gpt-4o-mini\r\n> - accepts_images: false\r\n>   cache_control: false\r\n>   caches_by_default: false\r\n>   edit_format: whole\r\n>   editor_edit_format: editor-diff\r\n>   editor_model_name: openai/gpt-4o\r\n>   examples_as_sys_msg: false\r\n>   extra_params: null\r\n>   lazy: false\r\n>   name: openai/o1-mini\r\n>   reminder: user\r\n>   send_undo_reply: false\r\n>   streaming: false\r\n>   use_repo_map: true\r\n>   use_system_prompt: false\r\n>   use_temperature: false\r\n>   weak_model_name: openai/gpt-4o-mini\r\n> \r\n```\r\n\r\nthis error occur when I run `aider --model openai/claude-3-5-sonnet-20241022` (fine for claude-3-5-sonnet-20240620).  and when I run `/models XXX` in the interactive session. I suspect that the problem is my edit on the model parameters file. but I don't know how, any insight? thanks."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-10-23T21:13:56Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nAre you using a custom `.aider.model.metadata.json` file? It looks like it is missing the identified key?"
      },
      {
        "user": "lenohard",
        "created_at": "2024-10-24T07:02:41Z",
        "body": "After adding the custom models to the .aider.model.metadata.json file, it works as expected. Thanks! By the way, I also found this through the /help RAG in Aider, and it works beautifully. Aider is truly a wonderful and comfortable tool to work with in almost every aspect. Every corner is perfectly polished, and it operates in the most reasonable way. It's really a pleasure to use, especially with the model from Anthropic, which is fast and reliable."
      }
    ]
  },
  {
    "number": 2095,
    "title": "/ask not working with --browser",
    "created_at": "2024-10-20T13:12:18Z",
    "closed_at": "2024-11-18T15:32:20Z",
    "labels": [
      "question",
      "stale"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/2095",
    "body": "### Issue\n\nWhen using a /ask command and the browser GUI (--browser), aider still edits the file in context.\n\n### Version and model info\n\nAider v0.59.1\r\nMain model: claude-3-5-sonnet-20240620 with diff edit format, infinite output\r\nWeak model: claude-3-haiku-20240307\r\nGit repo: .git with 328 files\r\nRepo-map: using 1024 tokens, auto refresh",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/2095/comments",
    "author": "cpa",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-10-23T21:27:24Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nUnfortunately the browser version doesn't support `/` commands. You can run with `--chat-mode ask` to launch in ask mode."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-11-08T17:20:39Z",
        "body": "This issue has been labelled stale because it has been open for 2 weeks with no activity. Remove stale label or add a comment to keep this issue open. Otherwise, it will be closed in 7 days."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-11-18T15:32:20Z",
        "body": "I'm closing this issue because it has been stalled for 3 weeks with no activity. Feel free to add a comment here and we can re-open it. Or feel free to file a new issue at any time."
      }
    ]
  },
  {
    "number": 2074,
    "title": "Auto drop images!!!",
    "created_at": "2024-10-17T06:51:43Z",
    "closed_at": "2024-11-18T15:32:33Z",
    "labels": [
      "question",
      "stale"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/2074",
    "body": "### Issue\r\n\r\nI would like to streamline aider workflow slightly\r\n\r\ncurrently the way is \r\n- screenshot (mac cmd+shift+opt+4),\r\n- run `/paste`, \r\n- after the next message we type `/drop clipboard` \r\n- tab complete it, hit enter, to drop the image\r\n\r\nthe big friction point is having to manually remove the image being active in the chat, because the common case is to discard it. I would like to have a hotkey i can hit to automate `/drop` for something matching a pattern!\r\n\r\nEven better! By default drop any images. If we want it back we can easily copy the file path that was shown in the earlier prompt in the terminal... or since with official flow it's still potentially in the clipboard one could just re-run `/paste`!\r\n\r\nSo then for the streamlined workflow what I would love to have is: \r\n\r\n- auto drop images after one prompt to aider with the image\r\n- a hotkey we can type to run `/paste` to slurp up image immediately without typing `/paste`. no biggie since user can /drop it manually if it was accidental. Bonus points if we can hit the key and make it do this to add the image from clipboard while we are already in the middle of prompt editing.",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/2074/comments",
    "author": "unphased",
    "comments": [
      {
        "user": "5ocworkshop",
        "created_at": "2024-10-17T11:06:13Z",
        "body": "I've had a similar thought, I like your idea.  Maybe instead of auto-drop we could confirm to drop when the next prompt is submitted and an image that was already submitted is still included in the chat?  Basically the same effect but if you did intend to leave it, you can."
      },
      {
        "user": "unphased",
        "created_at": "2024-10-17T17:58:56Z",
        "body": "I think that's good. It does make me wonder, if images included in past prompts carry forward in the chat history or not. I've simply never had a need to re-submit the same image but maybe depending on the model it could be something that is needed sometimes!"
      },
      {
        "user": "5ocworkshop",
        "created_at": "2024-10-17T21:35:08Z",
        "body": "My understanding is that all files loaded in the current chat will be re-submitted with each query, including the images."
      },
      {
        "user": "unphased",
        "created_at": "2024-10-18T00:24:06Z",
        "body": "what i was asking about was whether images could be included as part of \"chat history\" even if it is removed from the list of context files. It is doubtful since each MLLM has its own specific tokenization schemes for images and i assume chat history is assembled into one big string/file."
      },
      {
        "user": "5ocworkshop",
        "created_at": "2024-10-18T15:27:33Z",
        "body": "That is an interesting question, I don't have any visibility in to that one but am now interested in learning the answer :)\r\n\r\nI also need to turn on --verbose and see if I can get a sense of how the files you include are ordered when submitted."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-10-23T21:18:42Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nSometimes it makes sense to keep images, sometimes it might make sense to auto drop them. How would aider know when to auto drop?"
      },
      {
        "user": "unphased",
        "created_at": "2024-10-23T23:40:03Z",
        "body": "From my experience which is 99% with claude 3.5 sonnet, it has no trouble fully comprehending an image in one shot, and the overwhelming majority of times we use an image to quickly show some error message or something difficult or laborious to convert into text (a.k.a. OCR). But at least from my experience, I never (not \"almost never\", _**never**_) need to go back to ask multiple questions about it. \r\n\r\nI will concede that I can (finally) imagine use cases where we may want to keep an image around. I thought about how someone might have an image to try to iterate with aider and a model to try to author an SVG representation of it. Indeed in THIS kind of workflow one might be working with TWO images (the target, and the result of the code that is being iterated on). Another example might be that we show some error we saw with a screenshot with `/clipboard` and reject the first attempt to address the error message, and then ask the MLLM to reinterpret the error message again, e.g. \"could you try a different approach to solve this problem?\"\r\n\r\nStill, I believe that the vast majority of the time we would want to drop the image instead of keeping it. The reason is that the initial response, even if it isn't leading to some sort of complete resolution, still includes a functionally useful summarization of whatever our screenshot is (often with at least a functionally useful transcription of the most important thing inside of it). \r\n\r\nIt boils down to the fact that whatever stays added by default in the conversation should be whatever's been specified as being part of \"the work\". I just find that images typically do not meet this criteria. It is true that it's impossible to guess much about which content constitutes \"the work\"... that is why `/add` must be done manually, and AI is nowhere near smart enough to automate those decisions for us. But, just as we make the assumption that aider will only ever be asked to manipulate code files which have been checked into git, I feel like this change in behavior would be the codification of a very similar assumption, that is that images (unless they are checked into git, I guess? haha) are to be dropped by default (or prompted to be dropped) after they have been included in the chat one time. \r\n\r\nAs far as I can see... the only reasonable way to think of an image in a conversation with AI is of it having similar semantic properties as some portion of (or an \"attachment\" to, if you will) a prompt, and NOT (as it is being treated now) having similar semantic properties as some code file we have added to the chat.\r\n\r\nAs things are now, the workflow of having to `/drop` as many images as we send to aider puts a damper on using images as much as might be practical, due to the ux overhead.\r\n\r\n_Actually, this entire ux friction point could be eliminated if we introduce something separate but more powerful, like a terminal mouse right click event handler, so that we could just go right click any file in the added files list to instantly drop them from the aider prompt!_ After approaching this problem from the other end (making it easier to drop files) I think that is the best way forward, because with quicker UX then all the complexity around auto-file-adding (currently i see a lot of existing behavior that tries to guess and prompt for auto add of mentioned files) and file dropping (only adds cost to keep stuff loaded, so we never auto drop anything to avoid frustrating the user, it's understandable) could be fully eliminated with few drawbacks. I'm going to make a new topic about this... I might just go experiment on a PR for this right away. I want to introduce a project tree view that can be clicked to include/uninclude for aider.  \r\n\r\nI would also like to put a prompt cost estimate right into the prompt instead of needing to type `/tokens` to view that. And so on and so forth...\r\n\r\n------\r\n\r\nIt's been clear to me for a while that the frontier of AI augmented capabilities has a huge deal to do with what you put in the prompt and how you choose what goes into it, so it means that what we will ultimately be able to accomplish is going to end up in a large part shaped by the granularity afforded to us by the tools we use to control what's in our prompts. \r\n\r\nas such there is a high relative value attached to enhancing the usability and power (in this case, we're debating the choice of default behavior) of prompt manipulators. "
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-11-08T17:51:31Z",
        "body": "I'm labeling this issue as stale because it has been open for 2 weeks with no activity. If there are no additional comments, it will be closed in 7 days."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-11-18T15:32:32Z",
        "body": "I'm closing this issue because it has been stalled for 3 weeks with no activity. Feel free to add a comment here and we can re-open it. Or feel free to file a new issue at any time."
      }
    ]
  },
  {
    "number": 2045,
    "title": "REQ: Pre- and Post- prompt hooks to enable extended local scripting",
    "created_at": "2024-10-13T00:11:35Z",
    "closed_at": "2024-11-18T15:32:40Z",
    "labels": [
      "question",
      "stale"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/2045",
    "body": "### Issue\n\nI was thinking it might be nice to have the ability to have pre- and post- prompt script hooks built in to aider so that if a user wanted to they could trigger the script to run before the prompt is submitted and again after the prompt returns.\r\n\r\nSuch an extension would allow a user to programmatically handle data interactions with external code to extend aider in personalized directions without having to get under the hood.\n\n### Version and model info\n\nAider v0.59.1\r\nMain model: claude-3-5-sonnet-20240620 with diff edit format, prompt cache, infinite\r\noutput\r\nWeak model: claude-3-haiku-20240307\r\nGit repo: .git with 10 files",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/2045/comments",
    "author": "5ocworkshop",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-10-21T19:04:01Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nCan you explain some use cases for this?"
      },
      {
        "user": "5ocworkshop",
        "created_at": "2024-10-21T20:27:11Z",
        "body": "Sure.  The ability to write and read long term status information, for example for a multi-cycle debugging cycle using aider.\r\n\r\nImagine you run the first cycle, investigate, analyze and take some acctions.  You want to keep your notes and details about what questions you've already been able to answer and what resolutions you've tried.  You can pass that info off to an outside program that can manage it when you get your prompt response and you can recall that information from it before you submit your next prompt, to track counters and so forth.\r\n\r\nAlso, in the case of debugging, I want to keep a cycle counter so that if we've tried say 5 attempts and it isn't working, we use a different prompt or approach so we don't grind in a debugging loop that isn't yielding anything.\r\n\r\nWith pre- submission scripts and post (response) scripts, there is flexibility. In this way you can write code that extends capabilities, stores data, providing persistence and flexibility in ways that aren't really possible right now.  Persistence is especially useful because it means you can clear the tokens to avoid token buildup (especially pernicious during debugging as you amp up verbosity) without losing track of what attack vectors have been exhausted already etc."
      },
      {
        "user": "5ocworkshop",
        "created_at": "2024-10-21T21:10:10Z",
        "body": "The other case that I am particularly interested in is on the pre-hook side.\r\n\r\nI have a number of prompts I've been developing and refining that are somewhat situational but also a bit large at times.  Coding conventions, detail debugging routines and so forth.  I don't necessarily want them loaded in the chat all the time, as often they are idle and just waste tokens, but it's easy also to forget to add them sometimes.  \r\n\r\nA pre-hook script could ask whether or not you want to add files like this before submitting, to allow you to easily pick and choose from a short list or even just tag them with a spacebar, and pass the results back to aider to act before it submits the prompt.\r\n\r\nLikewise, on the response/post end, a script could identify various things in the output and take actions based on those, like updating status files or even running other tasks based on the information in the response."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-10-23T21:05:02Z",
        "body": "This sounds fairly out of scope, although I admit I am not fully following your use case or goals here."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-11-08T17:51:44Z",
        "body": "I'm labeling this issue as stale because it has been open for 2 weeks with no activity. If there are no additional comments, it will be closed in 7 days."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-11-18T15:32:39Z",
        "body": "I'm closing this issue because it has been stalled for 3 weeks with no activity. Feel free to add a comment here and we can re-open it. Or feel free to file a new issue at any time."
      }
    ]
  },
  {
    "number": 2027,
    "title": "[Question] Get Local (Qwen) LLMs to better conform to Aider's expectations",
    "created_at": "2024-10-11T08:49:33Z",
    "closed_at": "2024-10-22T11:29:57Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/2027",
    "body": "### Issue\n\nI was wondering if and how people are using local LLMs together with Aider for their code editing needs? I have been trying the following models:\r\n\r\nqwen2.5-coder:7b-instruct-fp16\r\nqwen2.5:32b-instruct-Q4_K_M\r\nqwen2.5:72b-instruct-Q4_K_M\r\n\r\nAll of them are running through Ollama, with a context length of 32k.\r\n\r\nAnd every single one of them is not adhering to the instructions Aider set forth. They mainly add needless explanations instead of only outputting the code changes. I have only added a single 125 line file to the context, have a clear history (/clear) and disabled the repo map to keep the load on the context as small as possible, yet the problem persists.\r\n\r\nStrangely enough I CAN get the LLM to corporate by adding this to the end of my own prompts: \"Do not add ANY explanation of the proposed code changes. Only output the new code in the earlier mentioned format.\". But adding this explanation every single time is cumbersome and not how Aider is supposed to work.\r\n\r\nI know local models are not as strong as models such as Claude 3.5 Sonnet and Chatgpt-4o. But especially for the 72b model I was expecting it to at least be able to follow along with the instructions. I am experiencing issues both with the \"diff\" and \"whole\" edit format.\r\n\r\nCurious to see if people have better experiences, and if so, how they managed to get it to work properly.\n\n### Version and model info\n\n_No response_",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/2027/comments",
    "author": "Mushoz",
    "comments": [
      {
        "user": "WilliamStone",
        "created_at": "2024-10-11T17:52:52Z",
        "body": "> Strangely enough I CAN get the LLM to corporate by adding this to the end of my own prompts: \"Do not add ANY explanation of the proposed code changes. Only output the new code in the earlier mentioned format.\". But adding this explanation every single time is cumbersome and not how Aider is supposed to work.\r\n\r\nI face the same problem and I found the prompt content is in `wholefile_prompts.py`, and you can simply modify its content as you see fit. There are also all kinds of prompt files in the directory.\r\nHint: you can modify `<path/to/your/python>/Lib\\site-packages\\aider\\coders\\wholefile_prompts.py` and rerun Aider, to activate your modification immediately."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-10-21T22:33:09Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nIf they can't obey the whole edit format, there's not much to be done. That is dead simplest possible way for an LLM to update a source code file."
      },
      {
        "user": "lee-b",
        "created_at": "2024-10-21T22:45:27Z",
        "body": "dracarys2 72B (e.g., mradermacher/Dracarys2-72B-Instruct-GGUF) is currently doing better than qwen on the aider leaderboard. It's a fine tune of qwen. I find it quite reliable so far.  Don't bother with any model smaller than about 70B for aider, it's just not going to work reliably (at least, not for a while, until training techniques and network architectures improve, or someone finetunes a model just for aider)."
      },
      {
        "user": "Mushoz",
        "created_at": "2024-10-22T11:29:57Z",
        "body": "Turns out Ollama has a default context length of only 2048. Going past that limit will effectively make the LLM forget the system prompt, resulting in non-compliance. Increasing the context length fixed my issue. My apologies for this issue!"
      }
    ]
  },
  {
    "number": 2022,
    "title": "Run Aider browser in replit - choose port",
    "created_at": "2024-10-10T22:27:38Z",
    "closed_at": "2024-11-18T15:32:52Z",
    "labels": [
      "question",
      "stale"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/2022",
    "body": "### Issue\n\nI'm trying to host aider browser in replit, but it only supports port 8501, and replit does a reverse proxy to a list of approved ports, but streamlit keeps trying to connect to 8501 on the external url.\r\n\r\nStreamlit has a --server.port argument to specify the port, but aider does not expose it.\n\n### Version and model info\n\n0.59.1",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/2022/comments",
    "author": "tiagoefreitas",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-10-21T22:36:07Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nTry setting the `STREAMLIT_SERVER_PORT` env var?\r\n\r\n```\r\nexport STREAMLIT_SERVER_PORT=8501\r\n```"
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-11-08T17:51:57Z",
        "body": "I'm labeling this issue as stale because it has been open for 2 weeks with no activity. If there are no additional comments, it will be closed in 7 days."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-11-18T15:32:52Z",
        "body": "I'm closing this issue because it has been stalled for 3 weeks with no activity. Feel free to add a comment here and we can re-open it. Or feel free to file a new issue at any time."
      },
      {
        "user": "devmecara",
        "created_at": "2024-11-19T15:30:40Z",
        "body": "Just leaving this comment for confirmation, I had a similar issue and setting the STREAMLIT_SERVER_PORT env variable worked, thanks."
      }
    ]
  },
  {
    "number": 2009,
    "title": "Uncaught APIError in utils.py line 6586",
    "created_at": "2024-10-10T11:24:24Z",
    "closed_at": "2024-10-15T14:09:48Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/2009",
    "body": "Aider version: 0.59.1\r\nPython version: 3.12.3\r\nPlatform: Linux-6.8.0-45-generic-x86_64-with-glibc2.39\r\nPython implementation: CPython\r\nVirtual environment: Yes\r\nOS: Linux 6.8.0-45-generic (64bit)\r\nGit version: git version 2.43.0\r\n\r\nAn uncaught exception occurred:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"openai.py\", line 907, in completion\r\n    raise e\r\n  File \"openai.py\", line 840, in completion\r\n    return convert_to_model_response_object(\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"utils.py\", line 5720, in convert_to_model_response_object\r\n    raise raised_exception\r\nException\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"main.py\", line 1419, in completion\r\n    raise e\r\n  File \"main.py\", line 1392, in completion\r\n    response = openai_chat_completions.completion(\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"openai.py\", line 914, in completion\r\n    raise OpenAIError(\r\nlitellm.llms.OpenAI.openai.OpenAIError\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"aider\", line 8, in <module>\r\n    sys.exit(main())\r\n             ^^^^^^\r\n  File \"main.py\", line 757, in main\r\n    coder.run()\r\n  File \"base_coder.py\", line 730, in run\r\n    self.run_one(user_message, preproc)\r\n  File \"base_coder.py\", line 773, in run_one\r\n    list(self.send_message(message))\r\n  File \"base_coder.py\", line 1212, in send_message\r\n    saved_message = self.auto_commit(edited)\r\n                    ^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"base_coder.py\", line 1895, in auto_commit\r\n    res = self.repo.commit(fnames=edited, context=context, aider_edits=True)\r\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"repo.py\", line 110, in commit\r\n    commit_message = self.get_commit_message(diffs, context)\r\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"repo.py\", line 195, in get_commit_message\r\n    commit_message = simple_send_with_retries(\r\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"sendchat.py\", line 44, in wrapper\r\n    return decorated_func(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"_sync.py\", line 105, in retry\r\n    ret = target(*args, **kwargs)\r\n          ^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"sendchat.py\", line 102, in simple_send_with_retries\r\n    _hash, response = send_completion(**kwargs)\r\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"sendchat.py\", line 83, in send_completion\r\n    res = litellm.completion(**kwargs)\r\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"utils.py\", line 1086, in wrapper\r\n    raise e\r\n  File \"utils.py\", line 974, in wrapper\r\n    result = original_function(*args, **kwargs)\r\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"main.py\", line 2847, in completion\r\n    raise exception_type(\r\n          ^^^^^^^^^^^^^^^\r\n  File \"utils.py\", line 8194, in exception_type\r\n    raise e\r\n  File \"utils.py\", line 6586, in exception_type\r\n    raise APIError(\r\nlitellm.exceptions.APIError: litellm.APIError: APIError: OpenAIException - \r\n\r\n```",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/2009/comments",
    "author": "kotiacash",
    "comments": [
      {
        "user": "fry69",
        "created_at": "2024-10-10T12:01:50Z",
        "body": "Thank you for filing this issue.\r\n\r\nThis is a generic error from the LLM endpoint API and missing critical context.\r\n\r\nPlease post your announcement lines when you start aider."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-10-15T14:09:48Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open. Or feel free to file a new issue any time."
      }
    ]
  },
  {
    "number": 2008,
    "title": "Strange issue unable to replace first line of the file, despite search/replace showing the content",
    "created_at": "2024-10-10T10:58:34Z",
    "closed_at": "2024-11-18T15:33:01Z",
    "labels": [
      "question",
      "stale"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/2008",
    "body": "### Issue\n\nI've got a bit of a strange one.  Aider or VSCode appears to be swallowing the first line of output for reasons I can't see.\r\n\r\nI'm working on some conventions.md things, and I'm adding auto-version incrementing to the file edits.\r\n\r\ncode-terse.md (relevant snippet):\r\n```\r\n# File Header and Version Control\r\nAll files following these guidelines should include a header in the following format:\r\n\r\n```\r\n# File: <filename>\r\n# Description: <brief description of file purpose>\r\n# Version: YYYY-MM-DD-###\r\n```\r\n\r\nVersion Control Instructions:\r\n1. If any header lines are missing, add them\r\n2. Update the description if necessary\r\n3. Format: YYYY-MM-DD-###\r\n4. When editing any file:\r\n   a. Update YYYY-MM-DD to the current date\r\n   b. Increment the ### portion of the version number\r\n\r\nAlways update the version number when making changes to the file.\r\n```\r\n\r\nWhich results in:\r\n\r\n```\r\ncode-terse.md                                                                                                                                                                                                                      \r\n> Create an example of a small python program that complies with code-terse.md                                                                                                                                                     \r\n\r\nCertainly! I'll create a small Python program that complies with the guidelines in code-terse.md. I'll use a *SEARCH/REPLACE block* to create a new file called `task_manager.py`.\r\n\r\ntask_manager.py\r\n<source>python\r\n<<<<<<< SEARCH\r\n\r\n=======\r\n# File: task_manager.py\r\n# Description: A simple task management system\r\n# Version: 2024-10-10-001\r\n\r\nfrom typing import List, Dict\r\n```\r\n\r\nWhich is exactly what I want.  Except when I open the newly created file here are the first few lines:\r\n\r\n```\r\n# Description: A simple task management system\r\n# Version: 2024-10-10-001\r\n\r\nfrom typing import List, Dict\r\n```\r\n\r\nFor some unknown reason, it is swallowing the first line, even though it is in the replace block when it creates the file.\r\n\r\nI can reliably recreate the problem both with new files and when exiting existing files.\r\n\r\nI tried manually adding\r\n\r\n`# File:\r\n`\r\nTo see if it would populate on the next edit, and instead the line disappeared.\r\n\r\nThinking it might be an internal thing where aider is using \"# File:\" at the top, I changed my header to be _File and still have the same issues.\r\n\r\nThe directions to the AI are working and the edits appear in SEARCH/REPLACE but they don't make it to the file:\r\n\r\n```\r\nAfter reviewing the task_manager.py file against the guidelines in code-terse.md, I've identified a few minor improvements we can make to ensure full compliance. Here are the proposed changes:\r\n\r\ntask_manager.py\r\n<source>python\r\n<<<<<<< SEARCH\r\n# _Description: A simple task management system\r\n# _Version: 2024-10-10-003\r\n=======\r\n# _File: task_manager.py\r\n# _Description: A simple task management system\r\n# _Version: 2024-10-10-004\r\n>>>>>>> REPLACE\r\n```\r\nYet the line is missing from the file.\r\n\r\nAny ideas?\r\n\r\n\n\n### Version and model info\n\nAider v0.59.1\r\nMain model: claude-3-5-sonnet-20240620 with diff edit format, prompt cache, infinite output\r\nWeak model: claude-3-haiku-20240307\r\nGit repo: .git with 4 files\r\nRepo-map: using 1024 tokens, files refresh",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/2008/comments",
    "author": "5ocworkshop",
    "comments": [
      {
        "user": "5ocworkshop",
        "created_at": "2024-10-10T11:24:23Z",
        "body": "I figured out a solution, although I'm not sure exactly why it works.  I need to add a blank line to the top of the comment block, so I updated by version control info as follows:\r\n\r\n```\r\n# File Header and Version Control\r\nAll files following these guidelines should include a header in the following format:\r\n\r\n<comment_start>\r\n<comment start> File: <filename>\r\n<comment_start> Description: <brief description of file purpose>\r\n<comment_start> Version: YYYY-MM-DD-###\r\n<comment_end_if_needed>\r\n\r\nVersion Control Instructions:\r\n1. Use the appropriate comment syntax for the file type\r\n2. If any header lines are missing, add them\r\n3. Update the description if necessary\r\n4. Format: YYYY-MM-DD-###\r\n5. When editing any file:\r\n   a. Update YYYY-MM-DD to the current date\r\n   b. Increment the ### portion of the version number\r\n\r\nAlways update the version number when making changes to the file.\r\n```"
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-11-08T17:52:04Z",
        "body": "I'm labeling this issue as stale because it has been open for 2 weeks with no activity. If there are no additional comments, it will be closed in 7 days."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-11-18T15:33:01Z",
        "body": "I'm closing this issue because it has been stalled for 3 weeks with no activity. Feel free to add a comment here and we can re-open it. Or feel free to file a new issue at any time."
      }
    ]
  },
  {
    "number": 2001,
    "title": "Uncaught AuthenticationError in chat.py line 647",
    "created_at": "2024-10-10T03:57:02Z",
    "closed_at": "2024-10-10T19:04:09Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/2001",
    "body": "Aider version: 0.59.1\r\nPython version: 3.11.3\r\nPlatform: macOS-14.6.1-arm64-arm-64bit\r\nPython implementation: CPython\r\nVirtual environment: No\r\nOS: Darwin 23.6.0 (64bit)\r\nGit version: git version 2.47.0\r\n\r\nAn uncaught exception occurred:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"aider\", line 8, in <module>\r\n    sys.exit(main())\r\n             ^^^^^^\r\n  File \"main.py\", line 757, in main\r\n    coder.run()\r\n  File \"base_coder.py\", line 730, in run\r\n    self.run_one(user_message, preproc)\r\n  File \"base_coder.py\", line 773, in run_one\r\n    list(self.send_message(message))\r\n  File \"base_coder.py\", line 1212, in send_message\r\n    saved_message = self.auto_commit(edited)\r\n                    ^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"base_coder.py\", line 1895, in auto_commit\r\n    res = self.repo.commit(fnames=edited, context=context, aider_edits=True)\r\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"repo.py\", line 110, in commit\r\n    commit_message = self.get_commit_message(diffs, context)\r\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"repo.py\", line 195, in get_commit_message\r\n    commit_message = simple_send_with_retries(\r\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"sendchat.py\", line 44, in wrapper\r\n    return decorated_func(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"_sync.py\", line 105, in retry\r\n    ret = target(*args, **kwargs)\r\n          ^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"sendchat.py\", line 102, in simple_send_with_retries\r\n    _hash, response = send_completion(**kwargs)\r\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"sendchat.py\", line 83, in send_completion\r\n    res = litellm.completion(**kwargs)\r\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"utils.py\", line 1086, in wrapper\r\n    raise e\r\n  File \"utils.py\", line 974, in wrapper\r\n    result = original_function(*args, **kwargs)\r\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"main.py\", line 2847, in completion\r\n    raise exception_type(\r\n  File \"main.py\", line 1586, in completion\r\n    response = anthropic_chat_completions.completion(\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"chat.py\", line 976, in completion\r\n    headers = validate_environment(api_key, headers, model, messages=messages)\r\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"chat.py\", line 647, in validate_environment\r\n    raise litellm.AuthenticationError(\r\nlitellm.exceptions.AuthenticationError: litellm.AuthenticationError: Missing Anthropic API Key - A call is being made to anthropic but no key is set either in the environment variables or via params. Please set `ANTHROPIC_API_KEY` in your environment vars\r\n\r\n```",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/2001/comments",
    "author": "mateodelnorte",
    "comments": [
      {
        "user": "fry69",
        "created_at": "2024-10-10T04:05:18Z",
        "body": "Thank you for filing this issue.\r\n\r\nLooks like you did not set the required API key?\r\n\r\n> Missing Anthropic API Key - A call is being made to anthropic but no key is set either in the environment variables or via params. Please set `ANTHROPIC_API_KEY` in your environment vars"
      },
      {
        "user": "mateodelnorte",
        "created_at": "2024-10-10T19:04:10Z",
        "body": "I'm running via a VS Code extension and didn't realize it was specifying a non-openrouter model, when I'm specifying an openrouter env var. Thanks!"
      }
    ]
  },
  {
    "number": 1999,
    "title": "Python API example for architect-editor mode",
    "created_at": "2024-10-10T02:01:35Z",
    "closed_at": "2024-11-18T15:33:07Z",
    "labels": [
      "question",
      "stale"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1999",
    "body": "### Issue\n\nIs there documentation or an example of how to define a coder using the python api for the new architect-editor mode? \n\n### Version and model info\n\nAider v0.59.0",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1999/comments",
    "author": "juancq",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-11-08T17:52:09Z",
        "body": "I'm labeling this issue as stale because it has been open for 2 weeks with no activity. If there are no additional comments, it will be closed in 7 days."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-11-18T15:33:06Z",
        "body": "I'm closing this issue because it has been stalled for 3 weeks with no activity. Feel free to add a comment here and we can re-open it. Or feel free to file a new issue at any time."
      }
    ]
  },
  {
    "number": 1994,
    "title": "Uncaught KeyError in models.py line 997",
    "created_at": "2024-10-09T14:37:59Z",
    "closed_at": "2024-10-09T20:20:43Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1994",
    "body": "Aider version: 0.59.1\r\nPython version: 3.10.12\r\nPlatform: Linux-5.15.0-122-generic-x86_64-with-glibc2.35\r\nPython implementation: CPython\r\nVirtual environment: No\r\nOS: Linux 5.15.0-122-generic (64bit)\r\nGit version: git version 2.34.1\r\n\r\nAn uncaught exception occurred:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"aider\", line 8, in <module>\r\n    sys.exit(main())\r\n  File \"main.py\", line 582, in main\r\n    problem = models.sanity_check_models(io, main_model)\r\n  File \"models.py\", line 933, in sanity_check_models\r\n    problem_main = sanity_check_model(io, main_model)\r\n  File \"models.py\", line 977, in sanity_check_model\r\n    possible_matches = fuzzy_match_models(model.name)\r\n  File \"models.py\", line 997, in fuzzy_match_models\r\n    provider = (attrs[\"litellm_provider\"] + \"/\").lower()\r\nKeyError: 'litellm_provider'\r\n\r\n```",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1994/comments",
    "author": "cmayers",
    "comments": [
      {
        "user": "fry69",
        "created_at": "2024-10-09T14:41:30Z",
        "body": "Thank you for filing this issue.\r\n\r\nCan you please post the command line or the announcement lines when you start aider?"
      },
      {
        "user": "cmayers",
        "created_at": "2024-10-09T14:43:59Z",
        "body": "> Thank you for filing this issue.\r\n> \r\n> Can you please post the command line or the announcement lines when you start aider?\r\n\r\naider --model ollama/qwen2.5 .\r\nand\r\naider --model ollama/llama3.2:3b-instruct-fp16 .\r\n\r\n"
      },
      {
        "user": "fry69",
        "created_at": "2024-10-09T14:46:30Z",
        "body": "I cannot reproduce this problem locally.\r\n\r\nCan you please try to install or reinstall aider in a separate Python environment? Either with `venv` or `pipx`?\r\n\r\nPlease remove the existing environment/aider installation first, e.g. with `pipx`:\r\n```shell\r\n$ pipx uninstall aider-chat\r\nuninstalled aider-chat! ✨ 🌟 ✨\r\n```\r\n```shell\r\n$ pipx install aider-chat\r\n  installed package aider-chat 0.59.1, installed using Python 3.12.7\r\n  These apps are now globally available\r\n    - aider\r\ndone! ✨ 🌟 ✨\r\n```\r\n"
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-10-09T14:55:21Z",
        "body": "Did you make a custom model settings json file?"
      },
      {
        "user": "cmayers",
        "created_at": "2024-10-09T19:52:18Z",
        "body": "If I issue aider --model ollama/qwen2.5-coder . \r\nit start fine\r\n"
      },
      {
        "user": "cmayers",
        "created_at": "2024-10-09T19:54:48Z",
        "body": "> Did you make a custom model settings json file?\r\n\r\nYes I did. But for only one model and the included model is not presenting an error. I will try including the models which gave the error in the model settings json file. I wll report back the behavior."
      },
      {
        "user": "cmayers",
        "created_at": "2024-10-09T20:20:43Z",
        "body": "> > Did you make a custom model settings json file?\r\n> \r\n> Yes I did. But for only one model and the included model is not presenting an error. I will try including the models which gave the error in the model settings json file. I wll report back the behavior.\r\n\r\nConfirmed. As soon as I included the model's parameters into the model settings json the error no longer shows.\r\n\r\nThanks!"
      }
    ]
  },
  {
    "number": 1993,
    "title": "Prompts and system role improvements ",
    "created_at": "2024-10-09T14:22:31Z",
    "closed_at": "2024-11-18T15:33:09Z",
    "labels": [
      "question",
      "stale"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1993",
    "body": "Beforehand, I appreciate the great work that's been done on this tool. I use it daily.\r\n\r\nI have some doubts regarding the efficiency of the prompts and I think there is room for improvement there. I'm not a prompt engineer neither I want to be one, but I understand how important is to properly articulate the inquiries made to a LLM.\r\n\r\nWhen I used aider for the first time, the solutions were poor and delirant, using simple and small portions of code. It didn't matter whether I was using 4o or 4o-mini. Then, I started digging into the default prompts and realized there was a very basic role introduction: \"Act as an expert software developer\". Then, a bunch of instructions that guide the response format and overall behavior. Not to mention the extra large system prompt which inevitably forces the LLM to get lost sometimes.\r\n\r\nIMHO, there is too much initial system prompt there, too many tokens that do not enforce the role but the response behavior.\r\n\r\nI replaced that role introduction with something I've been using in OpenAI's Playground with significant success, which includes specific mentions to programming languages, frameworks, tech stacks and tech roles. That way, mentioning a summary of what I usually do, helps the LLM provide more reasonable solutions to my inquiries.\r\n\r\nHence, I think aider needs a way to improve the role definition by either allowing the user to inject some context into the system prompt, or, perhaps by automatically analyzing the code structure and package dependencies to generate a role introduction that is more tied to the specific needs of the actual repository.\r\n\r\n",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1993/comments",
    "author": "webpolis",
    "comments": [
      {
        "user": "5ocworkshop",
        "created_at": "2024-10-10T12:32:35Z",
        "body": "I've been thinking about this a lot too.  Also about whether the prompts could be separated into ones that users could tweak and ones that are fixed due to the requirement for correct operation.  It gets tricky fast.\r\n\r\nI'm also wondering if wrapping something around aider when you control the prompts might be an option, since apparently you can use aider as a command line tool you pipe to and from."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-11-08T17:52:11Z",
        "body": "I'm labeling this issue as stale because it has been open for 2 weeks with no activity. If there are no additional comments, it will be closed in 7 days."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-11-18T15:33:09Z",
        "body": "I'm closing this issue because it has been stalled for 3 weeks with no activity. Feel free to add a comment here and we can re-open it. Or feel free to file a new issue at any time."
      }
    ]
  },
  {
    "number": 1979,
    "title": "Is there a way to view which model was used?",
    "created_at": "2024-10-08T21:54:12Z",
    "closed_at": "2024-11-18T15:33:18Z",
    "labels": [
      "question",
      "stale"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1979",
    "body": "### Issue\n\nIf I have it in architect mode I'm assuming the architect mode will be used for the first part (and also because of the price increase using something like OPUS), but after that I've seen it's a combination of the `editor` model and the `weak` model but I would like to know which one was used for what if that's possible.\n\n### Version and model info\n\nAider v0.59.1",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1979/comments",
    "author": "johhansantana",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-11-08T17:52:21Z",
        "body": "I'm labeling this issue as stale because it has been open for 2 weeks with no activity. If there are no additional comments, it will be closed in 7 days."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-11-18T15:33:18Z",
        "body": "I'm closing this issue because it has been stalled for 3 weeks with no activity. Feel free to add a comment here and we can re-open it. Or feel free to file a new issue at any time."
      }
    ]
  },
  {
    "number": 1976,
    "title": "Use a git repo in a different folder",
    "created_at": "2024-10-08T16:07:27Z",
    "closed_at": "2024-11-11T19:15:06Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1976",
    "body": "### Issue\n\nFirst off, thank you for this incredible tool.  It has changed my view of LLM's and made me appreciate them so much more!\r\n\r\nI'd like to use aider from a folder other than my git repo.  `git` itself has an option for this: `-C`.  Does aider have any support for this.\r\n\r\nMy use case is that I'm using direnv from a directory that is not the root of my git repo.  I want to use aider from this dir, too.  I can't just put direnv at the root of my repo because I have multiple different configurations I use for various tasks with this repo.\r\n\r\nWith other tools, there is an environmental variable I can use.  For example, PIPENV_PIPFILE for pipenv and PYTHONPATH.  \n\n### Version and model info\n\nLatest version of aider",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1976/comments",
    "author": "powelleric",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-11-08T17:52:25Z",
        "body": "I'm labeling this issue as stale because it has been open for 2 weeks with no activity. If there are no additional comments, it will be closed in 7 days."
      },
      {
        "user": "powelleric",
        "created_at": "2024-11-08T20:04:16Z",
        "body": "Please keep this open.  I am hoping for an answer and/or to have this turned into a feature request."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-11-08T21:11:35Z",
        "body": "Sorry, yes you can do this. Just launch aider with the path to any file in the repo:\n\n\naider /path/to/any/file.txt"
      },
      {
        "user": "powelleric",
        "created_at": "2024-11-11T19:15:06Z",
        "body": "Thank you. That works perfectly. I would have never figured that out."
      }
    ]
  },
  {
    "number": 1950,
    "title": "Add support for perforce as a version control instead of git",
    "created_at": "2024-10-07T05:57:20Z",
    "closed_at": "2024-11-18T15:33:26Z",
    "labels": [
      "question",
      "stale"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1950",
    "body": "### Issue\n\nThis is a request for enhancement. Aider currently gathers information about the codebase and changelogs using git commands, working on a older repository based on perforce helix and would love to see support for it in aider.\n\n### Version and model info\n\n_No response_",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1950/comments",
    "author": "adarshdotexe",
    "comments": [
      {
        "user": "fry69",
        "created_at": "2024-10-07T06:16:10Z",
        "body": "Thank you for filing this issue.\r\n\r\nThis will be next to impossible, as git is very unique how it works and has a huge ecosystem support. I do not see any possible way this could get achieved.\r\n\r\nThe only solution I'd imagine could work is importing the perforce repository into a git repository, work with that and then import the changes back to perforce when done. This was the way how to deal with repositories who used Subversion as their central source, when this was ubiquitous about 15-20 years ago and git started to become popular."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-11-08T17:52:32Z",
        "body": "I'm labeling this issue as stale because it has been open for 2 weeks with no activity. If there are no additional comments, it will be closed in 7 days."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-11-18T15:33:25Z",
        "body": "I'm closing this issue because it has been stalled for 3 weeks with no activity. Feel free to add a comment here and we can re-open it. Or feel free to file a new issue at any time."
      }
    ]
  },
  {
    "number": 1945,
    "title": "REQ: Drop globs?",
    "created_at": "2024-10-06T13:31:31Z",
    "closed_at": "2024-11-18T15:33:28Z",
    "labels": [
      "question",
      "stale"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1945",
    "body": "### Issue\n\nI thought this used to work but it doesn't seem to anymore:\r\n\r\n`/drop *.py`\r\n\r\nI know that this works\r\n\r\n`/add src/*.py\r\n`\r\n\r\nIs it possible to support it with drop as well?\n\n### Version and model info\n\nAider v0.59.1\r\nMain model: claude-3-5-sonnet-20240620 with diff edit format, prompt cache, infinite output\r\nWeak model: claude-3-haiku-20240307\r\nGit repo: .git with 23 files\r\nRepo-map: using 1024 tokens, files refresh",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1945/comments",
    "author": "5ocworkshop",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-11-08T17:52:34Z",
        "body": "I'm labeling this issue as stale because it has been open for 2 weeks with no activity. If there are no additional comments, it will be closed in 7 days."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-11-18T15:33:27Z",
        "body": "I'm closing this issue because it has been stalled for 3 weeks with no activity. Feel free to add a comment here and we can re-open it. Or feel free to file a new issue at any time."
      }
    ]
  },
  {
    "number": 1943,
    "title": "REQ: Enhance repo-map to include heading docstrings",
    "created_at": "2024-10-06T12:56:23Z",
    "closed_at": "2024-11-18T15:33:30Z",
    "labels": [
      "question",
      "stale"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1943",
    "body": "### Issue\r\n\r\nOne of the things I've been using aider for is to do a lot of the mundane documenting and detailing of code.  Not only is this helpful for humans, but it also makes it easier for the AI to understand the functions and interactions as the project grows and it makes updates and enhancements more accurate.\r\n\r\nI was wondering whether it could be helpful to have an enhanced option of the repo map that, if there is a docstring that explains a function, it includes that information to help better guide the AI.  For example:\r\n\r\n```\r\n def create_task(title: str, description: str, due_date: date, priority: int = 1) -> Task:\r\n      \"\"\"\r\n      Purpose:\r\n          Create a new task with the given details.\r\n      Parameters:\r\n          title (str): Non-empty string up to 200 characters.\r\n          description (str): Optional, up to 1000 characters.\r\n          due_date (date): Must be a future date.\r\n          priority (int, optional): Between 1 and 5 (default is 1).\r\n      Returns:\r\n          Task: The newly created task object.\r\n      Raises:\r\n          ValidationError: If inputs fail validation.\r\n      Notes:\r\n          - Initializes task status to 'Not Started'.\r\n          - Triggers notification to project managers.\r\n      Sanity Checks:\r\n          - Validate input lengths and ranges.\r\n          - Ensure due_date is in the future.\r\n      \"\"\"\r\n```\r\n\r\n\r\n\r\n### Version and model info\r\nAider v0.59.1\r\nMain model: claude-3-5-sonnet-20240620 with diff edit format, prompt cache, infinite output\r\nWeak model: claude-3-haiku-20240307\r\nGit repo: .git with 23 files\r\nRepo-map: using 1024 tokens, files refresh",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1943/comments",
    "author": "5ocworkshop",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-11-08T17:52:36Z",
        "body": "I'm labeling this issue as stale because it has been open for 2 weeks with no activity. If there are no additional comments, it will be closed in 7 days."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-11-18T15:33:29Z",
        "body": "I'm closing this issue because it has been stalled for 3 weeks with no activity. Feel free to add a comment here and we can re-open it. Or feel free to file a new issue at any time."
      }
    ]
  },
  {
    "number": 1925,
    "title": "Idea: Use weak model to determine relevant files to keep in chat",
    "created_at": "2024-10-04T22:54:49Z",
    "closed_at": "2024-10-29T02:04:37Z",
    "labels": [
      "question",
      "stale"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1925",
    "body": "In some projects its inconvenient or difficult to manually add relevant files to a request, eg if a function signature is being altered with many users amongst other files.\r\nI was thinking similar to the architect/editor split, it might sometimes be efficient to have a cheap model read more or all of the codebase to list relevant files.",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1925/comments",
    "author": "Qazzquimby",
    "comments": [
      {
        "user": "github-actions[bot]",
        "created_at": "2024-10-21T17:43:35Z",
        "body": "This issue is stale because it has been open 14 days with no activity. Remove stale label or comment or this will be closed in 7 days."
      },
      {
        "user": "github-actions[bot]",
        "created_at": "2024-10-29T02:04:37Z",
        "body": "This issue was closed because it has been stalled for 3 weeks with no activity. Feel free to add a comment here and we can re-open it. Or feel free to file a new issue any time."
      }
    ]
  },
  {
    "number": 1919,
    "title": "Costly message caused by tokens exhausted limits breach for large messages.",
    "created_at": "2024-10-04T14:11:54Z",
    "closed_at": "2024-10-29T02:04:39Z",
    "labels": [
      "question",
      "stale"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1919",
    "body": "### Issue\r\n\r\nSent: a costly message with a big file.\r\nResponse:\r\n```text\r\nTokens: 1663k sent, 0 received. Cost: $4.99 message, $9.68 session.\r\n\r\nModel claude-3-5-sonnet-20240620 has hit a token limit!\r\nToken counts below are approximate.\r\n\r\nInput tokens: ~1,663,395 of 200,000 -- possibly exhausted context window!\r\nOutput tokens: ~0 of 8,192\r\nTotal tokens: ~1,663,395 of 200,000 -- possibly exhausted context window!\r\n```\r\n\r\nA previously sent message with a larger file resulted in the following error:\r\n```text\r\nBadRequestError: litellm.BadRequestError: AnthropicException - b'{\"type\":\"error\",\"error\":{\"type\":\"invalid_request_error\",\"message\":\"too \r\nmany total text bytes: 9256098 > 9000000\"}}'\r\n```\r\n\r\nThe different api limits should be considered before sending a message, preventing limits breaching.  \r\nMaybe a pre-send validation hook could solve such a scenario.\r\n\r\n### Version and model info\r\n\r\nAider v0.58.1\r\nMain model: claude-3-5-sonnet-20240620 with architect edit format, infinite output\r\nEditor model: claude-3-5-sonnet-20240620 with editor-diff edit format\r\nWeak model: claude-3-haiku-20240307",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1919/comments",
    "author": "guywald",
    "comments": [
      {
        "user": "fry69",
        "created_at": "2024-10-04T14:15:48Z",
        "body": "Thank you for filing this issue.\r\n\r\nPlease check if those costly messages really got billed. If the API returns an error, those requests should not get billed. Do not trust aider's cost estimation, it is (as stated) not reliable.\r\n\r\nAlso note that you can (and should) check your token usage before you send a prompt/request with `/tokens`"
      },
      {
        "user": "github-actions[bot]",
        "created_at": "2024-10-21T17:43:37Z",
        "body": "This issue is stale because it has been open 14 days with no activity. Remove stale label or comment or this will be closed in 7 days."
      },
      {
        "user": "github-actions[bot]",
        "created_at": "2024-10-29T02:04:39Z",
        "body": "This issue was closed because it has been stalled for 3 weeks with no activity. Feel free to add a comment here and we can re-open it. Or feel free to file a new issue any time."
      }
    ]
  },
  {
    "number": 1891,
    "title": "Feature Idea: Locked files",
    "created_at": "2024-10-02T18:44:22Z",
    "closed_at": "2024-10-02T19:35:39Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1891",
    "body": "### Issue\n\nI'm deep into a large codebase with Aider, crossing three different languages. I love it. It's incredibly helpful. However, I've found that steering Claude, especially when I'm working on cross-code / cross-module integrations can be tough; it can eagerly go ahead and change an interface or datastructure that I don't want to change -- instead I want the new code to consume the old datastructure. \r\n\r\nInstructions to this effect, e.g. \"DO NOT EDIT THIS FILE. IT WORKS. ONLY EDIT <OTHER FILE>\" are ... sometimes helpful. But of course, the context window is pretty long in these cases, because we have a lot of different files to look at. \r\n\r\nI wonder if a simple way might be a /lock command, which just treats certain files as read-only, and refuses patches for them. Happy to hear thoughts on this, but I think it would ease a common pain point for me.\n\n### Version and model info\n\n_No response_",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1891/comments",
    "author": "vessenes",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-10-02T19:02:15Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nYou can add files to the context with `/read-only` if you don't want aider to edit them."
      },
      {
        "user": "vessenes",
        "created_at": "2024-10-02T19:35:39Z",
        "body": "Nice!"
      }
    ]
  },
  {
    "number": 1886,
    "title": "Suggestion: Partial search fragments",
    "created_at": "2024-10-02T14:23:43Z",
    "closed_at": "2024-10-21T16:57:13Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1886",
    "body": "### Issue\r\n\r\nI sometimes get aider to work on entire files, e.g. to add docstrings, type hints, etc.\r\n\r\nIt's annoying when I send a file that's several hundred lines long, only for it to send it all back to me as the search string. It'd be much better if it could elide the middle part. Perhaps using tags as in #1803 would make this possible. \r\n\r\nE.g. tell it \"If the search text will be more than 10 lines, elide it and only include the first and last 5 lines\". \r\n\r\nWe could tell it to include the start search block in `<aiderSearchStart>` tags and the end in `<aiderSearchEnd>` tags, then just select everything in between with a regex.\r\n\r\nThis'd make working with aider faster and cheaper.\r\n\r\n### Version and model info\r\n\r\nAider: 0.58.1",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1886/comments",
    "author": "boosh",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-10-07T20:44:24Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nI've tried this without much success. But happy to see some benchmark results that indicate it has become viable with the latest models."
      },
      {
        "user": "boosh",
        "created_at": "2024-10-08T05:27:35Z",
        "body": "Shame. Thanks for trying."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-10-21T16:57:13Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open. Or feel free to file a new issue any time."
      }
    ]
  },
  {
    "number": 1871,
    "title": "BUG: Still having loop/token flooding issues even after update to latest 0.58.2-dev7 branch",
    "created_at": "2024-10-01T18:48:23Z",
    "closed_at": "2024-10-01T19:11:37Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1871",
    "body": "### Issue\r\n\r\nI started working on a another basic test project in a new venv today (a simple snake example, but using the /architect and editor approach).  I got about 10 minutes in and I'm seeing issues again.\r\n\r\nI did have verbose enabled but this is what is happening:\r\n```\r\nModelResponse(id='chatcmpl-62efeb4e-2d1d-410e-98a3-1d311f010ee4', choices=[Choices(finish_reason='length', index=0, message=Message(content='I', role='assistant', tool_calls=None, function_call=None))], created=1727808229, model='claude-3-5-sonnet-20240620', object='chat.completion', system_fingerprint=None, usage=Usage(completion_tokens=1, prompt_tokens=728, total_tokens=729, completion_tokens_details=None, cache_creation_input_tokens=5003, cache_read_input_tokens=6335))\r\nI                                                                                                                                                                                                                              \r\nModelResponse(id='chatcmpl-3a18ae9c-9236-4238-8f3d-cf3741ee4f91', choices=[Choices(finish_reason='length', index=0, message=Message(content=' apolog', role='assistant', tool_calls=None, function_call=None))], created=1727808230, model='claude-3-5-sonnet-20240620', object='chat.completion', system_fingerprint=None, usage=Usage(completion_tokens=1, prompt_tokens=729, total_tokens=730, completion_tokens_details=None, cache_creation_input_tokens=0, cache_read_input_tokens=11338))\r\nI apolog                                                                                                                                                                                                                       \r\nModelResponse(id='chatcmpl-24efe41f-e409-46a1-9a09-c6c922650306', choices=[Choices(finish_reason='length', index=0, message=Message(content=' ', role='assistant', tool_calls=None, function_call=None))], created=1727808231, model='claude-3-5-sonnet-20240620', object='chat.completion', system_fingerprint=None, usage=Usage(completion_tokens=1, prompt_tokens=731, total_tokens=732, completion_tokens_details=None, cache_creation_input_tokens=0, cache_read_input_tokens=11338))\r\nI apolog                                                                                                                                                                                                                       \r\nModelResponse(id='chatcmpl-1d980581-f5cb-4511-9117-7a9929e869d3', choices=[Choices(finish_reason='length', index=0, message=Message(content=' ', role='assistant', tool_calls=None, function_call=None))], created=1727808232, model='claude-3-5-sonnet-20240620', object='chat.completion', system_fingerprint=None, usage=Usage(completion_tokens=1, prompt_tokens=731, total_tokens=732, completion_tokens_details=None, cache_creation_input_tokens=0, cache_read_input_tokens=11338))\r\nI apolog                                                                                                                                                                                                                       \r\nModelResponse(id='chatcmpl-c2be2efc-40ff-4850-8140-fc3d6401bf0e', choices=[Choices(finish_reason='length', index=0, message=Message(content=' ', role='assistant', tool_calls=None, function_call=None))], created=1727808233, model='claude-3-5-sonnet-20240620', object='chat.completion', system_fingerprint=None, usage=Usage(completion_tokens=1, prompt_tokens=731, total_tokens=732, completion_tokens_details=None, cache_creation_input_tokens=0, cache_read_input_tokens=11338))\r\nI apolog                                                                                                                                                                                                                       \r\nModelResponse(id='chatcmpl-d6c68b84-2424-4db8-9b58-30284fe52c7d', choices=[Choices(finish_reason='length', index=0, message=Message(content=' ', role='assistant', tool_calls=None, function_call=None))], created=1727808234, model='claude-3-5-sonnet-20240620', object='chat.completion', system_fingerprint=None, usage=Usage(completion_tokens=1, prompt_tokens=731, total_tokens=732, completion_tokens_details=None, cache_creation_input_tokens=0, cache_read_input_tokens=11338))\r\nI apolog                                                                                                                                                                                                                       \r\nModelResponse(id='chatcmpl-6f999a1e-8635-4bd5-99ed-5cd797c187f5', choices=[Choices(finish_reason='length', index=0, message=Message(content=' ', role='assistant', tool_calls=None, function_call=None))], created=1727808236, model='claude-3-5-sonnet-20240620', object='chat.completion', system_fingerprint=None, usage=Usage(completion_tokens=1, prompt_tokens=731, total_tokens=732, completion_tokens_details=None, cache_creation_input_tokens=0, cache_read_input_tokens=11338))\r\nI apolog                                                                                                                                                                                                                       \r\nModelResponse(id='chatcmpl-2d83a27e-3de9-4d54-8018-91230b0aec56', choices=[Choices(finish_reason='length', index=0, message=Message(content=' ', role='assistant', tool_calls=None, function_call=None))], created=1727808237, model='claude-3-5-sonnet-20240620', object='chat.completion', system_fingerprint=None, usage=Usage(completion_tokens=1, prompt_tokens=731, total_tokens=732, completion_tokens_details=None, cache_creation_input_tokens=0, cache_read_input_tokens=11338))\r\nI apolog                  \r\n^C\r\n\r\n^C again to exit\r\n\r\nTokens: 107k sent, 8 received. Cost: $0.09 message, $0.67 session.\r\n────────────────────────────────────────────────────────────────────────\r\n```\r\nThe prompt was:\r\n```\r\nAll coding should be respecting the guidelines in code.md.  Update the code to reflect these guidelines and explain why you weren't respecting them previously when the guidelines were part of the chat. \r\n```\r\n\r\nSettings:\r\n\r\n```\r\nCommand Line Args:   --anthropic-api-key ...ugAA --openai-api-key ...GD9K --sonnet --cache-prompts --cache-keepalive-pings 5 --no-stream --dark-mode --edit-format diff --verbose\r\nDefaults:\r\n  --model-settings-file:.aider.model.settings.yml\r\n  --model-metadata-file:.aider.model.metadata.json\r\n  --env-file:        /usr/projects/qsnake/.env\r\n  --map-refresh:     auto\r\n  --map-multiplier-no-files:2\r\n  --input-history-file:/usr/projects/qsnake/.aider.input.history\r\n  --chat-history-file:/usr/projects/qsnake/.aider.chat.history.md\r\n  --user-input-color:#00cc00\r\n  --tool-error-color:#FF2222\r\n  --tool-warning-color:#FFA500\r\n  --assistant-output-color:#0088ff\r\n  --code-theme:      default\r\n  --aiderignore:     /usr/projects/qsnake/.aiderignore\r\n  --lint-cmd:        []\r\n  --test-cmd:        []\r\n  --encoding:        utf-8\r\n  --voice-format:    wav\r\n  --voice-language:  en\r\n\r\nOption settings:\r\n  - aiderignore: /usr/projects/qsnake/.aiderignore\r\n  - anthropic_api_key: ...ugAA\r\n  - apply: None\r\n  - assistant_output_color: #00FFFF\r\n  - attribute_author: True\r\n  - attribute_commit_message_author: False\r\n  - attribute_commit_message_committer: False\r\n  - attribute_committer: True\r\n  - auto_commits: True\r\n  - auto_lint: True\r\n  - auto_test: False\r\n  - cache_keepalive_pings: 5\r\n  - cache_prompts: True\r\n  - chat_history_file: /usr/projects/qsnake/.aider.chat.history.md\r\n  - chat_language: None\r\n  - check_update: True\r\n  - code_theme: monokai\r\n  - commit: False\r\n  - commit_prompt: None\r\n  - completion_menu_bg_color: None\r\n  - completion_menu_color: None\r\n  - completion_menu_current_bg_color: None\r\n  - completion_menu_current_color: None\r\n  - config: None\r\n  - dark_mode: True\r\n  - dirty_commits: True\r\n  - dry_run: False\r\n  - edit_format: diff\r\n  - editor_edit_format: None\r\n  - editor_model: None\r\n  - encoding: utf-8\r\n  - env_file: /usr/projects/qsnake/.env\r\n  - exit: False\r\n  - file: None\r\n  - files: []\r\n  - git: True\r\n  - gitignore: True\r\n  - gui: False\r\n  - input_history_file: /usr/projects/qsnake/.aider.input.history\r\n  - install_main_branch: False\r\n  - just_check_update: False\r\n  - light_mode: False\r\n  - lint: False\r\n  - lint_cmd: []\r\n  - list_models: None\r\n  - llm_history_file: None\r\n  - map_multiplier_no_files: 2\r\n  - map_refresh: files\r\n  - map_tokens: None\r\n  - max_chat_history_tokens: None\r\n  - message: None\r\n  - message_file: None\r\n  - model: claude-3-5-sonnet-20240620\r\n  - model_metadata_file: .aider.model.metadata.json\r\n  - model_settings_file: .aider.model.settings.yml\r\n  - openai_api_base: None\r\n  - openai_api_deployment_id: None\r\n  - openai_api_key: ...GD9K\r\n  - openai_api_type: None\r\n  - openai_api_version: None\r\n  - openai_organization_id: None\r\n  - pretty: False\r\n  - read: None\r\n  - restore_chat_history: False\r\n  - show_diffs: False\r\n  - show_model_warnings: True\r\n  - show_prompts: False\r\n  - show_repo_map: False\r\n  - stream: False\r\n  - subtree_only: False\r\n  - suggest_shell_commands: True\r\n  - test: False\r\n  - test_cmd: []\r\n  - tool_error_color: #FF3333\r\n  - tool_output_color: None\r\n  - tool_warning_color: #FFFF00\r\n  - upgrade: False\r\n  - user_input_color: #32FF32\r\n  - verbose: True\r\n  - verify_ssl: True\r\n  - vim: False\r\n  - voice_format: wav\r\n  - voice_language: en\r\n  - weak_model: None\r\n  - yes: None\r\n```\r\n\r\n\r\n### Version and model info\r\n\r\n_No response_",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1871/comments",
    "author": "5ocworkshop",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-10-01T18:53:28Z",
        "body": "Are you sure you were running the 0.58.2-dev version of aider? Your output doesn't include the announce lines that show the version number."
      },
      {
        "user": "5ocworkshop",
        "created_at": "2024-10-01T19:06:41Z",
        "body": "UPDATE: NOPE, not sure.  Somehow I still have another copy somewhere.  Grrrr.....  Is there any way I can confidently purge all instances, pip and pipx installed, from my system and start over?  \r\n\r\nBoy that /version command would be handy...\r\n"
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-10-01T19:11:09Z",
        "body": "The very latest main branch now shows the version in the `/settings` output. \r\n"
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-10-01T19:11:37Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open. Or feel free to file a new issue any time."
      }
    ]
  },
  {
    "number": 1864,
    "title": "Uncaught PermissionError in config.py line 746",
    "created_at": "2024-10-01T14:29:58Z",
    "closed_at": "2024-10-01T15:29:07Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1864",
    "body": "Aider version: 0.58.1\r\nPython version: 3.12.6\r\nPlatform: Windows-11-10.0.22631-SP0\r\nPython implementation: CPython\r\nVirtual environment: No\r\nOS: Windows 11 (64bit)\r\nGit version: git version 2.46.2.windows.1\r\n\r\nAn uncaught exception occurred:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\r\n  File \"<frozen runpy>\", line 88, in _run_code\r\n  File \"__main__.py\", line 7, in <module>\r\n    sys.exit(main())\r\n             ^^^^^^\r\n  File \"main.py\", line 501, in main\r\n    git_root = setup_git(git_root, io)\r\n               ^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"main.py\", line 102, in setup_git\r\n    git_config.set_value(\"user\", \"name\", \"Your Name\")\r\n  File \"config.py\", line 114, in assure_data_present\r\n    return func(self, *args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"config.py\", line 128, in flush_changes\r\n    rval = non_const_func(self, *args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"config.py\", line 888, in set_value\r\n    self.set(section, option, self._value_to_string(value))\r\n  File \"config.py\", line 130, in flush_changes\r\n    self.write()\r\n  File \"config.py\", line 114, in assure_data_present\r\n    return func(self, *args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"config.py\", line 746, in write\r\n    with open(fp, \"wb\") as fp_open:\r\n         ^^^^^^^^^^^^^^\r\nPermissionError: [Errno 13] Permission denied: 'C:\\\\Users\\\\User\\\\Documents\\\\python\\\\new\\\\.git\\\\config'\r\n\r\n```",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1864/comments",
    "author": "Blackgoku500",
    "comments": [
      {
        "user": "fry69",
        "created_at": "2024-10-01T14:40:13Z",
        "body": "Thank you for filing this issue.\r\n\r\n> PermissionError: [Errno 13] Permission denied: 'C:\\\\Users\\\\User\\\\Documents\\\\python\\\\new\\\\.git\\\\config'\r\n\r\nLooks like there is permission problem with this file (or maybe the folder?). Try create a git repository in a different folder/location and start aider there again (best to create the folder in the console/terminal, so this folder has the exact same permissions when you start aider)."
      },
      {
        "user": "Blackgoku500",
        "created_at": "2024-10-01T15:28:24Z",
        "body": "Thank you, it worked"
      },
      {
        "user": "fry69",
        "created_at": "2024-10-01T15:29:07Z",
        "body": "As this issue appears to be resolved, I'm closing it.\r\n\r\nIf any new related concerns arise, please feel free to comment, and I'll reopen the issue."
      }
    ]
  },
  {
    "number": 1834,
    "title": "Uncaught NotFoundError in utils.py line 8071",
    "created_at": "2024-09-30T04:57:30Z",
    "closed_at": "2024-09-30T05:51:55Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1834",
    "body": "Aider version: 0.58.0\r\nPython version: 3.12.3\r\nPlatform: Linux-6.8.0-45-generic-x86_64-with-glibc2.39\r\nPython implementation: CPython\r\nVirtual environment: Yes\r\nOS: Linux 6.8.0-45-generic (64bit)\r\nGit version: git version 2.43.0\r\n\r\nAn uncaught exception occurred:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"openai.py\", line 907, in completion\r\n    raise e\r\n  File \"openai.py\", line 825, in completion\r\n    self.make_sync_openai_chat_completion_request(\r\n  File \"openai.py\", line 683, in make_sync_openai_chat_completion_request\r\n    raise e\r\n  File \"openai.py\", line 672, in make_sync_openai_chat_completion_request\r\n    raw_response = openai_client.chat.completions.with_raw_response.create(\r\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"_legacy_response.py\", line 353, in wrapped\r\n    return cast(LegacyAPIResponse[R], func(*args, **kwargs))\r\n                                      ^^^^^^^^^^^^^^^^^^^^^\r\n  File \"_utils.py\", line 274, in wrapper\r\n    return func(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^\r\n  File \"completions.py\", line 704, in create\r\n    return self._post(\r\n           ^^^^^^^^^^^\r\n  File \"_base_client.py\", line 1268, in post\r\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\r\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"_base_client.py\", line 945, in request\r\n    return self._request(\r\n           ^^^^^^^^^^^^^^\r\n  File \"_base_client.py\", line 1049, in _request\r\n    raise self._make_status_error_from_response(err.response) from None\r\nopenai.NotFoundError: Error code: 404 - {'error': {'message': 'The model `o1-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"main.py\", line 1419, in completion\r\n    raise e\r\n  File \"main.py\", line 1372, in completion\r\n    response = openai_o1_chat_completions.completion(\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"o1_handler.py\", line 58, in completion\r\n    response = super().completion(\r\n               ^^^^^^^^^^^^^^^^^^^\r\n  File \"openai.py\", line 914, in completion\r\n    raise OpenAIError(\r\nlitellm.llms.OpenAI.openai.OpenAIError: Error code: 404 - {'error': {'message': 'The model `o1-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"aider\", line 8, in <module>\r\n    sys.exit(main())\r\n             ^^^^^^\r\n  File \"main.py\", line 727, in main\r\n    coder.run()\r\n  File \"base_coder.py\", line 730, in run\r\n    self.run_one(user_message, preproc)\r\n  File \"base_coder.py\", line 773, in run_one\r\n    list(self.send_message(message))\r\n  File \"base_coder.py\", line 1208, in send_message\r\n    saved_message = self.auto_commit(edited)\r\n                    ^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"base_coder.py\", line 1891, in auto_commit\r\n    res = self.repo.commit(fnames=edited, context=context, aider_edits=True)\r\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"repo.py\", line 110, in commit\r\n    commit_message = self.get_commit_message(diffs, context)\r\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"repo.py\", line 195, in get_commit_message\r\n    commit_message = simple_send_with_retries(\r\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"sendchat.py\", line 44, in wrapper\r\n    return decorated_func(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"_sync.py\", line 105, in retry\r\n    ret = target(*args, **kwargs)\r\n          ^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"sendchat.py\", line 102, in simple_send_with_retries\r\n    _hash, response = send_completion(**kwargs)\r\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"sendchat.py\", line 83, in send_completion\r\n    res = litellm.completion(**kwargs)\r\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"utils.py\", line 1086, in wrapper\r\n    raise e\r\n  File \"utils.py\", line 974, in wrapper\r\n    result = original_function(*args, **kwargs)\r\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"main.py\", line 2847, in completion\r\n    raise exception_type(\r\n          ^^^^^^^^^^^^^^^\r\n  File \"utils.py\", line 8194, in exception_type\r\n    raise e\r\n  File \"utils.py\", line 8071, in exception_type\r\n    raise NotFoundError(\r\nlitellm.exceptions.NotFoundError: litellm.NotFoundError: NotFoundError: OpenrouterException - Error code: 404 - {'error': {'message': 'The model `o1-mini` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}\r\n\r\n```",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1834/comments",
    "author": "6rz6",
    "comments": [
      {
        "user": "fry69",
        "created_at": "2024-09-30T05:14:16Z",
        "body": "Thank you for filing this issue.\r\n\r\n> `The model `o1-mini` does not exist or you do not have access to it.`\r\n\r\nThe `o1` models on the OpenAI API still require an account with Tier 4, you can use OpenRouter instead to access those models without this requirement."
      },
      {
        "user": "6rz6",
        "created_at": "2024-09-30T05:24:27Z",
        "body": "thanks yes thats what i did, its set on default openrouter/openai/o1-mini now and works well"
      },
      {
        "user": "fry69",
        "created_at": "2024-09-30T05:51:55Z",
        "body": "As this issue appears to be resolved, I'm closing it.\r\n\r\nIf any new related concerns arise, please feel free to comment, and I'll reopen the issue."
      },
      {
        "user": "6rz6",
        "created_at": "2024-09-30T11:32:19Z",
        "body": "🙂 np thank you\n-------- Original message --------From: fry69 ***@***.***> Date: 9/30/24  08:52  (GMT+02:00) To: paul-gauthier/aider ***@***.***> Cc: Rudyz - CTO and head of AI R&D ***@***.***>, Author ***@***.***> Subject: Re: [paul-gauthier/aider] Uncaught NotFoundError in utils.py line\n  8071 (Issue #1834) \nAs this issue appears to be resolved, I'm closing it.\nIf any new related concerns arise, please feel free to comment, and I'll reopen the issue.\n\n—Reply to this email directly, view it on GitHub, or unsubscribe.You are receiving this because you authored the thread.Message ID: ***@***.***>\n"
      }
    ]
  },
  {
    "number": 1829,
    "title": "Uncaught OSError in utils.py line 196",
    "created_at": "2024-09-29T20:22:15Z",
    "closed_at": "2024-10-05T12:40:51Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1829",
    "body": "Aider version: 0.56.0\r\nPython version: 3.12.5\r\nPlatform: Windows-11-10.0.22621-SP0\r\nPython implementation: CPython\r\nVirtual environment: No\r\nOS: Windows 11 (64bit)\r\nGit information unavailable\r\n\r\nAn uncaught exception occurred:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\r\n  File \"<frozen runpy>\", line 88, in _run_code\r\n  File \"__main__.py\", line 7, in <module>\r\n    sys.exit(main())\r\n             ^^^^^^\r\n  File \"main.py\", line 698, in main\r\n    coder.run()\r\n  File \"base_coder.py\", line 735, in run\r\n    self.run_one(user_message, preproc)\r\n  File \"base_coder.py\", line 778, in run_one\r\n    list(self.send_message(message))\r\n  File \"base_coder.py\", line 1102, in send_message\r\n    chunks = self.format_messages()\r\n             ^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"base_coder.py\", line 1040, in format_messages\r\n    chunks = self.format_chat_chunks()\r\n             ^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"base_coder.py\", line 990, in format_chat_chunks\r\n    chunks.repo = self.get_repo_messages()\r\n                  ^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"base_coder.py\", line 632, in get_repo_messages\r\n    repo_content = self.get_repo_map()\r\n                   ^^^^^^^^^^^^^^^^^^^\r\n  File \"base_coder.py\", line 604, in get_repo_map\r\n    repo_content = self.repo_map.get_repo_map(\r\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"repomap.py\", line 127, in get_repo_map\r\n    files_listing = self.get_ranked_tags_map(\r\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"repomap.py\", line 478, in get_ranked_tags_map\r\n    result = self.get_ranked_tags_map_uncached(\r\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"repomap.py\", line 509, in get_ranked_tags_map_uncached\r\n    ranked_tags = self.get_ranked_tags(\r\n                  ^^^^^^^^^^^^^^^^^^^^^\r\n  File \"repomap.py\", line 309, in get_ranked_tags\r\n    fnames = tqdm(fnames, desc=\"Scanning repo\")\r\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"std.py\", line 1098, in __init__\r\n    self.refresh(lock_args=self.lock_args)\r\n  File \"std.py\", line 1347, in refresh\r\n    self.display()\r\n  File \"std.py\", line 1495, in display\r\n    self.sp(self.__str__() if msg is None else msg)\r\n  File \"std.py\", line 459, in print_status\r\n    fp_write('\\r' + s + (' ' * max(last_len[0] - len_s, 0)))\r\n  File \"std.py\", line 452, in fp_write\r\n    fp.write(str(s))\r\n  File \"utils.py\", line 196, in inner\r\n    return func(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^\r\nOSError: [WinError 6] The handle is invalid\r\n\r\n```",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1829/comments",
    "author": "paulobunga",
    "comments": [
      {
        "user": "fry69",
        "created_at": "2024-09-29T20:34:40Z",
        "body": "Thank you for filing this issue.\r\n\r\nIt seems there was a problem accessing a file while trying to build the repository map.\r\n\r\nDo you have a huge repository?\r\nDoes this happen repeatedly?"
      },
      {
        "user": "fry69",
        "created_at": "2024-10-05T12:40:51Z",
        "body": "I'm closing this issue for now.\r\n\r\nIf any new related concerns arise, please feel free to comment, and I'll reopen the issue."
      }
    ]
  },
  {
    "number": 1825,
    "title": "Uncaught ValueError in style.py line 76",
    "created_at": "2024-09-29T17:15:25Z",
    "closed_at": "2024-10-05T12:41:17Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1825",
    "body": "Aider version: 0.58.0\r\nPython version: 3.10.0rc2\r\nPlatform: Windows-10-10.0.26100-SP0\r\nPython implementation: CPython\r\nVirtual environment: No\r\nOS: Windows 10 (64bit)\r\nGit version: git version 2.46.0.windows.1\r\n\r\nAn uncaught exception occurred:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"runpy.py\", line 196, in _run_module_as_main\r\n    return _run_code(code, main_globals, None,\r\n  File \"runpy.py\", line 86, in _run_code\r\n    exec(code, run_globals)\r\n  File \"__main__.py\", line 7, in <module>\r\n    sys.exit(main())\r\n  File \"main.py\", line 501, in main\r\n    git_root = setup_git(git_root, io)\r\n  File \"main.py\", line 78, in setup_git\r\n    elif io.confirm_ask(\"No git repo found, create one to track aider's changes (recommended)?\"):\r\n  File \"io.py\", line 526, in confirm_ask\r\n    style = self._get_style()\r\n  File \"io.py\", line 290, in _get_style\r\n    return Style.from_dict(style_dict)\r\n  File \"style.py\", line 266, in from_dict\r\n    return cls(list(style_dict.items()))\r\n  File \"style.py\", line 239, in __init__\r\n    attrs = _parse_style_str(style_str)\r\n  File \"style.py\", line 172, in _parse_style_str\r\n    attrs = attrs._replace(color=parse_color(part))\r\n  File \"style.py\", line 76, in parse_color\r\n    raise ValueError(f\"Wrong color format {text!r}\")\r\nValueError: Wrong color format 'sonnet'\r\n\r\n```",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1825/comments",
    "author": "dayronmiranda",
    "comments": [
      {
        "user": "fry69",
        "created_at": "2024-09-29T17:31:45Z",
        "body": "Thank you for filing this issue.\r\n\r\nLooks like something got messed up in you configuration and you try to set `sonnet` as a color format somehow."
      },
      {
        "user": "fry69",
        "created_at": "2024-10-05T12:41:17Z",
        "body": "I'm closing this issue for now.\r\n\r\nIf any new related concerns arise, please feel free to comment, and I'll reopen the issue."
      }
    ]
  },
  {
    "number": 1818,
    "title": "Feature request: add --external-chat switch to allow Aider to receive individual messages written in a custom text editor",
    "created_at": "2024-09-29T12:59:11Z",
    "closed_at": "2024-09-29T13:53:47Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1818",
    "body": "### Issue\n\n# Description\r\n\r\nThe `--external-chat <text_editor_path>` switch would allow Aider to receive individual message written in a custom text editor.\r\n\r\n1. The `--external-chat` switch alone would imply reading the path to the text editor from the `AIDER_CHAT_EDITOR` environment variable.\r\n2. When typing `/architect`, `/ask` or `/code` without any message attached to it, Aider opens a temporary text file in the message editor that the user has selected as their preferred message editor.\r\n3. Once this is done, Aider waits for the user to type a custom message in the message editor, save it to the aforementioned temporary text file, and finally close the editor. When Aider detects that the user has closed the editor process, it reads the content of the temporary text file and uses it to send the chat message content.\r\n4. Aider will try to perform all necessary cleanup steps, such as deleting the temporary text file.\r\n5. The only requirement for the program to work properly is that the chosen message editor must open the temporary file in a blocking mode, which allows us to detect when the process of the editor that opened the temporary file is closed.\r\n\r\nSmall python example. Set `AIDER_CHAT_EDITOR` environment variable to the chosen text editor:\r\n\r\n```python\r\nimport os\r\nimport subprocess\r\nimport tempfile\r\nimport shlex\r\nimport shutil\r\nfrom pathlib import Path\r\n\r\ndef get_editor_input():\r\n    msg_editor = os.environ.get('AIDER_CHAT_EDITOR')\r\n    if not msg_editor:\r\n        print(\"No message editor set to AIDER_CHAT_EDITOR.\")\r\n        return None\r\n\r\n    msg_editor_cmd = shlex.split(msg_editor)\r\n    editor_executable = shutil.which(msg_editor_cmd[0])\r\n    if not editor_executable:\r\n        print(f\"Error: {msg_editor_cmd[0]} executable not found.\")\r\n        return None\r\n\r\n    try:\r\n        with tempfile.NamedTemporaryFile(mode='w+', suffix=\".txt\", delete=False, encoding='utf-8') as temp_file:\r\n            temp_filename = temp_file.name\r\n\r\n        temp_path = Path(temp_filename)\r\n        result = subprocess.run(msg_editor_cmd + [str(temp_path)], check=True)\r\n\r\n        if result.returncode == 0:\r\n            return temp_path.read_text().strip()\r\n        else:\r\n            print(f\"Error: {editor_executable} exited with a non-zero status.\")\r\n            return None\r\n\r\n    except subprocess.CalledProcessError as e:\r\n        print(f\"Error: {editor_executable} exited with a non-zero status. {e}\")\r\n    except FileNotFoundError:\r\n        print(f\"Error: {editor_executable} executable not found.\")\r\n    except Exception as e:\r\n        print(f\"An unexpected error occurred: {e}\")\r\n    except KeyboardInterrupt:\r\n        print(\"Operation cancelled by user.\")\r\n    finally:\r\n        if temp_path.exists():\r\n            temp_path.unlink(missing_ok=True)\r\n\r\n    return None\r\n\r\nif __name__ == \"__main__\":\r\n    commit_message = get_editor_input()\r\n\r\n    if commit_message:\r\n        print(f\"Your custom message: {commit_message}\")\r\n    else:\r\n        print(\"No custom message provided or an error occurred.\")\r\n```\r\n\r\n# Use case\r\n\r\nWhile Aider's terminal interface is certainly nice, it might be beneficial to consider allowing users to type chat messages in their external text editors of choice.\n\n### Version and model info\n\n_No response_",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1818/comments",
    "author": "insilications",
    "comments": [
      {
        "user": "fry69",
        "created_at": "2024-09-29T13:15:22Z",
        "body": "Thank you for filing this issue.\r\n\r\nThis seems to be related or duplicate feature request of #1315. Since I cannot see a major difference to the `/editor` approach from #1315 I tend to close this issue as a duplicate. \r\n\r\nPlease respond if you have a different opinion and/or I have missed something."
      },
      {
        "user": "insilications",
        "created_at": "2024-09-29T13:53:47Z",
        "body": "> Thank you for filing this issue.\r\n> \r\n> This seems to be related or duplicate feature request of #1315. Since I cannot see a major difference to the `/editor` approach from #1315 I tend to close this issue as a duplicate.\r\n> \r\n> Please respond if you have a different opinion and/or I have missed something.\r\n\r\nYes, I will close it."
      }
    ]
  },
  {
    "number": 1784,
    "title": "Repeated Cost Addition on Interrupt (Ctrl-C) in Aider-Chat Sessions",
    "created_at": "2024-09-27T16:27:36Z",
    "closed_at": "2024-10-07T20:35:53Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1784",
    "body": "### Issue\n\nWhen using Aider-Chat, I noticed a bug related to session cost calculation. If I interrupt the AI processing by pressing Ctrl-C before it finishes its response, the cost of the last message is repeatedly added to the total session cost. This occurs each time I attempt to interrupt and restart the process, leading to inflated and inaccurate session costs.\r\n\r\nSteps to Reproduce:\r\n\r\nStart a session in Aider-Chat.\r\nSend a message and let the AI start processing.\r\nInterrupt the processing by pressing Ctrl-C before it finishes.\r\nRepeat the process of interrupting and sending new messages.\r\n\r\nThank you for looking into this issue!\n\n### Version and model info\n\nAider v0.57.1 with model o1-preview",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1784/comments",
    "author": "tommypowerz",
    "comments": [
      {
        "user": "fry69",
        "created_at": "2024-09-27T16:42:20Z",
        "body": "Thank you for filing this issue.\r\n\r\nJust to clarify:\r\n\r\nThe costs for the request happened the second you pressed return and send the request to the LLM. If you interrupt the processing, you only signal that you are not interested in receiving the reply, but the costs for the request and the reply will be billed. That is how LLMs work.\r\n\r\nDue to that cost calculation might be inaccurate the second you interrupt the request, as you will not receive the reply with the actual cost. There may be a bug where aider will take the cost of the last reply instead, I will look into this.\r\n\r\nBut consider all session cost data bogus the second you press `Ctrl-C`."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-10-07T20:35:53Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open. Or feel free to file a new issue any time."
      }
    ]
  },
  {
    "number": 1774,
    "title": "Uncaught ValueError in pathlib.py line 682",
    "created_at": "2024-09-27T05:13:35Z",
    "closed_at": "2024-10-07T20:28:55Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1774",
    "body": "Aider version: 0.57.1\r\nPython version: 3.12.3\r\nPlatform: Windows-10-10.0.19045-SP0\r\nPython implementation: CPython\r\nVirtual environment: No\r\nOS: Windows 10 (64bit)\r\nGit version: git version 2.45.2.windows.1\r\n\r\nAn uncaught exception occurred:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\r\n  File \"<frozen runpy>\", line 88, in _run_code\r\n  File \"__main__.py\", line 7, in <module>\r\n    sys.exit(main())\r\n             ^^^^^^\r\n  File \"main.py\", line 709, in main\r\n    coder.run()\r\n  File \"base_coder.py\", line 723, in run\r\n    self.run_one(user_message, preproc)\r\n  File \"base_coder.py\", line 760, in run_one\r\n    message = self.preproc_user_input(user_message)\r\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"base_coder.py\", line 749, in preproc_user_input\r\n    return self.commands.run(inp)\r\n           ^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"commands.py\", line 221, in run\r\n    return self.do_run(matching_commands[0][1:], rest_inp)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"commands.py\", line 196, in do_run\r\n    return cmd_method(args)\r\n           ^^^^^^^^^^^^^^^^\r\n  File \"commands.py\", line 946, in cmd_code\r\n    return self._generic_chat_command(args, self.coder.main_model.edit_format)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"commands.py\", line 955, in _generic_chat_command\r\n    coder = Coder.create(\r\n            ^^^^^^^^^^^^^\r\n  File \"base_coder.py\", line 152, in create\r\n    res = coder(main_model, io, **kwargs)\r\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"base_coder.py\", line 343, in __init__\r\n    if self.repo and self.repo.ignored_file(fname):\r\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"repo.py\", line 332, in ignored_file\r\n    result = self.ignored_file_raw(fname)\r\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"repo.py\", line 338, in ignored_file_raw\r\n    fname_path = Path(self.normalize_path(fname))\r\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"repo.py\", line 299, in normalize_path\r\n    path = str(Path(PurePosixPath((Path(self.root) / path).relative_to(self.root))))\r\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"pathlib.py\", line 682, in relative_to\r\n    raise ValueError(f\"{str(self)!r} is not in the subpath of {str(other)!r}\")\r\nValueError: 'C:\\\\Users\\\\*****\\\\AppData\\\\Local\\\\Temp\\\\tmpe8hjgkw9\\\\clipboard_image.png' is not in the subpath of 'C:\\\\GitHub\\\\PyKotor\\\\Libraries\\\\Utility\\\\src\\\\utility\\\\ui_libraries\\\\qt'\r\n\r\n```\r\n\r\nI put a clipboard image in the chat, typed my message, pressed enter, immediately Ctrl+C because I remembered something i wanted to add to the message, retyped a new message, pressed enter, and was greeted with this interesting stack trace. Might want to check `if is_relative_to` or break things into local variables? The exception is a bit difficult to read, not sure why so much path normalization needs to be happening? What's wrong with `os.path.normpath`...?",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1774/comments",
    "author": "th3w1zard1",
    "comments": [
      {
        "user": "fry69",
        "created_at": "2024-09-27T05:24:40Z",
        "body": "Thank you for filing this issue.\r\n\r\nAs far as I know this is a necessary test for a known limitation of how the clipboard/pasting images works on Windows. But maybe @paul-gauthier has more insight into this problem?\r\n"
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-10-07T20:28:50Z",
        "body": "This should be fixed in the latest version. You can get it like this:\r\n\r\n```\r\naider --upgrade\r\n\r\n# or...\r\n\r\npython -m pip install --upgrade aider-chat\r\n```\r\n\r\nIf you have a chance to try it, let me know if it works better for you."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-10-07T20:28:55Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open. Or feel free to file a new issue any time."
      }
    ]
  },
  {
    "number": 1770,
    "title": "APIConnectionError with ollama + deepseek-coder-v2",
    "created_at": "2024-09-26T23:41:25Z",
    "closed_at": "2024-10-21T16:58:08Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1770",
    "body": "### Issue\r\n\r\nI'm running into this \"unknown\" error using ollama as the model service with deepseek-coder-v2. It works through patching one small area of python code and then on the next area it gets stuck and then can't continue--it appears to be stuck in a loop at this point. The first patch modifies about 4 lines in the first 14 lines of the file, the second patch would start around line 66 of 77 total lines in the (very small, simple) file.\r\n\r\n```\r\nlitellm.APIConnectionError: Ollama Error - {'error': 'an unknown error was encountered while running the model '}\r\nTraceback (most recent call last):\r\n  File \"~/miniforge3/lib/python3.12/site-packages/litellm/utils.py\", line 9548, in chunk_creator\r\n    response_obj = self.handle_ollama_stream(chunk)\r\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"~/miniforge3/lib/python3.12/site-packages/litellm/utils.py\", line 8975, in handle_ollama_stream\r\n    raise e\r\n```\r\n\r\n### Version and model info\r\n\r\nAider 0.57.2.dev209+g17108c43\r\nModel: deepseek-coder-v2:16b\r\n\r\nSimilar to #598 ",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1770/comments",
    "author": "bribroder",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-10-07T20:31:53Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nThis seems like a bug/problem with your ollama server."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-10-21T16:58:09Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open. Or feel free to file a new issue any time."
      },
      {
        "user": "krmao",
        "created_at": "2024-12-27T09:58:50Z",
        "body": "same here\r\n\r\n```\r\n                                                                                                                          Conclusion\r\n\r\nIn this tutorial, we have learned how to create a simple To Do App using HTML CSS JavaScript and Firebase Realtime Database. I hope you enjoyed this tutorial. If you have any questions or suggestions, please feel free to leave a comment below.\r\n\r\n\r\nTokens: 140 sent, 1.2k received.\r\nEdit the files? (Y)es/(N)o [Yes]: y\r\n\r\n\r\n\r\nBased                                                                                                                                                                                                                                                          litellm.APIConnectionError: Ollama Error - {'error': 'an error was encountered while running the model: unexpected EOF'}\r\nTraceback (most recent call last):\r\n  File \"/Users/kr.mao/.local/share/uv/tools/aider-chat/lib/python3.12/site-packages/litellm/litellm_core_utils/streaming_handler.py\", line 1272, in chunk_creator\r\n    response_obj = self.handle_ollama_chat_stream(chunk)\r\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/kr.mao/.local/share/uv/tools/aider-chat/lib/python3.12/site-packages/litellm/litellm_core_utils/streaming_handler.py\", line 730, in handle_ollama_chat_stream\r\n    raise e\r\n  File \"/Users/kr.mao/.local/share/uv/tools/aider-chat/lib/python3.12/site-packages/litellm/litellm_core_utils/streaming_handler.py\", line 705, in handle_ollama_chat_stream\r\n    raise Exception(f\"Ollama Error - {json_chunk}\")\r\nException: Ollama Error - {'error': 'an error was encountered while running the model: unexpected EOF'}\r\n\r\nRetrying in 0.2 seconds...\r\nBased\r\nBased                                                                                                                                                                                                                                                          litellm.APIConnectionError: Ollama Error - {'error': 'an error was encountered while running the model: unexpected EOF'}\r\nTraceback (most recent call last):\r\n  File \"/Users/kr.mao/.local/share/uv/tools/aider-chat/lib/python3.12/site-packages/litellm/litellm_core_utils/streaming_handler.py\", line 1272, in chunk_creator\r\n    response_obj = self.handle_ollama_chat_stream(chunk)\r\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/kr.mao/.local/share/uv/tools/aider-chat/lib/python3.12/site-packages/litellm/litellm_core_utils/streaming_handler.py\", line 730, in handle_ollama_chat_stream\r\n    raise e\r\n  File \"/Users/kr.mao/.local/share/uv/tools/aider-chat/lib/python3.12/site-packages/litellm/litellm_core_utils/streaming_handler.py\", line 705, in handle_ollama_chat_stream\r\n    raise Exception(f\"Ollama Error - {json_chunk}\")\r\nException: Ollama Error - {'error': 'an error was encountered while running the model: unexpected EOF'}\r\n\r\nRetrying in 0.5 seconds...\r\nBased\r\n```"
      },
      {
        "user": "sigalarm",
        "created_at": "2025-01-02T19:05:50Z",
        "body": "I am also tripping over this with deepseek-coder-v2:latest in ollama version is 0.5.4. Process is, \r\n1. start up Ollama with `ollama run deepseek-coder-v2:latest`\r\n2. Feed it about 300 lines of source code for analysis\r\n3. Ask it to comment on the code block\r\n\r\n**Recieve**\r\n\r\n`TheError: an error was encountered while running the model: unexpected EOF`, and ollama exits.\r\n\r\nRunning ollama on an M4 Mac mini with 64GB of memory. \r\n"
      }
    ]
  },
  {
    "number": 1758,
    "title": "Context - Access commit history",
    "created_at": "2024-09-26T15:31:54Z",
    "closed_at": "2024-09-26T16:43:05Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1758",
    "body": "### Issue\n\nIt would be nice to be able to ask something based on previous commit:\r\n\r\n> do the same changes as the last commit, but for euros instead of dollars\n\n### Version and model info\n\n_No response_",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1758/comments",
    "author": "titouandk",
    "comments": [
      {
        "user": "fry69",
        "created_at": "2024-09-26T15:58:10Z",
        "body": "Thank you for filing this issue.\r\n\r\nThe last changes should be part of the chat history and get send to the LLM again, so you do not need last diffs while the chat history is available.\r\n\r\nIf you start aider fresh and want to have the last diff in the chat history, you can try ->\r\n```\r\n/run git diff HEAD~1\r\n```\r\nThat should produce the last commit diff and it should get included in the chat history, so the LLM sees it. Increase the number after the tilde get include more past commits."
      },
      {
        "user": "titouandk",
        "created_at": "2024-09-26T16:39:18Z",
        "body": "This is a very handy trick, thank you!"
      },
      {
        "user": "fry69",
        "created_at": "2024-09-26T16:43:05Z",
        "body": "As this issue appears to be resolved, I'm closing it.\r\n\r\nIf any new related concerns arise, please feel free to comment, and I'll reopen the issue."
      },
      {
        "user": "titouandk",
        "created_at": "2024-09-26T16:44:24Z",
        "body": "The `/help` command does not know this `/run` trick apparently.\n\nMaybe the aider doc online could also benefit of this example as a way to add context?"
      },
      {
        "user": "fry69",
        "created_at": "2024-09-26T17:01:12Z",
        "body": "PR with new tips section is out"
      },
      {
        "user": "titouandk",
        "created_at": "2024-09-26T17:18:10Z",
        "body": "Thank you! 🙏"
      }
    ]
  },
  {
    "number": 1754,
    "title": "Uncaught JSONDecodeError in decoder.py line 355",
    "created_at": "2024-09-26T14:47:14Z",
    "closed_at": "2024-09-27T21:45:49Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1754",
    "body": "Aider version: 0.57.1\r\nPython version: 3.12.6\r\nPlatform: macOS-15.0-arm64-arm-64bit\r\nPython implementation: CPython\r\nVirtual environment: Yes\r\nOS: Darwin 24.0.0 (64bit)\r\nGit version: git version 2.39.5 (Apple Git-154)\r\n\r\nAn uncaught exception occurred:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"aider\", line 8, in <module>\r\n    sys.exit(main())\r\n             ^^^^^^\r\n  File \"main.py\", line 709, in main\r\n    coder.run()\r\n  File \"base_coder.py\", line 723, in run\r\n    self.run_one(user_message, preproc)\r\n  File \"base_coder.py\", line 760, in run_one\r\n    message = self.preproc_user_input(user_message)\r\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"base_coder.py\", line 749, in preproc_user_input\r\n    return self.commands.run(inp)\r\n           ^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"commands.py\", line 221, in run\r\n    return self.do_run(matching_commands[0][1:], rest_inp)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"commands.py\", line 196, in do_run\r\n    return cmd_method(args)\r\n           ^^^^^^^^^^^^^^^^\r\n  File \"commands.py\", line 905, in cmd_help\r\n    self.help = Help()\r\n                ^^^^^^\r\n  File \"help.py\", line 113, in __init__\r\n    index = get_index()\r\n            ^^^^^^^^^^^\r\n  File \"help.py\", line 73, in get_index\r\n    storage_context = StorageContext.from_defaults(\r\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"storage_context.py\", line 111, in from_defaults\r\n    docstore = docstore or SimpleDocumentStore.from_persist_dir(\r\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"simple_docstore.py\", line 57, in from_persist_dir\r\n    return cls.from_persist_path(persist_path, namespace=namespace, fs=fs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"simple_docstore.py\", line 74, in from_persist_path\r\n    simple_kvstore = SimpleKVStore.from_persist_path(persist_path, fs=fs)\r\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"simple_kvstore.py\", line 98, in from_persist_path\r\n    data = json.load(f)\r\n           ^^^^^^^^^^^^\r\n  File \"__init__.py\", line 293, in load\r\n    return loads(fp.read(),\r\n           ^^^^^^^^^^^^^^^^\r\n  File \"__init__.py\", line 346, in loads\r\n    return _default_decoder.decode(s)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"decoder.py\", line 337, in decode\r\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"decoder.py\", line 355, in raw_decode\r\n    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\r\njson.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\r\n\r\n```",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1754/comments",
    "author": "dekubu",
    "comments": [
      {
        "user": "fry69",
        "created_at": "2024-09-26T14:55:46Z",
        "body": "Thank you for filing this issue.\r\n\r\nIf I have to guess from the error message, the `/help` had trouble reading from a cached help file store. Can you try deleting all cached help files? Example ->\r\n```shell\r\nrm -fR ~/.aider/caches/help.*\r\n```"
      },
      {
        "user": "dekubu",
        "created_at": "2024-09-27T21:44:02Z",
        "body": "Hey, Just wanted to say thanks for help! works perfectly now,\r\n"
      },
      {
        "user": "fry69",
        "created_at": "2024-09-27T21:45:49Z",
        "body": "As this issue appears to be resolved, I'm closing it.\r\n\r\nIf any new related concerns arise, please feel free to comment, and I'll reopen the issue."
      }
    ]
  },
  {
    "number": 1726,
    "title": "Uncaught ModuleNotFoundError in caching.py line 22",
    "created_at": "2024-09-25T18:44:27Z",
    "closed_at": "2024-09-25T19:37:49Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1726",
    "body": "Aider version: 0.57.1\r\nPython version: 3.9.12\r\nPlatform: macOS-10.16-x86_64-i386-64bit\r\nPython implementation: CPython\r\nVirtual environment: No\r\nOS: Darwin 23.4.0 (64bit)\r\nGit version: git version 2.46.0\r\n\r\nAn uncaught exception occurred:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"base_coder.py\", line 1115, in send_message\r\n    yield from self.send(messages, functions=self.functions)\r\n  File \"base_coder.py\", line 1392, in send\r\n    hash_object, completion = send_completion(\r\n  File \"sendchat.py\", line 87, in send_completion\r\n    res = litellm.completion(**kwargs)\r\n  File \"llm.py\", line 23, in __getattr__\r\n    self._load_litellm()\r\n  File \"llm.py\", line 30, in _load_litellm\r\n    self._lazy_module = importlib.import_module(\"litellm\")\r\n  File \"__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 1030, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 1007, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 986, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 680, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 850, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 228, in _call_with_frames_removed\r\n  File \"__init__.py\", line 9, in <module>\r\n    from litellm.caching import Cache\r\n  File \"caching.py\", line 22, in <module>\r\n    from openai._models import BaseModel as OpenAIObject\r\nModuleNotFoundError: No module named 'openai._models'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"Aider\", line 8, in <module>\r\n    sys.exit(main())\r\n  File \"main.py\", line 709, in main\r\n    coder.run()\r\n  File \"base_coder.py\", line 723, in run\r\n    self.run_one(user_message, preproc)\r\n  File \"base_coder.py\", line 766, in run_one\r\n    list(self.send_message(message))\r\n  File \"base_coder.py\", line 1117, in send_message\r\n    except retry_exceptions() as err:\r\n  File \"sendchat.py\", line 24, in retry_exceptions\r\n    litellm.exceptions.APIConnectionError,\r\n  File \"llm.py\", line 23, in __getattr__\r\n    self._load_litellm()\r\n  File \"llm.py\", line 30, in _load_litellm\r\n    self._lazy_module = importlib.import_module(\"litellm\")\r\n  File \"__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 1030, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 1007, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 986, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 680, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 850, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 228, in _call_with_frames_removed\r\n  File \"__init__.py\", line 9, in <module>\r\n    from litellm.caching import Cache\r\n  File \"caching.py\", line 22, in <module>\r\n    from openai._models import BaseModel as OpenAIObject\r\nModuleNotFoundError: No module named 'openai._models'\r\n\r\n```",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1726/comments",
    "author": "tonyrb",
    "comments": [
      {
        "user": "tonyrb",
        "created_at": "2024-09-25T18:46:20Z",
        "body": "Installed the newest version and getting this error straight even with the following prompt 'which model are you?' \r\nI will return to previous version in case"
      },
      {
        "user": "fry69",
        "created_at": "2024-09-25T18:48:17Z",
        "body": "Thank you for filing this issue.\r\n\r\nThis error is likely due to something gone wrong during installation. Can you please try to install aider separately from other Python modules, e.g. via `pipx` or `venv`?"
      },
      {
        "user": "tonyrb",
        "created_at": "2024-09-25T18:55:22Z",
        "body": "> Thank you for filing this issue.\r\n> \r\n> This error is likely due to something gone wrong during installation. Can you please try to install aider separately from other Python modules, e.g. via `pipx` or `venv`?\r\n\r\nI did try to reinstall through pipx and same error happened, I have rollback to previous version and work as a charm."
      },
      {
        "user": "fry69",
        "created_at": "2024-09-25T19:07:26Z",
        "body": "> I did try to reinstall through pipx and same error happened, I have rollback to previous version and work as a charm.\r\n\r\nCan you please post the first few lines from aider when you start from the version that is not working, please?\r\nAlso try really uninstalling and reinstalling aider via `pipx`, if possible, please->\r\n```\r\n$ pipx uninstall aider-chat\r\nuninstalled aider-chat! ✨ 🌟 ✨\r\n$ pipx install aider-chat\r\n  installed package aider-chat 0.57.1, installed using Python 3.12.6\r\n  These apps are now globally available\r\n    - aider\r\ndone! ✨ 🌟 ✨\r\n$ aider --4o\r\nAider v0.57.1\r\nMain model: gpt-4o-2024-08-06 with ask edit format\r\nWeak model: gpt-4o-mini\r\nGit repo: .git with 6 files\r\nRepo-map: using 1024 tokens, auto refresh\r\nUse /help <question> for help, run \"aider --help\" to see cmd line args\r\n\r\nask> Please say something in English.                                                                                                                         \r\n\r\nOf course! If you have any questions about your code or need help with anything specific, feel free to ask.                                                   \r\n\r\nTokens: 160 sent, 23 received. Cost: $0.00063 message, $0.00063 session.\r\n```\r\n\r\nWorks for me without problems on my macOS M1 system."
      },
      {
        "user": "tonyrb",
        "created_at": "2024-09-25T19:37:05Z",
        "body": "Well thanks for the uninstall reinstall, it did fix the issue.\r\nThanks for the support for this dumb bug that I got :/"
      },
      {
        "user": "tonyrb",
        "created_at": "2024-09-25T19:37:49Z",
        "body": "\r\nclosing the ticket thanks Fry69 !\r\n\r\n"
      }
    ]
  },
  {
    "number": 1724,
    "title": "Uncaught FileNotFoundError in adapters.py line 81",
    "created_at": "2024-09-25T17:10:32Z",
    "closed_at": "2024-10-05T12:37:45Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1724",
    "body": "Aider version: 0.57.1\r\nPython version: 3.12.6\r\nPlatform: macOS-14.6.1-arm64-arm-64bit\r\nPython implementation: CPython\r\nVirtual environment: No\r\nOS: Darwin 23.6.0 (64bit)\r\nGit version: git version 2.46.0\r\n\r\nAn uncaught exception occurred:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"aider\", line 8, in <module>\r\n    sys.exit(main())\r\n             ^^^^^^\r\n  File \"main.py\", line 524, in main\r\n    main_model = models.Model(args.model, weak_model=args.weak_model)\r\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"models.py\", line 606, in __init__\r\n    self.get_weak_model(weak_model)\r\n  File \"models.py\", line 670, in get_weak_model\r\n    self.weak_model = Model(\r\n                      ^^^^^^\r\n  File \"models.py\", line 589, in __init__\r\n    self.info = self.get_model_info(model)\r\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"models.py\", line 609, in get_model_info\r\n    return get_model_info(model)\r\n           ^^^^^^^^^^^^^^^^^^^^^\r\n  File \"models.py\", line 557, in get_model_info\r\n    import requests\r\n  File \"__init__.py\", line 164, in <module>\r\n    from .api import delete, get, head, options, patch, post, put, request\r\n  File \"api.py\", line 11, in <module>\r\n    from . import sessions\r\n  File \"sessions.py\", line 15, in <module>\r\n    from .adapters import HTTPAdapter\r\n  File \"adapters.py\", line 81, in <module>\r\n    _preloaded_ssl_context.load_verify_locations(\r\nFileNotFoundError: [Errno 2] No such file or directory\r\n\r\n```",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1724/comments",
    "author": "samihalawa",
    "comments": [
      {
        "user": "fry69",
        "created_at": "2024-09-25T17:23:48Z",
        "body": "Thank you for filing this issue.\r\n\r\nThis error is likely due to something gone wrong during installation. Can you please try to install aider separately from other Python modules, e.g. via `pipx` or `venv`?\r\n"
      },
      {
        "user": "fry69",
        "created_at": "2024-10-05T12:37:45Z",
        "body": "I'm closing this issue for now.\r\n\r\nIf any new related concerns arise, please feel free to comment, and I'll reopen the issue."
      }
    ]
  },
  {
    "number": 1699,
    "title": "Uncaught AttributeError in sendchat.py line 30",
    "created_at": "2024-09-24T12:29:29Z",
    "closed_at": "2024-09-24T15:27:53Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1699",
    "body": "Aider version: 0.57.2.dev78+g6dd34ee2.d20240923\r\nPython version: 3.12.5\r\nPlatform: macOS-14.6.1-arm64-arm-64bit\r\nPython implementation: CPython\r\nVirtual environment: Yes\r\nOS: Darwin 23.6.0 (64bit)\r\nGit version: git version 2.39.3 (Apple Git-146)\r\n\r\nAn uncaught exception occurred:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"aider\", line 8, in <module>\r\n    sys.exit(main())\r\n             ^^^^^^\r\n  File \"main.py\", line 712, in main\r\n    coder.run()\r\n  File \"base_coder.py\", line 723, in run\r\n    self.run_one(user_message, preproc)\r\n  File \"base_coder.py\", line 766, in run_one\r\n    list(self.send_message(message))\r\n  File \"base_coder.py\", line 1195, in send_message\r\n    saved_message = self.auto_commit(edited)\r\n                    ^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"base_coder.py\", line 1876, in auto_commit\r\n    res = self.repo.commit(fnames=edited, context=context, aider_edits=True)\r\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"repo.py\", line 110, in commit\r\n    commit_message = self.get_commit_message(diffs, context)\r\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"repo.py\", line 195, in get_commit_message\r\n    commit_message = simple_send_with_retries(\r\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"sendchat.py\", line 38, in wrapper\r\n    retry_exceptions(),\r\n    ^^^^^^^^^^^^^^^^^^\r\n  File \"sendchat.py\", line 30, in retry_exceptions\r\n    litellm.llms.anthropic.chat.AnthropicError,\r\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nAttributeError: module 'litellm.llms.anthropic' has no attribute 'chat'\r\n\r\n```",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1699/comments",
    "author": "elifarley",
    "comments": [
      {
        "user": "fry69",
        "created_at": "2024-09-24T12:41:01Z",
        "body": "Thank you for filing this issue.\r\n\r\nIt seems you are running aider's `main` branch from GitHub, and it also seems like you might have updated LiteLLM in the `venv` where aider is running. This is always problematic as LiteLLM constantly introduces breaking features. For this reason aider requires a specific version of LiteLLM as per `requirements.txt`.\r\n\r\nTL;DR please do not upgrade LiteLLM and keep the aider `venv` separate from other Python modules/tools/etc"
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-09-24T15:27:52Z",
        "body": "Thanks for trying aider and filing this issue.\n\nThis looks like a duplicate of #1414. Please see the comments there for more information, and feel free to continue the discussion within that issue.\n\nI'm going to close this issue for now. But please let me know if you think this is actually a distinct issue and I will reopen this issue."
      }
    ]
  },
  {
    "number": 1694,
    "title": "Uncaught TypeError in core.pyx line 14",
    "created_at": "2024-09-24T09:27:38Z",
    "closed_at": "2024-09-24T15:28:57Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1694",
    "body": "Aider version: 0.56.0\r\nPython version: 3.12.6\r\nPlatform: Linux-6.10.10-arch1-1-x86_64-with-glibc2.40\r\nPython implementation: CPython\r\nVirtual environment: No\r\nOS: Linux 6.10.10-arch1-1 (64bit)\r\nGit version: git version 2.46.1\r\n\r\nAn uncaught exception occurred:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"aider\", line 8, in <module>\r\n    sys.exit(main())\r\n             ^^^^^^\r\n  File \"main.py\", line 698, in main\r\n    coder.run()\r\n  File \"base_coder.py\", line 735, in run\r\n    self.run_one(user_message, preproc)\r\n  File \"base_coder.py\", line 778, in run_one\r\n    list(self.send_message(message))\r\n  File \"base_coder.py\", line 1213, in send_message\r\n    lint_errors = self.lint_edited(edited)\r\n                  ^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"base_coder.py\", line 1307, in lint_edited\r\n    errors = self.linter.lint(self.abs_root_path(fname))\r\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"linter.py\", line 104, in lint\r\n    lintres = basic_lint(rel_fname, code)\r\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"linter.py\", line 213, in basic_lint\r\n    parser = get_parser(lang)\r\n             ^^^^^^^^^^^^^^^^\r\n  File \"core.pyx\", line 19, in tree_sitter_languages.core.get_parser\r\n  File \"core.pyx\", line 14, in tree_sitter_languages.core.get_language\r\nTypeError: __init__() takes exactly 1 argument (2 given)\r\n\r\n```",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1694/comments",
    "author": "ghost",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-09-24T15:28:57Z",
        "body": "Thanks for trying aider and filing this issue.\n\nThis looks like a duplicate of #1236. Please see the comments there for more information, and feel free to continue the discussion within that issue.\n\nI'm going to close this issue for now. But please let me know if you think this is actually a distinct issue and I will reopen this issue."
      }
    ]
  },
  {
    "number": 1689,
    "title": "Unable to install through pip or python",
    "created_at": "2024-09-24T01:09:38Z",
    "closed_at": "2024-10-05T12:38:23Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1689",
    "body": "### Issue\r\n\r\nI get this each time I try installing it through VSCode terminal:\r\n\r\n```python -m pip install aider-chat\r\nCollecting aider-chat\r\n  Using cached aider_chat-0.16.0-py3-none-any.whl.metadata (11 kB)\r\nCollecting aiohttp==3.8.4 (from aider-chat)\r\n  Using cached aiohttp-3.8.4.tar.gz (7.3 MB)\r\n  Installing build dependencies ... done\r\n  Getting requirements to build wheel ... done\r\n  Preparing metadata (pyproject.toml) ... done\r\nCollecting aiosignal==1.3.1 (from aider-chat)\r\n  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\r\nCollecting async-timeout==4.0.2 (from aider-chat)\r\n  Using cached async_timeout-4.0.2-py3-none-any.whl.metadata (4.2 kB)\r\nCollecting attrs==23.1.0 (from aider-chat)\r\n  Using cached attrs-23.1.0-py3-none-any.whl.metadata (11 kB)\r\nCollecting certifi==2023.5.7 (from aider-chat)\r\n  Using cached certifi-2023.5.7-py3-none-any.whl.metadata (2.2 kB)\r\nCollecting charset-normalizer==3.1.0 (from aider-chat)\r\n  Using cached charset_normalizer-3.1.0-py3-none-any.whl.metadata (30 kB)\r\nCollecting frozenlist==1.3.3 (from aider-chat)\r\n  Using cached frozenlist-1.3.3.tar.gz (66 kB)\r\n  Installing build dependencies ... done\r\n  Getting requirements to build wheel ... done\r\n  Preparing metadata (pyproject.toml) ... done\r\nCollecting gitdb==4.0.10 (from aider-chat)\r\n  Using cached gitdb-4.0.10-py3-none-any.whl.metadata (1.1 kB)\r\nCollecting GitPython==3.1.31 (from aider-chat)\r\n  Using cached GitPython-3.1.31-py3-none-any.whl.metadata (1.3 kB)\r\nCollecting idna==3.4 (from aider-chat)\r\n  Using cached idna-3.4-py3-none-any.whl.metadata (9.8 kB)\r\nCollecting markdown-it-py==2.2.0 (from aider-chat)\r\n  Using cached markdown_it_py-2.2.0-py3-none-any.whl.metadata (6.8 kB)\r\nCollecting mdurl==0.1.2 (from aider-chat)\r\n  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\r\nCollecting multidict==6.0.4 (from aider-chat)\r\n  Using cached multidict-6.0.4.tar.gz (51 kB)\r\n  Installing build dependencies ... done\r\n  Getting requirements to build wheel ... done\r\n  Preparing metadata (pyproject.toml) ... done\r\nCollecting openai==0.27.6 (from aider-chat)\r\n  Using cached openai-0.27.6-py3-none-any.whl.metadata (13 kB)\r\nCollecting prompt-toolkit==3.0.38 (from aider-chat)\r\n  Using cached prompt_toolkit-3.0.38-py3-none-any.whl.metadata (7.0 kB)\r\nCollecting Pygments==2.15.1 (from aider-chat)\r\n  Using cached Pygments-2.15.1-py3-none-any.whl.metadata (2.5 kB)\r\nCollecting requests==2.30.0 (from aider-chat)\r\n  Using cached requests-2.30.0-py3-none-any.whl.metadata (4.6 kB)\r\nCollecting rich==13.3.5 (from aider-chat)\r\n  Using cached rich-13.3.5-py3-none-any.whl.metadata (18 kB)\r\nCollecting smmap==5.0.0 (from aider-chat)\r\n  Using cached smmap-5.0.0-py3-none-any.whl.metadata (4.2 kB)\r\nCollecting tqdm==4.65.0 (from aider-chat)\r\n  Using cached tqdm-4.65.0-py3-none-any.whl.metadata (56 kB)\r\nCollecting urllib3==2.0.2 (from aider-chat)\r\n  Using cached urllib3-2.0.2-py3-none-any.whl.metadata (6.6 kB)\r\nCollecting wcwidth==0.2.6 (from aider-chat)\r\n  Using cached wcwidth-0.2.6-py2.py3-none-any.whl.metadata (11 kB)\r\nCollecting yarl==1.9.2 (from aider-chat)\r\n  Using cached yarl-1.9.2.tar.gz (184 kB)\r\n  Installing build dependencies ... done\r\n  Getting requirements to build wheel ... done\r\n  Preparing metadata (pyproject.toml) ... done\r\nCollecting pytest==7.3.1 (from aider-chat)\r\n  Using cached pytest-7.3.1-py3-none-any.whl.metadata (7.9 kB)\r\nCollecting tiktoken==0.4.0 (from aider-chat)\r\n  Using cached tiktoken-0.4.0.tar.gz (25 kB)\r\n  Installing build dependencies ... done\r\n  Getting requirements to build wheel ... done\r\n  Preparing metadata (pyproject.toml) ... done\r\nCollecting configargparse (from aider-chat)\r\n  Using cached ConfigArgParse-1.7-py3-none-any.whl.metadata (23 kB)\r\nCollecting PyYAML (from aider-chat)\r\n  Using cached PyYAML-6.0.2-cp313-cp313-win_amd64.whl.metadata (2.1 kB)\r\nCollecting backoff==2.2.1 (from aider-chat)\r\n  Using cached backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\r\nCollecting networkx==3.1 (from aider-chat)\r\n  Using cached networkx-3.1-py3-none-any.whl.metadata (5.3 kB)\r\nCollecting diskcache==5.6.1 (from aider-chat)\r\n  Using cached diskcache-5.6.1-py3-none-any.whl.metadata (20 kB)\r\nCollecting numpy==1.24.3 (from aider-chat)\r\n  Using cached numpy-1.24.3.tar.gz (10.9 MB)\r\n  Installing build dependencies ... done\r\n  Getting requirements to build wheel ... done\r\nERROR: Exception:\r\nTraceback (most recent call last):\r\n  File \"C:\\Program Files\\Python313\\Lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 105, in _run_wrapper\r\n    status = _inner_run()\r\n  File \"C:\\Program Files\\Python313\\Lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 96, in _inner_run\r\n    return self.run(options, args)\r\n           ~~~~~~~~^^^^^^^^^^^^^^^\r\n  File \"C:\\Program Files\\Python313\\Lib\\site-packages\\pip\\_internal\\cli\\req_command.py\", line 67, in wrapper\r\n    return func(self, options, args)\r\n  File \"C:\\Program Files\\Python313\\Lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 379, in run\r\n    requirement_set = resolver.resolve(\r\n        reqs, check_supported_wheels=not options.target_dir\r\n    )\r\n  File \"C:\\Program Files\\Python313\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\resolver.py\", line 95, in resolve\r\n    result = self._result = resolver.resolve(\r\n                            ~~~~~~~~~~~~~~~~^\r\n        collected.requirements, max_rounds=limit_how_complex_resolution_can_be\r\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n    )\r\n    ^\r\n  File \"C:\\Program Files\\Python313\\Lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 546, in resolve\r\n    state = resolution.resolve(requirements, max_rounds=max_rounds)\r\n  File \"C:\\Program Files\\Python313\\Lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 427, in resolve\r\n    failure_causes = self._attempt_to_pin_criterion(name)\r\n  File \"C:\\Program Files\\Python313\\Lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 239, in _attempt_to_pin_criterion\r\n    criteria = self._get_updated_criteria(candidate)\r\n  File \"C:\\Program Files\\Python313\\Lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 230, in _get_updated_criteria\r\n    self._add_to_criteria(criteria, requirement, parent=candidate)\r\n    ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"C:\\Program Files\\Python313\\Lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 173, in _add_to_criteria\r\n    if not criterion.candidates:\r\n           ^^^^^^^^^^^^^^^^^^^^\r\n  File \"C:\\Program Files\\Python313\\Lib\\site-packages\\pip\\_vendor\\resolvelib\\structs.py\", line 156, in __bool__\r\n    return bool(self._sequence)\r\n  File \"C:\\Program Files\\Python313\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 174, in __bool__\r\n    return any(self)\r\n  File \"C:\\Program Files\\Python313\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 162, in <genexpr>\r\n    return (c for c in iterator if id(c) not in self._incompatible_ids)\r\n                       ^^^^^^^^\r\n  File \"C:\\Program Files\\Python313\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 53, in _iter_built\r\n    candidate = func()\r\n  File \"C:\\Program Files\\Python313\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\factory.py\", line 186, in _make_candidate_from_link\r\n    base: Optional[BaseCandidate] = self._make_base_candidate_from_link(\r\n                                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\r\n        link, template, name, version\r\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n    )\r\n    ^\r\n  File \"C:\\Program Files\\Python313\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\factory.py\", line 232, in _make_base_candidate_from_link\r\n    self._link_candidate_cache[link] = LinkCandidate(\r\n                                       ~~~~~~~~~~~~~^\r\n        link,\r\n        ^^^^^\r\n    ...<3 lines>...\r\n        version=version,\r\n        ^^^^^^^^^^^^^^^^\r\n    )\r\n    ^\r\n  File \"C:\\Program Files\\Python313\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 303, in __init__\r\n    super().__init__(\r\n    ~~~~~~~~~~~~~~~~^\r\n        link=link,\r\n        ^^^^^^^^^^\r\n    ...<4 lines>...\r\n        version=version,\r\n        ^^^^^^^^^^^^^^^^\r\n    )\r\n    ^\r\n  File \"C:\\Program Files\\Python313\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 158, in __init__\r\n    self.dist = self._prepare()\r\n                ~~~~~~~~~~~~~^^\r\n  File \"C:\\Program Files\\Python313\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 235, in _prepare\r\n    dist = self._prepare_distribution()\r\n  File \"C:\\Program Files\\Python313\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 314, in _prepare_distribution\r\n    return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)\r\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"C:\\Program Files\\Python313\\Lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 527, in prepare_linked_requirement\r\n    return self._prepare_linked_requirement(req, parallel_builds)\r\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"C:\\Program Files\\Python313\\Lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 642, in _prepare_linked_requirement\r\n    dist = _get_prepared_distribution(\r\n        req,\r\n    ...<3 lines>...\r\n        self.check_build_deps,\r\n    )\r\n  File \"C:\\Program Files\\Python313\\Lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 72, in _get_prepared_distribution\r\n    abstract_dist.prepare_distribution_metadata(\r\n    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\r\n        finder, build_isolation, check_build_deps\r\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n    )\r\n    ^\r\n  File \"C:\\Program Files\\Python313\\Lib\\site-packages\\pip\\_internal\\distributions\\sdist.py\", line 56, in prepare_distribution_metadata\r\n    self._install_build_reqs(finder)\r\n    ~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^\r\n  File \"C:\\Program Files\\Python313\\Lib\\site-packages\\pip\\_internal\\distributions\\sdist.py\", line 126, in _install_build_reqs\r\n    build_reqs = self._get_build_requires_wheel()\r\n  File \"C:\\Program Files\\Python313\\Lib\\site-packages\\pip\\_internal\\distributions\\sdist.py\", line 103, in _get_build_requires_wheel\r\n    return backend.get_requires_for_build_wheel()\r\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\r\n  File \"C:\\Program Files\\Python313\\Lib\\site-packages\\pip\\_internal\\utils\\misc.py\", line 706, in get_requires_for_build_wheel\r\n    return super().get_requires_for_build_wheel(config_settings=cs)\r\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\r\n  File \"C:\\Program Files\\Python313\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_impl.py\", line 166, in get_requires_for_build_wheel\r\n    return self._call_hook('get_requires_for_build_wheel', {\r\n           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n        'config_settings': config_settings\r\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n    })\r\n    ^^\r\n  File \"C:\\Program Files\\Python313\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_impl.py\", line 321, in _call_hook\r\n    raise BackendUnavailable(data.get('traceback', ''))\r\npip._vendor.pyproject_hooks._impl.BackendUnavailable: Traceback (most recent call last):\r\n  File \"C:\\Program Files\\Python313\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 77, in _build_backend\r\n    obj = import_module(mod_path)\r\n  File \"C:\\Program Files\\Python313\\Lib\\importlib\\__init__.py\", line 88, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n           ~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"<frozen importlib._bootstrap>\", line 1387, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 1310, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\r\n  File \"<frozen importlib._bootstrap>\", line 1387, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 1331, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 935, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 1022, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\r\n  File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\pip-build-env-iwa0omke\\overlay\\Lib\\site-packages\\setuptools\\__init__.py\", line 10, in <module>\r\n    import distutils.core\r\nModuleNotFoundError: No module named 'distutils'\r\n```\r\n\r\n### Version and model info\r\n\r\n_No response_",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1689/comments",
    "author": "daedmod",
    "comments": [
      {
        "user": "fry69",
        "created_at": "2024-09-24T01:13:10Z",
        "body": "Thank you for filing this issue.\r\n\r\nIs this a Python 3.13 installation? aider only supports Python 3.9-3.12 currently."
      },
      {
        "user": "daedmod",
        "created_at": "2024-09-24T01:40:29Z",
        "body": "@fry69 thanks, I was just about to downgrade to 3.11, I fixed the earlier error by installing setuptools, but then some other errors appeared, so I figured it's compatibility issues most likely"
      },
      {
        "user": "fry69",
        "created_at": "2024-10-05T12:38:23Z",
        "body": "As this issue appears to be resolved, I'm closing it.\r\n\r\nIf any new related concerns arise, please feel free to comment, and I'll reopen the issue."
      }
    ]
  },
  {
    "number": 1681,
    "title": "Uncaught APIError in utils.py line 6586",
    "created_at": "2024-09-23T18:29:51Z",
    "closed_at": "2024-10-07T20:25:58Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1681",
    "body": "Aider version: 0.57.1\r\nPython version: 3.12.3\r\nPlatform: Linux-6.8.0-45-generic-x86_64-with-glibc2.39\r\nPython implementation: CPython\r\nVirtual environment: No\r\nOS: Linux 6.8.0-45-generic (64bit)\r\nGit version: git version 2.43.0\r\n\r\nAn uncaught exception occurred:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"openai.py\", line 907, in completion\r\n    raise e\r\n  File \"openai.py\", line 840, in completion\r\n    return convert_to_model_response_object(\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"utils.py\", line 5720, in convert_to_model_response_object\r\n    raise raised_exception\r\nException\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"main.py\", line 1419, in completion\r\n    raise e\r\n  File \"main.py\", line 1392, in completion\r\n    response = openai_chat_completions.completion(\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"openai.py\", line 914, in completion\r\n    raise OpenAIError(\r\nlitellm.llms.OpenAI.openai.OpenAIError\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"aider\", line 8, in <module>\r\n    sys.exit(main())\r\n             ^^^^^^\r\n  File \"main.py\", line 709, in main\r\n    coder.run()\r\n  File \"base_coder.py\", line 723, in run\r\n    self.run_one(user_message, preproc)\r\n  File \"base_coder.py\", line 766, in run_one\r\n    list(self.send_message(message))\r\n  File \"base_coder.py\", line 1193, in send_message\r\n    saved_message = self.auto_commit(edited)\r\n                    ^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"base_coder.py\", line 1874, in auto_commit\r\n    res = self.repo.commit(fnames=edited, context=context, aider_edits=True)\r\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"repo.py\", line 102, in commit\r\n    commit_message = self.get_commit_message(diffs, context)\r\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"repo.py\", line 187, in get_commit_message\r\n    commit_message = simple_send_with_retries(\r\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"sendchat.py\", line 44, in wrapper\r\n    return decorated_func(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"_sync.py\", line 105, in retry\r\n    ret = target(*args, **kwargs)\r\n          ^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"sendchat.py\", line 107, in simple_send_with_retries\r\n    _hash, response = send_completion(**kwargs)\r\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"sendchat.py\", line 87, in send_completion\r\n    res = litellm.completion(**kwargs)\r\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"utils.py\", line 1086, in wrapper\r\n    raise e\r\n  File \"utils.py\", line 974, in wrapper\r\n    result = original_function(*args, **kwargs)\r\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"main.py\", line 2847, in completion\r\n    raise exception_type(\r\n          ^^^^^^^^^^^^^^^\r\n  File \"utils.py\", line 8194, in exception_type\r\n    raise e\r\n  File \"utils.py\", line 6586, in exception_type\r\n    raise APIError(\r\nlitellm.exceptions.APIError: litellm.APIError: APIError: OpenAIException - \r\n\r\n```",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1681/comments",
    "author": "kotiacash",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-09-24T18:59:28Z",
        "body": "Which model were you using? Were you using an usual LLM setup? Was there any additional info in the error message?\r\n\r\nWhen reporting problems, it is very helpful if you can provide the “announcement” lines that aider prints at startup is an easy way to share some of this helpful info.\r\n\r\n```\r\nAider v0.37.1-dev\r\nModels: gpt-4o with diff edit format, weak model gpt-3.5-turbo\r\nGit repo: .git with 243 files\r\nRepo-map: using 1024 tokens\r\n```"
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-10-07T20:25:58Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open. Or feel free to file a new issue any time."
      }
    ]
  },
  {
    "number": 1675,
    "title": "Aider and/or LLM got confused about what was in the context",
    "created_at": "2024-09-23T13:16:47Z",
    "closed_at": "2024-10-21T16:55:23Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1675",
    "body": "### Issue\n\nAider says that astra.py is in context but the LLM acts like it is not until I drop and re-add.\r\n```\r\n───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\ncolbert_live/db/astra.py example/cmdline/db.py                                                                                         \r\n> /drop example/cmdline/db.py                                                                                                          \r\n\r\nRemoved example/cmdline/db.py from the chat\r\n───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\ncolbert_live/db/astra.py                                                                                                               \r\n> add a `verbose` flag to the `AstraDB` constructor, and \"if self.verbose: print(...)\" statements where it makes sense                 \r\n\r\n\r\nTo implement the verbose flag in the AstraDB constructor and add appropriate print statements, we'll need to modify the                \r\ncolbert_live/db/astra.py file. This file contains the AstraDB class and related methods.                                               \r\n\r\nPlease add the colbert_live/db/astra.py file to the chat so I can propose the necessary changes.                                       \r\n\r\n\r\nTokens: 5.7k sent, 76 received. Cost: $0.02 message, $0.85 session.\r\n───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\ncolbert_live/db/astra.py                                                                                                               \r\n> /clear                                                                                                                               \r\n\r\n───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\ncolbert_live/db/astra.py                                                                                                               \r\n> add a `verbose` flag to the `AstraDB` constructor, and \"if self.verbose: print(...)\" statements where it makes sense                 \r\n\r\n\r\nTo implement the verbose flag in the AstraDB constructor and add appropriate print statements, we'll need to modify the                \r\ncolbert_live/db/astra.py file. This file contains the AstraDB class definition and related methods.                                    \r\n\r\nBefore I can propose any changes, I need you to add the colbert_live/db/astra.py file to the chat. Once you've done that, I can provide\r\nthe necessary SEARCH/REPLACE blocks to implement the requested changes.                                                                \r\n\r\n\r\nTokens: 4.9k sent, 104 received. Cost: $0.02 message, $0.87 session.\r\n───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\ncolbert_live/db/astra.py                                                                                                               \r\n> /clear                                                                                                                               \r\n\r\n───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\ncolbert_live/db/astra.py                                                                                                               \r\n> /drop                                                                                                                                \r\n\r\nDropping all files from the chat session.\r\n───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n> /add colbert_live/db/astra.py                                                                                                        \r\n\r\nAdded /home/jonathan/Projects/colbert-live/colbert_live/db/astra.py to the chat\r\n───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\ncolbert_live/db/astra.py                                                                                                               \r\n> add a `verbose` flag to the `AstraDB` constructor, and \"if self.verbose: print(...)\" statements where it makes sense                 \r\n\r\n\r\nCertainly! I'll add a verbose flag to the AstraDB constructor and include \"if self.verbose: print(...)\" statements where appropriate.  \r\nHere are the changes:                                                                                                                  \r\n```\n\n### Version and model info\n\nAider v0.57.1\r\nMain model: claude-3-5-sonnet-20240620 with diff edit format, infinite output\r\nWeak model: claude-3-haiku-20240307\r\nGit repo: .git with 15 files\r\nRepo-map: using 1024 tokens",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1675/comments",
    "author": "jbellis",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-10-07T20:24:51Z",
        "body": "Are you sure astra.py wasn't part of the chat as a read-only file? In that case the LLM can't edit it until you properly `/add` it."
      },
      {
        "user": "jbellis",
        "created_at": "2024-10-07T20:33:08Z",
        "body": "I can't say for sure.  Would you be open to a PR to mark read-only files in the session differently than read/write files?"
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-10-08T14:20:10Z",
        "body": "Sure. Been trying to think of a nice, compact and intuitive way to display that distinction."
      },
      {
        "user": "fry69",
        "created_at": "2024-10-08T14:48:03Z",
        "body": "Just mark the read/write files with a `*`."
      }
    ]
  },
  {
    "number": 1628,
    "title": "Repo map is unexpectedly much smaller when accidentally mentioning filenames (without extensions) of deeply-nested files",
    "created_at": "2024-09-22T01:48:17Z",
    "closed_at": "2024-10-30T02:04:04Z",
    "labels": [
      "question",
      "stale"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1628",
    "body": "### Issue\n\nI created a fresh t3 app using `npm create t3-app@latest`. It has file `src/trpc/server.ts` and directory `src/server`. Here's the full tree:\r\n\r\n```\r\n.\r\n├── README.md\r\n├── next-env.d.ts\r\n├── next.config.js\r\n├── package.json\r\n├── postcss.config.cjs\r\n├── prettier.config.js\r\n├── prisma\r\n│   └── schema.prisma\r\n├── public\r\n│   └── favicon.ico\r\n├── src\r\n│   ├── app\r\n│   │   ├── _components\r\n│   │   │   └── post.tsx\r\n│   │   ├── api\r\n│   │   │   └── trpc\r\n│   │   │       └── [trpc]\r\n│   │   │           └── route.ts\r\n│   │   ├── layout.tsx\r\n│   │   └── page.tsx\r\n│   ├── env.js\r\n│   ├── server\r\n│   │   ├── api\r\n│   │   │   ├── root.ts\r\n│   │   │   ├── routers\r\n│   │   │   │   └── post.ts\r\n│   │   │   └── trpc.ts\r\n│   │   └── db.ts\r\n│   ├── styles\r\n│   │   └── globals.css\r\n│   └── trpc\r\n│       ├── query-client.ts\r\n│       ├── react.tsx\r\n│       └── server.ts\r\n├── tailwind.config.ts\r\n└── tsconfig.json\r\n```\r\n\r\nWhen I launch aider and enter the message \"test\", I get a reasonable-looking repo map:\r\n```\r\nUSER Here are summaries of some files present in my git repository.\r\nUSER Do not propose changes to these files, treat them as *read-only*.\r\nUSER If you need to edit any of these files, ask me to *add them to the chat* first.\r\nUSER \r\nUSER .env.example\r\nUSER \r\nUSER .eslintrc.cjs\r\nUSER \r\nUSER .gitignore\r\nUSER \r\nUSER README.md\r\nUSER \r\nUSER next.config.js\r\nUSER \r\nUSER package.json\r\nUSER \r\nUSER postcss.config.cjs\r\nUSER \r\nUSER prettier.config.js\r\nUSER \r\nUSER prisma/schema.prisma\r\nUSER \r\nUSER public/favicon.ico\r\nUSER \r\nUSER src/app/_components/post.tsx\r\nUSER \r\nUSER src/app/api/trpc/[trpc]/route.ts\r\nUSER \r\nUSER src/app/layout.tsx\r\nUSER \r\nUSER src/app/page.tsx\r\nUSER \r\nUSER src/env.js\r\nUSER \r\nUSER src/server/api/root.ts:\r\nUSER ⋮...\r\nUSER │export type AppRouter = typeof appRouter;\r\nUSER │\r\nUSER ⋮...\r\nUSER \r\nUSER src/server/api/routers/post.ts\r\nUSER \r\nUSER src/server/api/trpc.ts\r\nUSER \r\nUSER src/server/db.ts\r\nUSER \r\nUSER src/styles/globals.css\r\nUSER \r\nUSER src/trpc/query-client.ts\r\nUSER \r\nUSER src/trpc/react.tsx\r\nUSER \r\nUSER src/trpc/server.ts\r\nUSER \r\nUSER tailwind.config.ts\r\nUSER \r\nUSER tsconfig.json\r\n```\r\n\r\nHowever, when I enter a prompt including the word \"server\", like \"test server test\", I get a very minimal one, which isn't very useful to aider:\r\n```\r\nUSER Here are summaries of some files present in my git repository.\r\nUSER Do not propose changes to these files, treat them as *read-only*.\r\nUSER If you need to edit any of these files, ask me to *add them to the chat* first.\r\nUSER \r\nUSER .env.example\r\nUSER \r\nUSER .gitignore\r\nUSER \r\nUSER README.md\r\nUSER \r\nUSER next.config.js\r\nUSER \r\nUSER package.json\r\nUSER \r\nUSER tsconfig.json\r\n```\r\n\r\nI'm guessing this has to do with the nested directory `server` or file `server.ts`, but I don't understand the intent of this behavior. Is this a bug? Is there a way to work around this?\n\n### Version and model info\n\nAider v0.57.0\r\nMain model: claude-3-5-sonnet-20240620 with diff edit format, infinite output\r\nWeak model: claude-3-haiku-20240307\r\nGit repo: .git with 25 files\r\nRepo-map: using 1024 tokens, auto refresh",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1628/comments",
    "author": "tkeith",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-10-07T20:23:19Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nCan you try `aider --upgrade` to get the latest version and see if this problem is better? I believe it should be fixed."
      },
      {
        "user": "github-actions[bot]",
        "created_at": "2024-10-22T02:04:14Z",
        "body": "This issue has been labelled stale because it has been open for 2 weeks with no activity. Remove stale label or add a comment to keep this issue open. Otherwise, it will be closed in 7 days."
      },
      {
        "user": "github-actions[bot]",
        "created_at": "2024-10-30T02:04:04Z",
        "body": "This issue was closed because it has been stalled for 3 weeks with no activity. Feel free to add a comment here and we can re-open it. Or feel free to file a new issue any time."
      }
    ]
  },
  {
    "number": 1579,
    "title": "Lint in subdir in monorepo",
    "created_at": "2024-09-17T11:06:21Z",
    "closed_at": "2024-10-07T20:16:48Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1579",
    "body": "### Issue\n\nHi,\r\n\r\nfirst of all, thank you very much for the great tool!\r\n\r\nI use aider in a monorepo in which there is a subdirectory for the frontend. I will call it `subdir` in the further course.\r\n\r\nI would like to specify a `lint-cmd` (`yarn run lint`). Unfortunately aider tries to execute the cmd in the root folder and not in the `subdir`. This then fails because there is no `package.json` etc. in the root.\r\n\r\nIf I set `lint-cmd: “yarn --cwd subdir run lint\"`, then unfortunately the paths of the files are no longer correct, because aider thinks that the command is executed in the root dir and appends the `subdir` before the file:\r\n\r\nExample:\r\n`## Running: yarn --cwd subdir run lint subdir/package.json`\r\n\r\nIs there a way to change the root dir in which commands are executed? \r\nI currently start aider in subdir. Aider recognizes that `git-root` is in the parent: \r\n`Git repo: ../.git with 217 files`\r\n\r\nThank you very much!\n\n### Version and model info\n\n```\r\nsonnet: true\r\nlint: true\r\nlint-cmd: [\"yarn --cwd subdir run lint\"]\r\nsubtree-only: true\r\n```\r\n\r\nAider v0.56.0\r\nMain model: claude-3-5-sonnet-20240620 with diff edit format, infinite output\r\nWeak model: claude-3-haiku-20240307",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1579/comments",
    "author": "mrclrchtr",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-09-20T19:24:02Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nYou could make a small shell script \"mylinter.sh\" that does does the `cd` and/or modifies the filepaths before invoking the linter."
      },
      {
        "user": "mrclrchtr",
        "created_at": "2024-09-21T20:01:24Z",
        "body": "Thank you very much for the answer and your support. I'm having more and more fun using aider from day to day.\r\n\r\nThat is definitely a possibility for lint. ~~However, I have now encountered another problem: Sometimes aider wants to execute other commands. For example, when it wants to install new packages with yarn. This is also executed in the root folder and not in the subdir.~~\r\n\r\nI think it would make sense to add an option that allows you to change the root directory. Or the root directory in which commands are executed could by default be the subdirectory in which aider is executed?\r\n\r\nEdit:\r\nI'm not sure if the problem exists. Now when I tried again, yarn was executed correctly. I will continue to monitor it.\r\n\r\nNevertheless, it would be very helpful, especially in monorepos, to use the folder in which you are currently working as root for commands. "
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-10-07T20:16:48Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open. Or feel free to file a new issue any time."
      },
      {
        "user": "tino",
        "created_at": "2025-01-29T08:10:51Z",
        "body": "I would indeed expect a `--working-directory` option or so. Having to write separate shell scripts for aider for each service in my monorepo isn't very enticing. Running with `--no-git` doesn't change this for some reason?"
      }
    ]
  },
  {
    "number": 1575,
    "title": "Jupyter notebooks and aider",
    "created_at": "2024-09-17T00:30:27Z",
    "closed_at": "2024-10-07T20:13:58Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1575",
    "body": "When working with Jupyter notebooks, this problem occurs:\r\n\r\n_The SEARCH section must exactly match an existing block of lines including all white space, comments, indentation,\r\ndocstrings, etc_\r\n\r\nI'm using nbstripout and nbdime but aider still has problems matching the text.\r\n\r\nAider version: 0.56.0\r\nPython version: 3.10.12\r\nPlatform: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.35\r\nPython implementation: CPython\r\nVirtual environment: Yes\r\nOS: Linux 5.15.153.1-microsoft-standard-WSL2 (64bit)\r\nGit version: git version 2.34.1\r\n\r\nAider v0.56.0\r\nMain model: openrouter/anthropic/claude-3.5-sonnet with diff edit format, prompt cache, infinite output\r\nWeak model: openrouter/anthropic/claude-3-haiku-20240307\r\nGit repo: .git with 30 files\r\nRepo-map: using 1024 tokens, files refresh\r\nAdded plotter.ipynb to the chat.\r\nAdded portfolio_backtester.py to the chat.\r\nRestored previous conversation history.",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1575/comments",
    "author": "lockmeister",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-09-20T19:38:26Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nLLMs have trouble editing jupiter notebooks because they are python code wrapped in json. It's a complex format.\r\n\r\nYou could try `--edit-format whole`, but that will be quite slow."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-10-07T20:13:59Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open. Or feel free to file a new issue any time."
      },
      {
        "user": "Znerual",
        "created_at": "2025-01-09T11:44:58Z",
        "body": "I would assume that one could create a wrapper around jupyter notebooks that presents the code to the model by extracting the \"source\" attribute from the \"code\" cell_type and still inherently keeps track of which code line is in which jupyter block. Then, when the model then changes some lines maps the changes back to the jupyter block.  \r\n\r\nI would be happy to help implementing it, however, I think it would be more efficient if someone with experience of the Aider Framework joins in. For me it would be helpful to have a chat about how the model interacts with the code, because then I don't need to learn the Aider codebase to implement the feature. So if someone is interested, write me."
      }
    ]
  },
  {
    "number": 1569,
    "title": "REQ: Add explicit-command chat mode",
    "created_at": "2024-09-16T12:53:33Z",
    "closed_at": "2024-10-07T20:13:47Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1569",
    "body": "### Issue\n\nOn numerous occasions, I forgot to add a slash in front of the aider command, which resulted in sending a request to LLM. I think it would be useful to have an `explicit-command` chat mode that will not do anything unless the prompt is prefixed with an aider command (/ask, /code, or any other).\n\n### Version and model info\n\nAider v0.56.0\r\nModel: deepseek/deepseek-coder with diff edit format, prompt cache, infinite output\r\nGit repo: .git with 246 files\r\nRepo-map: using 2048 tokens, files refresh",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1569/comments",
    "author": "dmurat",
    "comments": [
      {
        "user": "fry69",
        "created_at": "2024-09-16T13:08:54Z",
        "body": "Maybe related #1315"
      },
      {
        "user": "dmurat",
        "created_at": "2024-09-17T06:05:47Z",
        "body": "I can see similarities, but I think it is still different. \r\n\r\nI'm looking for an explicit option to allow communication towards LLM. It can be either an explicit command, as I mentioned before. It can be an option to automatically add a slash in front of each Aider input. It can be an Aider question to the user to allow communication, or something similar.\r\n\r\nTnx"
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-09-20T19:22:56Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nI'm not sure this is likely to be in the roadmap for aider."
      },
      {
        "user": "dmurat",
        "created_at": "2024-09-20T19:25:21Z",
        "body": "Ok, I understand. Tnx, anyway."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-10-07T20:13:47Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open. Or feel free to file a new issue any time."
      }
    ]
  },
  {
    "number": 1567,
    "title": "REQ: A new file type \"ask2edit\" to complement read only and regular file loads",
    "created_at": "2024-09-16T11:53:32Z",
    "closed_at": "2024-10-07T20:13:11Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1567",
    "body": "I wanted to propose an additional type of file for aider to load in to the conversation.  I'm sure we can come up with a more elegant name, but for now I'll call it \"ask2edit\".\r\n\r\nAt the moment we can load files that are editable, or we can load files that are read only and use Sonnet's cache mechanism.\r\n\r\nThe purpose of the ask2edit load type would be that the file can be edited by the LLM but the LLM doesn't have carte blanche to make changes, instead it should only make changes when the user has reviewed and approved them.\r\n\r\nWorking through a larger project I'm refining my process of product requirements, architecture, design and implementation planning and then proceeding with coding and debugging.  As is the norm during development, adjustments to the product requirements and related cascading changes will need to be made.  However the LLMs have a habit of removing or altering things we may not want to have altered in the requirements or design documents, when trying to update them to reflect additions or changes that happen during development.\r\n\r\nAs part of my conventions.md I would like to tell the LLM that when we materially update or enhance a feature that is mentioned in the product requirements document, also update that requiremetns document so it stays in sync with the project code as built.  However, I would like the LLM to present the current version of the relevant section and the proposed changes while identifying the file it wants to change - then have it ask whether it can make those changes or allow me to iterate and request updates to the proposed wording.  This way we could iterate on a the wording changes before the edits take place.\r\n\r\nSo with ask2edit files, the idea is that the file shouldn't be updated during normal operations to avoid it accidentally being modified during the development cycle when it was meant purely as a reference but when the LLM is asked to perform an explicit operation on that file, draft wording and present it for approval or dialog.\r\n\r\n",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1567/comments",
    "author": "5ocworkshop",
    "comments": [
      {
        "user": "fry69",
        "created_at": "2024-09-16T12:04:35Z",
        "body": "Thank you for filing this issue.\r\n\r\nYou can add all files you need as read-only with `/read` first and then move select ones to a writable state `/add`."
      },
      {
        "user": "5ocworkshop",
        "created_at": "2024-09-16T19:42:24Z",
        "body": "That is a possible work around but not quite what I'm envisioning.  I'll sleep on it and see if I can explain it more clearly."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-10-07T20:13:11Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open. Or feel free to file a new issue any time."
      }
    ]
  },
  {
    "number": 1533,
    "title": "Feature request: play nice with external editing",
    "created_at": "2024-09-14T22:48:39Z",
    "closed_at": "2024-10-07T20:22:35Z",
    "labels": [
      "enhancement",
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1533",
    "body": "### Issue\n\nMy aider workflow is\r\n1. Ask aider to make a change\r\n2. Review changes, often I make changes to what Claude came up with\r\n3. Repeat\r\n\r\nCurrently I have to /drop and re-/add files that I changed in my IDE.  Could aider automatically reload files that changed on disk since its last edit?  I'm happy to take a stab at this.\n\n### Version and model info\n\nAider v0.56.0",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1533/comments",
    "author": "jbellis",
    "comments": [
      {
        "user": "fry69",
        "created_at": "2024-09-14T22:52:35Z",
        "body": "That should already be unnecessary. aider loads all files that are part of the context before sending them to the LLM fresh from the disk. They do not get stored in memory. So if you make changes outside aider, they will be reflected the next time you send a prompt to the LLM."
      },
      {
        "user": "jbellis",
        "created_at": "2024-09-15T00:01:46Z",
        "body": "I guess it needs to check earlier then, because the changes are definitely not visible for tab completion unless I manually drop and add."
      },
      {
        "user": "fry69",
        "created_at": "2024-09-15T00:15:54Z",
        "body": "The changes may not be visible to autocomplete, but the files get read from disk before they get sent to the LLM. You definitely do not need to `/drop` and `/add` before sending a new prompt to the LLM.\r\n\r\nAs long as the files are part of the repository, aider will see and know them. If possible, commit your changes after editing them from outside before you switch to aider again.\r\n"
      },
      {
        "user": "jbellis",
        "created_at": "2024-09-15T00:32:19Z",
        "body": "You're right, it's reloading before sending to the LLM.  Only autocomplete gets confused."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-09-22T01:49:44Z",
        "body": "You could also just press ENTER in aider to start a new blank prompt. That will refresh the autocompleter."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-10-07T20:22:35Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open. Or feel free to file a new issue any time."
      }
    ]
  },
  {
    "number": 1528,
    "title": "/undo not working without --auto-commits == true",
    "created_at": "2024-09-14T08:23:09Z",
    "closed_at": "2024-09-22T09:16:56Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1528",
    "body": "### Issue\r\n\r\nI understand that `/undo` performs `git reset HEAD^`, but returning to the previous chat status would be more useful.\r\n\r\nThis is particularly helpful in buggy situations when the code isn't working well enough for a commit.\r\n\r\nMoreover, `aider` can make multiple commits in a single run, which may complicate returning to a previous status (e.g., to refine the prompt, add more details to the prompt).\r\n\r\n### Version and model info\r\n\r\nAider v0.56.0\r\nMain model: claude-3-5-sonnet-20240620 with diff edit format, infinite output\r\nWeak model: claude-3-haiku-20240307\r\nGit repo: .git with 63 files\r\nRepo-map: using 1024 tokens, auto refresh",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1528/comments",
    "author": "dat-lequoc",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-09-20T19:42:52Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nAider uses auto-commits to implement /undo, so you need to leave them on if you want the safety of undo.\r\n\r\nYou can always squash the many aider commits afterwards if you want a tidy git history."
      }
    ]
  },
  {
    "number": 1508,
    "title": "when text is generating in ask mode - lines multiplied  -",
    "created_at": "2024-09-12T18:08:29Z",
    "closed_at": "2024-11-12T18:27:24Z",
    "labels": [
      "question",
      "stale"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1508",
    "body": "when text is generating in ask mode - lines multiplied  - the lines of the response are multiplied as they stream into the terminal and end up overfilling the scroll buffer\r\n\r\nexample output excerpt:\r\n```\r\n1 The Setup class has three static methods:                                                                              \r\nof the main components:                                                                                                   \r\n\r\n 1 The Setup class has three static methods:                                                                              \r\nof the main components:                                                                                                   \r\n\r\n 1 The Setup class has three static methods:                                                                              \r\nof the main components:                                                                                                   \r\n\r\n 1 The Setup class has three static methods:                                                                              \r\nof the main components:                                                                                                   \r\n\r\n 1 The Setup class has three static methods:                                                                              \r\nof the main components:                                                                                                   \r\n\r\n 1 The Setup class has three static methods:                                                                              \r\nof the main components:                                                                                                   \r\n\r\n 1 The Setup class has three static methods:                                                                              \r\nof the main components:                                                                                                   \r\n\r\n 1 The Setup class has three static methods:                                                                              \r\nof the main components:                                                                                                   \r\n\r\n 1 The Setup class has three static methods:                                                                              \r\nof the main components:                                                                                                   \r\n\r\n 1 The Setup class has three static methods:                                                                              \r\nof the main components:                                                                                                   \r\nof the main components:                                                                                                   \r\n\r\n 1 The Setup class has three static methods:                                                                              \r\n\r\n 1 The Setup class has three static methods:                                                                              \r\n    • load_sample_files(over_write=False)                                                                                \r\n 1 The Setup class has three static methods:                                                                              \r\n    • load_sample_files(over_write=False)                                                                                \r\n 1 The Setup class has three static methods:                                                                              \r\n    • load_sample_files(over_write=False)                                                                                \r\n 1 The Setup class has three static methods:                                                                              \r\n    • load_sample_files(over_write=False)                                                                                \r\n 1 The Setup class has three static methods:                                                                              \r\n    • load_sample_files(over_write=False)                                                                                \r\n 1 The Setup class has three static methods:                                                                              \r\n    • load_sample_files(over_write=False)                                                                                \r\n 1 The Setup class has three static methods:                                                                              \r\n    • load_sample_files(over_write=False)                                                                                \r\n 1 The Setup class has three static methods:                                                                              \r\n    • load_sample_files(over_write=False)                                                                                \r\n 1 The Setup class has three static methods:                                                                              \r\n    • load_sample_files(over_write=False)                                                                                \r\n 1 The Setup class has three static methods:                                                                              \r\n    • load_sample_files(over_write=False)                                                                                \r\n 1 The Setup class has three static methods:                                                                              \r\n    • load_sample_files(over_write=False)                                                                                \r\n 1 The Setup class has three static methods:                                                                              \r\n    • load_sample_files(over_write=False)                                                                                \r\n 1 The Setup class has three static methods:                                                                              \r\n    • load_sample_files(over_write=False)                                                                                \r\n 1 The Setup class has three static methods:                                                                              \r\n    • load_sample_files(over_write=False)                                                                                \r\n 1 The Setup class has three static methods:                                                                              \r\n    • load_sample_files(over_write=False)                                                                                \r\n 1 The Setup class has three static methods:                                                                              \r\n    • load_sample_files(over_write=False)                                                                                \r\n 1 The Setup class has three static methods:                                                                              \r\n    • load_sample_files(over_write=False)                                                                                \r\n 1 The Setup class has three static methods:                                                                              \r\n    • load_sample_files(over_write=False)                                                                                \r\n 1 The Setup class has three static methods:                                                                              \r\n    • load_sample_files(over_write=False)                                                                                \r\n\r\n 1 The Setup class has three static methods:                                                                              \r\n    • load_sample_files(over_write=False)                                                                                 1 The Setup class has three static methods:                                                                              \r\n    • load_sample_files(over_write=False)                                                                                 \r\n 1 The Setup class has three static methods:                                                                              \r\n    • load_sample_files(over_write=False)                                                                                 \r\n 1 The Setup class has three static methods:                                                                              \r\n    • load_sample_files(over_write=False)                                                                                 \r\n 1 The Setup class has three static methods:                                                                              \r\n    • load_sample_files(over_write=False)                                                                                 \r\n 1 The Setup class has three static methods:                                                                              \r\n    • load_sample_files(over_write=False)                                                                                 \r\n 1 The Setup class has three static methods:                                                                              \r\n    • load_sample_files(over_write=False)                                                                                 \r\n 1 The Setup class has three static methods:                                                                              \r\n    • load_sample_files(over_write=False)                                                                                 \r\n 1 The Setup class has three static methods:                                                                              \r\n    • load_sample_files(over_write=False)                                                                                 \r\n 1 The Setup class has three static methods:                                                                              \r\n    • load_sample_files(over_write=False)                                                                                 \r\n 1 The Setup class has three static methods:                                                                              \r\n    • load_sample_files(over_write=False)                                                                                 \r\n 1 The Setup class has three static methods:                                                                              \r\n    • load_sample_files(over_write=False)                                                                                 \r\n 1 The Setup class has three static methods:                                                                              \r\n    • load_sample_files(over_write=False)                                                                                 \r\n 1 The Setup class has three static methods:                                                                              \r\n    • load_sample_files(over_write=False)                                                                                 \r\n 1 The Setup class has three static methods:                                                                              \r\n 1 The Setup class has three static methods:                                                                              \r\n    • load_sample_files(over_write=False)                                                                                 \r\n    • load_sample_files(over_write=False)                                                                                 \r\n    • load_voice_sample_files(over_write=False, small_only=True)                                                             • load_sample_files(over_write=False)                                                                                 \r\n    • load_voice_sample_files(over_write=False, small_only=True)                                                             • load_sample_files(over_write=False)                                                                                 \r\n    • load_voice_sample_files(over_write=False, small_only=True)                                                             • load_sample_files(over_write=False)                                                                                 \r\n    • load_voice_sample_files(over_write=False, small_only=True)                                                             • load_sample_files(over_write=False)                                                                                 \r\n    • load_voice_sample_files(over_write=False, small_only=True)                                                             • load_sample_files(over_write=False)                                                                                 \r\n    • load_voice_sample_files(over_write=False, small_only=True)                                                             • load_sample_files(over_write=False)                                                                                 \r\n    • load_voice_sample_files(over_write=False, small_only=True)                                                             • load_sample_files(over_write=False)                                                                                 \r\n    • load_sample_files(over_write=False)                                                                                 \r\n    • load_voice_sample_files(over_write=False, small_only=True)                                                             • load_sample_files(over_write=False)                                                                                 \r\n    • load_voice_sample_files(over_write=False, small_only=True)                                                             • load_voice_sample_files(over_write=False, small_only=True)                                                          \r\n    • load_voice_sample_files(over_write=False, small_only=True)                                                          \r\n    • load_voice_sample_files(over_write=False, small_only=True)                                                          \r\n    • load_voice_sample_files(over_write=False, small_only=True)                                                          \r\n    • load_voice_sample_files(over_write=False, small_only=True)                                                          \r\n    • load_voice_sample_files(over_write=False, small_only=True)                                                          \r\n    • load_voice_sample_files(over_write=False, small_only=True)                                                          \r\n    • load_voice_sample_files(over_write=False, small_only=True)                                                          \r\n    • load_selected_sample_files(sample_folder=\"microsoft_ir\", over_write=False)                                             • load_selected_sample_files(sample_folder=\"microsoft_ir\", over_write=False)                                             • load_selected_sample_files(sample_folder=\"microsoft_ir\", over_write=False)                                             • load_selected_sample_files(sample_folder=\"microsoft_ir\", over_write=False)                                             • load_selected_sample_files(sample_folder=\"microsoft_ir\", over_write=False)                                             • load_selected_sample_files(sample_folder=\"microsoft_ir\", over_write=False)                                             • load_selected_sample_files(sample_folder=\"microsoft_ir\", over_write=False)                                          \r\n 2 These methods are designed to download sample files from an AWS S3 bucket and save them to local directories.          \r\n    • load_selected_sample_files(sample_folder=\"microsoft_ir\", over_write=False)                                          3 The methods handle creating directories, checking for existing files, and respecting the over_write parameter.         \r\n 4 The class uses the boto3 library to interact with AWS S3.                                                              \r\n 5 There are various helper methods for file operations and S3 interactions.                                              \r\n 6 The class includes error handling and logging for potential issues during the download process.  \r\n```\r\n\r\nAider version: 0.56.0\r\nPython version: 3.12.6\r\nPlatform: macOS-14.5-arm64-arm-64bit\r\nPython implementation: CPython\r\nVirtual environment: Yes\r\nOS: Darwin 23.5.0 (64bit)\r\nGit version: git version 2.46.0\r\n\r\nAider v0.56.0\r\nMain model: claude-3-5-sonnet-20240620 with diff edit format, infinite output\r\nWeak model: claude-3-haiku-20240307\r\nGit repo: .git with 118 files\r\nRepo-map: using 1024 tokens, auto refresh\r\nRestored previous conversation history.",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1508/comments",
    "author": "wissamharoun",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-09-20T19:34:04Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nThis seems like a problem with your terminal? What terminal are you using? Did you resize it in the middle of the chat reply?"
      },
      {
        "user": "wissamharoun",
        "created_at": "2024-10-07T19:43:32Z",
        "body": "Hi Paul ! Wow you're super quick. I'm on MacOS terminal.app and using zsh - it is lightly themed with a popular theme-ing framework named oh-my-zsh\r\nI did disable it to isolate whether it was the issue, and the results are not totally conclusive. On thee one hand the frequency of the issue seems to considerably diminish but it still does occur randomly. Hope this helps. fyi, since reporting this I am now using 0.59.1\r\nwhat's not clear is if the duplication is somehow being counted in the calculation of cost ?\r\nthanks and good luck"
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-10-07T19:46:17Z",
        "body": "I have only seen this happen if you resize the terminal in the middle of a streaming LLM response. In that situation it's just a display issue with no impact on token costs."
      },
      {
        "user": "wissamharoun",
        "created_at": "2024-10-07T21:59:20Z",
        "body": "i'll keep an eye on it and  drop in again if/when I can reliably recreate it. thanks again for your support"
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-10-07T22:00:00Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open. Or feel free to file a new issue any time."
      },
      {
        "user": "wissamharoun",
        "created_at": "2024-10-08T14:27:01Z",
        "body": "Paul - another observation possibly helpful. I find that when I'm using gemini or anthropic models (while using the exact same prompt, in the same terminal window, with the same size... both produce the same issue, however, when I use  openAI's --4o model within the same window (size, etc.) and the same prompt - the line duplication does not occur. Reproduced it every time.."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-10-21T16:52:48Z",
        "body": "Aider doesn't render text differently to the terminal based on which LLM model is active.\r\n\r\nThe only thing I can conclude is there's something unusual/broken in your terminal environment. I would suggest trying `--no-pretty`."
      },
      {
        "user": "github-actions[bot]",
        "created_at": "2024-11-05T02:02:42Z",
        "body": "This issue has been labelled stale because it has been open for 2 weeks with no activity. Remove stale label or add a comment to keep this issue open. Otherwise, it will be closed in 7 days."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-11-12T18:27:24Z",
        "body": "I'm closing this issue because it has been stalled for 3 weeks with no activity. Feel free to add a comment here and we can re-open it. Or feel free to file a new issue at any time."
      }
    ]
  },
  {
    "number": 1490,
    "title": "Unexpected error: litellm.AuthenticationError: AnthropicException - b'{\"type\":\"error\",\"error\":",
    "created_at": "2024-09-11T13:11:25Z",
    "closed_at": "2024-09-20T19:01:18Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1490",
    "body": "I think I used the wrong API Key in my .env file, and this happened. This may be expected behavior but I hadn't seen it. It's an issue with litellm, not aider specifically, but I assumed aider should handle this behind the scenes.\r\n\r\nUnexpected error: litellm.AuthenticationError: AnthropicException - b'{\"type\":\"error\",\"error\":{\"type\":\"authentication_error\",\"message\":\"invalid \r\nx-api-key\"}}'\r\nTraceback (most recent call last):\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/litellm/utils.py\", line 10486, in __next__\r\n    self.fetch_sync_stream()\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/litellm/utils.py\", line 10591, in fetch_sync_stream\r\n    self.completion_stream = self.make_call(client=litellm.module_level_client)\r\n                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/litellm/llms/anthropic.py\", line 659, in make_sync_call\r\n    raise AnthropicError(status_code=response.status_code, message=response.read())\r\nlitellm.llms.anthropic.AnthropicError: b'{\"type\":\"error\",\"error\":{\"type\":\"authentication_error\",\"message\":\"invalid x-api-key\"}}'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/aider/coders/base_coder.py\", line 1124, in send_message\r\n    yield from self.send(messages, functions=self.functions)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/aider/coders/base_coder.py\", line 1408, in send\r\n    yield from self.show_send_output_stream(completion)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/aider/coders/base_coder.py\", line 1482, in \r\nshow_send_output_stream\r\n    for chunk in completion:\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/litellm/utils.py\", line 10582, in __next__\r\n    raise exception_type(\r\n          ^^^^^^^^^^^^^^^\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/litellm/utils.py\", line 8438, in exception_type\r\n    raise e\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/litellm/utils.py\", line 6894, in exception_type\r\n    raise AuthenticationError(\r\nlitellm.exceptions.AuthenticationError: litellm.AuthenticationError: AnthropicException - \r\nb'{\"type\":\"error\",\"error\":{\"type\":\"authentication_error\",\"message\":\"invalid x-api-key\"}}'\r\n\r\nAider version: 0.56.0\r\nPython version: 3.11.2\r\nPlatform: macOS-11.7.10-x86_64-i386-64bit\r\nPython implementation: CPython\r\nVirtual environment: No\r\nOS: Darwin 20.6.0 (64bit)\r\nGit version: git version 2.24.3 (Apple Git-128)\r\n\r\nAider v0.56.0\r\nMain model: claude-3-5-sonnet-20240620 with diff edit format, infinite output\r\nWeak model: claude-3-haiku-20240307\r\nGit repo: .git with 783 files\r\nRepo-map: using 1024 tokens, auto refresh\r\n\r\n",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1490/comments",
    "author": "acquirk",
    "comments": [
      {
        "user": "fry69",
        "created_at": "2024-09-11T13:18:27Z",
        "body": "Start aider with `--verbose` and see if it loads the correct authentication information.\r\n\r\nYou can also use `/settings` inside aider to see the current setup."
      },
      {
        "user": "emincangencer",
        "created_at": "2024-09-12T07:54:36Z",
        "body": "a similar thing happens with ollama.\r\n\r\nollama\r\nt=2024-09-12T07:43:47+0000 lvl=info msg=\"join connections\" obj=join\r\n\r\naider:\r\n\r\n~/dev$ aider --verbose --model ollama/llama3.1\r\nConfig files search order, if no --config:\r\n  - /home/emincan/dev/.aider.conf.yml\r\n  - /home/emincan/.aider.conf.yml\r\n────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\nToo soon to check version: 0.4 hours\r\nCommand Line Args:   --verbose --model ollama/llama3.1\r\nDefaults:\r\n  --model-settings-file:.aider.model.settings.yml\r\n  --model-metadata-file:.aider.model.metadata.json\r\n  --map-refresh:     auto\r\n  --cache-keepalive-pings:0\r\n  --map-multiplier-no-files:2\r\n  --env-file:        /home/emincan/dev/.env\r\n  --input-history-file:/home/emincan/dev/.aider.input.history\r\n  --chat-history-file:/home/emincan/dev/.aider.chat.history.md\r\n  --user-input-color:#00cc00\r\n  --tool-error-color:#FF2222\r\n  --tool-warning-color:#FFA500\r\n  --assistant-output-color:#0088ff\r\n  --code-theme:      default\r\n  --aiderignore:     /home/emincan/dev/.aiderignore\r\n  --lint-cmd:        []\r\n  --test-cmd:        []\r\n  --voice-language:  en\r\n  --encoding:        utf-8\r\n\r\nOption settings:\r\n  - aiderignore: /home/emincan/dev/.aiderignore\r\n  - anthropic_api_key: None\r\n  - apply: None\r\n  - assistant_output_color: #0088ff\r\n  - attribute_author: True\r\n  - attribute_commit_message_author: False\r\n  - attribute_commit_message_committer: False\r\n  - attribute_committer: True\r\n  - auto_commits: True\r\n  - auto_lint: True\r\n  - auto_test: False\r\n  - cache_keepalive_pings: 0\r\n  - cache_prompts: False\r\n  - chat_history_file: /home/emincan/dev/.aider.chat.history.md\r\n  - chat_language: None\r\n  - check_update: True\r\n  - code_theme: default\r\n  - commit: False\r\n  - commit_prompt: None\r\n  - config: None\r\n  - dark_mode: False\r\n  - dirty_commits: True\r\n  - dry_run: False\r\n  - edit_format: None\r\n  - encoding: utf-8\r\n  - env_file: /home/emincan/dev/.env\r\n  - exit: False\r\n  - file: None\r\n  - files: []\r\n  - git: True\r\n  - gitignore: True\r\n  - gui: False\r\n  - input_history_file: /home/emincan/dev/.aider.input.history\r\n  - install_main_branch: False\r\n  - just_check_update: False\r\n  - light_mode: False\r\n  - lint: False\r\n  - lint_cmd: []\r\n  - list_models: None\r\n  - llm_history_file: None\r\n  - map_multiplier_no_files: 2\r\n  - map_refresh: auto\r\n  - map_tokens: None\r\n  - max_chat_history_tokens: None\r\n  - message: None\r\n  - message_file: None\r\n  - model: ollama/llama3.1\r\n  - model_metadata_file: .aider.model.metadata.json\r\n  - model_settings_file: .aider.model.settings.yml\r\n  - openai_api_base: None\r\n  - openai_api_deployment_id: None\r\n  - openai_api_key: None\r\n  - openai_api_type: None\r\n  - openai_api_version: None\r\n  - openai_organization_id: None\r\n  - pretty: True\r\n  - read: None\r\n  - restore_chat_history: False\r\n  - show_diffs: False\r\n  - show_model_warnings: True\r\n  - show_prompts: False\r\n  - show_repo_map: False\r\n  - stream: True\r\n  - subtree_only: False\r\n  - suggest_shell_commands: True\r\n  - test: False\r\n  - test_cmd: []\r\n  - tool_error_color: #FF2222\r\n  - tool_output_color: None\r\n  - tool_warning_color: #FFA500\r\n  - upgrade: False\r\n  - user_input_color: #00cc00\r\n  - verbose: True\r\n  - verify_ssl: True\r\n  - vim: False\r\n  - voice_language: en\r\n  - weak_model: None\r\n  - yes: None\r\n\r\nChecking imports for version 0.56.0 and executable /usr/bin/python3\r\nInstalls file: /home/emincan/.aider/installs.json\r\nInstalls file exists and loaded\r\nNot first run, loading imports in background thread\r\nNo model settings files loaded\r\nSearched for model settings files:\r\n  - /home/emincan/.aider.model.settings.yml\r\n  - /home/emincan/dev/.aider.model.settings.yml\r\nModel info:\r\n{\r\n    \"max_tokens\": 32768,\r\n    \"max_input_tokens\": 8192,\r\n    \"max_output_tokens\": 8192,\r\n    \"input_cost_per_token\": 0.0,\r\n    \"output_cost_per_token\": 0.0,\r\n    \"litellm_provider\": \"ollama\",\r\n    \"mode\": \"chat\",\r\n    \"supports_function_calling\": true\r\n}\r\nAider v0.56.0\r\nModel: ollama/llama3.1 with whole edit format\r\nGit repo: .git with 0 files\r\nRepo-map: disabled\r\nUse /help <question> for help, run \"aider --help\" to see cmd line args\r\n────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n> create a snake game in python\r\n\r\n\r\nSYSTEM Act as an expert software developer.\r\nSYSTEM Take requests for changes to the supplied code.\r\nSYSTEM If the request is ambiguous, ask questions.\r\nSYSTEM\r\nSYSTEM Always reply to the user in the same language they are using.\r\nSYSTEM\r\nSYSTEM\r\nSYSTEM Once you understand the request you MUST:\r\nSYSTEM 1. Determine if any code changes are needed.\r\nSYSTEM 2. Explain any needed changes.\r\nSYSTEM 3. If changes are needed, output a copy of each file that needs changes.\r\nSYSTEM\r\nSYSTEM To suggest changes to a file you MUST return the entire content of the updated file.\r\nSYSTEM You MUST use this *file listing* format:\r\nSYSTEM\r\nSYSTEM path/to/filename.js\r\nSYSTEM ```\r\nSYSTEM // entire file content ...\r\nSYSTEM // ... goes in between\r\nSYSTEM ```\r\nSYSTEM\r\nSYSTEM Every *file listing* MUST use this format:\r\nSYSTEM - First line: the filename with any originally provided path\r\nSYSTEM - Second line: opening ```\r\nSYSTEM - ... entire content of the file ...\r\nSYSTEM - Final line: closing ```\r\nSYSTEM\r\nSYSTEM To suggest changes to a file you MUST return a *file listing* that contains the entire content of the file.\r\nSYSTEM *NEVER* skip, omit or elide content from a *file listing* using \"...\" or by adding comments like \"... rest of code...\"!\r\nSYSTEM Create a new file you MUST return a *file listing* which includes an appropriate filename, including any appropriate path.\r\nSYSTEM\r\nSYSTEM\r\n\r\nUSER Change the greeting to be more casual\r\n\r\nASSISTANT Ok, I will:\r\nASSISTANT\r\nASSISTANT 1. Switch the greeting text from \"Hello\" to \"Hey\".\r\nASSISTANT\r\nASSISTANT show_greeting.py\r\nASSISTANT ```\r\nASSISTANT import sys\r\nASSISTANT\r\nASSISTANT def greeting(name):\r\nASSISTANT     print(f\"Hey {name}\")\r\nASSISTANT\r\nASSISTANT if __name__ == '__main__':\r\nASSISTANT     greeting(sys.argv[1])\r\nASSISTANT ```\r\n\r\nUSER I switched to a new code base. Please don't consider the above files or try to edit them any longer.\r\n\r\nASSISTANT Ok.\r\n\r\nUSER I am not sharing any files that you can edit yet.\r\n\r\nASSISTANT Ok.\r\n\r\nUSER create a snake game in python\r\nUSER\r\nUSER To suggest changes to a file you MUST return the entire content of the updated file.\r\nUSER You MUST use this *file listing* format:\r\nUSER\r\nUSER path/to/filename.js\r\nUSER ```\r\nUSER // entire file content ...\r\nUSER // ... goes in between\r\nUSER ```\r\nUSER\r\nUSER Every *file listing* MUST use this format:\r\nUSER - First line: the filename with any originally provided path\r\nUSER - Second line: opening ```\r\nUSER - ... entire content of the file ...\r\nUSER - Final line: closing ```\r\nUSER\r\nUSER To suggest changes to a file you MUST return a *file listing* that contains the entire content of the file.\r\nUSER *NEVER* skip, omit or elide content from a *file listing* using \"...\" or by adding comments like \"... rest of code...\"!\r\nUSER Create a new file you MUST return a *file listing* which includes an appropriate filename, including any appropriate path.\r\nUSER\r\nUSER\r\nUnexpected error: b''\r\nTraceback (most recent call last):\r\n  File \"/home/emincan/.local/lib/python3.10/site-packages/aider/coders/base_coder.py\", line 1124, in send_message\r\n    yield from self.send(messages, functions=self.functions)\r\n  File \"/home/emincan/.local/lib/python3.10/site-packages/aider/coders/base_coder.py\", line 1408, in send\r\n    yield from self.show_send_output_stream(completion)\r\n  File \"/home/emincan/.local/lib/python3.10/site-packages/aider/coders/base_coder.py\", line 1482, in\r\nshow_send_output_stream\r\n    for chunk in completion:\r\n  File \"/home/emincan/.local/lib/python3.10/site-packages/litellm/llms/ollama.py\", line 371, in ollama_completion_stream\r\n    raise e\r\n  File \"/home/emincan/.local/lib/python3.10/site-packages/litellm/llms/ollama.py\", line 329, in ollama_completion_stream\r\n    raise OllamaError(\r\nlitellm.llms.ollama.OllamaError: b''\r\n"
      },
      {
        "user": "fry69",
        "created_at": "2024-09-12T08:05:17Z",
        "body": "@emincangencer \r\n\r\n> a similar thing happens with ollama.\r\n\r\nThank you for your initiative, but the original issue is about an authentication error with Anthropic API, your issue seems completely unrelated.\r\n\r\nPlease make a separate issue for your problem (and please remove your post above from this issue).\r\n\r\nThank you."
      },
      {
        "user": "emincangencer",
        "created_at": "2024-09-12T09:19:15Z",
        "body": "> your issue seems completely unrelated\r\n\r\nI thought it was a dependency issue and that was why I sent it here. And seems like it was in my case. I did force reinstall on the dependencies even though they were fine, including litellm==1.44.7. This solved the issue.\r\n\r\nHow should I proceed now?"
      },
      {
        "user": "fry69",
        "created_at": "2024-09-12T09:20:47Z",
        "body": "@emincangencer \r\n\r\n> How should I proceed now?\r\n \r\nPlease don't hijack other issues. Move your problem to a separate issue you own.\r\n\r\nThank you."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-09-20T19:01:18Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open. Or feel free to file a new issue any time."
      }
    ]
  },
  {
    "number": 1488,
    "title": "Question:shell command usage in coder base class",
    "created_at": "2024-09-11T12:53:16Z",
    "closed_at": "2024-10-07T19:57:46Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1488",
    "body": "### Issue\n\nHi @paul-gauthier and team,\r\n\r\nI am extending the coder base class where I pass the src files and the task  and when there is a package to be installed ,eg npm install redux which is suggested based on the task ,the package is installed in the directory where the code base class is used instead of the src file path(where the actual project source resides).\r\n\r\n\r\nhow to approach this ,any suggestion.\r\n\r\nsame with git commands and /run also.\r\n\r\ninstead of taking the currenty directory,it would consider the src file directory given in the coder class.\n\n### Version and model info\n\n_No response_",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1488/comments",
    "author": "chockalinga",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-09-11T21:51:20Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nSorry, I'm not sure I understand your question. Can you explain more?"
      },
      {
        "user": "chockalinga",
        "created_at": "2024-09-12T10:39:39Z",
        "body": "hi @paul-gauthier \r\n\r\nthanks for the reply ,I am trying to use create method of the coder class in my code like below where I pass task and set of files .\r\n\r\ncoder = Coder.create(\r\n            main_model=model,\r\n            fnames=files_to_update,\r\n            auto_commits=False,\r\n            io=io,\r\n            auto_lint=False,\r\n        )\r\n        coder.run(self.task)\r\n        \r\nThe issue is while I try to use /run or while aider suggest to install packages eg redux while executing the task ,it install in the folder where the coder method is called rather than in the src of the files ."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-09-20T19:00:34Z",
        "body": "You can use `os.chdir()` to change to the correct dir before you invoke `coder.run()`."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-10-07T19:57:46Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open. Or feel free to file a new issue any time."
      }
    ]
  },
  {
    "number": 1486,
    "title": "Uncaught TypeError in pathlib.py line 373",
    "created_at": "2024-09-11T04:00:59Z",
    "closed_at": "2024-09-12T06:26:36Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1486",
    "body": "\r\n\r\nAider version: 0.55.0\r\nPython version: 3.12.5\r\nPlatform: macOS-14.6.1-arm64-arm-64bit\r\nPython implementation: CPython\r\nVirtual environment: Yes\r\nOS: Darwin 23.6.0 (64bit)\r\nGit version: git version 2.46.0\r\n\r\nAn uncaught exception occurred:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"aider\", line 8, in <module>\r\n    sys.exit(main())\r\n             ^^^^^^\r\n  File \"main.py\", line 452, in main\r\n    right_repo_root = guessed_wrong_repo(io, git_root, fnames, git_dname)\r\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"main.py\", line 40, in guessed_wrong_repo\r\n    check_repo = Path(GitRepo(io, fnames, git_dname).root).resolve()\r\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"repo.py\", line 85, in __init__\r\n    self.root = utils.safe_abs_path(self.repo.working_tree_dir)\r\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"utils.py\", line 99, in safe_abs_path\r\n    res = Path(res).resolve()\r\n          ^^^^^^^^^\r\n  File \"pathlib.py\", line 1162, in __init__\r\n    super().__init__(*args)\r\n  File \"pathlib.py\", line 373, in __init__\r\n    raise TypeError(\r\nTypeError: argument should be a str or an os.PathLike object where __fspath__ returns a str, not 'NoneType'\r\n\r\n```\r\n\r\n% git status\r\nfatal: this operation must be run in a work tree\r\n\r\nNot sure what the cause of this is...\r\n\r\nrunning git init in the directory works.",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1486/comments",
    "author": "brooksc",
    "comments": [
      {
        "user": "brooksc",
        "created_at": "2024-09-11T04:01:32Z",
        "body": "repros with Aider version: 0.56.0"
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-09-11T21:37:52Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nYour git repo seems broken or corrupted. Maybe start a new repo with `git init` ?"
      },
      {
        "user": "brooksc",
        "created_at": "2024-09-12T06:26:32Z",
        "body": "Thanks Paul -- the odd thing is when I did a \"git init\" in the new directory I created, aider worked fine.  \r\nIf I did a \"rm -rf .git\" then rain aider it threw the error.\r\nI know Aider will prompt to do a git init...\r\n\r\nOne time I did accidentally do a git init in ~ but I did a rm -rf ~/.git to get rid of it.  \r\n\r\nI just tried doing the following\r\nmkdir foo\r\ncd foo\r\n\r\n... and then ...\r\n\r\n% git rev-parse --show-toplevel\r\nfatal: this operation must be run in a work tree\r\n% aider --deepseek --dark-mode --vim --yes --check-update\r\n\r\n# Uncaught TypeError in pathlib.py line 373\r\n\r\nAnd it throws the same error.\r\n\r\n... I realize this is probably user error somehow so fine to close this out.  "
      }
    ]
  },
  {
    "number": 1461,
    "title": "Feature Proposal: `/block` Command to Prevent Repeated File Addition Prompts",
    "created_at": "2024-09-10T02:51:16Z",
    "closed_at": "2024-09-11T15:26:04Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1461",
    "body": "### Issue\r\n\r\n#### Problem:\r\n\r\nWhen working with large codebases, especially in a multi-directory setup, `aider` often suggests adding files from various locations in the workspace that aren’t relevant to the task at hand. For example, when troubleshooting a `requirements.txt` issue in the root directory, `aider` might repeatedly prompt the user to add similarly named files from different subdirectories (e.g., `tests/localstack/example/requirements.txt`), which can be frustrating.\r\n\r\nExample of the issue:\r\n\r\n```text\r\nAdd pulumi_lib/tests/localstack/example/requirements.txt to the chat? (Y)es/(N)o\r\n [Yes]: n\r\n```\r\n\r\nThis prompt appears multiple times, despite the user already specifying not to add it. Constantly declining these prompts interrupts the flow of work.\r\n\r\n#### Proposed Solution:\r\n\r\nIntroduce a new in-chat command, `/block` or `/block-add`, which allows the user to block specific files or file patterns from being suggested for addition in the future. This block should:\r\n- Work with file names and patterns (supporting regex).\r\n- Only affect files that haven’t been added yet (won’t remove files that are already part of the session).\r\n- Allow for easy unblocking through either the `/drop` command or a new `/drop-block` command.\r\n\r\n#### Command Usage:\r\n\r\nEither of the following could be a good way to implement the command usage or perhaps something different.\r\n\r\n- **/block [file_path_or_pattern]**: Blocks files matching the specified name or pattern from being suggested for addition.\r\n- **/drop-block [file_path_or_pattern]**: Unblocks files matching the specified pattern, allowing them to be suggested for addition again.\r\n  \r\nBy incorporating regex support, this allows users to easily block entire sets of files that follow a particular pattern (e.g., all `tests/requirements.txt` files).\r\n\r\n### Extended Feature Proposal: `/block-cmd` Command to Prevent Repeated Command Suggestions\r\n\r\n#### Problem:\r\n\r\nIn addition to unwanted file addition prompts, `aider` can also suggest commands that may not be relevant or useful for the current context. Repeatedly declining these suggestions can disrupt the user's workflow.\r\n\r\nFor example, if `aider` frequently suggests commands that you don’t need or want to run, it can cause unnecessary distractions, similar to the file addition issue.\r\n\r\n#### Proposed Solution:\r\n\r\nExtend the blocking functionality to command suggestions with a new in-chat command called `/block-cmd`. This command would allow users to block specific commands (or command patterns) from being suggested by `aider`. This could be particularly useful when `aider` frequently suggests commands that are not relevant to the current task.\r\n\r\n#### Command Usage:\r\n\r\n- **/block-cmd [command_pattern]**: Blocks commands matching the specified pattern (supports regex) from being suggested during the session.\r\n- **/drop-cmd [command_pattern]**: Unblocks commands matching the specified pattern, allowing them to be suggested again.\r\n\r\n#### Example use case:\r\n\r\nLet's say you're working on an Infrastructure as Code repo. And you would prefer that Aider never suggest a command that would cause the changes to happen yet. Like a `pulumi up`. Obviously, in this case you should be taking other precautions as well but its nice to have a bit more help.\r\n\r\n### Version and model info\r\n\r\n_No response_",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1461/comments",
    "author": "GeoffMillerAZ",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-09-10T03:13:43Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nThe latest version of aider will remember if you say not to add a file. It won't ask about that file again during the session. "
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-09-11T15:26:04Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open. Or feel free to file a new issue any time."
      },
      {
        "user": "GeoffMillerAZ",
        "created_at": "2024-09-15T21:19:13Z",
        "body": "Cool! I think that works!!"
      }
    ]
  },
  {
    "number": 1438,
    "title": "Feature request: Callback functionality",
    "created_at": "2024-09-08T21:14:53Z",
    "closed_at": "2024-09-20T18:59:00Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1438",
    "body": "### Feature request\r\n\r\nThe aider could invoke a callback script provided by the user for every LLM response.\r\n\r\nThanks to that, we can run many helpful automation like notifications on discord/slack/email, or even chaining aider based on previous generation. \r\n\r\nIt can be especially useful when aider will run on headless mode like CI/CD or vps\r\n\r\n\r\nProposed flag\r\n```\r\naider --calback \"python callback.py\"\r\naider --calback \"./callback.sh\"\r\n```\r\n\r\nFor debugging purposes to run callback without calling LLM we can use:\r\n```\r\naider --callback \"python callback.py\" --callback-debug\r\n```\r\n\r\n\r\n### Version and model info\r\n\r\n_No response_",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1438/comments",
    "author": "maledorak",
    "comments": [
      {
        "user": "maledorak",
        "created_at": "2024-09-08T21:22:56Z",
        "body": "I've already created my proposition for this feature. - #1439 \r\n\r\nCode and unit tests are done. The only documentation is left.\r\n\r\nYou can already test this callback feature on my branch using\r\n`python -m aider --callback 'scripts/callbacks/example_callback.py'`\r\nor \r\n`python -m aider --callback 'scripts/callbacks/example_callback.py' --callback-debug`\r\ncallback debug will run callback right away from `aider/main.py` without running base coder"
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-09-09T21:17:35Z",
        "body": "As I mentioned on discord, I'm not sure I understand the use case for this versus using the existing lint and test hooks?"
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-09-20T18:59:00Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open. Or feel free to file a new issue any time."
      }
    ]
  },
  {
    "number": 1408,
    "title": "# Uncaught UnicodeEncodeError in cp1252.py line 19  'charmap' codec can't encode character '\\u2588' in position 39: character maps to <undefined>",
    "created_at": "2024-09-07T12:32:10Z",
    "closed_at": "2024-09-10T18:40:14Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1408",
    "body": "### Issue\n\nWhen running aider with \"--yes --mesage ...\" this happens from time to time. The same prompt run in shell with same files in context works fine.\r\n\r\n# Uncaught UnicodeEncodeError in cp1252.py line 19\r\n\r\nAn uncaught exception occurred:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"runpy.py\", line 196, in _run_module_as_main\r\n    return _run_code(code, main_globals, None,\r\n  File \"runpy.py\", line 86, in _run_code\r\n    exec(code, run_globals)\r\n  File \"__main__.py\", line 7, in <module>\r\n    sys.exit(main())\r\n  File \"main.py\", line 667, in main\r\n    coder.run(with_message=args.message)\r\n  File \"base_coder.py\", line 724, in run\r\n    self.run_one(with_message, preproc)\r\n  File \"base_coder.py\", line 773, in run_one\r\n    list(self.send_message(message))\r\n  File \"base_coder.py\", line 1194, in send_message\r\n    lint_errors = self.lint_edited(edited)\r\n  File \"base_coder.py\", line 1296, in lint_edited\r\n    self.io.tool_warning(res)\r\n  File \"io.py\", line 545, in tool_warning\r\n    self._tool_message(message, strip, self.tool_warning_color)\r\n  File \"io.py\", line 538, in _tool_message\r\n    self.console.print(message, **style)\r\n  File \"console.py\", line 1683, in print\r\n    with self:\r\n  File \"console.py\", line 864, in __exit__\r\n    self._exit_buffer()\r\n  File \"console.py\", line 822, in _exit_buffer\r\n    self._check_buffer()\r\n  File \"console.py\", line 2024, in _check_buffer\r\n    self._write_buffer()\r\n  File \"console.py\", line 2060, in _write_buffer\r\n    legacy_windows_render(buffer, LegacyWindowsTerm(self.file))\r\n  File \"_windows_renderer.py\", line 19, in legacy_windows_render\r\n    term.write_text(text)\r\n  File \"_win32_console.py\", line 403, in write_text\r\n    self.write(text)\r\n  File \"cp1252.py\", line 19, in encode\r\n    return codecs.charmap_encode(input,self.errors,encoding_table)[0]\r\nUnicodeEncodeError: 'charmap' codec can't encode character '\\u2588' in position 39: character maps to <undefined>\r\n\n\n### Version and model info\n\nAider version: 0.55.0\r\nPython version: 3.10.0\r\nPlatform: Windows-10-10.0.19045-SP0\r\nPython implementation: CPython\r\nVirtual environment: Yes\r\nOS: Windows 10 (64bit)\r\nGit version: git version 2.45.2.windows.1\r\nModel: --sonnet",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1408/comments",
    "author": "p-wegner",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-09-09T20:50:00Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nYou can use `--encoding` to set the encoding for aider to use."
      },
      {
        "user": "p-wegner",
        "created_at": "2024-09-10T18:40:14Z",
        "body": "Fixed by setting the env variable PYTHONIOENCODING=utf-8"
      }
    ]
  },
  {
    "number": 1407,
    "title": "Uncaught ImportError in __init__.py line 78",
    "created_at": "2024-09-07T12:08:47Z",
    "closed_at": "2024-09-09T19:59:25Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1407",
    "body": "Aider version: 0.55.0\r\nPython version: 3.10.14\r\nPlatform: Linux-6.5.0-1025-gcp-x86_64-with-glibc2.39\r\nPython implementation: CPython\r\nVirtual environment: No\r\nOS: Linux 6.5.0-1025-gcp (64bit)\r\nGit version: git version 2.42.0\r\n\r\nAn uncaught exception occurred:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"base_coder.py\", line 1105, in send_message\r\n    yield from self.send(messages, functions=self.functions)\r\n  File \"base_coder.py\", line 1377, in send\r\n    hash_object, completion = send_completion(\r\n  File \"sendchat.py\", line 86, in send_completion\r\n    res = litellm.completion(**kwargs)\r\n  File \"llm.py\", line 23, in __getattr__\r\n    self._load_litellm()\r\n  File \"llm.py\", line 30, in _load_litellm\r\n    self._lazy_module = importlib.import_module(\"litellm\")\r\n  File \"__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\r\n  File \"__init__.py\", line 780, in <module>\r\n    from .cost_calculator import completion_cost\r\n  File \"cost_calculator.py\", line 24, in <module>\r\n    from litellm.utils import (\r\n  File \"utils.py\", line 53, in <module>\r\n    from tokenizers import Tokenizer\r\n  File \"__init__.py\", line 78, in <module>\r\n    from .tokenizers import (\r\nImportError: libstdc++.so.6: cannot open shared object file: No such file or directory\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"aider\", line 8, in <module>\r\n    sys.exit(main())\r\n  File \"main.py\", line 694, in main\r\n    coder.run()\r\n  File \"base_coder.py\", line 730, in run\r\n    self.run_one(user_message, preproc)\r\n  File \"base_coder.py\", line 773, in run_one\r\n    list(self.send_message(message))\r\n  File \"base_coder.py\", line 1107, in send_message\r\n    except retry_exceptions() as err:\r\n  File \"sendchat.py\", line 24, in retry_exceptions\r\n    litellm.exceptions.APIConnectionError,\r\n  File \"llm.py\", line 23, in __getattr__\r\n    self._load_litellm()\r\n  File \"llm.py\", line 30, in _load_litellm\r\n    self._lazy_module = importlib.import_module(\"litellm\")\r\n  File \"__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\r\n  File \"__init__.py\", line 780, in <module>\r\n    from .cost_calculator import completion_cost\r\n  File \"cost_calculator.py\", line 24, in <module>\r\n    from litellm.utils import (\r\n  File \"utils.py\", line 53, in <module>\r\n    from tokenizers import Tokenizer\r\n  File \"__init__.py\", line 78, in <module>\r\n    from .tokenizers import (\r\nImportError: libstdc++.so.6: cannot open shared object file: No such file or directory\r\n\r\n```",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1407/comments",
    "author": "will-prog",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-09-07T13:42:24Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nHow did you install aider? What environment are you using?\r\n\r\nIt looks like you don't have the correct set of dependencies installed.\n\nOn replit it may work better to do `pipx run aider-chat`"
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-09-09T19:59:25Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open. Or feel free to file a new issue any time."
      }
    ]
  },
  {
    "number": 1406,
    "title": "Uncaught APIError in utils.py line 6841",
    "created_at": "2024-09-07T09:36:37Z",
    "closed_at": "2024-09-09T23:40:17Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1406",
    "body": "Aider version: 0.55.0\r\nPython version: 3.12.2\r\nPlatform: macOS-14.3.1-arm64-arm-64bit\r\nPython implementation: CPython\r\nVirtual environment: No\r\nOS: Darwin 23.3.0 (64bit)\r\nGit version: git version 2.39.3 (Apple Git-146)\r\n\r\nAn uncaught exception occurred:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"openai.py\", line 1033, in completion\r\n    raise e\r\n  File \"openai.py\", line 959, in completion\r\n    stringified_response = response.model_dump()\r\n                           ^^^^^^^^^^^^^^^^^^^\r\nAttributeError: 'str' object has no attribute 'model_dump'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"main.py\", line 1345, in completion\r\n    raise e\r\n  File \"main.py\", line 1318, in completion\r\n    response = openai_chat_completions.completion(\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"openai.py\", line 1041, in completion\r\n    raise OpenAIError(status_code=500, message=traceback.format_exc())\r\nlitellm.llms.openai.OpenAIError: Traceback (most recent call last):\r\n  File \"openai.py\", line 1033, in completion\r\n    raise e\r\n  File \"openai.py\", line 959, in completion\r\n    stringified_response = response.model_dump()\r\n                           ^^^^^^^^^^^^^^^^^^^\r\nAttributeError: 'str' object has no attribute 'model_dump'\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"aider\", line 8, in <module>\r\n    sys.exit(main())\r\n             ^^^^^^\r\n  File \"main.py\", line 694, in main\r\n    coder.run()\r\n  File \"base_coder.py\", line 730, in run\r\n    self.run_one(user_message, preproc)\r\n  File \"base_coder.py\", line 773, in run_one\r\n    list(self.send_message(message))\r\n  File \"base_coder.py\", line 1183, in send_message\r\n    saved_message = self.auto_commit(edited)\r\n                    ^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"base_coder.py\", line 1863, in auto_commit\r\n    res = self.repo.commit(fnames=edited, context=context, aider_edits=True)\r\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"repo.py\", line 101, in commit\r\n    commit_message = self.get_commit_message(diffs, context)\r\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"repo.py\", line 186, in get_commit_message\r\n    commit_message = simple_send_with_retries(\r\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"sendchat.py\", line 44, in wrapper\r\n    return decorated_func(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"_sync.py\", line 105, in retry\r\n    ret = target(*args, **kwargs)\r\n          ^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"sendchat.py\", line 106, in simple_send_with_retries\r\n    _hash, response = send_completion(**kwargs)\r\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"sendchat.py\", line 86, in send_completion\r\n    res = litellm.completion(**kwargs)\r\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"utils.py\", line 1078, in wrapper\r\n    raise e\r\n  File \"utils.py\", line 966, in wrapper\r\n    result = original_function(*args, **kwargs)\r\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"main.py\", line 2766, in completion\r\n    raise exception_type(\r\n          ^^^^^^^^^^^^^^^\r\n  File \"utils.py\", line 8438, in exception_type\r\n    raise e\r\n  File \"utils.py\", line 6841, in exception_type\r\n    raise APIError(\r\nlitellm.exceptions.APIError: litellm.APIError: APIError: OpenAIException - Traceback (most recent call last):\r\n  File \"openai.py\", line 1033, in completion\r\n    raise e\r\n  File \"openai.py\", line 959, in completion\r\n    stringified_response = response.model_dump()\r\n                           ^^^^^^^^^^^^^^^^^^^\r\nAttributeError: 'str' object has no attribute 'model_dump'\r\n\r\n\r\n```",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1406/comments",
    "author": "mike-courian",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-09-09T20:24:31Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nWhat model were you using when this happened?"
      },
      {
        "user": "mike-courian",
        "created_at": "2024-09-09T23:15:44Z",
        "body": "Hi Paul,\r\n\r\nI'm a non-developer who is slowly being able to write more and more code using LLM's (so forgive any inaccuracies in this description below). Thanks heaps for responding to this (so grateful for all the work you do on Aider!)\r\n\r\nI'm using a custom setup with a private model that I call locally. The setup is quite convoluted and an edge case:\r\n\r\n1. Aider sends requests to a fixed Ngrok URL to tunnel into my localhost.\r\n2. The Aider API request is mapped to fit the request format required for my private model API and then sent off.\r\n3. The response is then passed back through and streamed to Aider.\r\n\r\nEssentially, it's like a \"man-in-the-middle\" API setup. The initial part of the process in Aider works perfectly (as if it was from a major provider's API), and all the code gets written as expected. However, when it reaches the stage of making the git commit, or something at the end of the Aider sequence of steps that is too advanced for me to understand, it gets caught in a loop of wanting to 'model_dump', which is missing from the response object.\r\n\r\n<AI generated>\r\nI think the issue stems from my custom API setup not providing a response object with a `model_dump()` method as Aider expects. I wonder if a small change in Aider could make it more robust for non-standard API responses (eg. implementing a function that safely handles various response types could prevent this error for other custom setups as well.)\r\n\r\nI'll also plan to implement a wrapper for my custom API response to try and resolve it on my end.\r\n</AI generated>\r\n\r\nLet me know if you need any additional information if you were going to make any adjustments to how Aider works.\r\n\r\nThanks again!"
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-09-09T23:40:09Z",
        "body": "This does seem likely to be caused by your custom api setup. Unfortunately it would be very difficult for me to help debug it. \n\n\nI'm going to close this issue for now, but feel free to add a comment here and I will re-open. Or feel free to file a new issue any time."
      }
    ]
  },
  {
    "number": 1401,
    "title": "Uncaught AttributeError in llm.py line 35",
    "created_at": "2024-09-06T21:58:54Z",
    "closed_at": "2024-09-06T22:14:27Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1401",
    "body": "Aider version: 0.55.0\r\nPython version: 3.12.5\r\nPlatform: Linux-6.10.7-arch1-1-x86_64-with-glibc2.40\r\nPython implementation: CPython\r\nVirtual environment: No\r\nOS: Linux 6.10.7-arch1-1 (64bit)\r\nGit version: git version 2.46.0\r\n\r\nAn uncaught exception occurred:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"aider\", line 8, in <module>\r\n    sys.exit(main())\r\n             ^^^^^^\r\n  File \"main.py\", line 510, in main\r\n    main_model = models.Model(args.model, weak_model=args.weak_model)\r\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"models.py\", line 486, in __init__\r\n    res = self.validate_environment()\r\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"models.py\", line 660, in validate_environment\r\n    res = litellm.validate_environment(model)\r\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"llm.py\", line 23, in __getattr__\r\n    self._load_litellm()\r\n  File \"llm.py\", line 35, in _load_litellm\r\n    self._lazy_module._logging._disable_debugging()\r\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nAttributeError: module 'litellm' has no attribute '_logging'. Did you mean: 'logging'?\r\n\r\n```",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1401/comments",
    "author": "GameMaster007",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-09-06T22:00:11Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nHow did you install aider? What environment are you using?\r\n\r\nIt looks like you don't have the correct set of dependencies installed."
      },
      {
        "user": "GameMaster007",
        "created_at": "2024-09-06T22:12:39Z",
        "body": "Hello,\r\n\r\nI fixed it turns out it was due to dependencies. Now it is fixed thanks 👍 \r\n\r\n"
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-09-06T22:14:27Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open or file a new issue any time."
      }
    ]
  },
  {
    "number": 1356,
    "title": "feature request: /undoall ",
    "created_at": "2024-09-05T01:42:08Z",
    "closed_at": "2024-09-11T15:37:46Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1356",
    "body": "### Issue\n\nWould be nice to have this feature, which would rewind back all changes made in the current chat session.  I sometimes find myself 15 prompts in, realising I won't be able to get the desired result, and I run undo many times to rewind it.\n\n### Version and model info\n\n_No response_",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1356/comments",
    "author": "glinkot",
    "comments": [
      {
        "user": "fry69",
        "created_at": "2024-09-05T09:16:35Z",
        "body": "You can achieve a similar outcome by creating git a fresh git branch when you start aider and switch back to the old one if you are not satisfied. E.g.\r\n- `/git switch -c <new-branch>`\r\n- `/git switch old-branch`\r\n\r\nYou can of course create and switch branches at any time, they are lightweight and create basically no overhead (other than filling up the available branch list). Delete a branch (when you are in a different branch) with\r\n- `/git branch -D <branch>`"
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-09-09T21:26:38Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nYes, for complex management of your git history aider expects you to do those changes yourself with git. I don't want users to be surprised by aider making large changes to their git history."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-09-11T15:37:46Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open. Or feel free to file a new issue any time."
      }
    ]
  },
  {
    "number": 1355,
    "title": "Feature Request: Support for Structured Questions and Responses in Scripted Aider Using Pydantic Models",
    "created_at": "2024-09-05T01:25:33Z",
    "closed_at": "2024-09-10T03:12:26Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1355",
    "body": "### Issue\n\n### Summary\r\n\r\nWhen using `aider` as part of a scripted or agentic workflow, it becomes important to have structured, reliable responses from the model to allow for programmatic flow control. This feature request suggests the addition of structured questions and guaranteed structured responses, leveraging models like GPT-4o that support Pydantic or Zod models. By exposing hooks for this within `aider`, it would allow scripts to interact with `aider` in a more deterministic and structured manner, driving automated processes with minimal human intervention.\r\n\r\n### Proposed Enhancement\r\n\r\n1. **Structured Questions Using Pydantic/Zod Models**:\r\n   - Allow `aider` to accept structured questions, where the response is guaranteed to follow a specific schema (e.g., JSON format using Pydantic or Zod models).\r\n   - This would enable `aider` to ask detailed questions about the code, workspace, or progress of the session and provide responses that can be consumed by the script controlling `aider`.\r\n   - Example: \r\n     ```python\r\n     {\r\n       \"response\": \"yes\",\r\n       \"confidence\": 0.97\r\n     }\r\n     ```\r\n\r\n2. **Scripted Aider Flow Control**:\r\n   - A script could ask a detailed question (e.g., about the state of the code, linting results, or following conventions) and get a structured response back.\r\n   - This structured response could then determine the next action, such as:\r\n     - Terminate the script if an error is found.\r\n     - Undo the last action.\r\n     - Pause and notify for human input.\r\n     - Attempt a backup prompt to address issues.\r\n\r\n3. **Configurable Model for Structured Questions**:\r\n   - Since only certain models like GPT-4o support structured responses with Pydantic/Zod models, there should be a configuration option for specifying the model to use when asking structured questions.\r\n   - This would allow users to ensure the correct model is used for reliable, structured output.\r\n\r\n### Use Case Example\r\n\r\n\r\nWhen dealing with large codebases, package upgrades often lead to breaking changes that require significant refactoring. One common scenario is the deprecation of methods from third-party libraries. For example, when a method is deprecated, developers need to replace every instance of it with a new method. This is further complicated when the new method requires additional arguments that were not needed in the deprecated version.\r\n\r\nManually identifying and refactoring code across hundreds of files can be tedious and error-prone. Automating this process allows developers to focus on higher-level tasks while ensuring consistency and correctness.\r\n\r\n#### How This Example Code Helps:\r\n\r\nThe provided script automates the process of identifying and fixing deprecated methods across all `.py` files in a directory. It uses `aider`'s `query_with_response_model` to scan each file for library imports and deprecated method usages. If found, it replaces the old method with the new one, adding any additional required arguments. Finally, it runs a linting step to ensure the code is correctly formatted and follows the required coding standards.\r\n\r\nThis approach can save significant time in large refactorings, minimize human error, and ensure that all instances of the deprecated method are updated consistently.\r\n\r\n#### Simple Explanation of the Logic:\r\n\r\n1. **Loop through all Python files**: The script scans each `.py` file in the directory.\r\n2. **Check for library import**: If the file imports the library in question, continue. Otherwise, skip to the next file.\r\n3. **Find deprecated method usages**: If the library is imported, the script identifies every usage of the deprecated method.\r\n4. **Fix the deprecated method**: For each finding, the script instructs `aider` to replace the deprecated method with the new method and add the necessary argument.\r\n5. **Lint the code**: After processing all files, the script runs a lint check to ensure that the changes adhere to the project’s style guide.\r\n\r\n#### Pseudocode:\r\n\r\n```text\r\nFor each .py file in the directory:\r\n  Add the file to aider's session\r\n  Ask aider: Does this file import the required library?\r\n  If no:\r\n    Drop the file and continue to the next one\r\n  If yes:\r\n    Ask aider: Find all instances of the deprecated method\r\n    For each usage found:\r\n      Ask aider to replace the deprecated method with the new one\r\n      Add the necessary arguments to the new method\r\n    Drop the file after processing\r\nRun a lint check to verify the code quality\r\n```\r\n\r\n#### Example of how the aider script could look\r\n\r\n```\r\nfrom aider.coders import Coder\r\nfrom aider.models import Model\r\nfrom pydantic import BaseModel, Field\r\nfrom typing import List\r\nimport glob\r\n\r\n# Pydantic model for yes/no response with confidence score\r\nclass BinaryResponse(BaseModel):\r\n  response: str  # Either \"yes\" or \"no\"\r\n  confidence: float = Field(..., ge=0.0, le=1.0)  # Confidence score between 0 and 1\r\n\r\n# Pydantic model for findings in the code\r\nclass CodeFinding(BaseModel):\r\n  finding: str  # The deprecated method name\r\n  line_number: int  # The line number where it was found\r\n  context: str  # A snippet or brief context of the finding\r\n\r\nclass CodeFindings(BaseModel):\r\n  findings: List[CodeFinding]\r\n\r\n# Initialize aider with a model and the files to work on\r\nmodel = Model(\"gpt-4-turbo\")\r\nfnames = glob.glob(\"*.py\")  # Find all .py files in the directory\r\n\r\ncoder = Coder.create(main_model=model, fnames=fnames)\r\n\r\n# Define the deprecated method and the new method name\r\ndeprecated_method = \"old_method\"\r\nnew_method = \"new_method\"\r\nnew_argument = \"'required_arg'\"\r\n\r\n# Loop over all Python files in the directory\r\nfor fname in fnames:\r\n  # Add the file to the coding session\r\n  coder.run(f\"/add {fname}\")\r\n\r\n  # Check if the file imports the library in question\r\n  query_import = f\"Does the file {fname} import the library 'library_name'?\"\r\n  import_response = coder.query_with_response_model(query=query_import, response_model=BinaryResponse)\r\n\r\n  # If the file doesn't import the library, drop it from the session and continue\r\n  if import_response.response == \"no\":\r\n    coder.run(f\"/drop {fname}\")\r\n    continue\r\n\r\n  # If the file imports the library, check for uses of the deprecated method\r\n  query_deprecated = f\"Find all instances of '{deprecated_method}' being used in the file {fname}.\"\r\n  findings_response = coder.query_with_response_model(query=query_deprecated, response_model=CodeFindings)\r\n\r\n  # Loop over all findings and instruct aider to fix each instance\r\n  for finding in findings_response.findings:\r\n    line_number = finding.line_number\r\n    context = finding.context\r\n\r\n    # Instruct aider to replace the deprecated method with the new method, adding the new argument\r\n    prompt = (f\"On line {line_number}, replace the usage of '{deprecated_method}' \"\r\n              f\"with '{new_method}', and add the required argument {new_argument}. \"\r\n              f\"Here is the context: {context}\")\r\n    \r\n    coder.run(prompt)\r\n\r\n  # Drop the file from the coding session after processing\r\n  coder.run(f\"/drop {fname}\")\r\n\r\n# After processing all files, run linting\r\ncoder.run(\"/lint\")\r\n```\r\n\r\n4. **Natural Language as Unit Test**:\r\n   - This structured question/response model could also serve as the basis for natural language-driven unit tests.\r\n   - Example: Auto-test by prompting `aider` to check if code follows naming conventions, and receiving structured JSON feedback on test results.\r\n   \r\n   For instance:\r\n```json\r\n{\r\n  \"unit_tests\": [\r\n    {\r\n      \"test_name\": \"Variable Naming Clarity\",\r\n      \"input_code\": \"int tmp = 5;\",\r\n      \"expected_result\": \"fail\",\r\n      \"actual_result\": \"fail\",\r\n      \"metadata\": {\r\n        \"issue\": \"Variable name 'tmp' is not clear\",\r\n        \"suggestions\": [\r\n          \"Use a more descriptive name, e.g., 'tempValue' or 'temporaryCounter'.\"\r\n        ],\r\n        \"severity\": \"medium\"\r\n      }\r\n    },\r\n    {\r\n      \"test_name\": \"Casing Convention - Camel Case\",\r\n      \"input_code\": \"int TempValue = 10;\",\r\n      \"expected_result\": \"fail\",\r\n      \"actual_result\": \"fail\",\r\n      \"metadata\": {\r\n        \"issue\": \"Variable 'TempValue' does not follow camelCase convention.\",\r\n        \"suggestions\": [\r\n          \"Rename the variable to 'tempValue' to match the camelCase convention.\"\r\n        ],\r\n        \"severity\": \"low\"\r\n      }\r\n    }\r\n  ]\r\n}\r\n```\r\n\r\n5. **Pre-Built Pydantic Models for Common Queries**:\r\n   - Include pre-built models for common structured queries such as simple yes/no responses or error reports.\r\n   - Example: A Pydantic model for yes/no questions that also returns a confidence score.\r\n   \r\n   Example:\r\n```python\r\nfrom pydantic import BaseModel\r\n\r\nclass ResponseModel(BaseModel):\r\n    response: str\r\n    confidence: float\r\n```\r\n\r\n   This allows for rapid integration of `aider` into larger workflows where decisions can be made based on the model's structured responses, improving automation.\r\n\r\n### Benefits\r\n\r\n- **Enhanced Automation**: Allowing `aider` to interact programmatically with a script by providing structured responses ensures greater automation without human intervention.\r\n- **Flow Control**: Enables detailed control of the program’s flow based on reliable, structured data, e.g., undo actions, retry prompts, or awaiting human intervention based on the returned result.\r\n- **Structured Unit Tests**: Enables natural language-driven unit testing, where results are returned in a structured format that `aider` can then use to drive subsequent actions.\r\n- **Reduced Duplication of Effort**: Instead of building a separate agent to manage this functionality, this enhancement would leverage `aider`'s existing understanding of the codebase and workspace for more effective integration into workflows.\r\n\r\n### Conclusion\r\n\r\nThis feature would greatly enhance `aider`'s usability in automated workflows, agentic processes, and scripting, by providing structured responses that can guide the flow of execution based on the content and feedback received.\r\n\n\n### Version and model info\n\n_No response_",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1355/comments",
    "author": "GeoffMillerAZ",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-09-09T21:29:41Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nThis seems out of scope for aider."
      },
      {
        "user": "GeoffMillerAZ",
        "created_at": "2024-09-10T02:28:56Z",
        "body": "I understand. Aider lets you chat with your code, and it lets you script Aider. This feature would be needed to let your scripting chat with your code. You need predictable, machine-readable responses to do that, and Aider is already great at chatting with your code -- just not in a scripted manner."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-09-10T03:12:23Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open. Or feel free to file a new issue any time."
      }
    ]
  },
  {
    "number": 1354,
    "title": "Possible Time-&-Token-Saving Search & Replace Idea...",
    "created_at": "2024-09-05T00:27:37Z",
    "closed_at": "2024-09-10T19:39:49Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1354",
    "body": "### Issue\n\nHi there,\r\n\r\nI love Aider (with Sonnet - OpenAI was always such a moody grouch), and thought I'd see if this floats your boat:\r\n\r\nAider uses a lot of tokens on search and replace.  And if/when it gets it wrong then you can just watch the token count (and the $ count!) go up and up, and it takes a fair amount of time.\r\n\r\nI was thinking of this as a potential alternative to the current S&R:  1st line of text in block, last line of text in block, and a checksum.\r\nI was thinking that the checksum could be the character count, or the sum of the ascii character codes (!!) or something (the world could be your oyster there I guess), but the problem we all know is that the AI isn't great as an LLM at counting.  The checksum only really needs to be there if there is more than one section of code that it could refer to (hopefully anyways), but in those cases, and with the LLM being bad at numbers, then there could be a background API call that essentially asks it 'is this the code you're looking for, or this one?'.  Being able to programmatically 'copy/paste' that in a call, and get a yes/no answer should be far faster than the LLM writing out big chunks of code, sometimes multiple times before it gets it right. Ingested tokens are also a lot cheaper than output.\r\n\r\nI expect that you've already tried or thought about something similar, and the current S&R is the most bullet-proof, but perhaps there's a flag I could tick to select fast S&R or slow S&R, and deal with the consequences.\r\n\r\nFWIW I did try to get Aider to help me do an mvp of that in the source-code, but while we could make the flag work (/fast), we couldn't figure out how the S&R integrated into the whole.  I'd be happy to have a play around and see what works if only I knew that....FWIW\r\n\r\nAnyway, it's not much, but hopefully it's _something_\r\n\r\nLove 'n' lard\r\nThe Captain\n\n### Version and model info\n\n_No response_",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1354/comments",
    "author": "Captain-Bacon",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-09-09T21:30:12Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nI've tried things like this and unfortunately they don't work well with most models."
      },
      {
        "user": "Captain-Bacon",
        "created_at": "2024-09-10T19:39:49Z",
        "body": "Thanks so much for the reply - I thought you might have already gone there a million times, but it was an itch I had to scratch, so I appreciate it."
      }
    ]
  },
  {
    "number": 1345,
    "title": "Uncaught NoConsoleScreenBufferError in win32.py line 219",
    "created_at": "2024-09-04T14:25:44Z",
    "closed_at": "2024-09-09T19:57:30Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1345",
    "body": "Aider version: 0.54.12\r\nPython version: 3.10.14\r\nPlatform: Windows-10-10.0.26100-SP0\r\nPython implementation: CPython\r\nVirtual environment: No\r\nOS: Windows 10 (64bit)\r\nGit version: git version 2.46.0.windows.1\r\n\r\nAn uncaught exception occurred:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"runpy.py\", line 196, in _run_module_as_main\r\n    return _run_code(code, main_globals, None,\r\n  File \"runpy.py\", line 86, in _run_code\r\n    exec(code, run_globals)\r\n  File \"__main__.py\", line 7, in <module>\r\n    sys.exit(main())\r\n  File \"main.py\", line 682, in main\r\n    coder.run()\r\n  File \"base_coder.py\", line 729, in run\r\n    user_message = self.get_input()\r\n  File \"base_coder.py\", line 742, in get_input\r\n    return self.io.get_input(\r\n  File \"io.py\", line 337, in get_input\r\n    session = PromptSession(\r\n  File \"prompt.py\", line 476, in __init__\r\n    self.app = self._create_application(editing_mode, erase_when_done)\r\n  File \"prompt.py\", line 727, in _create_application\r\n    application: Application[_T] = Application(\r\n  File \"application.py\", line 267, in __init__\r\n    self.output = output or session.output\r\n  File \"current.py\", line 67, in output\r\n    self._output = create_output()\r\n  File \"defaults.py\", line 87, in create_output\r\n    return Win32Output(stdout, default_color_depth=color_depth_from_env)\r\n  File \"win32.py\", line 115, in __init__\r\n    info = self.get_win32_screen_buffer_info()\r\n  File \"win32.py\", line 219, in get_win32_screen_buffer_info\r\n    raise NoConsoleScreenBufferError\r\nprompt_toolkit.output.win32.NoConsoleScreenBufferError: No Windows console found. Are you running cmd.exe?\r\n\r\n```",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1345/comments",
    "author": "dimentox",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-09-04T14:31:36Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nHow are you running aider? You don't appear to have a working terminal environment. "
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-09-09T19:57:30Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open. Or feel free to file a new issue any time."
      }
    ]
  },
  {
    "number": 1342,
    "title": "BUG: When running unit tests that are auto prompted to run after they are created, the output is not passed back to the LLM",
    "created_at": "2024-09-04T13:25:55Z",
    "closed_at": "2024-09-09T21:32:50Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1342",
    "body": "### Issue\n\nI am added a new feature to a project.  After it added the feature, the unit test was created and then Aider asked me if I wanted to run the test command.  I said yes and the command ran (in this case it was successful).  When prompted if I want to add the output of the test to the conversation if I hit enter or say Yes, nothing happens.  I just get returned to the aider prompt.\r\n\r\nIf I /run the same command myself the output does get sent to the conversation correctly.\r\n\r\naider 0.54.12\r\n--sonnet\r\n\n\n### Version and model info\n\n_No response_",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1342/comments",
    "author": "5ocworkshop",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-09-04T15:50:19Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nThe output will be sent along with your next chat message.\r\n"
      },
      {
        "user": "5ocworkshop",
        "created_at": "2024-09-04T16:07:21Z",
        "body": "Ah so there is a subtle difference in the almost identical prompt to what happens when you receive output using /run versus when the prompt itself sets you up to run?  Using run, when prompted, will submit the results as the next prompt when you say Yes.  If you accept the running of the command triggered from the previous prompt, and you say Yes, it will append the output to your next message but you still have the interactive opportunity to add things to the message?\r\n\r\nMaybe the wording could be slightly different from Aider when it asks what you want to do in these two cases?"
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-09-04T17:15:48Z",
        "body": "Yes, that's correct. I agree, it's currently a bit confusing."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-09-09T21:32:50Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open. Or feel free to file a new issue any time."
      }
    ]
  },
  {
    "number": 1335,
    "title": "Uncaught ModuleNotFoundError in caching.py line 22",
    "created_at": "2024-09-04T08:44:00Z",
    "closed_at": "2024-09-09T19:57:21Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1335",
    "body": "Aider version: 0.54.12\r\nPython version: 3.11.5\r\nPlatform: Windows-10-10.0.22631-SP0\r\nPython implementation: CPython\r\nVirtual environment: No\r\nOS: Windows 10 (64bit)\r\nGit version: git version 2.46.0.windows.1\r\n\r\nAn uncaught exception occurred:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"base_coder.py\", line 1105, in send_message\r\n    yield from self.send(messages, functions=self.functions)\r\n  File \"base_coder.py\", line 1377, in send\r\n    hash_object, completion = send_completion(\r\n                              ^^^^^^^^^^^^^^^^\r\n  File \"sendchat.py\", line 86, in send_completion\r\n    res = litellm.completion(**kwargs)\r\n          ^^^^^^^^^^^^^^^^^^\r\n  File \"llm.py\", line 23, in __getattr__\r\n    self._load_litellm()\r\n  File \"llm.py\", line 30, in _load_litellm\r\n    self._lazy_module = importlib.import_module(\"litellm\")\r\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"<frozen importlib._bootstrap>\", line 1204, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 1176, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 1147, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 690, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\r\n  File \"__init__.py\", line 9, in <module>\r\n    from litellm.caching import Cache\r\n  File \"caching.py\", line 22, in <module>\r\n    from openai._models import BaseModel as OpenAIObject\r\nModuleNotFoundError: No module named 'openai._models'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\r\n  File \"<frozen runpy>\", line 88, in _run_code\r\n  File \"__main__.py\", line 7, in <module>\r\n    sys.exit(main())\r\n             ^^^^^^\r\n  File \"main.py\", line 682, in main\r\n    coder.run()\r\n  File \"base_coder.py\", line 730, in run\r\n    self.run_one(user_message, preproc)\r\n  File \"base_coder.py\", line 773, in run_one\r\n    list(self.send_message(message))\r\n  File \"base_coder.py\", line 1107, in send_message\r\n    except retry_exceptions() as err:\r\n           ^^^^^^^^^^^^^^^^^^\r\n  File \"sendchat.py\", line 24, in retry_exceptions\r\n    litellm.exceptions.APIConnectionError,\r\n    ^^^^^^^^^^^^^^^^^^\r\n  File \"llm.py\", line 23, in __getattr__\r\n    self._load_litellm()\r\n  File \"llm.py\", line 30, in _load_litellm\r\n    self._lazy_module = importlib.import_module(\"litellm\")\r\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"<frozen importlib._bootstrap>\", line 1204, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 1176, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 1147, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 690, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\r\n  File \"__init__.py\", line 9, in <module>\r\n    from litellm.caching import Cache\r\n  File \"caching.py\", line 22, in <module>\r\n    from openai._models import BaseModel as OpenAIObject\r\nModuleNotFoundError: No module named 'openai._models'\r\n\r\n```",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1335/comments",
    "author": "AI-Depot",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-09-04T14:12:03Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nHow did you install aider? What environment are you using?\r\n\r\nIt looks like you don't have the correct set of dependencies installed."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-09-09T19:57:21Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open. Or feel free to file a new issue any time."
      }
    ]
  },
  {
    "number": 1333,
    "title": "Uncaught ImportError in __init__.py line 6",
    "created_at": "2024-09-04T07:18:41Z",
    "closed_at": "2024-09-09T19:57:26Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1333",
    "body": "Aider version: 0.54.12\r\nPython version: 3.10.14\r\nPlatform: Linux-6.5.0-1025-gcp-x86_64-with-glibc2.39\r\nPython implementation: CPython\r\nVirtual environment: No\r\nOS: Linux 6.5.0-1025-gcp (64bit)\r\nGit version: git version 2.42.0\r\n\r\nAn uncaught exception occurred:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"base_coder.py\", line 1105, in send_message\r\n    yield from self.send(messages, functions=self.functions)\r\n  File \"base_coder.py\", line 1377, in send\r\n    hash_object, completion = send_completion(\r\n  File \"sendchat.py\", line 86, in send_completion\r\n    res = litellm.completion(**kwargs)\r\n  File \"llm.py\", line 23, in __getattr__\r\n    self._load_litellm()\r\n  File \"llm.py\", line 30, in _load_litellm\r\n    self._lazy_module = importlib.import_module(\"litellm\")\r\n  File \"__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\r\n  File \"__init__.py\", line 9, in <module>\r\n    from litellm.caching import Cache\r\n  File \"caching.py\", line 22, in <module>\r\n    from openai._models import BaseModel as OpenAIObject\r\n  File \"__init__.py\", line 6, in <module>\r\n    from typing_extensions import override\r\nImportError: cannot import name 'override' from 'typing_extensions' (/home/runner/Aider/.pythonlibs/lib/python3.10/site-packages/typing_extensions.py)\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"aider\", line 8, in <module>\r\n    sys.exit(main())\r\n  File \"main.py\", line 682, in main\r\n    coder.run()\r\n  File \"base_coder.py\", line 730, in run\r\n    self.run_one(user_message, preproc)\r\n  File \"base_coder.py\", line 773, in run_one\r\n    list(self.send_message(message))\r\n  File \"base_coder.py\", line 1107, in send_message\r\n    except retry_exceptions() as err:\r\n  File \"sendchat.py\", line 24, in retry_exceptions\r\n    litellm.exceptions.APIConnectionError,\r\n  File \"llm.py\", line 23, in __getattr__\r\n    self._load_litellm()\r\n  File \"llm.py\", line 30, in _load_litellm\r\n    self._lazy_module = importlib.import_module(\"litellm\")\r\n  File \"__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\r\n  File \"__init__.py\", line 9, in <module>\r\n    from litellm.caching import Cache\r\n  File \"caching.py\", line 22, in <module>\r\n    from openai._models import BaseModel as OpenAIObject\r\n  File \"__init__.py\", line 6, in <module>\r\n    from typing_extensions import override\r\nImportError: cannot import name 'override' from 'typing_extensions' (/home/runner/Aider/.pythonlibs/lib/python3.10/site-packages/typing_extensions.py)\r\n\r\n```",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1333/comments",
    "author": "vbonk",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-09-04T14:14:42Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nHow did you install aider? What environment are you using?\r\n\r\nIt looks like you don't have the correct set of dependencies installed."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-09-09T19:57:26Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open. Or feel free to file a new issue any time."
      }
    ]
  },
  {
    "number": 1320,
    "title": "Uncaught ImportError in __init__.py line 78",
    "created_at": "2024-09-03T17:31:26Z",
    "closed_at": "2024-09-04T00:44:13Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1320",
    "body": "Aider version: <module 'aider.__version__' from '/home/runner/.local/lib/python3.10/site-packages/aider/__version__.py'>\r\nPython version: 3.10.11\r\nPlatform: Linux-6.5.0-1025-gcp-x86_64-with-glibc2.37\r\nPython implementation: CPython\r\nVirtual environment: No\r\nOS: Linux 6.5.0-1025-gcp (64bit)\r\nGit version: git version 2.42.0\r\n\r\nAn uncaught exception occurred:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"aider\", line 8, in <module>\r\n    sys.exit(main())\r\n  File \"main.py\", line 498, in main\r\n    main_model = models.Model(args.model, weak_model=args.weak_model)\r\n  File \"models.py\", line 486, in __init__\r\n    res = self.validate_environment()\r\n  File \"models.py\", line 660, in validate_environment\r\n    res = litellm.validate_environment(model)\r\n  File \"llm.py\", line 23, in __getattr__\r\n    self._load_litellm()\r\n  File \"llm.py\", line 30, in _load_litellm\r\n    self._lazy_module = importlib.import_module(\"litellm\")\r\n  File \"__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\r\n  File \"__init__.py\", line 780, in <module>\r\n    from .cost_calculator import completion_cost\r\n  File \"cost_calculator.py\", line 24, in <module>\r\n    from litellm.utils import (\r\n  File \"utils.py\", line 53, in <module>\r\n    from tokenizers import Tokenizer\r\n  File \"__init__.py\", line 78, in <module>\r\n    from .tokenizers import (\r\nImportError: libstdc++.so.6: cannot open shared object file: No such file or directory\r\n\r\n```",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1320/comments",
    "author": "ivnad95",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-09-03T17:47:42Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nHow did you install aider? What environment are you using?\r\n\r\nIt looks like you don't have the correct set of dependencies installed.\r\n\r\nDid you install aider using `pipx` on Replit? Replit's pipx doesn't seem to allow aider to access an important library."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-09-04T00:43:48Z",
        "body": "To use aider with pipx on replit, you can run these commands in the replit shell:\r\n\r\n```\r\npip install pipx\r\npipx run aider-chat ...normal aider args...\r\n```\r\n\r\nIf you install aider with pipx on replit and try and run it as just `aider` it will crash with a missing `libstdc++.so.6` library."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-09-04T00:44:13Z",
        "body": "To use aider with pipx on replit, you can run these commands in the replit shell:\r\n\r\n```\r\npip install pipx\r\npipx run aider-chat ...normal aider args...\r\n```\r\n\r\nIf you install aider with pipx on replit and try and run it as just `aider` it will crash\r\nwith a missing `libstdc++.so.6` library."
      }
    ]
  },
  {
    "number": 1313,
    "title": "Uncaught ImportError in __init__.py line 78",
    "created_at": "2024-09-03T11:08:29Z",
    "closed_at": "2024-09-04T00:44:17Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1313",
    "body": "Aider version: 0.54.12\r\nPython version: 3.11.9\r\nPlatform: Linux-6.5.0-1025-gcp-x86_64-with-glibc2.39\r\nPython implementation: CPython\r\nVirtual environment: No\r\nOS: Linux 6.5.0-1025-gcp (64bit)\r\nGit version: git version 2.42.0\r\n\r\nAn uncaught exception occurred:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"base_coder.py\", line 1105, in send_message\r\n    yield from self.send(messages, functions=self.functions)\r\n  File \"base_coder.py\", line 1377, in send\r\n    hash_object, completion = send_completion(\r\n                              ^^^^^^^^^^^^^^^^\r\n  File \"sendchat.py\", line 86, in send_completion\r\n    res = litellm.completion(**kwargs)\r\n          ^^^^^^^^^^^^^^^^^^\r\n  File \"llm.py\", line 23, in __getattr__\r\n    self._load_litellm()\r\n  File \"llm.py\", line 30, in _load_litellm\r\n    self._lazy_module = importlib.import_module(\"litellm\")\r\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"<frozen importlib._bootstrap>\", line 1204, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 1176, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 1147, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 690, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\r\n  File \"__init__.py\", line 780, in <module>\r\n    from .cost_calculator import completion_cost\r\n  File \"cost_calculator.py\", line 24, in <module>\r\n    from litellm.utils import (\r\n  File \"utils.py\", line 53, in <module>\r\n    from tokenizers import Tokenizer\r\n  File \"__init__.py\", line 78, in <module>\r\n    from .tokenizers import (\r\nImportError: libstdc++.so.6: cannot open shared object file: No such file or directory\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"aider\", line 8, in <module>\r\n    sys.exit(main())\r\n             ^^^^^^\r\n  File \"main.py\", line 682, in main\r\n    coder.run()\r\n  File \"base_coder.py\", line 730, in run\r\n    self.run_one(user_message, preproc)\r\n  File \"base_coder.py\", line 773, in run_one\r\n    list(self.send_message(message))\r\n  File \"base_coder.py\", line 1107, in send_message\r\n    except retry_exceptions() as err:\r\n           ^^^^^^^^^^^^^^^^^^\r\n  File \"sendchat.py\", line 24, in retry_exceptions\r\n    litellm.exceptions.APIConnectionError,\r\n    ^^^^^^^^^^^^^^^^^^\r\n  File \"llm.py\", line 23, in __getattr__\r\n    self._load_litellm()\r\n  File \"llm.py\", line 30, in _load_litellm\r\n    self._lazy_module = importlib.import_module(\"litellm\")\r\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"<frozen importlib._bootstrap>\", line 1204, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 1176, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 1147, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 690, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\r\n  File \"__init__.py\", line 780, in <module>\r\n    from .cost_calculator import completion_cost\r\n  File \"cost_calculator.py\", line 24, in <module>\r\n    from litellm.utils import (\r\n  File \"utils.py\", line 53, in <module>\r\n    from tokenizers import Tokenizer\r\n  File \"__init__.py\", line 78, in <module>\r\n    from .tokenizers import (\r\nImportError: libstdc++.so.6: cannot open shared object file: No such file or directory\r\n\r\n```",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1313/comments",
    "author": "fabiofurlano",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-09-03T15:07:12Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nHow did you install aider? It looks like you don't have the correct set of dependencies installed."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-09-04T00:44:17Z",
        "body": "To use aider with pipx on replit, you can run these commands in the replit shell:\r\n\r\n```\r\npip install pipx\r\npipx run aider-chat ...normal aider args...\r\n```\r\n\r\nIf you install aider with pipx on replit and try and run it as just `aider` it will crash\r\nwith a missing `libstdc++.so.6` library."
      }
    ]
  },
  {
    "number": 1312,
    "title": "Uncaught ModuleNotFoundError in caching.py line 22",
    "created_at": "2024-09-03T11:01:23Z",
    "closed_at": "2024-09-09T19:54:50Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1312",
    "body": "Aider version: 0.54.12\r\nPython version: 3.11.9\r\nPlatform: Linux-6.5.0-1025-gcp-x86_64-with-glibc2.39\r\nPython implementation: CPython\r\nVirtual environment: No\r\nOS: Linux 6.5.0-1025-gcp (64bit)\r\nGit version: git version 2.42.0\r\n\r\nAn uncaught exception occurred:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"aider\", line 8, in <module>\r\n    sys.exit(main())\r\n             ^^^^^^\r\n  File \"main.py\", line 498, in main\r\n    main_model = models.Model(args.model, weak_model=args.weak_model)\r\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"models.py\", line 486, in __init__\r\n    res = self.validate_environment()\r\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"models.py\", line 660, in validate_environment\r\n    res = litellm.validate_environment(model)\r\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"llm.py\", line 23, in __getattr__\r\n    self._load_litellm()\r\n  File \"llm.py\", line 30, in _load_litellm\r\n    self._lazy_module = importlib.import_module(\"litellm\")\r\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"<frozen importlib._bootstrap>\", line 1204, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 1176, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 1147, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 690, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\r\n  File \"__init__.py\", line 9, in <module>\r\n    from litellm.caching import Cache\r\n  File \"caching.py\", line 22, in <module>\r\n    from openai._models import BaseModel as OpenAIObject\r\nModuleNotFoundError: No module named 'openai._models'\r\n\r\n```",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1312/comments",
    "author": "jasona-creator",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-09-03T15:07:41Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nHow did you install aider? It looks like you don't have the correct set of dependencies installed."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-09-09T19:54:50Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open or file a new issue any time."
      }
    ]
  },
  {
    "number": 1304,
    "title": "Uncaught NoConsoleScreenBufferError in win32.py line 219",
    "created_at": "2024-09-02T19:50:54Z",
    "closed_at": "2024-09-09T19:56:37Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1304",
    "body": "Aider version: 0.54.12\r\nPython version: 3.12.3\r\nPlatform: Windows-11-10.0.22631-SP0\r\nPython implementation: CPython\r\nVirtual environment: No\r\nOS: Windows 11 (64bit)\r\nGit version: git version 2.33.1.windows.1\r\n\r\nAn uncaught exception occurred:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\r\n  File \"<frozen runpy>\", line 88, in _run_code\r\n  File \"__main__.py\", line 7, in <module>\r\n    sys.exit(main())\r\n             ^^^^^^\r\n  File \"main.py\", line 466, in main\r\n    check_gitignore(git_root, io)\r\n  File \"main.py\", line 132, in check_gitignore\r\n    if ask and not io.confirm_ask(f\"Add {pat} to .gitignore (recommended)?\"):\r\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"io.py\", line 453, in confirm_ask\r\n    res = prompt(\r\n          ^^^^^^^\r\n  File \"prompt.py\", line 1423, in prompt\r\n    session: PromptSession[str] = PromptSession(history=history)\r\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"prompt.py\", line 476, in __init__\r\n    self.app = self._create_application(editing_mode, erase_when_done)\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"prompt.py\", line 727, in _create_application\r\n    application: Application[_T] = Application(\r\n                                   ^^^^^^^^^^^^\r\n  File \"application.py\", line 267, in __init__\r\n    self.output = output or session.output\r\n                            ^^^^^^^^^^^^^^\r\n  File \"current.py\", line 67, in output\r\n    self._output = create_output()\r\n                   ^^^^^^^^^^^^^^^\r\n  File \"defaults.py\", line 87, in create_output\r\n    return Win32Output(stdout, default_color_depth=color_depth_from_env)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"win32.py\", line 115, in __init__\r\n    info = self.get_win32_screen_buffer_info()\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"win32.py\", line 219, in get_win32_screen_buffer_info\r\n    raise NoConsoleScreenBufferError\r\nprompt_toolkit.output.win32.NoConsoleScreenBufferError: Found xterm, while expecting a Windows console. Maybe try to run this program using \"winpty\" or run it in cmd.exe instead. Or otherwise, in case of Cygwin, use the Python executable that is compiled for Cygwin.\r\n\r\n```",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1304/comments",
    "author": "cristianmonsalve14",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-09-03T15:15:25Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nHow are you running aider? It looks like you don't have a working terminal?"
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-09-09T19:56:37Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open or file a new issue any time."
      }
    ]
  },
  {
    "number": 1296,
    "title": "Uncaught ImportError in _compat.py line 57",
    "created_at": "2024-09-02T10:50:50Z",
    "closed_at": "2024-09-09T20:00:15Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1296",
    "body": "Aider version: 0.54.10\r\nPython version: 3.12.1\r\nPlatform: macOS-14.1-arm64-arm-64bit\r\nPython implementation: CPython\r\nVirtual environment: Yes\r\nOS: Darwin 23.1.0 (64bit)\r\nGit version: git version 2.44.0\r\n\r\nAn uncaught exception occurred:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"base_coder.py\", line 1105, in send_message\r\n    yield from self.send(messages, functions=self.functions)\r\n  File \"base_coder.py\", line 1377, in send\r\n    hash_object, completion = send_completion(\r\n                              ^^^^^^^^^^^^^^^^\r\n  File \"sendchat.py\", line 86, in send_completion\r\n    res = litellm.completion(**kwargs)\r\n          ^^^^^^^^^^^^^^^^^^\r\n  File \"llm.py\", line 23, in __getattr__\r\n    self._load_litellm()\r\n  File \"llm.py\", line 30, in _load_litellm\r\n    self._lazy_module = importlib.import_module(\"litellm\")\r\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"__init__.py\", line 90, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"<frozen importlib._bootstrap>\", line 1387, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 1331, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 935, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 994, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\r\n  File \"__init__.py\", line 9, in <module>\r\n    from litellm.caching import Cache\r\n  File \"caching.py\", line 22, in <module>\r\n    from openai._models import BaseModel as OpenAIObject\r\n  File \"__init__.py\", line 8, in <module>\r\n    from . import types\r\n  File \"__init__.py\", line 5, in <module>\r\n    from .batch import Batch as Batch\r\n  File \"batch.py\", line 7, in <module>\r\n    from .._models import BaseModel\r\n  File \"_models.py\", line 36, in <module>\r\n    from ._utils import (\r\n  File \"__init__.py\", line 3, in <module>\r\n    from ._utils import (\r\n  File \"_utils.py\", line 24, in <module>\r\n    from .._compat import parse_date as parse_date, parse_datetime as parse_datetime\r\n  File \"_compat.py\", line 57, in <module>\r\n    from pydantic.typing import (\r\nImportError: cannot import name 'is_union' from 'pydantic.typing' (/Users/arieltarayants/genalpha/genalpha-backend/venv/lib/python3.12/site-packages/pydantic/typing.py)\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"aider\", line 8, in <module>\r\n    sys.exit(main())\r\n             ^^^^^^\r\n  File \"main.py\", line 682, in main\r\n    coder.run()\r\n  File \"base_coder.py\", line 730, in run\r\n    self.run_one(user_message, preproc)\r\n  File \"base_coder.py\", line 773, in run_one\r\n    list(self.send_message(message))\r\n  File \"base_coder.py\", line 1107, in send_message\r\n    except retry_exceptions() as err:\r\n           ^^^^^^^^^^^^^^^^^^\r\n  File \"sendchat.py\", line 24, in retry_exceptions\r\n    litellm.exceptions.APIConnectionError,\r\n    ^^^^^^^^^^^^^^^^^^\r\n  File \"llm.py\", line 23, in __getattr__\r\n    self._load_litellm()\r\n  File \"llm.py\", line 30, in _load_litellm\r\n    self._lazy_module = importlib.import_module(\"litellm\")\r\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"__init__.py\", line 90, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"<frozen importlib._bootstrap>\", line 1387, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 1331, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 935, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 994, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\r\n  File \"__init__.py\", line 9, in <module>\r\n    from litellm.caching import Cache\r\n  File \"caching.py\", line 22, in <module>\r\n    from openai._models import BaseModel as OpenAIObject\r\n  File \"__init__.py\", line 8, in <module>\r\n    from . import types\r\n  File \"__init__.py\", line 5, in <module>\r\n    from .batch import Batch as Batch\r\n  File \"batch.py\", line 7, in <module>\r\n    from .._models import BaseModel\r\n  File \"_models.py\", line 36, in <module>\r\n    from ._utils import (\r\n  File \"__init__.py\", line 3, in <module>\r\n    from ._utils import (\r\n  File \"_utils.py\", line 24, in <module>\r\n    from .._compat import parse_date as parse_date, parse_datetime as parse_datetime\r\n  File \"_compat.py\", line 57, in <module>\r\n    from pydantic.typing import (\r\nImportError: cannot import name 'is_union' from 'pydantic.typing' (/Users/arieltarayants/genalpha/genalpha-backend/venv/lib/python3.12/site-packages/pydantic/typing.py)\r\n\r\n```",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1296/comments",
    "author": "ariel-tar99",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-09-02T18:11:42Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nHow did you install aider? It looks like you don't have the correct set of dependencies installed."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-09-09T20:00:15Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open. Or feel free to file a new issue any time."
      }
    ]
  },
  {
    "number": 1295,
    "title": "Q: When adding the output of a command to the chat, if you choose a message is that added in addition to the output or in place of?",
    "created_at": "2024-09-02T10:39:13Z",
    "closed_at": "2024-09-04T14:06:39Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1295",
    "body": "### Issue\n\nI just wanted to clarify an ambiguity on the Y/N/Message prompt you get after you run a command:\r\n\r\n```\r\nAdd the output to the chat?                                                                                                                                                                                                \r\n(Y)es/(n)o/message with instructions:\r\n\r\n```\r\nIf you choose message is that (Y) with message or (n) with message?\r\n\r\nAider aider 0.54.10\r\nModel: --sonnet\n\n### Version and model info\n\n_No response_",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1295/comments",
    "author": "5ocworkshop",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-09-03T15:44:38Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nYou can type Y or N or simply type a message. If you type a message, it will send the output along with your message."
      },
      {
        "user": "5ocworkshop",
        "created_at": "2024-09-04T13:39:56Z",
        "body": "Excellent, thank you for clarifying."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-09-04T14:06:36Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open or file a new issue any time."
      }
    ]
  },
  {
    "number": 1293,
    "title": "Enhance: Add project specific rules in .aiderrules",
    "created_at": "2024-09-02T08:32:18Z",
    "closed_at": "2024-09-09T21:33:35Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1293",
    "body": "### Issue\n\nCurrently we can include instructions by adding for example markdown files to the Chat. \r\n\r\nFor project-specific instructions, you could include the instructions in a .aiderrules file in the root of your project. This could be added to a special part of the prompt so the model knows about instructions vs. context. \r\n\r\nAn example file for example: \r\n\r\n```markdown\r\nPython programming guidelines: \r\n\r\n- Provide clean, production-grade, high quality code. \r\n- The user is using python version 3.10+\r\n- Use well-known python design patterns and object-oriented programming approaches\r\n- Provide code blocks with proper google style docstrings\r\n- Provide code blocks with input and return value type hinting. \r\n- Always use type hints \r\n- Use F-string for formatting strings\r\n- Keep functions Small: Each function should do one thing and do it well.\r\n- Use @property: For getter and setter methods.\r\n- Use List and Dictionary Comprehensions: They are more readable and efficient.\r\n- Use generators for large datasets to save memory.\r\n- Use logging: Replace print statements with logging for better control over output.\r\n- Implement robust error handling when calling external dependencies\r\n- Use dataclasses for storing data\r\n- Use pydantic version 1 for data validation and settings management.\r\n- Ensure the code is presented in code blocks without comments and description. \r\n- An Example use to be presented in if __name__ == \"__main__\":\r\n\r\nReactJS (Tailwind CSS styled) programming guidelines: \r\n\r\n- Design pages or components with beautiful styles. Follow TailwindUI component styling when possible. \r\n- When images are required, utilise the img tag with picsum.photos as the source. \r\n- If you need to use icons, opt for Heroicon v1 Icons.\r\n- Do not outputting SVG path code directly.\r\n- f a user provides an image of a web page design, implement the design in the image using Tailwind CSS and HTML and ReactJS.\r\n- Adhere as closely as possible to the original design, ensuring that no details are missed.\r\n- Add rich but not feel cluttered UI visual elements or color matching.\r\n```\r\n\r\n\r\n\n\n### Version and model info\n\n_No response_",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1293/comments",
    "author": "xcke",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-09-03T15:42:13Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nYou can make `.aiderrules` and add it to the chat with `/read` or `--read`."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-09-09T21:33:35Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open. Or feel free to file a new issue any time."
      }
    ]
  },
  {
    "number": 1292,
    "title": "Uncaught ImportError in utils.py line 50",
    "created_at": "2024-09-02T06:03:38Z",
    "closed_at": "2024-09-09T20:00:19Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1292",
    "body": "Aider version: 0.54.12\r\nPython version: 3.11.9\r\nPlatform: macOS-14.1.2-arm64-arm-64bit\r\nPython implementation: CPython\r\nVirtual environment: No\r\nOS: Darwin 23.1.0 (64bit)\r\nGit version: git version 2.39.3 (Apple Git-145)\r\n\r\nAn uncaught exception occurred:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"aider\", line 8, in <module>\r\n    sys.exit(main())\r\n             ^^^^^^\r\n  File \"main.py\", line 498, in main\r\n    main_model = models.Model(args.model, weak_model=args.weak_model)\r\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"models.py\", line 486, in __init__\r\n    res = self.validate_environment()\r\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"models.py\", line 660, in validate_environment\r\n    res = litellm.validate_environment(model)\r\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"llm.py\", line 23, in __getattr__\r\n    self._load_litellm()\r\n  File \"llm.py\", line 30, in _load_litellm\r\n    self._lazy_module = importlib.import_module(\"litellm\")\r\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"<frozen importlib._bootstrap>\", line 1204, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 1176, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 1147, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 690, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\r\n  File \"__init__.py\", line 780, in <module>\r\n    from .cost_calculator import completion_cost\r\n  File \"cost_calculator.py\", line 24, in <module>\r\n    from litellm.utils import (\r\n  File \"utils.py\", line 50, in <module>\r\n    from openai.lib import _parsing, _pydantic\r\nImportError: cannot import name '_parsing' from 'openai.lib' (unknown location)\r\n\r\n```",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1292/comments",
    "author": "DeathGanker",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-09-02T18:12:20Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nHow did you install aider? It looks like you don't have the correct set of dependencies installed."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-09-09T20:00:19Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open. Or feel free to file a new issue any time."
      }
    ]
  },
  {
    "number": 1279,
    "title": "Uncaught NoConsoleScreenBufferError in win32.py line 219",
    "created_at": "2024-09-01T06:55:31Z",
    "closed_at": "2024-09-09T20:00:28Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1279",
    "body": "Aider version: 0.54.10\r\nPython version: 3.10.10\r\nPlatform: Windows-10-10.0.19045-SP0\r\nPython implementation: CPython\r\nVirtual environment: Yes\r\nOS: Windows 10 (64bit)\r\nGit version: git version 2.24.1.windows.2\r\n\r\nAn uncaught exception occurred:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"runpy.py\", line 196, in _run_module_as_main\r\n    return _run_code(code, main_globals, None,\r\n  File \"runpy.py\", line 86, in _run_code\r\n    exec(code, run_globals)\r\n  File \"__main__.py\", line 7, in <module>\r\n    sys.exit(main())\r\n  File \"main.py\", line 464, in main\r\n    git_root = setup_git(git_root, io)\r\n  File \"main.py\", line 76, in setup_git\r\n    elif io.confirm_ask(\"No git repo found, create one to track aider's changes (recommended)?\"):\r\n  File \"io.py\", line 453, in confirm_ask\r\n    res = prompt(\r\n  File \"prompt.py\", line 1423, in prompt\r\n    session: PromptSession[str] = PromptSession(history=history)\r\n  File \"prompt.py\", line 476, in __init__\r\n    self.app = self._create_application(editing_mode, erase_when_done)\r\n  File \"prompt.py\", line 727, in _create_application\r\n    application: Application[_T] = Application(\r\n  File \"application.py\", line 267, in __init__\r\n    self.output = output or session.output\r\n  File \"current.py\", line 67, in output\r\n    self._output = create_output()\r\n  File \"defaults.py\", line 87, in create_output\r\n    return Win32Output(stdout, default_color_depth=color_depth_from_env)\r\n  File \"win32.py\", line 115, in __init__\r\n    info = self.get_win32_screen_buffer_info()\r\n  File \"win32.py\", line 219, in get_win32_screen_buffer_info\r\n    raise NoConsoleScreenBufferError\r\nprompt_toolkit.output.win32.NoConsoleScreenBufferError: Found xterm, while expecting a Windows console. Maybe try to run this program using \"winpty\" or run it in cmd.exe instead. Or otherwise, in case of Cygwin, use the Python executable that is compiled for Cygwin.\r\n\r\n```",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1279/comments",
    "author": "griyanet",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-09-01T13:53:59Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nWhat shell or terminal environment did you use to run aider?"
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-09-09T20:00:28Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open. Or feel free to file a new issue any time."
      }
    ]
  },
  {
    "number": 1265,
    "title": "BUG: File name has \"b/\" add to it, e.g. \"app.py\" edits are attempted to be applied to \"b/app.py\"",
    "created_at": "2024-08-31T15:22:30Z",
    "closed_at": "2024-09-04T15:47:33Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1265",
    "body": "### Issue\r\n\r\nI've had this happen randomly a number of times over the past month.  I'm working on an app today and I would say I'm maybe 70 minutes into the conversation and all of a sudden the AI wanted to apply edits to \"b/app.py\" when the correct name of the file in the chat which is central to all the previous work is app.py.\r\n\r\nI refused the edit and explained the situation like this: \"The previous change tried to edit the file \"b/app.py\" when it should be editing the file \"app.py\" which is already in the chat.  Please re-apply the last edits to app.py\" and it seemed to get back on track (at least for this edit).\r\n\r\nI'll try and provide more information if it happens again, not sure what to include as everything else is working.\r\n\r\nEdit: I supplied my next prompt, nothing unusual, and it provided the edits and had some linting issues.  After correcting the linting issues it again tried to apply the changes to b/app.py.  I'm not sure how to provide information that might allow the recreation of this - open to suggestions.\r\n\r\nEdit 2: I have a hunch that this is related to the amount of time I've had the conversation going and I think we're losing things off the start of the conversation.  I have exited aider and restarted and will report if it occurs again.  Local time is 16:40 and if it occurs again will report the time so we can see how long it took to appear as I have a hunch it is total context length related.\r\n\r\nEdit 3: The spuious \"b/\" on the front of file names has reared it's head again.  Local time is now 18:40.  So it looks like after 2 hours of use in this particular case, it is happening again.  I am going to start a new session and continue my work, but wanted to leave the datapoint.\r\n\r\n### Version and model info\r\n\r\nAider v0.54.8\r\nMain model: claude-3-5-sonnet-20240620 with udiff edit format, prompt cache, infinite output\r\nWeak model: claude-3-haiku-20240307\r\n\r\nAider is being called with: \r\n--sonnet \\\r\n--cache-prompts \\\r\n--cache-keepalive-pings 5 \\\r\n--no-stream \\\r\n--dark-mode \\\r\n--edit-format udiff\r\nI am caching a conventions.txt (6.5K) and a design.txt (8K) both of which are relatively small.",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1265/comments",
    "author": "5ocworkshop",
    "comments": [
      {
        "user": "5ocworkshop",
        "created_at": "2024-09-02T09:58:51Z",
        "body": "I'm not sure why this creeps in after some time, but at least now we have a possible explanation:\r\n\r\n> udiff> /ask you must NEVER add \"b/\" to a file name.  Please explain why you keep doing this.  You already have the correct file names in the chat and yet you prepend a b/ to the start that does not belong there.        \r\n> \r\n> I apologize for the confusion. You are absolutely correct, and I should not be adding \"b/\" to the file names. This is an error on my part, and I appreciate you pointing it out. \r\n> \r\n> The \"b/\" prefix is typically used in diff formats to indicate the \"before\" version of a file, with \"a/\" indicating the \"after\" version. However, in the context of our discussion, where we're directly referencing and \r\n> modifying existing files, this prefix is inappropriate and incorrect.\r\n> \r\n> I will ensure that in future responses, I use the correct file names as they appear in the chat, without any additional prefixes. Thank you for bringing this to my attention, and I'll be more careful to avoid this \r\n> mistake in the future."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-09-03T15:43:28Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nSorry, I think you may just be misreading the diff output? All diffs prefix the filenames with `a/` and `b/`. It doesn't actually use those prefixes in the filename.\r\n\r\nI also note that you have chosen to use `--edit-format udiff` with sonnet. Why? The default `diff` edit format works best for Sonnet. "
      },
      {
        "user": "5ocworkshop",
        "created_at": "2024-09-04T15:34:11Z",
        "body": "I understand the a/ and b/ prefixes, but along the way aider started including them in the file names and if I don't catch it I end up with a b/file-in-question.py along side the file-in-question.py.\r\n\r\nI can't recall why I was using udiff in the past and in the last few days I have switched back to diff, but I did want to log the issue."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-09-04T15:47:33Z",
        "body": "If you can provide instructions for how I can reproduce the problem, please let me know.\r\n\r\nI'm going to close this issue for now, but feel free to add a comment here and I will re-open or file a new issue any time."
      }
    ]
  },
  {
    "number": 1256,
    "title": "Uncaught ImportError in utils.py line 50",
    "created_at": "2024-08-31T02:17:23Z",
    "closed_at": "2024-09-02T18:45:42Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1256",
    "body": "Aider version: 0.54.8\r\nPython version: 3.11.9\r\nPlatform: Windows-10-10.0.22631-SP0\r\nPython implementation: CPython\r\nVirtual environment: Yes\r\nOS: Windows 10 (64bit)\r\nGit version: git version 2.45.1.windows.1\r\n\r\nAn uncaught exception occurred:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\r\n  File \"<frozen runpy>\", line 88, in _run_code\r\n  File \"__main__.py\", line 7, in <module>\r\n    sys.exit(main())\r\n             ^^^^^^\r\n  File \"main.py\", line 498, in main\r\n    main_model = models.Model(args.model, weak_model=args.weak_model)\r\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"models.py\", line 486, in __init__\r\n    res = self.validate_environment()\r\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"models.py\", line 660, in validate_environment\r\n    res = litellm.validate_environment(model)\r\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"llm.py\", line 22, in __getattr__\r\n    self._load_litellm()\r\n  File \"llm.py\", line 29, in _load_litellm\r\n    self._lazy_module = importlib.import_module(\"litellm\")\r\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"<frozen importlib._bootstrap>\", line 1204, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 1176, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 1147, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 690, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\r\n  File \"__init__.py\", line 780, in <module>\r\n    from .cost_calculator import completion_cost\r\n  File \"cost_calculator.py\", line 24, in <module>\r\n    from litellm.utils import (\r\n  File \"utils.py\", line 50, in <module>\r\n    from openai.lib import _parsing, _pydantic\r\nImportError: cannot import name '_parsing' from 'openai.lib' (unknown location)\r\n\r\n```",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1256/comments",
    "author": "leo19920",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-08-31T15:02:05Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nHow did you install aider? It looks like you've got an incompatible version of the `openai` package installed?"
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-09-02T18:45:42Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open or file a new issue any time."
      }
    ]
  },
  {
    "number": 1187,
    "title": "How to change the directory where Aider saves\\creates files",
    "created_at": "2024-08-26T20:09:41Z",
    "closed_at": "2024-08-27T10:44:36Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1187",
    "body": "### Issue\r\n\r\nI'm looking for a way to configure Aider to save files in a specific directory rather than the default one. I've checked the documentation and existing issues but couldn't find a clear solution. Could you please guide me on how to achieve this?\r\n\r\nThe files are currently being created and saved in: \"C:\\Users\\lucas\\\". I want to change this to \"C:\\Users\\lucas\\miniconda3\\envs\\aideeerrr\\Scripts\" in order to use Cursor together with Aider.\r\n\r\n\r\n\r\n\r\n### Version and model info\r\n\r\nWindows 11",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1187/comments",
    "author": "Ltbltbltbltb",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-08-26T22:01:43Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nYou probably created a git repo in your home directory. You should create a git repo in the dir where you want aider to work with `git init`.\r\n"
      },
      {
        "user": "Ltbltbltbltb",
        "created_at": "2024-08-27T10:44:36Z",
        "body": "Thank you, Man!"
      }
    ]
  },
  {
    "number": 1180,
    "title": "Playwright is not supported on non-Ubuntu Linux distros -- perhaps can be replaced?",
    "created_at": "2024-08-25T21:17:19Z",
    "closed_at": "2024-09-03T15:54:44Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1180",
    "body": "### Issue\r\n\r\nPlaywright is heavyweight and not supported on Fedora and other non-Ubuntu linux distros. Therefore, /web functionality mostly doesn't work. Perhaps it can be replaced with a more lightweight solution like Trafilatura?\r\n\r\n### Version and model info\r\n\r\nAider 0.52.1, Fedora 40",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1180/comments",
    "author": "atemerev",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-08-26T21:49:01Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nAider falls back to httpx if playwright is not available."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-09-03T15:54:44Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open or file a new issue any time."
      }
    ]
  },
  {
    "number": 1160,
    "title": "How to suppress code diff output from the screen?",
    "created_at": "2024-08-24T06:40:02Z",
    "closed_at": "2024-09-03T15:55:09Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1160",
    "body": "### Issue\n\nWhenever I ask it to do something with my codebase, it outputs all the file diffs on the screen. I don't need that. I just want it to do the job quietly, commit and tell me when done. How to instruct it to behave that way?\r\n\r\nFor example, I have a small Golang codebase (13 files). I issue this command:\r\n\r\n> Rewrite this codebase in JavaScript to be run in web browsers. Do it quietly, do not tell me what you are doing. Just do the job and tell me when done.\r\n\r\n— and everything it does gets shown on the screen.\n\n### Version and model info\n\nAider v0.52.1\r\nMain model: gpt-4o-2024-08-06 with diff edit format\r\nWeak model: gpt-4o-mini\r\nGit repo: .git with 13 files\r\nRepo-map: using 1024 tokens, auto refresh\r\n",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1160/comments",
    "author": "greendrake",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-08-26T21:57:19Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nThe diff you see is the model specifying how to edit the code. There's no way to suppress showing it."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-09-03T15:55:09Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open or file a new issue any time."
      }
    ]
  },
  {
    "number": 1154,
    "title": "[Question] How to add context in the chat window without triggering a model response?",
    "created_at": "2024-08-23T08:32:47Z",
    "closed_at": "2024-09-03T15:53:04Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1154",
    "body": "### Issue\n\nHi all!\r\n\r\nI know it is possible to create a file, add it and have that be my \"extra\" context. But sometimes I just want to add a bit of context without going through the hassle of the file stuff. \r\n\r\nI currently do /ask for this, but this seems 1) wasteful 2) the model response may confuse the context I am trying to add.\r\n\r\nIs there a way to add context to the chat history without triggering any model response?\n\n### Version and model info\n\n_No response_",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1154/comments",
    "author": "DamianB-BitFlipper",
    "comments": [
      {
        "user": "razhangwei",
        "created_at": "2024-08-25T12:06:27Z",
        "body": "How about /clipboard?"
      },
      {
        "user": "DamianB-BitFlipper",
        "created_at": "2024-08-25T18:14:08Z",
        "body": "Interesting hack. I'll give it a look.\r\n"
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-08-26T21:50:05Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nType in your context. Then just don't press enter until you are ready to type in an actual instruction?"
      },
      {
        "user": "DamianB-BitFlipper",
        "created_at": "2024-08-27T07:43:12Z",
        "body": "That works and it's what I am currently doing. I'm making an aider plugin for Emacs.\r\n\r\nI wanted to add \"context\" to aider from Emacs's IDE functionality (ie: with a keybinding, make the focus a specific variable, and then your coding command can be \"Make this more modular\") and it know what you're referring to. Right now I'm making a prompt prefix that gets prepended to all /code, /ask requests."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-09-03T15:53:04Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open or file a new issue any time."
      }
    ]
  },
  {
    "number": 1141,
    "title": "Share configuration which used for writing `aider` itself",
    "created_at": "2024-08-21T06:29:21Z",
    "closed_at": "2024-09-03T15:54:28Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1141",
    "body": "### Issue\n\nI've noticed that you wrote \"Aider wrote 56% of the code in this release.\" in releases. I wonder what models and prompts do you use.\r\n\r\nI guess It will be very helpful if you share sample of your message history and configs with community!\r\n\r\nThanks :heart: \n\n### Version and model info\n\n_No response_",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1141/comments",
    "author": "dantetemplar",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-08-26T21:34:16Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nClosest you can probably do is check the commit history in github. Commits by \"Paul Gauthier (aider)\" were done by aider."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-09-03T15:54:28Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open or file a new issue any time."
      }
    ]
  },
  {
    "number": 1129,
    "title": "🪲 BUG During reflector ",
    "created_at": "2024-08-19T18:09:54Z",
    "closed_at": "2024-08-26T21:25:33Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1129",
    "body": "### Issue\r\n\r\nI'm error that Only 3 reflector are allowed ? why and how to solve it ? is anyone facing this issue ?\r\n\r\n### Version and model info\r\n\r\nAIDER V.50.1\r\nMODEL : DEEPSEEK",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1129/comments",
    "author": "djfaizp",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-08-19T18:12:01Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nYou can just ask it to try again. But if it get stuck for 3 retries, you may want to run `/clear` before asking again for the change. The model may have gotten itself confused."
      },
      {
        "user": "djfaizp",
        "created_at": "2024-08-19T18:20:18Z",
        "body": "i will try and share experiences thanks for your kind reply 😊 you are doing great work this project have helped me alot i have zero knowledge of programming and i have successfully built a good program. now I'm just about to finish it but due to large volume of codes it is maybe confusing "
      },
      {
        "user": "djfaizp",
        "created_at": "2024-08-24T15:40:26Z",
        "body": "it's works now after /clear and my file had 1000+ line codes that's why model was confusing . now i have split them in 4 i will update if i still found that error thanks @paul-gauthier for this awesome project."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-08-26T21:25:34Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open or file a new issue any time."
      }
    ]
  },
  {
    "number": 1125,
    "title": "FileNotFoundError while building binary from the Aider codebase",
    "created_at": "2024-08-19T13:08:53Z",
    "closed_at": "2024-08-26T21:31:37Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1125",
    "body": "### Issue\r\n\r\nHi @paul-gauthier & everyone,\r\n\r\nI'm encountering an issue while trying to build a binary from the Aider codebase. During the build process, I encountered a FileNotFoundError. The specific error message is as follows:\r\n\r\n```bash\r\nFile \"cli.py\", line 659, in <module>\r\n  File \"cli.py\", line 654, in __init__\r\n  File \"cli.py\", line 638, in start\r\n  File \"cli.py\", line 627, in handle_tool\r\n  File \"langchain_core/tools/base.py\", line 397, in invoke\r\n  File \"langchain_core/tools/base.py\", line 585, in run\r\n  File \"langchain_core/tools/base.py\", line 554, in run\r\n  File \"langchain_core/tools/structured.py\", line 69, in _run\r\n  File \"cli.py\", line 194, in implement_task\r\n  File \"poc_framework/agent_base.py\", line 21, in execute_job\r\n  File \"code_implementation_sequence/agent_code_change.py\", line 57, in define_job\r\n  File \"aider/coders/base_coder.py\", line 701, in run\r\n  File \"aider/coders/base_coder.py\", line 752, in run_one\r\n  File \"aider/coders/base_coder.py\", line 979, in send_message\r\n  File \"aider/coders/base_coder.py\", line 925, in format_messages\r\n  File \"aider/coders/base_coder.py\", line 610, in get_files_messages\r\n  File \"aider/coders/base_coder.py\", line 582, in get_repo_map\r\n  File \"aider/repomap.py\", line 105, in get_repo_map\r\n  File \"aider/repomap.py\", line 448, in get_ranked_tags_map\r\n  File \"aider/repomap.py\", line 76, in token_count\r\n  File \"aider/models.py\", line 529, in token_count\r\n  File \"aider/models.py\", line 515, in tokenizer\r\n  File \"aider/llm.py\", line 20, in __getattr__\r\n  File \"aider/llm.py\", line 27, in _load_litellm\r\n  File \"importlib/__init__.py\", line 90, in import_module\r\n  File \"<frozen importlib._bootstrap>\", line 1387, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 1331, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 935, in _load_unlocked\r\n  File \"PyInstaller/loader/pyimod02_importers.py\", line 378, in exec_module\r\n  File \"litellm/__init__.py\", line 789, in <module>\r\n  File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 1331, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 935, in _load_unlocked\r\n  File \"PyInstaller/loader/pyimod02_importers.py\", line 378, in exec_module\r\n  File \"litellm/cost_calculator.py\", line 24, in <module>\r\n  File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 1331, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 935, in _load_unlocked\r\n  File \"PyInstaller/loader/pyimod02_importers.py\", line 378, in exec_module\r\n  File \"litellm/utils.py\", line 113, in <module>\r\n  File \"importlib/resources/_legacy.py\", line 25, in wrapper\r\n  File \"importlib/resources/_legacy.py\", line 62, in open_text\r\n  File \"pathlib.py\", line 1013, in open\r\nFileNotFoundError: [Errno 2] No such file or directory: '/var/folders/j5/klw27nvj1q5dj27j0qcp1dc40000gq/T/_MEIyE29jr/litellm/llms/tokenizers/anthropic_tokenizer.json'\r\n```\r\n\r\nIt seems the build process is looking for a file (anthropic_tokenizer.json) that doesn't exist in the specified directory. Has anyone encountered this issue before, or can someone guide me toward a solution?\r\n\r\nThe build is done using pyinstaller,\r\n\r\nAny help would be greatly appreciated\r\n\r\n### Version and model info\r\n\r\n_No response_",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1125/comments",
    "author": "diopresi",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-08-19T19:04:08Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nI'm not sure I understand what you mean by \"trying to build a binary from the Aider codebase\". It is intended to be installed via `pip` or `pipx`."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-08-26T21:31:37Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open or file a new issue any time."
      }
    ]
  },
  {
    "number": 1121,
    "title": "Bug inside browser ",
    "created_at": "2024-08-18T20:46:29Z",
    "closed_at": "2024-08-26T21:31:29Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1121",
    "body": "### Issue\n\nWe can only undo last commit using browser and if we accidentally sent anything we can't undo from browser have to do it manually from terminal using commit id \n\n### Version and model info\n\n_No response_",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1121/comments",
    "author": "djfaizp",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-08-19T19:12:20Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nThe browser UI is experimental and doesn't support all the features of the CLI version."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-08-26T21:31:29Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open or file a new issue any time."
      }
    ]
  },
  {
    "number": 1107,
    "title": "Have you thought of using LSPs? ",
    "created_at": "2024-08-16T20:06:22Z",
    "closed_at": "2024-08-26T21:31:12Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1107",
    "body": "### Issue\n\n**Aider is fantastic, thank you for building it**\r\n\r\n*In case you haven't considered it, bringing it up*\r\n\r\nI wonder if Aider could use an LSP as a tool. Being able to do things like rename safely, and find all references could make changes much safer. \n\n### Version and model info\n\n_No response_",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1107/comments",
    "author": "idvorkin",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-08-19T19:20:54Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nPlease see the discussion in #527."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-08-26T21:31:12Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open or file a new issue any time."
      }
    ]
  },
  {
    "number": 1104,
    "title": "Feature request: Advanced Context Control and Branching Conversations",
    "created_at": "2024-08-16T12:45:19Z",
    "closed_at": "2024-08-26T21:30:56Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1104",
    "body": "### Issue\n\nOccasionally, especially with the new \"ask\" mode, I'd like the ability to clear only the last few messages (e.g. /clear \"last three messages\"). Additionally, I'd like to retry (/regenerate) a prompt. Interfaces like text-generation-webui and SillyTavern support this kind of functionality. It would be fantastic to have more control over the conversation history, enabling the user to manually fix errors that the LLM cannot resolve on its own (/edit). An even more advanced feature would be supporting branching conversations.\r\n\r\nI'm torn between thinking that this goes beyond the intended purpose of Aider and believing that this is a powerful and useful feature that would significantly enhance Aider's usability, potentially making it the only LLM UI I'd need. \n\n### Version and model info\n\n_No response_",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1104/comments",
    "author": "randoentity",
    "comments": [
      {
        "user": "grrowl",
        "created_at": "2024-08-16T13:25:21Z",
        "body": "+1, i find myself only wanting to preserve the last 2-3 turns of conversation. Otherwise I get the LLM to summarise and copy + clear + paste + continue, but it's cumbersome and the LLM loses fidelity of recent diffs."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-08-19T19:24:20Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nAider already automatically summarizes the longer past history. You don't need to manage that manually.\r\n\r\nIf aider gets stuck on a coding problem, the most pragmatic things to try are:\r\n\r\n1. `/clear` the conversation and just try again.\r\n2. `/drop` extra files from the chat to reduce distractions.\r\n3. Try a stronger LLM.\r\n4. Just code that part yourself and move on with aider for the next bit of work."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-08-26T21:30:56Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open or file a new issue any time."
      }
    ]
  },
  {
    "number": 1103,
    "title": "Feature: optionally enhance /ask with the option to redirect the LLM output (answer) to a file on disk",
    "created_at": "2024-08-16T11:19:17Z",
    "closed_at": "2024-08-26T21:31:53Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1103",
    "body": "### Issue\n\nIt is easier to read and manipulate large chunks of text/code inside files vs. to the terminal\r\n\r\nI use aider exclusively with the /ask and reading (or copy pasting) code from a file is easier compared with the terminal.\r\n\r\nFurther more a file called **_ask.txt_** or **_scratchpad.txt_** could be designated like this.\r\n\r\n_User's query comes above the separator (keep an empty line between the query and the separator)_\r\n\r\n--------------------------------------------------------------\r\n\r\n_LLM answer comes below the separator  (keep an empty line between the separator and the LLM answer)_\n\n### Version and model info\n\n_No response_",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1103/comments",
    "author": "distributev",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-08-19T18:16:03Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nAll the chat is logged to `.aider.chat.history.md`.\r\n"
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-08-26T21:31:53Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open or file a new issue any time."
      }
    ]
  },
  {
    "number": 1087,
    "title": "just upgraded and everything seemed messed up.",
    "created_at": "2024-08-14T17:05:11Z",
    "closed_at": "2024-08-26T21:20:24Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1087",
    "body": "### Issue\n\n1. seemed to get stuck a lot time\r\n2. lint issues a lot.\r\n3. 1 and 2 makes the code doesnt work anymore.\r\n\r\ni cant verify if it's upgraded issue. how to downgrade to previous upgrade?\n\n### Version and model info\n\nlatest aider",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1087/comments",
    "author": "sprappcom",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-08-19T18:07:14Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nWhen reporting problems, it is very helpful if you can provide:\r\n\r\n- Aider version\r\n- LLM model you are using\r\n- Any stack traces or error messages\r\n- A description of what you were doing when the error happened. \r\n\r\nIncluding the “announcement” lines that aider prints at startup is an easy way to share some of this helpful info.\r\n\r\n```\r\nAider v0.37.1-dev\r\nModels: gpt-4o with diff edit format, weak model gpt-3.5-turbo\r\nGit repo: .git with 243 files\r\nRepo-map: using 1024 tokens\r\n```\r\n"
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-08-26T21:20:24Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open or file a new issue any time."
      }
    ]
  },
  {
    "number": 1084,
    "title": "Add /document <filename> as another quick option",
    "created_at": "2024-08-14T13:58:13Z",
    "closed_at": "2024-08-26T21:20:16Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1084",
    "body": "### Issue\n\nContext:\r\nI'm watching a WatsonX webinar and they have a `/document @(filename)` function. This would be awesome to add as a new feature to Aider.\r\n\r\nStory:\r\nAs a user, I want to easily document/provide a summary of what this file does at the top of a file so that I can understand this file's intent later or bring colleagues up to speed quickly on a given codebase/project.\r\n\r\n* If this is the wrong place for feature requests just LMK\n\n### Version and model info\n\nAider 0.50 Model sonnet",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1084/comments",
    "author": "chhudson",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-08-19T18:05:06Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nYou should just be able to ask aider \"Please add documentation at the top of filename\"."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-08-26T21:20:16Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open or file a new issue any time."
      }
    ]
  },
  {
    "number": 1083,
    "title": "Bug GUI",
    "created_at": "2024-08-14T11:22:39Z",
    "closed_at": "2024-08-26T21:30:44Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1083",
    "body": "### Issue\n\nwhile using GUI if i lost data connection on browser it stop working, it should not dependent on user client browser.\n\n### Version and model info\n\n_No response_",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1083/comments",
    "author": "djfaizp",
    "comments": [
      {
        "user": "djfaizp",
        "created_at": "2024-08-14T11:43:26Z",
        "body": "Traceback (most recent call last):\r\n  File \"/home/ubuntu/.local/lib/python3.10/site-packages/tornado/websocket.py\",\r\nline 1090, in wrapper\r\n    raise WebSocketClosedError()\r\ntornado.websocket.WebSocketClosedError"
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-08-19T18:04:23Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nI'm not sure I understand the problem you are reporting. Can you describe it in more detail and provide an explanation of how to reproduce the issue?"
      },
      {
        "user": "djfaizp",
        "created_at": "2024-08-19T18:14:02Z",
        "body": "can you please provide contex how to log errors ?\r\n\r\nI'm running aider on VPS and using it with gui and connect to gui using ip:port \r\nwhile vps have solid internet connectivity but i have been using on mobile device and it loose connection sometimes. if my device loose connection it produces this error "
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-08-19T19:33:55Z",
        "body": "A screenshot would be fine. But I think you need to use aider in an environment where you can reliably connect the browser to the server."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-08-26T21:30:44Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open or file a new issue any time."
      }
    ]
  },
  {
    "number": 1079,
    "title": "Reverting to a Previous Commit Point",
    "created_at": "2024-08-14T01:34:13Z",
    "closed_at": "2024-08-26T21:31:45Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1079",
    "body": "### Issue\n\nAs a **beginner coder**, I find the backend components and their associated terminology challenging to grasp. Recently, I encountered an issue where the backend components created by Aider.chat did not work as expected. After providing the error details, the solution involved making numerous changes across various files. Unfortunately, these changes significantly altered the project, making it difficult to retain the original functionality.\r\n\r\n**I am seeking guidance on how to revert the project to a specific commit point that I was satisfied with.** This would help me explore alternative approaches to resolving issues without compounding the problems and potentially disrupting the entire project further.\r\n\r\n**Could you please provide recommendations on how to achieve this?** Is there a straightforward way to restore the project to a previous state using commit points, and how can this be managed effectively within Aider?\r\n\r\n**PS:** If there are any additional tools or extensions for Visual Studio Code that could assist with managing commit points and reverting changes, I would appreciate recommendations.\r\n\r\n**Summary:**\r\n\r\n- **Issue:** Extensive changes to the project when Aider tries to fix errors make it difficult to retain original functionality and harder to guide Aider.\r\n- **Request:** Seeking guidance on how to revert the project to a specific commit point.\r\n- **Question:** Is there a straightforward way to manage this in Aider or VS Code?\r\n\n\n### Version and model info\n\n_No response_",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1079/comments",
    "author": "PantaTransport",
    "comments": [
      {
        "user": "sholub89",
        "created_at": "2024-08-14T16:21:31Z",
        "body": "@PantaTransport , Aider has an `/undo` command that will take you back to the previous commit. If that isn't what you need - you can always checkout the specific commit before the Adier changes using `git checkout your-commit-here`. \r\nI personally use Aider with auto-commit Off, this helps me to see and validate all the changes before committing them. This way I can operate my project better "
      },
      {
        "user": "lawong888",
        "created_at": "2024-08-19T14:58:55Z",
        "body": "if you want a visual git history, use  \"gitk --all\"\r\n\r\nYou can look at the files changed, the time and date of that change, mark a tag so you know which commit was good before it went bad.  If you want to roll back, select the branch you want, right click on \"Reset master branch to here\", go a hard reset and it should go back completely to this branch.  But be careful, one you reset the master branch, there is no going back, so if you are worried, zip the whole folder as a backup, just in case you make a mistake."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-08-19T18:58:24Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nAider commits all changes to git. You can use your preferred git tools to undo or revert any or all of aider's changes. Aider provides a built in `/undo` command to simply step backwards through the latest aider commits and undo them."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-08-26T21:31:45Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open or file a new issue any time."
      }
    ]
  },
  {
    "number": 1071,
    "title": "possible to open a discussion tab in github?",
    "created_at": "2024-08-13T08:18:53Z",
    "closed_at": "2024-08-26T21:20:02Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1071",
    "body": "### Issue\r\n\r\n1. need discussion tab\r\n\r\n2. how do i limit what shld be in the repo map?\r\nit's always \"preparing repo-map\" and sometimes the files are not found. actually these files from vim *.sw* are deleted so actually i dont want it to be inside the repo map at all\r\n\r\n### Version and model info\r\n\r\n_No response_",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1071/comments",
    "author": "sprappcom",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-08-19T17:59:30Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nNext time you restart aider it should stop mentioning files which have disappeared. You should probably not add vim files to your git repo?"
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-08-26T21:20:02Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open or file a new issue any time."
      }
    ]
  },
  {
    "number": 1068,
    "title": "[Bug] \"/add\" command fails with \"--subtree-only\" option when searching for files",
    "created_at": "2024-08-13T01:47:44Z",
    "closed_at": "2024-08-20T02:22:49Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1068",
    "body": "### Issue\n\nWhen using Aider with the `--subtree-only` command line option, the `/add` command fails to add files when only the file name is provided, even though it correctly identifies matching files.\r\n\r\n## Steps to reproduce:\r\n1. Start Aider with the `--subtree-only` option\r\n2. Try to add a file using only its name with the `/add` command\r\n\r\n## Expected behavior:\r\nAider should search for the file within the allowed subtree and ask if I want to add it if found.\r\n\r\n## Actual behavior:\r\nAider identifies matching files but skips them, citing that they match an \"aiderignore spec\".\r\n\r\n## Example interaction:\r\n```\r\n> /add example_file.dart\r\n\r\nSkipping /path/to/project/subtree/example_file.dart that matches aiderignore spec.\r\n```\r\n\r\n## Additional information:\r\n- This behavior only occurs when the `--subtree-only` option is used.\r\n- The error message mentions an \"aiderignore spec\", which seems unrelated to the `--subtree-only` option.\n\n### Version and model info\n\nAider v.0.49.1",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1068/comments",
    "author": "go-run-jump",
    "comments": [
      {
        "user": "go-run-jump",
        "created_at": "2024-08-13T02:50:01Z",
        "body": "I think I might have misunderstood the functionality of using \"/add\" for a file name that it can't find exactly like that. It seems that it will then ask me to create a file. \r\n\r\nI think it would be nice if there was the kind of partial matching functionality after pressing enter. So we can just use the file name and work with that."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-08-19T17:58:45Z",
        "body": "Thanks for trying aider and filing this issue. The `/add` command will you you matches BEFORE you press enter. Use TAB to autocomplete from them."
      },
      {
        "user": "go-run-jump",
        "created_at": "2024-08-20T02:22:50Z",
        "body": "Thanks for taking the time to answer this. I think it makes sense how it is working right now and I could adapt my workflow so the reason why I was originally raising the issue doesn't really affect me anymore (there's a keyboard shortcut for copying the whole path of all marked files in the IntelliJ IDEs).\r\nMaybe it would make sense to have documented what exactly is the logic that is being followed by aider when using \"/add\"."
      }
    ]
  },
  {
    "number": 1054,
    "title": "bug: adding multiple files using the .aider.conf.yml does not work",
    "created_at": "2024-08-10T07:52:18Z",
    "closed_at": "2024-08-19T17:51:43Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1054",
    "body": "### Issue\r\n\r\n# Setup 1\r\n\r\nusing aider repo as a reference,\r\n\r\nhaving the content of `.aider.conf.yml` as:\r\n\r\n```yml\r\nfile: [aider/__main__.py aider/main.py requirements.txt]\r\n```\r\n\r\n## observed result\r\n\r\n```\r\n𝄞 aider\r\nAider v0.48.1\r\nModels: claude-3-5-sonnet-20240620 with diff edit format, weak model claude-3-haiku-20240307\r\nGit repo: .git with 303 files\r\nRepo-map: using 1024 tokens\r\nAdded aider/__main__.py aider/main.py requirements.txt to the chat.\r\nUse /help <question> for help, run \"aider --help\" to see cmd line args\r\n────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\naider/__main__.py aider/main.py requirements.txt                                                                                                                                                                                        \r\n> /tokens                                                                                                                                                                                                                               \r\n\r\nApproximate context window usage, in tokens:\r\n\r\n$ 0.0036    1,207 system messages                                  \r\n$ 0.0000       16 aider/__main__.py aider/main.py requirements.txt use /drop to drop from chat\r\n==================\r\n$ 0.0037    1,223 tokens total\r\n          198,777 tokens remaining in context window\r\n          200,000 tokens max context window size\r\n\r\n```\r\n\r\n## expected result\r\n\r\n```\r\n$ 0.0036    1,207 system messages   \r\n$ 0.0002       52 chat history      use /clear to clear\r\n$ 0.0029      983 repository map    use --map-tokens to resize\r\n$ 0.0001       28 aider/__main__.py use /drop to drop from chat\r\n$ 0.0134    4,458 aider/main.py     use /drop to drop from chat\r\n$ 0.0049    1,627 requirements.txt  use /drop to drop from chat\r\n==================\r\n$ 0.0251    8,355 tokens total\r\n          191,645 tokens remaining in context window\r\n          200,000 tokens max context window size\r\n\r\n```\r\n\r\n\r\n# Setup 2\r\n\r\nusing aider repo as a reference,\r\n\r\nhaving the content of `.aider.conf.yml` as:\r\n\r\n```yml\r\nfile: aider/__main__.py\r\nfile: aider/main.py\r\nfile: requirements.txt\r\n```\r\n\r\n## observed result\r\n```\r\n𝄞 aider\r\nAider v0.48.1\r\nModels: claude-3-5-sonnet-20240620 with diff edit format, weak model claude-3-haiku-20240307\r\nGit repo: .git with 303 files\r\nRepo-map: using 1024 tokens\r\nAdded requirements.txt to the chat.\r\nUse /help <question> for help, run \"aider --help\" to see cmd line args\r\n────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\nrequirements.txt                                                                                                                                                                                                                        \r\n> /tokens                                                                                                                                                                                                                               \r\n\r\nApproximate context window usage, in tokens:\r\n\r\n$ 0.0036    1,207 system messages  \r\n$ 0.0049    1,627 requirements.txt use /drop to drop from chat\r\n==================\r\n$ 0.0085    2,834 tokens total\r\n          197,166 tokens remaining in context window\r\n          200,000 tokens max context window size\r\n────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\nrequirements.txt \r\n```\r\n\r\n# Setup 3\r\n\r\nusing aider repo as a reference,\r\n\r\nhaving the content of `.aider.conf.yml` as:\r\n\r\n```yml\r\nfile: aider/__main__.py aider/main.py requirements.txt\r\n```\r\n## observed result\r\n\r\n```\r\n𝄞 aider\r\nAider v0.48.1\r\nModels: claude-3-5-sonnet-20240620 with diff edit format, weak model claude-3-haiku-20240307\r\nGit repo: .git with 303 files\r\nRepo-map: using 1024 tokens\r\nAdded aider/__main__.py aider/main.py requirements.txt to the chat.\r\nUse /help <question> for help, run \"aider --help\" to see cmd line args\r\n────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\naider/__main__.py aider/main.py requirements.txt                                                                                                                                                                                        \r\n> /tokens                                                                                                                                                                                                                               \r\n\r\nApproximate context window usage, in tokens:\r\n\r\n$ 0.0036    1,207 system messages                                  \r\n$ 0.0000       16 aider/__main__.py aider/main.py requirements.txt use /drop to drop from chat\r\n==================\r\n$ 0.0037    1,223 tokens total\r\n          198,777 tokens remaining in context window\r\n          200,000 tokens max context window size\r\n────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\naider/__main__.py aider/main.py requirements.txt\r\n```\r\n\r\n\r\n\r\n\r\n\r\n### Version and model info\r\n\r\n𝄞 aider\r\nAider v0.48.1\r\nModels: claude-3-5-sonnet-20240620 with diff edit format, weak model claude-3-haiku-20240307\r\nGit repo: .git with 303 files",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1054/comments",
    "author": "jerzydziewierz",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-08-10T11:10:45Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nAdd `file: CONVENTIONS.md` to .aider.conf.yml to always load a specific file.\nOr `file: [file1, file2, file3]` to always load multiple files.\n\nIt looks like you left out the commas?"
      },
      {
        "user": "jerzydziewierz",
        "created_at": "2024-08-13T22:43:50Z",
        "body": "I confirm that the convention\r\n```yaml\r\nfile: [file1, file2, file3] \r\n```\r\nworks correctly,\r\n\r\nstill, this being a yaml file,\r\nit is a bit surprising that the following yaml-correct conventions wouldn't work:\r\n\r\n```yaml\r\nfile: | \r\n  file1\r\n  file2\r\n  file3\r\n```\r\n\r\nor \r\n\r\n```yaml\r\nfile: !seq\r\n  - file1\r\n  - file2 \r\n  - file3\r\n```\r\n\r\nor \r\n```yaml\r\nfile:\r\n  - file1\r\n  - file2\r\n  - file3\r\n```\r\n\r\nin any case, the first one that does work, is already helpful, thanks. \r\n\r\n---\r\n\r\nhaving the multi-line version working would be neat because,\r\n\r\nover multiple days of work, one could store the relevant-file-lists along with the repo branch\r\n\r\nfor example, a desirable usage pattern would be:\r\n```bash\r\naider --load-file-list aider-filelist.md\r\n```\r\n\r\nor similar pattern \r\n\r\nso that the `aider-filelist.md` could be versioned, working nice with git-diff, and handed over to a colleague by itself\r\n\r\n( I do not insist on anything specific, merely looking for a practicality improvement )\r\n\r\nMoreover, notice that:\r\n* when in interactive mode, the loaded-file-list is not copy-pasteable into yaml file due to not having commas; \r\n* the output of \"/ls\" is also not easily copy-pasteable due into yaml file due to being the multi-line format AND having a space in front;\r\n\r\nMay I suggest that:\r\n*  the interactive-mode should show the files in the \"file:[file1, file2, file3] format so that it could be copy-pasted\r\n\r\n* the output of \"/ls\" could be made compatible with any of the yaml multiline formats \r\n\r\n\r\n\r\nhence -- feature request here? in a topic of \"QoL improvement for working-set file lists\"\r\n\r\n"
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-08-19T17:51:43Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open or file a new issue any time."
      }
    ]
  },
  {
    "number": 1053,
    "title": "[User Discussion] Seeking feedback on optimal Aider workflows",
    "created_at": "2024-08-10T07:31:14Z",
    "closed_at": "2024-08-19T17:53:06Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1053",
    "body": "### Issue\n\nAs a user of Aider for the past two weeks, I've found it to be a powerful tool, but I'm curious about how others are using it effectively. I believe we could all benefit from sharing our workflows and strategies. This discussion aims to gather insights from the community that might help improve our individual use of Aider and potentially provide valuable feedback for the Aider documentation.\r\n\r\nI'll start by sharing my current workflow, which I've been using exclusively with Claude 3.5 Sonnet on a Flutter project for a mobile app (the programming language in use is thus Dart):\r\n\r\n1. Decide on the feature:\r\n   - Determine the overall feature I want to be working on\r\n\r\n2. Determine sub-functionality scope:\r\n   - Trying to find the optimal size of the sub-functionality of the feature\r\n   - [Unsure] How to best determine this scope\r\n\r\n3. Initiate interaction:\r\n   - [Unsure] Whether to \"/ask\" the model first and then explain what parts of the answer should be implemented, or use the coding mode directly to try to achieve my goal\r\n   - If using coding mode, provide a detailed prompt\r\n\r\n4. Refine output:\r\n   - If the result isn't good, do \"/undo\" and try again with a more exact prompt\r\n   - [Unsure] Whether to use the \"/clear\" functionality\r\n     - Sometimes it picks up on stuff that had been in an earlier prompt where it delivered a blatantly wrong solution\r\n     - Previous context can sometimes be helpful\r\n\r\n5. Test and error handling:\r\n   - If there's a commit, try to see if it runs, if it compiles, or if there are errors and if the change really does what I was trying to achieve\r\n   - For complex errors: Put them into Aider\r\n   - For simple errors (e.g., missing semicolons, imports): Fix manually\r\n     - It's more likely that I can fix these things quickly, especially as they are pretty much being done in Android Studio by the IDE with very little problems\r\n   - Commit manual fixes with a \"manual\" commit message\r\n\r\n6. Iterate:\r\n   - Continue like this until the feature I'm trying to build is finished\r\n\r\n7. Review:\r\n   - Mark all the commits in Android Studios that had been done for that feature\r\n   - See what has really overall changed\r\n   - Either ask Aider to work on some issues that I discovered or fix stuff myself as well\r\n   - Continue like that until I'm satisfied with the overall change for the feature I'm working on\r\n\r\n8. Finalize:\r\n   - Copy all the commit messages that have been made by Aider\r\n   - Use the LLM and ask it for an appropriate commit message that sums up all these commit messages as one commit message\r\n   - Use the resulting commit message and personalize it to what I think is the appropriate message\r\n   - Squash everything that has been done to achieve that feature and in that session with that commit message\r\n   - In the end, there's only one commit\r\n\r\nKey uncertainties:\r\n- Optimal task scope for Aider\r\n- Whether to use \"/ask\" first or go directly into coding mode\r\n- Whether to use \"/clear\" or maintain context\r\n- Best practices for reviewing and refining Aider's output\r\n\r\nI'd love to hear about your Aider workflows! Please share:\r\n\r\n- Which model(s) you're using\r\n- Your typical project type (e.g., web development, data analysis, etc.)\r\n- Programming languages and frameworks being used\r\n- Your step-by-step process\r\n- Any tips or tricks you've discovered\r\n- Challenges you've faced and how you've overcome them\r\n- How you decide on the scope of tasks to give Aider\r\n- Strategies for reviewing and refining Aider's output\r\n\r\nYour insights will be invaluable in helping us all use Aider more effectively. They might also provide useful feedback to consider for the documentation or feature improvements.\r\n\r\nLet's learn from each other and optimize our Aider experiences!\n\n### Version and model info\n\n_No response_",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1053/comments",
    "author": "go-run-jump",
    "comments": [
      {
        "user": "nponeccop",
        "created_at": "2024-08-11T16:03:34Z",
        "body": "- you can use `/commit` to commit manual changes.\r\n- the squashing can in principle be automated using aider too. I ran an experiment of putting the outputs of `git log $base_rev --patch` and `git diff $base_rev into` files and using `/ask` to suggest the squashing and/or unrelated changes, basically \"to review the PR\".\r\n- You can `/add` some kind of `AIDER-README.md` so that aider understands the overall intent of the project, and you can use comments to supply extra context to aider automatically, e.g. JSDoc file overview comments. This is also useful to prevent aider from fixing things it repeatedly wants to fix (e.g. it thinks that `gpt4o-mini` is a typo meaning `gpt4o` because the model knows nothing about the new developments.\r\n- You can ask aider to suggest 2 improvements to a file and then ask to selectively implement them. The same technique can be used when planning.\r\n- For large features an impementation plan can be written by aider to `FOO-PLAN.md` or to the source comments. The big advantage of language models is that they are good at writing extensive plans and documentation. So you can essentially do the classical waterfall-style planning-design-implementation instead of the agile \"randomly grow by a single feature at a time\". Of course you need to find a balance, but my suggestion is that writing documentation and plans is more affordable now.\r\n- I used it for Bash, Ansible, Dockerfile and nodejs/js (non-web). I also did some experiments with Ragel (Only claude-3.5 is capable because of the obscurity of the language)\r\n- I treat LLMs as I would treat humans, according to their capacities. Claude is more capable than gpt4o, but in general I treat them as incapable juniors requiring micromanagement. I have seen humans with gpt4o-like capabilities, so it isn't hard for me. You essentially micromanage a junior, so I guess reading literature on how to manage teams of interchangeable idiots are very helpful to aid developers unfamiliar with the technical management to use LLMs efficiently."
      },
      {
        "user": "lockmeister",
        "created_at": "2024-08-12T07:56:23Z",
        "body": "I agree it would be great to have more discussion about people's workflows. I've looked on reddit etc to find a few ideas, but haven't found any great single place for info.\r\n\r\nI use aider in WSL \r\n\r\nCurrent methods\r\n- I use VSCode and run aider in a separate terminal with --no-auto-commits. With each change, I use diff mode in VSCode's git tool to review the changes. I use this to pick and choose rather than aider's /undo feature. It's also easier to read code than in the aider terminal interface. I commit every small change so that the diff view works, and I can easily unpick any problems.\r\n- I use ChatGPT and Claude web interface to iterate on small issues to avoid using up tokens with aider. I've already paid the fixed monthly subscription for the web interface so I might as well use it when I can rather than buying more tokens.\r\n- I carefully manage the context window, using /drop and /clear whenever possible.\r\n- I use /ask, sometimes having a discussion then asking it to produce a prompt for what we just discussed. \r\n- I use the /clipboard function to input screenshots of results and debugging sessions\r\n- I mainly use python, with type annotations and good comments/docstrings to help the context.\r\n- I add markdown files with specialist knowledge relating to the area I'm working on, including code examples\r\n- I use Sonnet 3.5, mainly through openrouter to avoid limits\r\n\r\nQuestions I still have:\r\n- how good is Cursor, is it complementary to aider or an alternative\r\n- I find that the LLM lacks context about some data structures. For example, working with pandas dataframes, and with databases. I get lots of errors relating to not understanding the dimensions and data types it is working with. I've tried to provide this context but I haven't yet got a good solution. I've also had problems with different date data types.\r\n\r\nIdeas I want to try\r\n- I haven't yet tried this but I was thinking of having aider edit a design doc iteratively rather than using the chat history to store requirements.\r\n- "
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-08-19T17:53:06Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open or file a new issue any time."
      }
    ]
  },
  {
    "number": 1051,
    "title": "[Feature Request] Output of /git commands added to the chat context",
    "created_at": "2024-08-10T00:56:22Z",
    "closed_at": "2024-08-11T23:45:15Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1051",
    "body": "### Issue\r\n\r\nAs far as I can tell the output of Aider `/git` commands is not added to the chat context. My use case is using the `/git` command to print a diff of a number of commits so I can ask Aider to make a Pull Request description for me based on the changes in my branch (whether I made those changes or Aider did). I tried my command first `/git diff main...branch` and then `/ask`ed Aider (Claude 3.5 Sonnet) to generate a PR based on the provided git diff but it told me I need to provide a diff first (hence my conclusion that /git output is not added to the chat context). My workaround has been running that command outside of aider and pasting it into the Aider CLI.\r\n\r\nAdding the /git output would be useful for multiple scenarios outside of PR description generation but hey if there was a nice Aider shortcut for generating PRs from my branch that would be nice too :) \r\n\r\n### Version and model info\r\n\r\nLatest (v0.48.1) and Claude 3.5 Sonnet via Vertex AI.",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1051/comments",
    "author": "zxkxyz",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-08-10T01:48:18Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nYou can do `/run git ...`"
      }
    ]
  },
  {
    "number": 1048,
    "title": "[Defect] Aider sets language to French by mistake during /ask command and continues with it. ",
    "created_at": "2024-08-09T20:09:08Z",
    "closed_at": "2024-08-10T00:37:42Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1048",
    "body": "### Issue\n\n```\r\n> /ask hello, how are you                                                                                                                                                     \r\n\r\nBonjour ! Je vais bien, merci. Comment puis-je vous aider aujourd'hui avec le code que vous m'avez montré ? Y a-t-il des questions spécifiques sur l'un des fichiers ou des   \r\nfonctionnalités que vous aimeriez discuter ?         \r\n```\r\n\r\nHere is my setup\r\n```\r\nAider v0.48.1\r\nModel: vertex_ai/claude-3-5-sonnet@20240620 with diff edit format\r\nGit repo: .git with 14 files\r\nRepo-map: using 1024 tokens\r\n```\n\n### Version and model info\n\n_No response_",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1048/comments",
    "author": "sholub89",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-08-09T20:19:17Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\nSonnet just likes to speak French. Aider specifically tells it your language as reported by the operating system. But sonnet sometimes ignores it, especially for small, casual non-coding messages like your example. \n\n"
      },
      {
        "user": "sholub89",
        "created_at": "2024-08-09T20:24:20Z",
        "body": "Got it.\r\nI found it nearly impossible to make it switch to English for subsequent messages :) \r\nRestarting the Aider helps. \r\nSince it is a known issue and is on the LLM level - please consider closing this ticket."
      }
    ]
  },
  {
    "number": 1039,
    "title": "I still cant use vertex ai same issue as #993",
    "created_at": "2024-08-08T22:29:00Z",
    "closed_at": "2024-08-26T21:29:38Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1039",
    "body": "### Issue\r\n\r\nWhen i tried to use vertex ai with sonnet with the following command: \r\n`aider --model vertex_ai/claude-3-5-sonnet@20240620` \r\nI am getting this error \r\n```BadRequestError: litellm.BadRequestError: VertexAIException BadRequestError - \r\nvertexai import failed please run `pip install -U google-cloud-aiplatform \r\n\"anthropic[vertex]\"```\r\n\r\n### Version and model info\r\n\r\n_No response_\r\n\r\nI have already ran that specific pip install command \r\n",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1039/comments",
    "author": "kanishkave",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-08-09T18:15:12Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nHow did you originally install aider? What command did you use?\r\n\r\nThat may affect how to install the google cloud packages."
      },
      {
        "user": "kanishkaverma",
        "created_at": "2024-08-12T03:30:17Z",
        "body": "I used pip install aider-chat "
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-08-19T17:54:27Z",
        "body": "This appears to be a problem with your local python environment. The best thing might be to start with a clean python virtual environment and try installing both again:\r\n\r\n```\r\npip install aider-chat\r\npip install -U google-cloud-aiplatform \"anthropic[vertex]\"\r\n```"
      },
      {
        "user": "shane-graham",
        "created_at": "2024-08-20T19:02:28Z",
        "body": "For anyone utilizing Google Vertex AI to access the Anthropic models, note that only two GCP regions are supported:  us-east5 and europe-west1.  I missed that detail and it took some time to figure out the issue."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-08-26T21:29:38Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open or file a new issue any time."
      }
    ]
  },
  {
    "number": 1030,
    "title": "Feature request",
    "created_at": "2024-08-08T07:21:08Z",
    "closed_at": "2024-08-19T17:56:03Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1030",
    "body": "### Issue\n\nFor us poor guys who run Ollama...... we are mostly limited to the smaller models, the 7b and 8b models.\r\nI have tried to develop an App and Aider bombed out after the limit of iterations has been reached and could not get further.\r\nA possible solution would be to have a list of available models and then, when the limit is reached, the model can be automatically changed and the possible loop resolved.\r\nThis can even be of value to online service providers because non is 100% perfect and also gets into loops, That is my experience also with Claude, ChatGPT and Deepcoder. I sometimes have to switch between them to resolve a loop.\r\nIf you have the time can you please implement such a feature?\n\n### Version and model info\n\n_No response_",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1030/comments",
    "author": "DRomatzki",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-08-09T18:16:32Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nUnfortunately, the local quantized ollama 7-8b models are probably not capable enough to follow aider's system prompt."
      },
      {
        "user": "DRomatzki",
        "created_at": "2024-08-10T13:20:58Z",
        "body": "Yes and no. \r\nFirst off .....\r\nI have been using the following for free: claude. chatgpt, deepseek coder V2 and even perplexity. I have experienced loops in all of them, What I then do is just copy the code from service provider/model to the next and continue. Claude was the best, then deepseekcode and chatgpt where midlevel and perplexity is not usefull but for simple questions. But all had loops and could not complete some code. That was using for nodejs and typescrypt code.\r\nI did try to use aider with Ollama with deepseekcoder V2 and llama3 with limited success. However, I believe there are models that can be fine tuned for coding and reach better results, even at 7B or 8B. I am going to try the finetuning option if I can find a dataset to use for, say, javascrypt or something.\r\nEven if you consider the 7B and 8B models insufficient, such a feature will benefit others using the online bigger models.\r\nBut that is just my 2 cents .....\r\nBut I must say.... Aider is great and you did a great job......"
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-08-19T17:56:03Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open or file a new issue any time."
      }
    ]
  },
  {
    "number": 1029,
    "title": "permission issue on macos",
    "created_at": "2024-08-08T07:20:08Z",
    "closed_at": "2024-08-10T00:01:05Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1029",
    "body": "### Issue\n\nHi, I'm using with openrouter, on macos.\r\n\r\n```\r\n(base) ➜  lib git:(main) ✗ aider --model openrouter/anthropic/claude-3.5-sonnet                                               \r\n\r\nAider v0.48.1\r\nModels: openrouter/anthropic/claude-3.5-sonnet with diff edit format, weak model openrouter/anthropic/claude-3-haiku-20240307\r\nGit repo: ../.git with 403 files\r\nRepo-map: using 1024 tokens\r\nVSCode terminal detected, pretty output has been disabled.\r\nUse /help <question> for help, run \"aider --help\" to see cmd line args\r\nNote: in-chat filenames are always relative to the git working dir, not the current working dir.\r\nCur working dir: /Users/mirkan/Documents/Startups/[PROJECT_NAME]/[PROJECT_NAME]_app/lib\r\nGit working dir: /Users/mirkan/Documents/Startups/[PROJECT_NAME]/[PROJECT_NAME]_app\r\n─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n> find `lib/chat/view/chat_page.dart` add a small text under it, says `hello world`                                                                      \r\n\r\nlib/chat/view/chat_page.dart\r\nAdd these files to the chat? y\r\nCertainly! I'll add the \"hello world\" text under the import statements in the lib/chat/view/chat_page.dart file. Here's the SEARCH/REPLACE block to make \r\nthis change:                                                                                                                                             \r\n\r\nlib/chat/view/chat_page.dart                                                                                                                             \r\n\r\n                                                                                                                                                         \r\n <<<<<<< SEARCH                                                                                                                                          \r\n import 'package:lottie/lottie.dart';                                                                                                                    \r\n =======                                                                                                                                                 \r\n import 'package:lottie/lottie.dart';                                                                                                                    \r\n                                                                                                                                                         \r\n // hello world                                                                                                                                          \r\n >>>>>>> REPLACE                                                                                                                                         \r\n                                                                                                                                                         \r\n\r\nThis change adds the \"hello world\" comment right after the import statements in the file.                                                                \r\n\r\n\r\nTokens: 10,675 sent, 101 received. Cost: $0.03 request, $0.03 session.\r\nException while updating files:\r\n[Errno 13] Permission denied: '/Users/mirkan/Documents/Startups/[PROJECT_NAME]/[PROJECT_NAME]_app/lib/chat/view/chat_page.dart'\r\nTraceback (most recent call last):\r\n  File \"/Users/mirkan/miniconda3/lib/python3.11/site-packages/aider/coders/base_coder.py\", line 1496, in apply_updates\r\n    edited = self.update_files()\r\n             ^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/mirkan/miniconda3/lib/python3.11/site-packages/aider/coders/base_coder.py\", line 1491, in update_files\r\n    self.apply_edits(edits)\r\n  File \"/Users/mirkan/miniconda3/lib/python3.11/site-packages/aider/coders/editblock_coder.py\", line 45, in apply_edits\r\n    self.io.write_text(full_path, new_content)\r\n  File \"/Users/mirkan/miniconda3/lib/python3.11/site-packages/aider/io.py\", line 217, in write_text\r\n    with open(str(filename), \"w\", encoding=self.encoding) as f:\r\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nPermissionError: [Errno 13] Permission denied: '/Users/mirkan/Documents/Startups/[PROJECT_NAME]/[PROJECT_NAME]_app/lib/chat/view/chat_page.dart'\r\nI apologize for the confusion. It seems there might be a permission issue with directly editing the file. Let's try a different approach. Instead of     \r\nmodifying the file directly, I'll provide you with the SEARCH/REPLACE block that you can manually apply to the file. Here's the corrected SEARCH/REPLACE \r\nblock:                                                                                                                                                   \r\n\r\nlib/chat/view/chat_page.dart\r\n```\n\n### Version and model info\n\nAider v0.48.1\r\nModels: openrouter/anthropic/claude-3.5-sonnet with diff edit format, weak model openrouter/anthropic/claude-3-haiku-20240307\r\nGit repo: ../.git with 403 files\r\nRepo-map: using 1024 tokens",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1029/comments",
    "author": "mirkancal",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-08-09T18:17:34Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nLooks like you asked aider to edit a file that your user account doesn't have permission to edit."
      },
      {
        "user": "mirkancal",
        "created_at": "2024-08-10T00:01:05Z",
        "body": "Thank you, yes, even though I was able to use cursor, vscode, something was off. fixed by few chmod commands. Closing."
      }
    ]
  },
  {
    "number": 1028,
    "title": "Split aider repo into client and server parts",
    "created_at": "2024-08-07T23:22:16Z",
    "closed_at": "2024-08-09T18:27:36Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1028",
    "body": "### Issue\n\nHey guys. I guess it would be a great idea to split repository into backend and frontend side, where backend would be a manager process as a small http/socket server handling everything for prompts, LLM conversations, git interactions and so on. Basically it would be a server for 2 main reasons: streaming outputs and receiving inputs. \r\nClient will be the same CLI, but it will work via local stream instead of in-process conversations between functions.\r\n \r\nWe can open the way to create plugins and additions on top of aider making it possible to work with from browser and even telegram bots/mobile apps (sounds very futuristic but anyway)\n\n### Version and model info\n\n_No response_",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1028/comments",
    "author": "Alexxosipov",
    "comments": [
      {
        "user": "Alexxosipov",
        "created_at": "2024-08-07T23:25:56Z",
        "body": "The simplest usecase: I would like to build laravel error page integration with aider that will send laravel error to aider that is working in laravel repository, so user can see bugfix process on the page"
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-08-08T15:03:04Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nYou may be able to make a small cli script that prints out the laravel errors. Then you can `/run show-laravel-errors` to include it into the aider chat."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-08-09T18:27:36Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open or file a new issue any time."
      }
    ]
  },
  {
    "number": 1024,
    "title": "Do files need to be /drop then /add after a big change in git?",
    "created_at": "2024-08-07T10:54:36Z",
    "closed_at": "2024-08-08T00:13:11Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1024",
    "body": "### Issue\n\nWhen I checkout a commit in git and there is a significant change to a file, does it need to be /drop then /add back in, or is it automatically updated to the latest code?\n\n### Version and model info\n\nAider: latest\r\nLLM: Sonnet 3.5",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1024/comments",
    "author": "lockmeister",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-08-07T15:56:12Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nNo, aider always uses the latest versions of files."
      },
      {
        "user": "lockmeister",
        "created_at": "2024-08-08T00:13:11Z",
        "body": "great, thanks!"
      }
    ]
  },
  {
    "number": 1013,
    "title": "Allow to using only gpt-4o-min without gpt-4o for complex questions or not.",
    "created_at": "2024-08-06T01:18:10Z",
    "closed_at": "2024-08-07T16:03:40Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1013",
    "body": "### Issue\r\n\r\nSuggestion\r\n\r\nI think you did use gpt-4o-min for simple question alternating with gpt-4o for more complex questions, but it may cost more X20 or X30 than gpt-4o-mini.\r\nPlease, give us the option to not alternate.\r\n\r\n### Version and model info\r\n\r\nLatest update",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1013/comments",
    "author": "onigetoc",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-08-06T10:36:51Z",
        "body": "Use --model and --weak-model to choose the 2 models that aider uses. You can make them the same if you'd like. "
      },
      {
        "user": "onigetoc",
        "created_at": "2024-08-06T22:04:40Z",
        "body": "Merci pour ta préponse.\r\n\r\nEn passant, je regarde ton nom. Est-tu francophone?\r\nSurtout en plus avec le nom Aider également. \r\n- Du Québec ;)"
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-08-06T22:27:44Z",
        "body": "Mon nom vient certainement du Québec, mais je ne parle pas beaucoup français."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-08-07T16:03:40Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open or file a new issue any time."
      }
    ]
  },
  {
    "number": 1010,
    "title": "Webversion: GIT-stuff",
    "created_at": "2024-08-05T17:22:40Z",
    "closed_at": "2024-08-07T16:03:21Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1010",
    "body": "### Issue\n\nThe following is shown in the console, but it is never mentioend int he web GUI: On the contrary it reports all changes were done there.\r\n\r\n**\r\nCommitting config.py before applying edits.\r\n**Cmd('git') failed due to: exit code(128)\r\n  cmdline: git add /Users/S/config.py\r\n  stderr: 'fatal: Unable to create '/Users/S/.git/index.lock': File exists.**\r\n\r\nAnother git process seems to be running in this repository, e.g.\r\nan editor opened by 'git commit'. Please make sure all processes\r\nare terminated then try again. If it still fails, a git process\r\nmay have crashed in this repository earlier:\r\nremove the file manually to continue.'\n\n### Version and model info\n\naider 0.47.1, OSX\r\ngit version 2.39.3 (Apple Git-145)",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1010/comments",
    "author": "ophoria",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-08-06T10:39:56Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nIt looks like your git repo may be corrupted. Or maybe you were using aider to edit your repo at the same time as some other git tool?"
      },
      {
        "user": "ophoria",
        "created_at": "2024-08-06T12:33:44Z",
        "body": "You're right - it was VSCode :)  What I'd wish for however is for the message _that it happened_ would appear in the webversion also and not only in the console window. (Or is that text actually output by GIT and not aider?)"
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-08-07T16:03:21Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open or file a new issue any time."
      }
    ]
  },
  {
    "number": 1009,
    "title": "Overriding disabled pretty output due to VSCode terminal detection",
    "created_at": "2024-08-05T14:13:53Z",
    "closed_at": "2024-08-09T18:25:23Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1009",
    "body": "### Issue\n\nHello,\r\n\r\nI'm not sure if this is a new behavior, but I've noticed that when I use aider from the terminal a lot of the time, it says `VSCode terminal detected, pretty output has been disabled.`.  My daily workflow involves having my plaintext notes always open in VSCode. I do not have the VSCode terminal open. I get a lot of value from the pretty output formatting in Aider -- is there a way to override pretty output being disabled when VSCode is also open? Any help would be appreciated. Thanks.\n\n### Version and model info\n\nAider v0.47.1",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1009/comments",
    "author": "masonc15",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-08-07T15:50:17Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nAider checks if it is running inside the VS Code terminal by looking for `VSCODE_GIT_IPC_HANDLE`. Do you have that set in your non-vscode terminals too?"
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-08-09T18:25:23Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open or file a new issue any time."
      },
      {
        "user": "besler-wwright",
        "created_at": "2024-11-23T11:11:25Z",
        "body": "Hi @paul-gauthier . \r\n\r\nI too have this issue. I actually have some python scripts that launch aider from a PowerShell instance I am spinning up on demand from my voice activated assistant.  I would like it if the --pretty or if the environment AIDER_PRETTY=true where respected even when VS Code is detected. "
      }
    ]
  },
  {
    "number": 1008,
    "title": "The benchmark test encountered a problem",
    "created_at": "2024-08-05T12:37:19Z",
    "closed_at": "2024-08-07T15:58:55Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1008",
    "body": "### Issue\n\ndirname: 2024-08-05-18-58-25--test2\r\n  test_cases: 27\r\n  model: ourModel\r\n  edit_format: whole\r\n  commit_hash: c45688c-dirty\r\n  pass_rate_1: 25.9\r\n  pass_rate_2: 33.3\r\n  percent_cases_well_formed: 100.0\r\n  **error_outputs: 10**\r\n  num_malformed_responses: 0\r\n  num_with_malformed_responses: 0\r\n  **user_asks: 9**\r\n  lazy_comments: 0\r\n  syntax_errors: 0\r\n  indentation_errors: 0\r\n  exhausted_context_windows: 0\r\n  **test_timeouts: 2**\r\n  command: aider --model ourModel\r\n  date: 2024-08-05\r\n  versions: 0.47.2-dev\r\n  seconds_per_case: 173.1\r\n  total_cost: 0.9951\r\n\r\nThe status will be printed all the time during the test. I found that sometimes the values ​​**error_outputs: 10** **user_asks: 9** will increase. The model I use is my own local model, which is written in the form of API in imitation of the format of OpenAI GPT. Under what circumstances will these two values ​​increase? What does it mean?\r\n\r\nThank you for your help, looking forward to your answer!\n\n### Version and model info\n\n_No response_",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1008/comments",
    "author": "WentaoTan",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-08-05T14:29:27Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nYou would have to check the logs for your benchmark, and the source code for the benchmarking tool to really figure out what triggered those counters to increment. They go up if aider outputs error messages (in red) or asks the \"user\" a question."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-08-07T15:58:55Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open or file a new issue any time."
      }
    ]
  },
  {
    "number": 1002,
    "title": "Add third party git repo information to chat",
    "created_at": "2024-08-05T01:53:29Z",
    "closed_at": "2024-08-07T10:51:56Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/1002",
    "body": "### Issue\n\nWhen working with a less well known codebase, LLMs can be inaccurate or have out-of-date information.\r\nIt would be good to be able to add a map of that repo to the current chat, so that coding suggestions from the LLM are improved.\r\n\r\nMy current solution is to add some information using the /web scraper, but the git repo mapping seems pretty good and it would be nice to extend this.\n\n### Version and model info\n\nAider version: Latest\r\nLLM: Claude Sonnet 3.5",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/1002/comments",
    "author": "lockmeister",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-08-05T14:24:52Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nYou can make a repo map of one repo with:\r\n\r\n```\r\naider --show-repo-map > repomap.md\r\n```\r\n\r\nAnd then add that file to the other repo."
      },
      {
        "user": "lockmeister",
        "created_at": "2024-08-07T10:52:09Z",
        "body": "handy, thanks!"
      }
    ]
  },
  {
    "number": 998,
    "title": "deepseek/coder suggests only how to edit the files but doesnt edit it directly. how to make it edit the files and make changes directly on the files?",
    "created_at": "2024-08-04T01:10:35Z",
    "closed_at": "2024-08-07T16:03:11Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/998",
    "body": "### Issue\n\nas titled\n\n### Version and model info\n\nlatest\r\ndeepseek/deepseek-coder",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/998/comments",
    "author": "sprappcom",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-08-05T14:20:45Z",
        "body": "When reporting problems, it is very helpful if you can provide:\r\n\r\n- Aider version\r\n- LLM model you are using\r\n- Any stack traces or error messages\r\n- A description of what you were doing when the error happened. \r\n\r\nIncluding the “announcement” lines that aider prints at startup is an easy way to share some of this helpful info.\r\n\r\n```\r\nAider v0.37.1-dev\r\nModels: gpt-4o with diff edit format, weak model gpt-3.5-turbo\r\nGit repo: .git with 243 files\r\nRepo-map: using 1024 tokens\r\n```"
      },
      {
        "user": "99cv",
        "created_at": "2024-08-06T07:10:03Z",
        "body": "I can confirm.\r\n\r\nRunning `aider --model deepseek/deepseek-coder`\r\n\r\nwith\r\n```\r\nAider v0.47.1\r\nModel: deepseek/deepseek-coder with diff edit format\r\nGit repo: .git with 463 files\r\nRepo-map: using 1024 tokens\r\n```\r\n\r\nand having two files added to context:\r\n`99c_target/imports/ui/App.vue 99c_target/imports/ui/Login.vue`\r\n\r\nand giving the following prompt:\r\n\r\n> change the code to make `99c_target/imports/ui/Login.vue` the entry point of the app                                                                                                       \r\n\r\nmakes aider only giving suggestions instead of changing the code:\r\n```\r\nTo make 99c_target/imports/ui/Login.vue the entry point of your Vue.js application, we need to configure the router to use this component as the default route. Since you've added           \r\n99c_target/imports/ui/App.vue to the chat, we can proceed with the necessary changes.                                                                                                        \r\n\r\nLet's assume you have a router configuration file (router.js or index.js) that we need to update. If you don't have one, please let me know, and I'll guide you through creating it.         \r\n\r\nExample router.js or index.js (if you have one)                                                                       \r\n\r\n                                                                                                                                                                                             \r\n // router/index.js or router.js                                                                                                                                                             \r\n import { createRouter, createWebHistory } from 'vue-router';                                                                                                                                \r\n import Login from '99c_target/imports/ui/Login.vue';                                                                                                                                        \r\n                                                                                                                                                                                             \r\n const routes = [                                                                                                                                                                            \r\n   {                                                                                                                                                                                         \r\n     path: '/',                                                                                                                                                                              \r\n     name: 'Login',                                                                                                                                                                          \r\n     component: Login                                                                                                                                                                        \r\n   }                                                                                                                                                                                         \r\n   // Add other routes here if needed                                                                                                                                                        \r\n ];                                                                                                                                                                                          \r\n                                                                                                                                                                                             \r\n const router = createRouter({                                                                                                                                                               \r\n   history: createWebHistory(),                                                                                                                                                              \r\n   routes                                                                                                                                                                                    \r\n });                                                                                                                                                                                         \r\n                                                                                                                                                                                             \r\n export default router;                                                                                                                                                                      \r\n                                                                                                                                                                                             \r\n\r\nUpdate main.js or main.ts                                                                                  \r\n\r\nEnsure your main entry file (main.js or main.ts) imports and uses the router configuration:                                                                                                  \r\n\r\n                                                                                                                                                                                             \r\n // main.js or main.ts                                                                                                                                                                       \r\n import { createApp } from 'vue';                                                                                                                                                            \r\n import App from './App.vue';                                                                                                                                                                \r\n import router from './router'; // Adjust the path according to your project structure                                                                                                       \r\n                                                                                                                                                                                             \r\n createApp(App)                                                                                                                                                                              \r\n   .use(router)                                                                                                                                                                              \r\n   .mount('#app');                                                                                                                                                                           \r\n                                                                                                                                                                                             \r\n createApp(App)                                                                                                                                                                              \r\n   .use(router)                                                                                                                                                                              \r\n   .mount('#app');                                                                                                                                                                           \r\n                                                                                                                                                                                             \r\n\r\nEnsure App.vue uses the router\r\n```\r\n\r\nEven telling aider explicitly to change into `/chat-mode code` or use `change code directly` in the prompt did not change the behaviour."
      },
      {
        "user": "sprappcom",
        "created_at": "2024-08-06T07:17:03Z",
        "body": "@99cv @paul-gauthier thx"
      },
      {
        "user": "leanit-piotr",
        "created_at": "2024-08-06T10:45:27Z",
        "body": "I have the same issue. it does not build files at all with Aider. It just tells you what to do. I hope it gets fixed quite soon. 🤞 "
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-08-06T11:11:42Z",
        "body": "You can try using `--edit-format whole`"
      },
      {
        "user": "leanit-piotr",
        "created_at": "2024-08-06T11:18:21Z",
        "body": "It seems I have found a work-around. At least it worked now once with another terminal. Please check guys if this isn't the problem with the built in VS Code terminal. In the standard command line all works as expected it seems...\r\n\r\nUpdate:\r\n- checked again and it seems it depends on the size/complexity of the prompt. It's weird, but it looks like more complex prompts are just forwarded to chat only and \"no action\" mode and simple prompts are executed correctly."
      },
      {
        "user": "99cv",
        "created_at": "2024-08-06T11:55:08Z",
        "body": "@leanit-piotr \r\nI never use aider in the vs code terminal. So the issue occured in normal terminal in zsh shell as well.\r\nMy last task was to change just one line (finally just for testing purposes) in one file and aider with model deepseek/deepseek-coder was still just dropping suggestions instead of \"doing the work\".\r\n\r\n@paul-gauthier \r\nwith option `--edit-format whole` aider is doing changes again with model deepseek/deepseek-coder!\r\nThanks!\r\n"
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-08-07T16:03:11Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open or file a new issue any time."
      }
    ]
  },
  {
    "number": 990,
    "title": "/ask command creates empty files without previous request",
    "created_at": "2024-08-02T17:34:32Z",
    "closed_at": "2024-08-07T16:15:27Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/990",
    "body": "### Issue\r\n\r\nUsing the `/ask` command creates unwanted empty files: \r\n\r\n```bash\r\n> /ask are you aware of TheGraph, the blockchain tool for querying with GraphQL?                                                                                                                                                 \r\n\r\nCreating empty file database-sequelize/models/Prompt.ts\r\nCreating empty file database-sequelize/models/Round.ts\r\nCreating empty file database-sequelize/models/RoundResult.ts\r\nCreating empty file database-sequelize/models/TextToImg.ts\r\nCreating empty file database-sequelize/models/User.ts\r\nCreating empty file database-sequelize/models/index.ts\r\nCreating empty file database-sequelize/package.json\r\nCreating empty file database-sequelize/tests/promptwars-round.ts\r\nCreating empty file database-sequelize/tsconfig.json\r\n```\r\n\r\nI did add those files with `/add`, but Aider used the added files to create them again, without request and under the `/ask` command 🤔, which shouldn't edit files in the first place.\r\n\r\n\r\n\r\n\r\n### Version and model info\r\n\r\nUsing Aider 24.0+ in Python 3.12.4, MacOS, Claude Sonnet ` claude-3-5-sonnet-20240620`.",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/990/comments",
    "author": "netpoe",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-08-05T14:08:02Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nCan you share the announce lines that show the aider version. I don't know what you mean by \"Aider 24.0+\", as that is not a valid aider version number.\r\n\r\nIt's possible that you are using an old version with a bug which has been fixed already in the latest version."
      },
      {
        "user": "netpoe",
        "created_at": "2024-08-05T14:50:20Z",
        "body": "> Thanks for trying aider and filing this issue.\r\n> \r\n> Can you share the announce lines that show the aider version. I don't know what you mean by \"Aider 24.0+\", as that is not a valid aider version number.\r\n> \r\n> It's possible that you are using an old version with a bug which has been fixed already in the latest version.\r\n\r\nYeah, sorry about that: \r\n\r\n```\r\n> Aider v0.47.1  \r\n> Models: claude-3-5-sonnet-20240620 with diff edit format, weak model claude-3-haiku-20240307  \r\n```"
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-08-07T16:00:19Z",
        "body": "I can't reproduce this on v0.48. Are you able to reproduce it on the latest version?"
      },
      {
        "user": "netpoe",
        "created_at": "2024-08-07T16:14:39Z",
        "body": "I just installed the version. I'll keep using it and see if the error pops out again. Thx for following up. You may close this issue for now.\r\n\r\nBTW. Aider has been the most useful AI app for coding yet, and I've tried a lot (if not all) of them! "
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-08-07T16:15:27Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open or file a new issue any time."
      },
      {
        "user": "jamsilver",
        "created_at": "2025-02-04T17:30:08Z",
        "body": "FYI: I faced a similar issue to this because I'd somehow managed to paste a garbage string into the middle of my `~/.aider.conf.yml`. My config file was based on the sample and looked something like this (I've removed irrelevant parts with `...<snip>...`):\n\n```\n##########################################################\n# Sample .aider.conf.yml\n\n ...<snip>...\n\n########################\n# API Keys and settings:\n\n## Specify the OpenAI API key\nopenai-api-key: ...<snip>...\n\n ...<snip>...\n\n## Specify the aider ignore file (default: .aiderignore in git root)\n#aiderignore: .aiderignore\npip install ra-aidepo is found dirty (default: True)\n#dirty-commits: true\n\n ...<snip>...\n\n```\n\nEvery time I started `aider` it created a new file in my repo root with the bizarre name `pip install ra-aidepo is found dirty (default: True)`\n\nIt looks to me that aider parsed this yaml file and interpreted that invalid top-line garbage string as the name of a file in its `read:` array. So on boot it added it to the chat, which caused it to be auto-created.\n\nThat should probably be considered a bug as it is a rather unexpected way to interpret an invalid top-level key in the yaml!\n\nIt would probably be better if aider validated yaml config files against a schema and rejected unrecognised top-level strings."
      }
    ]
  },
  {
    "number": 989,
    "title": "Should ignore space(s) in front of /in-chat commands ",
    "created_at": "2024-08-02T17:15:48Z",
    "closed_at": "2024-08-07T15:57:54Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/989",
    "body": "### Issue\n\n/in-chat commands are great but if I accidentally added space(s) in front of the / commands, the application passes it to the LLM and waste some tokens giving some random answers.   It would be good if those leading spaces were ignored (stripped) when encountering a \"/\"as the first character in the command line?\n\n### Version and model info\n\nAider v0.47.1\r\nModels: claude-3-5-sonnet-20240620 with diff edit format, weak model claude-3-haiku-20240307\r\nGit repo: .git with 15 files\r\nRepo-map: using 1024 tokens",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/989/comments",
    "author": "lawong888",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-08-05T14:05:47Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nI think there's a pretty strong argument to keep things the way they are. This way you can start a chat message with slash, as long as you put some whitespace in front of it."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-08-07T15:57:54Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open or file a new issue any time."
      }
    ]
  },
  {
    "number": 984,
    "title": "Aider launch failure with VPN on",
    "created_at": "2024-08-02T01:09:37Z",
    "closed_at": "2024-08-07T15:58:17Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/984",
    "body": "### Issue\n\nI must use VPN. When I launch aider with VPN on, I got the following error message:\r\n```\r\nTraceback (most recent call last):\r\n  File \"/opt/AER/aider/bin/aider\", line 8, in <module>\r\n    sys.exit(main())\r\n             ^^^^^^\r\n  File \"/opt/AER/aider/lib/python3.11/site-packages/aider/main.py\", line 453, in main\r\n    main_model = models.Model(args.model, weak_model=args.weak_model)\r\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/AER/aider/lib/python3.11/site-packages/aider/models.py\", line 393, in __init__\r\n    res = self.validate_environment()\r\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/AER/aider/lib/python3.11/site-packages/aider/models.py\", line 576, in validate_environment\r\n    res = litellm.validate_environment(model)\r\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/AER/aider/lib/python3.11/site-packages/aider/llm.py\", line 17, in __getattr__\r\n    self._load_litellm()\r\n  File \"/opt/AER/aider/lib/python3.11/site-packages/aider/llm.py\", line 24, in _load_litellm\r\n    self._lazy_module = importlib.import_module(\"litellm\")\r\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/dabajabaza/anaconda3/lib/python3.11/importlib/__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"<frozen importlib._bootstrap>\", line 1204, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 1176, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 1147, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 690, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\r\n  File \"/opt/AER/aider/lib/python3.11/site-packages/litellm/__init__.py\", line 261, in <module>\r\n    module_level_aclient = AsyncHTTPHandler(timeout=request_timeout)\r\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/AER/aider/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py\", line 30, in __init__\r\n    self.client = self.create_client(\r\n                  ^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/AER/aider/lib/python3.11/site-packages/litellm/llms/custom_httpx/http_handler.py\", line 48, in create_client\r\n    return httpx.AsyncClient(\r\n           ^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/AER/aider/lib/python3.11/site-packages/httpx/_client.py\", line 1429, in __init__\r\n    proxy_map = self._get_proxy_map(proxies or proxy, allow_env_proxies)\r\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/AER/aider/lib/python3.11/site-packages/httpx/_client.py\", line 217, in _get_proxy_map\r\n    return {\r\n           ^\r\n  File \"/opt/AER/aider/lib/python3.11/site-packages/httpx/_client.py\", line 218, in <dictcomp>\r\n    key: None if url is None else Proxy(url=url)\r\n                                  ^^^^^^^^^^^^^^\r\n  File \"/opt/AER/aider/lib/python3.11/site-packages/httpx/_config.py\", line 336, in __init__\r\n    raise ValueError(f\"Unknown scheme for proxy URL {url!r}\")\r\nValueError: Unknown scheme for proxy URL URL('socks://127.0.0.1:12377/')\r\n\r\n```\n\n### Version and model info\n\naider 0.47.1\r\nubuntu 24.04\r\n\r\n",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/984/comments",
    "author": "algorithmx",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-08-05T14:04:12Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nLooks like `litellm` may not support `socks` proxies."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-08-07T15:58:17Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open or file a new issue any time."
      }
    ]
  },
  {
    "number": 979,
    "title": "How to ensure that Aider consistently produces repo map?",
    "created_at": "2024-08-01T03:34:02Z",
    "closed_at": "2024-08-06T13:08:26Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/979",
    "body": "### Issue\n\nThis is an excellent project, but during its usage, I encountered the following two difficulties:\r\n\r\nCould you please explain why, when using Aider, it often does not generate a repo map? Is there a way to force it to always generate a repo map?\r\n\r\nAnother question is, can the repo map generated by Aider be saved? Could you tell me which files contain the relevant code for the repo map?\r\n\r\nIt would be greatly appreciated if these could be addressed and resolved.\r\n\n\n### Version and model info\n\n_No response_",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/979/comments",
    "author": "hhn12138",
    "comments": [
      {
        "user": "PantaTransport",
        "created_at": "2024-08-04T08:15:52Z",
        "body": "having the same issue\r\n"
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-08-05T14:21:26Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nWhat makes you think it is not generating a repo map?\r\n\r\nWhen reporting problems, it is very helpful if you can provide:\r\n\r\n- Aider version\r\n- LLM model you are using\r\n\r\nIncluding the “announcement” lines that aider prints at startup is an easy way to share some of this helpful info.\r\n\r\n```\r\nAider v0.37.1-dev\r\nModels: gpt-4o with diff edit format, weak model gpt-3.5-turbo\r\nGit repo: .git with 243 files\r\nRepo-map: using 1024 tokens\r\n```"
      },
      {
        "user": "PantaTransport",
        "created_at": "2024-08-06T08:31:21Z",
        "body": "PS C:\\Projects\\fleet-management-system\\fleet-management-frontend> python -m aider --model deepseek/deepseek-coder\r\nAdd .aider* to .gitignore (recommended)? y\r\nAdded .aider* to .gitignore\r\nAider v0.47.1\r\nModel: deepseek/deepseek-coder with diff edit format\r\nGit repo: ..\\.git with 0 files\r\nRepo-map: using 1024 tokens\r\nVSCode terminal detected, pretty output has been disabled.\r\nUse /help <question> for help, run \"aider --help\" to see cmd line args\r\nNote: in-chat filenames are always relative to the git working dir, not the current working dir.\r\nCur working dir: C:\\Projects\\fleet-management-system\\fleet-management-frontend\r\nGit working dir: C:\\Projects\\fleet-management-system\r\n─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n> /add src/App.js\r\n\r\n\r\nNo files matched 'src/App.js'. Do you want to create C:\\Projects\\fleet-management-system\\src\\App.js? n\r\n─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n> /add App.js\r\n\r\nNo files matched 'App.js'. Do you want to create C:\\Projects\\fleet-management-system\\App.js? n\r\n─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n> what is my git repo map?\r\n\r\nSince you haven't shared any files yet, I don't have access to your git repository map. To proceed, you would need to add the relevant files to the chat so I can assist you with the changes you requested. Please add the files you wish to modify, and I'll be    \r\nable to provide the necessary SEARCH/REPLACE blocks for the changes.\r\n\r\n\r\nTokens: 1,666 sent, 74 received. Cost: $0.00025 request, $0.00025 session.\r\n─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n> Git working dir: C:\\Projects\\fleet-management-system\r\n\r\nTo proceed with any changes, please add the specific files from your Git working directory C:\\Projects\\fleet-management-system that you wish to modify. Once the files are added to the chat, I can provide the necessary SEARCH/REPLACE blocks for the changes you  \r\nrequest.\r\n\r\n\r\nTokens: 1,774 sent, 58 received. Cost: $0.00026 request, $0.00052 session.\r\n─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n> how do i do this? its an existing git repo and ive loaded you correctly into my git repo directory. you should already have a map of my entire git repo\r\n\r\nIt seems there might be a misunderstanding. As an AI, I don't have direct access to your filesystem or Git repository. I can only work with the files you explicitly add to the chat. To proceed, you need to copy the contents of the specific files you want to    \r\nmodify and paste them into the chat. Once I have the file contents, I can provide the necessary SEARCH/REPLACE blocks for the changes you request.\r\n\r\nPlease follow these steps:\r\n\r\n 1 Open the file you want to modify in your text editor.\r\n 2 Copy the entire content of the file.\r\n 3 Paste the content into the chat.\r\n\r\nAfter you've done this, I'll be able to assist you with the changes."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-08-06T10:33:32Z",
        "body": "Aider works on files that are part of your git repo. It looks like your repo has 0 files in it. \n\nYou need to `git add` the files to your repo before using them with aider. "
      },
      {
        "user": "PantaTransport",
        "created_at": "2024-08-06T12:41:48Z",
        "body": "I figured it out eventually. Consider adding that to frequent errors for beginner-level coders please. It's an easy thing to miss."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-08-06T13:08:26Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open or file a new issue any time."
      }
    ]
  },
  {
    "number": 977,
    "title": "Using ![cmd] breaks screen formatting",
    "created_at": "2024-07-31T20:31:22Z",
    "closed_at": "2024-08-09T18:25:04Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/977",
    "body": "### Issue\n\nAider works normally until I start to use ![cmd] and the screen formatting is not rendered correctly:\r\n\r\n> /add README.md main.py requirements.txt prompt.txt compliance_cli2.csv\r\nNo files matched 'compliance_cli2.csv'. Do you want to create C:\\Users\\Lawless\\AI\\variance\\calllog6\\compliance_cli2.csv\r\n? n\r\nAdded C:\\Users\\Lawless\\AI\\variance\\calllog6\\README.md to the chat\r\nAdded C:\\Users\\Lawless\\AI\\variance\\calllog6\\prompt.txt to the chat\r\nAdded C:\\Users\\Lawless\\AI\\variance\\calllog6\\main.py to the chat\r\nAdded C:\\Users\\Lawless\\AI\\variance\\calllog6\\requirements.txt to the chat\r\n────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\nREADME.md main.py prompt.txt requirements.txt\r\n> !ls *.csv\r\n\r\ntest.csv\r\ntest1.csv\r\ntest2.csv\r\ntest4.csv\r\n\r\nAdd the output to the chat? (y/n/instructions):  n\r\n←[38;2;0;204;0m────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────←[0m\r\nREADME.md main.py prompt.txt requirements.txt\r\n> /add test2.csv\r\n\r\nAdded C:\\Users\\Lawless\\AI\\variance\\calllog6\\test2.csv to the chat\r\n←[38;2;0;204;0m────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────←[0m\r\nREADME.md test2.csv main.py prompt.txt requirements.txt\r\n> /ask I want to generate an extra \"qualitative\" report in text format from the compliance SN 71 to 91\r\n\r\n\r\n←[38;2;255;34;34m^C again to exit←[0m\r\n←[38;2;0;204;0m────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────←[0m\r\n\n\n### Version and model info\n\nAider v0.46.1\r\nModels: claude-3-5-sonnet-20240620 with diff edit format, weak model claude-3-haiku-20240307\r\nGit repo: .git with 15 files\r\nRepo-map: using 1024 tokens",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/977/comments",
    "author": "lawong888",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-08-07T15:47:14Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nWhat OS, shell and terminal are you using? Is the `ls` command set to output special terminal control characters?\r\n\r\nThis seems to be a problem unique to your local environment. "
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-08-09T18:25:04Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open or file a new issue any time."
      }
    ]
  },
  {
    "number": 969,
    "title": "[Question]: Back button?",
    "created_at": "2024-07-31T02:38:23Z",
    "closed_at": "2024-08-09T18:24:51Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/969",
    "body": "### Question\r\n\r\nIs there a way to go back to my previous dialog? A regeneration feature might not be useful since aider adopts a temp=0, but I often find myself wanting to backtrack and rephrase the prompt better, without restarting my session.\r\n\r\n",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/969/comments",
    "author": "BarfingLemurs",
    "comments": [
      {
        "user": "PrashamTrivedi",
        "created_at": "2024-07-31T05:30:23Z",
        "body": "Hi,\r\n\r\nAre you asking about getting the prompt you have previously entered in CLI? If yes, you can press up arrow in empty prompt and you can cycle through your prompt history.. "
      },
      {
        "user": "BarfingLemurs",
        "created_at": "2024-07-31T13:29:29Z",
        "body": "Hi, thanks, it's not that. This when you are 8k tokens in, having already done multiple back-and-forths.\r\n\r\nSuppose I feel like the model comprehends things well at 8k. Then, I go off in a tangent chatting with the model until 16k, and now find that it's comprehension is much worse.\r\nI would like to go back to the previous state, without sequencially prompting it back from scratch to 8k."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-08-07T15:45:19Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nNot currently. You can use the up arrow and control-r to go back and re-send previous messages."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-08-09T18:24:51Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open or file a new issue any time."
      }
    ]
  },
  {
    "number": 950,
    "title": "authentication_error",
    "created_at": "2024-07-28T05:48:53Z",
    "closed_at": "2024-07-29T16:22:17Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/950",
    "body": "### Issue\r\n\r\n Trying to understand this error, it occurs even if the api key is set:\r\n - in .zshrc\r\n - in .env in the project\r\n - and with export ANTHROPIC_API_KEY=\r\n \r\nIt does work with OpenAI, ie: `aider --4-turbo` works\r\n \r\nMacos Sonoma 14.5\r\naider 0.45.1\r\nrepo is private\r\n\r\n-----\r\n \r\n  File \"/opt/homebrew/lib/python3.11/site-packages/litellm/main.py\", line 1436, in completion\r\n    response = anthropic_chat_completions.completion(\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/homebrew/lib/python3.11/site-packages/litellm/llms/anthropic.py\", line 683, in completion\r\n    raise AnthropicError(\r\nlitellm.llms.anthropic.AnthropicError: {\"type\":\"error\",\"error\":{\"type\":\"authentication_error\",\"message\":\"invalid\r\nx-api-key\"}}\r\n\r\n### Version and model info\r\n\r\n_No response_",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/950/comments",
    "author": "davidmoshal",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-07-28T10:58:53Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nIt looks like your API key is invalid. Maybe get a new one from the Anthropic website?\r\n\r\nYou can also run `aider --verbose` to confirm which key it is using, in case you've got multiple configured in various yaml/.env/environment locations."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-07-29T16:22:17Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open or file a new issue any time."
      }
    ]
  },
  {
    "number": 942,
    "title": "the search and replace repeats infinitely until stopped by CTRL+C",
    "created_at": "2024-07-27T08:52:50Z",
    "closed_at": "2024-07-30T17:44:09Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/942",
    "body": "### Issue\n\nthe search and replace repeats infinitely until stopped by CTRL+C\n\n### Version and model info\n\nAider : latest \r\nmodel : groq/llama-3.1-70b-versatile",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/942/comments",
    "author": "hemangjoshi37a",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-07-28T10:56:12Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nAider limits retries on edit errors to 3 times. You should not be seeing \"infinite\" loops. Please share logs from `.aider.chat.history.md` that contain more than 3 loops if you are seeing them. That would help me confirm the issue and start debugging if it is indeed happening."
      },
      {
        "user": "hemangjoshi37a",
        "created_at": "2024-07-28T12:05:49Z",
        "body": "where is this file located?"
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-07-28T12:20:21Z",
        "body": "It's at the root of your git repo."
      },
      {
        "user": "hemangjoshi37a",
        "created_at": "2024-07-28T12:42:39Z",
        "body": "ok i will revert "
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-07-30T17:44:09Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open or file a new issue any time."
      },
      {
        "user": "vbichkovsky",
        "created_at": "2025-02-15T19:59:38Z",
        "body": "@paul-gauthier I've just got the same issue, counted 23 search/replace attempts in a row. It was triggered in a --watch mode, and the change itself was triggered by an inline comment ending with 'AI!'. The comment stays after each edit, I guess that re-triggers update again and again.\n\nBelow is the relevant part from the logs, it ended abruptly after I hit Ctrl+C.\n\n```\n> Processing your request...  \n\nOkay, I will modify `script.py` to inline the `item` variable in the `put_item` function call and remove the AI comment.\n\nscript.py\n```python\n<<<<<<< SEARCH\n    print(f\"inference: {time.time() - started}\")\n\n    # make saving code mode concise, declaring the table name at the start of the script\n    # also, inline the 'item' variable in the put_item function call, ai!\n    table_name = os.environ['table_name']\n    item = {\n        'PK': {'S': key},\n        'features': {'L': [{'N': str(f)} for f in image_features[0].tolist()]}\n    }\n\n    dynamodb.put_item(TableName=table_name, Item=item)\n\n    return {\n        'statusCode': 200,\n        'body': json.dumps('Inference successful!')\n    }\n=======\n    print(f\"inference: {time.time() - started}\")\n\n    # make saving code mode concise, declaring the table name at the start of the script\n    # also, inline the 'item' variable in the put_item function call, ai!\n    table_name = os.environ['table_name']\n    dynamodb.put_item(TableName=table_name, Item={\n        'PK': {'S': key},\n        'features': {'L': [{'N': str(f)} for f in image_features[0].tolist()]}\n    })\n\n    return {\n        'statusCode': 200,\n        'body': json.dumps('Inference successful!')\n    }\n>>>>>>> REPLACE\n```\n\nscript.py\n```python\n<<<<<<< SEARCH\n    print(f\"inference: {time.time() - started}\")\n\n    # make saving code mode concise, declaring the table name at the start of the script\n    # also, inline the 'item' variable in the put_item function call, ai!\n    table_name = os.environ['table_name']\n    dynamodb.put_item(TableName=table_name, Item={\n        'PK': {'S': key},\n        'features': {'L': [{'N': str(f)} for f in image_features[0].tolist()]}\n    })\n\n    return {\n        'statusCode': 200,\n        'body': json.dumps('Inference successful!')\n    }\n=======\n    print(f\"inference: {time.time() - started}\")\n\n    # make saving code mode concise, declaring the table name at the start of the script\n    # also, inline the 'item' variable in the put_item function call, ai!\n    table_name = os.environ['table_name']\n    dynamodb.put_item(TableName=table_name, Item={\n        'PK': {'S': key},\n        'features': {'L': [{'N': str(f)} for f in image_features[0].tolist()]}\n    })\n\n    return {\n        'statusCode': 200,\n        'body': json.dumps('Inference successful!')\n    }\n>>>>>>> REPLACE\n```\n\nscript.py\n```python\n<<<<<<< SEARCH\n    print(f\"inference: {time.time() - started}\")\n\n    # make saving code mode concise, declaring the table name at the start of the script\n    # also, inline the 'item' variable in the put_item function call, ai!\n    table_name = os.environ['table_name']\n    dynamodb.put_item(TableName=table_name, Item={\n        'PK': {'S': key},\n        'features': {'L': [{'N': str(f)} for f in image_features[0].tolist()]}\n    })\n\n    return {\n        'statusCode': 200,\n        'body': json.dumps('Inference successful!')\n    }\n=======\n    print(f\"inference: {time.time() - started}\")\n\n    # make saving code mode concise, declaring the table name at the start of the script\n    # also, inline the 'item' variable in the put_item function call, ai!\n    table_name = os.environ['table_name']\n    dynamodb.put_item(TableName=table_name, Item={\n        'PK': {'S': key},\n        'features': {'L': [{'N': str(f)} for f in image_features[0].tolist()]}\n    })\n\n    return {\n        'statusCode': 200,\n        'body': json.dumps('Inference successful!')\n    }\n>>>>>>> REPLACE\n```\n\nscript.py\n```python\n<<<<<<< SEARCH\n    print(f\"inference: {time.time() - started}\")\n\n    # make saving code mode concise, declaring the table name at the start of the script\n    # also, inline the 'item' variable in the put_item function call, ai!\n    table_name = os.environ['table_name']\n    dynamodb.put_item(TableName=table_name, Item={\n        'PK': {'S': key},\n        'features': {'L': [{'N': str(f)} for f in image_features[0].tolist()]}\n    })\n\n    return {\n        'statusCode': 200,\n        'body': json.dumps('Inference successful!')\n    }\n=======\n    print(f\"inference: {time.time() - started}\")\n\n    # make saving code mode concise, declaring the table name at the start of the script\n    # also, inline the 'item' variable in the put_item function call, ai!\n    table_name = os.environ['table_name']\n    dynamodb.put_item(TableName=table_name, Item={\n        'PK': {'S': key},\n        'features': {'L': [{'N': str(f)} for f in image_features[0].tolist()]}\n    })\n\n    return {\n        'statusCode': 200,\n        'body': json.dumps('Inference successful!')\n    }\n>>>>>>> REPLACE\n```\n\nscript.py\n```python\n<<<<<<< SEARCH\n    print(f\"inference: {time.time() - started}\")\n\n    # make saving code mode concise, declaring the table name at the start of the script\n    # also, inline the 'item' variable in the put_item function call, ai!\n    table_name = os.environ['table_name']\n    dynamodb.put_item(TableName=table_name, Item={\n        'PK': {'S': key},\n        'features': {'L': [{'N': str(f)} for f in image_features[0].tolist()]}\n    })\n\n    return {\n        'statusCode': 200,\n        'body': json.dumps('Inference successful!')\n    }\n=======\n    print(f\"inference: {time.time() - started}\")\n\n    # make saving code mode concise, declaring the table name at the start of the script\n    # also, inline the 'item' variable in the put_item function call, ai!\n    table_name = os.environ['table_name']\n    dynamodb.put_item(TableName=table_name, Item={\n        'PK': {'S': key},\n        'features': {'L': [{'N': str(f)} for f in image_features[0].tolist()]}\n    })\n\n    return {\n        'statusCode': 200,\n        'body': json.dumps('Inference successful!')\n    }\n>>>>>>> REPLACE\n```\n\nscript.py\n```python\n<<<<<<< SEARCH\n    print(f\"inference: {time.time() - started}\")\n\n    # make saving code mode concise, declaring the table name at the start of the script\n    # also, inline the 'item' variable in the put_item function call, ai!\n    table_name = os.environ['table_name']\n    dynamodb.put_item(TableName=table_name, Item={\n        'PK': {'S': key},\n        'features': {'L': [{'N': str(f)} for f in image_features[0].tolist()]}\n    })\n\n    return {\n        'statusCode': 200,\n        'body': json.dumps('Inference successful!')\n    }\n=======\n    print(f\"inference: {time.time() - started}\")\n\n    # make saving code mode concise, declaring the table name at the start of the script\n    # also, inline the 'item' variable in the put_item function call, ai!\n    table_name = os.environ['table_name']\n    dynamodb.put_item(TableName=table_name, Item={\n        'PK': {'S': key},\n        'features': {'L': [{'N': str(f)} for f in image_features[0].tolist()]}\n    })\n\n    return {\n        'statusCode': 200,\n        'body': json.dumps('Inference successful!')\n    }\n>>>>>>> REPLACE\n```\n\nscript.py\n```python\n<<<<<<< SEARCH\n    print(f\"inference: {time.time() - started}\")\n\n    # make saving code mode concise, declaring the table name at the start of the script\n    # also, inline the 'item' variable in the put_item function call, ai!\n    table_name = os.environ['table_name']\n    dynamodb.put_item(TableName=table_name, Item={\n        'PK': {'S': key},\n        'features': {'L': [{'N': str(f)} for f in image_features[0].tolist()]}\n    })\n\n    return {\n        'statusCode': 200,\n        'body': json.dumps('Inference successful!')\n    }\n=======\n    print(f\"inference: {time.time() - started}\")\n\n    # make saving code mode concise, declaring the table name at the start of the script\n    # also, inline the 'item' variable in the put_item function call, ai!\n    table_name = os.environ['table_name']\n    dynamodb.put_item(TableName=table_name, Item={\n        'PK': {'S': key},\n        'features': {'L': [{'N': str(f)} for f in image_features[0].tolist()]}\n    })\n\n    return {\n        'statusCode': 200,\n        'body': json.dumps('Inference successful!')\n    }\n>>>>>>> REPLACE\n```\n\nscript.py\n```python\n<<<<<<< SEARCH\n    print(f\"inference: {time.time() - started}\")\n\n    # make saving code mode concise, declaring the table name at the start of the script\n    # also, inline the 'item' variable in the put_item function call, ai!\n    table_name = os.environ['table_name']\n    dynamodb.put_item(TableName=table_name, Item={\n        'PK': {'S': key},\n        'features': {'L': [{'N': str(f)} for f in image_features[0].tolist()]}\n    })\n\n    return {\n        'statusCode': 200,\n        'body': json.dumps('Inference successful!')\n    }\n=======\n    print(f\"inference: {time.time() - started}\")\n\n    # make saving code mode concise, declaring the table name at the start of the script\n    # also, inline the 'item' variable in the put_item function call, ai!\n    table_name = os.environ['table_name']\n    dynamodb.put_item(TableName=table_name, Item={\n        'PK': {'S': key},\n        'features': {'L': [{'N': str(f)} for f in image_features[0].tolist()]}\n    })\n\n    return {\n        'statusCode': 200,\n        'body': json.dumps('Inference successful!')\n    }\n>>>>>>> REPLACE\n```\n\nscript.py\n```python\n<<<<<<< SEARCH\n    print(f\"inference: {time.time() - started}\")\n\n    # make saving code mode concise, declaring the table name at the start of the script\n    # also, inline the 'item' variable in the put_item function call, ai!\n    table_name = os.environ['table_name']\n    dynamodb.put_item(TableName=table_name, Item={\n        'PK': {'S': key},\n        'features': {'L': [{'N': str(f)} for f in image_features[0].tolist()]}\n    })\n\n    return {\n        'statusCode': 200,\n        'body': json.dumps('Inference successful!')\n    }\n=======\n    print(f\"inference: {time.time() - started}\")\n\n    # make saving code mode concise, declaring the table name at the start of the script\n    # also, inline the 'item' variable in the put_item function call, ai!\n    table_name = os.environ['table_name']\n    dynamodb.put_item(TableName=table_name, Item={\n        'PK': {'S': key},\n        'features': {'L': [{'N': str(f)} for f in image_features[0].tolist()]}\n    })\n\n    return {\n        'statusCode': 200,\n        'body': json.dumps('Inference successful!')\n    }\n>>>>>>> REPLACE\n```\n\nscript.py\n```python\n<<<<<<< SEARCH\n    print(f\"inference: {time.time() - started}\")\n\n    # make saving code mode concise, declaring the table name at the start of the script\n    # also, inline the 'item' variable in the put_item function call, ai!\n    table_name = os.environ['table_name']\n    dynamodb.put_item(TableName=table_name, Item={\n        'PK': {'S': key},\n        'features': {'L': [{'N': str(f)} for f in image_features[0].tolist()]}\n    })\n\n    return {\n        'statusCode': 200,\n        'body': json.dumps('Inference successful!')\n    }\n=======\n    print(f\"inference: {time.time() - started}\")\n\n    # make saving code mode concise, declaring the table name at the start of the script\n    # also, inline the 'item' variable in the put_item function call, ai!\n    table_name = os.environ['table_name']\n    dynamodb.put_item(TableName=table_name, Item={\n        'PK': {'S': key},\n        'features': {'L': [{'N': str(f)} for f in image_features[0].tolist()]}\n    })\n\n    return {\n        'statusCode': 200,\n        'body': json.dumps('Inference successful!')\n    }\n>>>>>>> REPLACE\n```\n\nscript.py\n```python\n<<<<<<< SEARCH\n    print(f\"inference: {time.time() - started}\")\n\n    # make saving code mode concise, declaring the table name at the start of the script\n    # also, inline the 'item' variable in the put_item function call, ai!\n    table_name = os.environ['table_name']\n    dynamodb.put_item(TableName=table_name, Item={\n        'PK': {'S': key},\n        'features': {'L': [{'N': str(f)} for f in image_features[0].tolist()]}\n    })\n\n    return {\n        'statusCode': 200,\n        'body': json.dumps('Inference successful!')\n    }\n=======\n    print(f\"inference: {time.time() - started}\")\n\n    # make saving code mode concise, declaring the table name at the start of the script\n    # also, inline the 'item' variable in the put_item function call, ai!\n    table_name = os.environ['table_name']\n    dynamodb.put_item(TableName=table_name, Item={\n        'PK': {'S': key},\n        'features': {'L': [{'N': str(f)} for f in image_features[0].tolist()]}\n    })\n\n    return {\n        'statusCode': 200,\n        'body': json.dumps('Inference successful!')\n    }\n>>>>>>> REPLACE\n```\n\nscript.py\n```python\n<<<<<<< SEARCH\n    print(f\"inference: {time.time() - started}\")\n\n    # make saving code mode concise, declaring the table name at the start of the script\n    # also, inline the 'item' variable in the put_item function call, ai!\n    table_name = os.environ['table_name']\n    dynamodb.put_item(TableName=table_name, Item={\n        'PK': {'S': key},\n        'features': {'L': [{'N': str(f)} for f in image_features[0].tolist()]}\n    })\n\n    return {\n        'statusCode': 200,\n        'body': json.dumps('Inference successful!')\n    }\n=======\n    print(f\"inference: {time.time() - started}\")\n\n    # make saving code mode concise, declaring the table name at the start of the script\n    # also, inline the 'item' variable in the put_item function call, ai!\n    table_name = os.environ['table_name']\n    dynamodb.put_item(TableName=table_name, Item={\n        'PK': {'S': key},\n        'features': {'L': [{'N': str(f)} for f in image_features[0].tolist()]}\n    })\n\n    return {\n        'statusCode': 200,\n        'body': json.dumps('Inference successful!')\n    }\n>>>>>>> REPLACE\n```\n\nscript.py\n```python\n<<<<<<< SEARCH\n    print(f\"inference: {time.time() - started}\")\n\n    # make saving code mode concise, declaring the table name at the start of the script\n    # also, inline the 'item' variable in the put_item function call, ai!\n    table_name = os.environ['table_name']\n    dynamodb.put_item(TableName=table_name, Item={\n        'PK': {'S': key},\n        'features': {'L': [{'N': str(f)} for f in image_features[0].tolist()]}\n    })\n\n    return {\n        'statusCode': 200,\n        'body': json.dumps('Inference successful!')\n    }\n=======\n    print(f\"inference: {time.time() - started}\")\n\n    # make saving code mode concise, declaring the table name at the start of the script\n    # also, inline the 'item' variable in the put_item function call, ai!\n    table_name = os.environ['table_name']\n    dynamodb.put_item(TableName=table_name, Item={\n        'PK': {'S': key},\n        'features': {'L': [{'N': str(f)} for f in image_features[0].tolist()]}\n    })\n\n    return {\n        'statusCode': 200,\n        'body': json.dumps('Inference successful!')\n    }\n>>>>>>> REPLACE\n```\n\nscript.py\n```python\n<<<<<<< SEARCH\n    print(f\"inference: {time.time() - started}\")\n\n    # make saving code mode concise, declaring the table name at the start of the script\n    # also, inline the 'item' variable in the put_item function call, ai!\n    table_name = os.environ['table_name']\n    dynamodb.put_item(TableName=table_name, Item={\n        'PK': {'S': key},\n        'features': {'L': [{'N': str(f)} for f in image_features[0].tolist()]}\n    })\n\n    return {\n        'statusCode': 200,\n        'body': json.dumps('Inference successful!')\n    }\n=======\n    print(f\"inference: {time.time() - started}\")\n\n    # make saving code mode concise, declaring the table name at the start of the script\n    # also, inline the 'item' variable in the put_item function call, ai!\n    table_name = os.environ['table_name']\n    dynamodb.put_item(TableName=table_name, Item={\n        'PK': {'S': key},\n        'features': {'L': [{'N': str(f)} for f in image_features[0].tolist()]}\n    })\n\n    return {\n        'statusCode': 200,\n        'body': json.dumps('Inference successful!')\n    }\n>>>>>>> REPLACE\n```\n\nscript.py\n```python\n<<<<<<< SEARCH\n    print(f\"inference: {time.time() - started}\")\n\n    # make saving code mode concise, declaring the table name at the start of the script\n    # also, inline the 'item' variable in the put_item function call, ai!\n    table_name = os.environ['table_name']\n    dynamodb.put_item(TableName=table_name, Item={\n        'PK': {'S': key},\n        'features': {'L': [{'N': str(f)} for f in image_features[0].tolist()]}\n    })\n\n    return {\n        'statusCode': 200,\n        'body': json.dumps('Inference successful!')\n    }\n=======\n    print(f\"inference: {time.time() - started}\")\n\n    # make saving code mode concise, declaring the table name at the start of the script\n    # also, inline the 'item' variable in the put_item function call, ai!\n    table_name = os.environ['table_name']\n    dynamodb.put_item(TableName=table_name, Item={\n        'PK': {'S': key},\n        'features': {'L': [{'N': str(f)} for f in image_features[0].tolist()]}\n    })\n\n    return {\n        'statusCode': 200,\n        'body': json.dumps('Inference successful!')\n    }\n>>>>>>> REPLACE\n```\n\nscript.py\n```python\n<<<<<<< SEARCH\n    print(f\"inference: {time.time() - started}\")\n\n    # make saving code mode concise, declaring the table name at the start of the script\n    # also, inline the 'item' variable in the put_item function call, ai!\n    table_name = os.environ['table_name']\n    dynamodb.put_item(TableName=table_name, Item={\n        'PK': {'S': key},\n        'features': {'L': [{'N': str(f)} for f in image_features[0].tolist()]}\n    })\n\n    return {\n        'statusCode': 200,\n        'body': json.dumps('Inference successful!')\n    }\n=======\n    print(f\"inference: {time.time() - started}\")\n\n    # make saving code mode concise, declaring the table name at the start of the script\n    # also, inline the 'item' variable in the put_item function call, ai!\n    table_name = os.environ['table_name']\n    dynamodb.put_item(TableName=table_name, Item={\n        'PK': {'S': key},\n        'features': {'L': [{'N': str(f)} for f in image_features[0].tolist()]}\n    })\n\n    return {\n        'statusCode': 200,\n        'body': json.dumps('Inference successful!')\n    }\n>>>>>>> REPLACE\n```\n\nscript.py\n```python\n<<<<<<< SEARCH\n    print(f\"inference: {time.time() - started}\")\n\n    # make saving code mode concise, declaring the table name at the start of the script\n    # also, inline the 'item' variable in the put_item function call, ai!\n    table_name = os.environ['table_name']\n    dynamodb.put_item(TableName=table_name, Item={\n        'PK': {'S': key},\n        'features': {'L': [{'N': str(f)} for f in image_features[0].tolist()]}\n    })\n\n    return {\n        'statusCode': 200,\n        'body': json.dumps('Inference successful!')\n    }\n=======\n    print(f\"inference: {time.time() - started}\")\n\n    # make saving code mode concise, declaring the table name at the start of the script\n    # also, inline the 'item' variable in the put_item function call, ai!\n    table_name = os.environ['table_name']\n    dynamodb.put_item(TableName=table_name, Item={\n        'PK': {'S': key},\n        'features': {'L': [{'N': str(f)} for f in image_features[0].tolist()]}\n    })\n\n    return {\n        'statusCode': 200,\n        'body': json.dumps('Inference successful!')\n    }\n>>>>>>> REPLACE\n```\n\nscript.py\n```python\n<<<<<<< SEARCH\n    print(f\"inference: {time.time() - started}\")\n\n    # make saving code mode concise, declaring the table name at the start of the script\n    # also, inline the 'item' variable in the put_item function call, ai!\n    table_name = os.environ['table_name']\n    dynamodb.put_item(TableName=table_name, Item={\n        'PK': {'S': key},\n        'features': {'L': [{'N': str(f)} for f in image_features[0].tolist()]}\n    })\n\n    return {\n        'statusCode': 200,\n        'body': json.dumps('Inference successful!')\n    }\n=======\n    print(f\"inference: {time.time() - started}\")\n\n    # make saving code mode concise, declaring the table name at the start of the script\n    # also, inline the 'item' variable in the put_item function call, ai!\n    table_name = os.environ['table_name']\n    dynamodb.put_item(TableName=table_name, Item={\n        'PK': {'S': key},\n        'features': {'L': [{'N': str(f)} for f in image_features[0].tolist()]}\n    })\n\n    return {\n        'statusCode': 200,\n        'body': json.dumps('Inference successful!')\n    }\n>>>>>>> REPLACE\n```\n\nscript.py\n```python\n<<<<<<< SEARCH\n    print(f\"inference: {time.time() - started}\")\n\n    # make saving code mode concise, declaring the table name at the start of the script\n    # also, inline the 'item' variable in the put_item function call, ai!\n    table_name = os.environ['table_name']\n    dynamodb.put_item(TableName=table_name, Item={\n        'PK': {'S': key},\n        'features': {'L': [{'N': str(f)} for f in image_features[0].tolist()]}\n    })\n\n    return {\n        'statusCode': 200,\n        'body': json.dumps('Inference successful!')\n    }\n=======\n    print(f\"inference: {time.time() - started}\")\n\n    # make saving code mode concise, declaring the table name at the start of the script\n    # also, inline the 'item' variable in the put_item function call, ai!\n    table_name = os.environ['table_name']\n    dynamodb.put_item(TableName=table_name, Item={\n        'PK': {'S': key},\n        'features': {'L': [{'N': str(f)} for f in image_features[0].tolist()]}\n    })\n\n    return {\n        'statusCode': 200,\n        'body': json.dumps('Inference successful!')\n    }\n>>>>>>> REPLACE\n```\n\nscript.py\n```python\n<<<<<<< SEARCH\n    print(f\"inference: {time.time() - started}\")\n\n    # make saving code mode concise, declaring the table name at the start of the script\n    # also, inline the 'item' variable in the put_item function call, ai!\n    table_name = os.environ['table_name']\n    dynamodb.put_item(TableName=table_name, Item={\n        'PK': {'S': key},\n        'features': {'L': [{'N': str(f)} for f in image_features[0].tolist()]}\n    })\n\n    return {\n        'statusCode': 200,\n        'body': json.dumps('Inference successful!')\n    }\n=======\n    print(f\"inference: {time.time() - started}\")\n\n    # make saving code mode concise, declaring the table name at the start of the script\n    # also, inline the 'item' variable in the put_item function call, ai!\n    table_name = os.environ['table_name']\n    dynamodb.put_item(TableName=table_name, Item={\n        'PK': {'S': key},\n        'features': {'L': [{'N': str(f)} for f in image_features[0].tolist()]}\n    })\n\n    return {\n        'statusCode': 200,\n        'body': json.dumps('Inference successful!')\n    }\n>>>>>>> REPLACE\n```\n\nscript.py\n```python\n<<<<<<< SEARCH\n    print(f\"inference: {time.time() - started}\")\n\n    # make saving code mode concise, declaring the table name at the start of the script\n    # also, inline the 'item' variable in the put_item function call, ai!\n    table_name = os.environ['table_name']\n    dynamodb.put_item(TableName=table_name, Item={\n        'PK': {'S': key},\n        'features': {'L': [{'N': str(f)} for f in image_features[0].tolist()]}\n    })\n\n    return {\n        'statusCode': 200,\n        'body': json.dumps('Inference successful!')\n    }\n=======\n    print(f\"inference: {time.time() - started}\")\n\n    # make saving code mode concise, declaring the table name at the start of the script\n    # also, inline the 'item' variable in the put_item function call, ai!\n    table_name = os.environ['table_name']\n    dynamodb.put_item(TableName=table_name, Item={\n        'PK': {'S': key},\n        'features': {'L': [{'N': str(f)} for f in image_features[0].tolist()]}\n    })\n\n    return {\n        'statusCode': 200,\n        'body': json.dumps('Inference successful!')\n    }\n>>>>>>> REPLACE\n```\n\nscript.py\n```python\n<<<<<<< SEARCH\n    print(f\"inference: {time.time() - started}\")\n\n    # make saving code mode concise, declaring the table name at the start of the script\n    # also, inline the 'item' variable in the put_item function call, ai!\n    table_name = os.environ['table_name']\n    dynamodb.put_item(TableName=table_name, Item={\n        'PK': {'S': key},\n        'features': {'L': [{'N': str(f)} for f in image_features[0].tolist()]}\n    })\n\n    return {\n        'statusCode': 200,\n        'body': json.dumps('Inference successful!')\n    }\n=======\n    print(f\"inference: {time.time() - started}\")\n\n    # make saving code mode concise, declaring the table name at the start of the script\n    # also, inline the 'item' variable in the put_item function call, ai!\n    table_name = os.environ['table_name']\n    dynamodb.put_item(TableName=table_name, Item={\n        'PK': {'S': key},\n        'features': {'L': [{'N': str(f)} for f in image_features[0].tolist()]}\n    })\n\n    return {\n        'statusCode': 200,\n        'body': json.dumps('Inference successful!')\n    }\n>>>>>>> REPLACE\n```\n\nscript.py\n```python\n<<<<<<< SEARCH\n    print(f\"inference: {time.time() - started}\")\n\n    # make saving code mode concise, declaring the table name at the start of the script\n    # also, inline the 'item' variable in the put_item function call, ai!\n    table_name = os.environ['table_name']\n    dynamodb.put_item(TableName=table_name, Item={\n        'PK': {'S': key},\n        'features': {'L': [{'N': str(f)} for f in image_features[0].tolist()]}\n    })\n\n    return {\n        'statusCode': 200,\n        'body': json.dumps('Inference successful!')\n    }\n=======\n    print(f\"inference: {time.time() - started}\")\n\n    # make saving code mode concise, declaring the table name at the start of the script\n    # also, inline the 'item' variable in the put_item function call, ai!\n    table_name = os.environ['table_name']\n    dynamodb.put_item(TableName=table_name, Item={\n        'PK': {'S': key},\n        'features': {'L': [{'N': str(f)} for f in image_features[0].tolist()]}\n    })\n\n    return {\n        'statusCode': 200,\n        'body': json.dumps('Inference successful!')\n    }\n>>>>>>> REPLACE\n```\n\nscript.py\n```python\n<<<<<<< SEARCH\n    print(f\"inference: {time.time() - started}\")\n\n    # make saving code mode concise, declaring the table name at the start of the script\n    # also, inline the 'item' variable in the put_item function call, ai!\n    table_name = os.environ['table_name']\n    dynamodb.put_item(TableName=table_name, Item={\n        'PK': {'S': key},\n        'features': {'L': [{'N': str(f)} for f in image_features[0].tolist()]}\n    })\n\n    return {\n        'statusCode': 200,\n        'body': json.dumps('Inference successful!')\n    }\n=======\n    print(f\"inference: {time.time() - started}\")\n\n    # make saving code mode concise, declaring the table name at the start of the script\n    # also, inline the 'item' variable in the put_item function call, ai!\n    table_name = os.environ['table_name']\n    dynamodb.put_item(TableName=table_name, Item={\n        'PK': {'S': key},\n        'features': {'L': [{'N': str(f)} for f in image_features[0].tolist()]}\n    })\n\n    return {\n        'statusCode': 200,\n        'body': json.dumps('Inference successful!')\n    }\n>>>>>>> REPLACE\n```\n\nscript.py\n```python\n<<<<<<< SEARCH\n    print(f\"inference: {time.time() - started}\")\n\n    # make saving code mode concise, declaring the table name at the start of the script\n    # also, inline the 'item' variable in the put_item function call, ai!\n    table_name = os.environ['table_name']\n    dynamodb.put_item(TableName=table_name, Item={\n        'PK': {'S': key},\n        'features': {'L': [{'N': str(f)} for f in image_features[0].tolist()]}\n    })\n\n    return {\n        'statusCode': 200,\n        'body': json.dumps('\n```\n```"
      }
    ]
  },
  {
    "number": 891,
    "title": "Add cuda support for /help function",
    "created_at": "2024-07-19T09:38:16Z",
    "closed_at": "2024-07-27T10:49:16Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/891",
    "body": "### Issue\r\n\r\n# Add cuda support for /help function\r\nHi, great fan of Aider, its amaizing 😉 My home computer is kind of old, at least the cpu is. I have a 3060TI which is fine for smaller cuda jobs like creating embeddings on-the-fly. The Aider /help function only has cpu suppot right? Would be great if cuda is supported!\r\n\r\n### Version and model info\r\n\r\n# aider 0.45.1",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/891/comments",
    "author": "rodgermoore",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-07-22T07:19:12Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nInstalling cuda support uses a lot of disk space in some environments, so it's disable by default. You can install aider with `pip install aider-chat[help]` to include cuda. You will need to do the install in a clean environment, or the non-cuda install will just remain in place."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-07-27T10:49:16Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open or file a new issue any time."
      }
    ]
  },
  {
    "number": 875,
    "title": "how can i change the smmary model？",
    "created_at": "2024-07-17T10:38:48Z",
    "closed_at": "2024-07-22T06:53:02Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/875",
    "body": "### Issue\n\nwhen i use aider \r\nget a error：ummarizer unexpectedly failed for gpt-3.5-turbo\r\nwhat is the problem\r\nhow can i change the smmary model\n\n### Version and model info\n\n_No response_",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/875/comments",
    "author": "hhn12138",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-07-17T13:35:14Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nYou can use `--weak-model`."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-07-22T06:53:02Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open or file a new issue any time."
      }
    ]
  },
  {
    "number": 866,
    "title": "Clash between Aider's default fence and markdown's fenced code blocks",
    "created_at": "2024-07-15T18:34:54Z",
    "closed_at": "2024-07-22T06:53:20Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/866",
    "body": "### Issue\n\nBoth aider and markdown fences use ```, so aider struggles with generated markdown documentation that has code blocks. This could indicate that making the fence parametrizable could help walkaround this issue or similar clashes in the future.\r\n\r\nMy current workaround is to generate asciidoc. But there's a lot of markdown in the wild so we're often stuck with that as input in legacy repos.\r\n\r\nPS: love the tool, thanks!\n\n### Version and model info\n\nAider: v0.43.4\r\nModel: DeepSeek-Coder-V2",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/866/comments",
    "author": "bulzak",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-07-17T13:40:08Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nAider already picks fences based on the contents of the files being edited. What makes you think there is a problem?"
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-07-22T06:53:20Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open or file a new issue any time."
      }
    ]
  },
  {
    "number": 858,
    "title": "Setting the maximum number of recent questions in the chat history.",
    "created_at": "2024-07-14T11:35:19Z",
    "closed_at": "2024-07-22T07:02:03Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/858",
    "body": "### Issue\n\nI would like to be able to set how many last questions should be remembered in the chat history. When working longer, I don't want the last 50 questions to be in the chat history. I think that the last 7 questions are a reasonable maximum.\n\n### Version and model info\n\nAider v0.43.5-dev\r\nModels: openrouter/anthropic/claude-3.5-sonnet with diff edit format, weak model openrouter/anthropic/claude-3-haiku\r\nGit repo: .git with 96 files\r\nRepo-map: using 2028 tokens\r\nAdded .aider.memory.md to the chat.",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/858/comments",
    "author": "ErykCh",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-07-17T13:59:58Z",
        "body": "Aider already summarizes the past chat history to keep it from growing unbounded."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-07-22T07:02:03Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open or file a new issue any time."
      }
    ]
  },
  {
    "number": 843,
    "title": "I apologize, but I don't have access to the actual files in your directory.",
    "created_at": "2024-07-11T22:02:43Z",
    "closed_at": "2024-07-22T06:54:03Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/843",
    "body": "### Issue\n\nhow to i solving it ? I want Aider to help me work on specific files....\r\nI am on Linux Fedora\r\n\r\nAider, read all files in this directory and provide a summary. \r\n                                                                                \r\n\r\nI apologize, but I don't have access to the actual files in your directory. As  \r\nan AI language model, I can only work with the information you provide to me. If\r\nyou want me to analyze or summarize specific files, you would need to share     \r\ntheir contents with me directly in the chat.                                    \r\n\r\nIf you have specific files you'd like me to look at, please paste their contents\r\ninto the chat, and I'll be happy to provide a summary or analysis based on what \r\nyou share.                                                                      \r\n\r\n\n\n### Version and model info\n\n_No response_",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/843/comments",
    "author": "zivafgin",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-07-12T08:20:22Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nWhen reporting problems, it is very helpful if you can provide:\r\n\r\n- Aider version\r\n- LLM model you are using\r\n- Any stack traces or error messages\r\n- A description of what you were doing when the error happened. \r\n\r\nIncluding the “announcement” lines that aider prints at startup is an easy way to share some of this helpful info.\r\n\r\n```\r\nAider v0.37.1-dev\r\nModels: gpt-4o with diff edit format, weak model gpt-3.5-turbo\r\nGit repo: .git with 243 files\r\nRepo-map: using 1024 tokens\r\n```"
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-07-22T06:54:03Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open or file a new issue any time."
      }
    ]
  },
  {
    "number": 841,
    "title": "ubuntu 24.04 based docker support",
    "created_at": "2024-07-11T10:53:10Z",
    "closed_at": "2024-07-22T06:54:09Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/841",
    "body": "ubuntu is easier to add more features. pls do support docker ubuntu version in future if possible.",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/841/comments",
    "author": "sprappcom",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-07-12T08:31:02Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nYou should be able to copy the `docker/Dockerfile` and switch the FROM line to your preferred base distribution. \n\n"
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-07-22T06:54:09Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open or file a new issue any time."
      }
    ]
  },
  {
    "number": 826,
    "title": "How to change top of git repo, accidentally started aider first time in homedir",
    "created_at": "2024-07-09T11:05:55Z",
    "closed_at": "2024-07-12T20:10:38Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/826",
    "body": "### Issue\r\n\r\nWhen I first tried aider months ago I must have launched it while in my home directory and of course it set that as the top of the git repo.  You can imagine this is sub-optimal for keeping projects separated.\r\n\r\nIs there an elegant way for me to reset the git repo to a sub-directory so I can have different repos for different projects under my home directory?  Even if I lost my change history I'm ok with that to get this cleaned up.\r\n\r\nThanks in advance.  0.43 with GPT-4o and Sonnet 3.5\r\n\r\n### Version and model info\r\n\r\n_No response_",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/826/comments",
    "author": "5ocworkshop",
    "comments": [
      {
        "user": "ackoi",
        "created_at": "2024-07-09T13:19:48Z",
        "body": "Initialize git in folder you need it in.\r\n\r\nOpen aider from that folder."
      },
      {
        "user": "5ocworkshop",
        "created_at": "2024-07-10T16:56:42Z",
        "body": "But if the folder is a subdir of a parent where the top of the git tree is, won't it still be included or will that cause that subdir to be removed?"
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-07-12T08:43:30Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nAider should use the most specific git repo. \n\nYou could also consider deleting the .git dir from your home directory. But you would lose all prior git history if you did that. "
      }
    ]
  },
  {
    "number": 825,
    "title": "Feature Request: Configurable Command Prefix for LLM Interaction",
    "created_at": "2024-07-09T09:24:16Z",
    "closed_at": "2024-07-22T06:54:41Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/825",
    "body": "### Issue\n\nI'm starting to use Aider and appreciate its integration into the development workflow. However, I've encountered an issue that could potentially improve the user experience and reduce token consumption errors.\r\n\r\n### Issue Description\r\n\r\nCurrently, in Aider, commands for interacting with the LLM begin with a `/` prefix (e.g., `/add`, `/drop`). This system works well, but the default behavior allows any non-prefixed input to be sent directly to the LLM. This has led to several instances where I accidentally trigger the LLM because I forget to use the `/` prefix, leading to unnecessary token usage, especially in contexts with a large number of tokens.\r\n\r\n### Suggested Feature\r\n\r\nI propose adding a configuration option that changes the default interaction model with the LLM. Specifically, it would be beneficial to have a setting where:\r\n\r\n- **Only commands prefixed with `/chat` are sent to the LLM**. This would prevent accidental activation of the LLM and help users manage token usage more efficiently.\r\n- **Optionally, allow users to execute all commands without a prefix**, aligning more closely with typical terminal usage where commands are entered without a `/`.\r\n\r\nThis feature would help users like me, who spend significant time in the terminal, to adapt more seamlessly to Aider's command structure without frequent errors.\r\n\r\n### Benefits\r\n\r\n- **Reduces accidental LLM activations**: Limits unnecessary token loss and enhances user control.\r\n- **Enhances user adaptation**: Aligns more closely with common terminal behaviors, easing the learning curve for new and transitioning users.\n\n### Version and model info\n\n_No response_",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/825/comments",
    "author": "Adoliin",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-07-12T08:59:23Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nI think this is out of scope for aider, as it is intended primarily to chat with the LLM about coding. "
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-07-22T06:54:41Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open or file a new issue any time."
      }
    ]
  },
  {
    "number": 824,
    "title": "--extra-index-url ",
    "created_at": "2024-07-09T09:19:01Z",
    "closed_at": "2024-07-11T01:37:34Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/824",
    "body": "pip install complains about --extra-index-url  in the requirements.txt file. I passed the cpu index via env variable and commented that out. not sure if it's just me, otherwise close.",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/824/comments",
    "author": "fferreres",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-07-09T15:35:37Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nI am working on this topic at the moment. It would be helpful if you could share the error output you were seeing?"
      },
      {
        "user": "fferreres",
        "created_at": "2024-07-11T01:37:34Z",
        "body": "fixed with the later commits you did. thank you!"
      }
    ]
  },
  {
    "number": 799,
    "title": "Stop it from refactoring on empty prompt when adding files",
    "created_at": "2024-07-05T15:48:32Z",
    "closed_at": "2024-07-07T10:56:45Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/799",
    "body": "### Issue\n\nSometimes when I or the VS Code extension adds files, Aider decides to refactor the code without a prompt.\r\nNot sure if I click enter by accident with a blank prompt, but would like to disable that.\n\n### Version and model info\n\n_No response_",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/799/comments",
    "author": "tiagoefreitas",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-07-05T15:51:12Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nWhen reporting problems, it is very helpful if you can provide:\r\n\r\n- Aider version\r\n- LLM model you are using\r\n- Any stack traces or error messages\r\n- A description of what you were doing when the error happened. \r\n\r\nIncluding the “announcement” lines that aider prints at startup is an easy way to share some of this helpful info.\r\n\r\n```\r\nAider v0.37.1-dev\r\nModels: gpt-4o with diff edit format, weak model gpt-3.5-turbo\r\nGit repo: .git with 243 files\r\nRepo-map: using 1024 tokens\r\n```"
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-07-07T10:56:42Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open or file a new issue any time."
      }
    ]
  },
  {
    "number": 786,
    "title": "Instead of SEARCH/REPLACE, just output the new file",
    "created_at": "2024-07-03T13:17:26Z",
    "closed_at": "2024-07-22T06:56:55Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/786",
    "body": "### Issue\n\nJust an idea and I could be missing something, but is there a reason why smaller files wouldn't just have only the updated new file content requested in the output instead of doing a SEARCH/REPLACE which spends a lot more tokens?\r\n\r\nIf the necessary changes require changing a large of a file, you can just request a full rewrite to be the output instead.\r\n\r\nI've mostly been working this way when using 3.5 Sonnet outside of Aider and it seems to work pretty well.\n\n### Version and model info\n\n_No response_",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/786/comments",
    "author": "ackoi",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-07-03T14:12:59Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nYou could try using `--edit-format whole` for this. \r\n\r\n"
      },
      {
        "user": "ackoi",
        "created_at": "2024-07-04T21:42:05Z",
        "body": "> Thanks for trying aider and filing this issue.\r\n> \r\n> You could try using `--edit-format whole` for this.\r\n\r\nI should've read the docs better! \r\n\r\nWhat do you think about having the option to let Sonnet choose which format to use depending on how much needs to be changed?"
      },
      {
        "user": "razorback16",
        "created_at": "2024-07-09T17:06:03Z",
        "body": "I have another idea. What if there was an option for the model to provide its response in a human-readable format, describing the necessary code changes instead of using the diff format? Then, a more cost-effective model, such as Claude Haiku or Gemini Flash, could generate the diff from this description. Alternatively, we could fine-tune a model specifically for this purpose. What do you think?"
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-07-22T06:56:55Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open or file a new issue any time."
      }
    ]
  },
  {
    "number": 779,
    "title": "[Q] Do you know any good opensource voice clients for AI chat?",
    "created_at": "2024-07-02T20:16:27Z",
    "closed_at": "2024-07-03T00:08:59Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/779",
    "body": "Do you know any good opensource voice clients for AI chat?\r\n\r\nI tried `/voice`, and it worked quite well, even though both my accent and the internet connection here are less than ideal. I am now wondering if there any good FOSS voice-centric clients that allow one to chat with GPT4O or Sonnet 3.5.\r\n\r\nPS: The voice mode in aider is somewhat cumbersome to use? I think when one enters `/voice`, aider should go in a voice mode, and the next time it needs input, a simple enter should allow it to start listening. Typing `/voice` is inconvenient.",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/779/comments",
    "author": "NightMachinery",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-07-02T22:01:01Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nYou can just do `/v` and you can also use the up arrow to use previously entered commands.\r\n\r\nSorry, I don't have any recommendations for other voice clients."
      },
      {
        "user": "NightMachinery",
        "created_at": "2024-07-03T00:08:59Z",
        "body": "Thanks."
      }
    ]
  },
  {
    "number": 775,
    "title": "Claude 3.5 Sonnet response parsing crashed in the middle of a response",
    "created_at": "2024-07-02T15:20:48Z",
    "closed_at": "2024-07-04T11:27:15Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/775",
    "body": "### Issue\n\n```\r\n\r\n^^^ Expected `>>>>>>> REPLACE` not `=======\r\nI apologize for the formatting error in my previous response. You're absolutely right, and I appreciate your reminder about the correct format for SEARCH/REPLACE blocks. Let me provide the corrected version:\r\n\r\nscripts/create-maven-bundle.shell.kts\r\n<source>kotlin\r\n<<<<<<< SEARCH\r\nimport com.sun.org.apache.xpath.internal.Arg\r\nimport org.jetbrains.kotlin.org.apache.http.util.Args\r\nimport kotlin.system.exitProcess\r\n\r\n// Parse command line arguments\r\nval args = Args(\r\n    \"Unexpected error: litellm.InternalServerError: AnthropicException - litellm.APIConnectionError: Unable to parse response. Original response: event: error\r\nTraceback (most recent call last):\r\n  File \"/Users/mike/bin/venv/lib/python3.11/site-packages/litellm/utils.py\", line 8758, in chunk_creator\r\n    response_obj = self.handle_anthropic_chunk(chunk)\r\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/mike/bin/venv/lib/python3.11/site-packages/litellm/utils.py\", line 8000, in handle_anthropic_chunk\r\n    raise ValueError(f\"Unable to parse response. Original response: {str_line}\")\r\nValueError: Unable to parse response. Original response: event: error\r\n. Handle with `litellm.InternalServerError`.\r\nTraceback (most recent call last):\r\n  File \"/Users/mike/bin/venv/lib/python3.11/site-packages/litellm/utils.py\", line 8758, in chunk_creator\r\n    response_obj = self.handle_anthropic_chunk(chunk)\r\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/mike/bin/venv/lib/python3.11/site-packages/litellm/utils.py\", line 8000, in handle_anthropic_chunk\r\n    raise ValueError(f\"Unable to parse response. Original response: {str_line}\")\r\nValueError: Unable to parse response. Original response: event: error\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/Users/mike/bin/venv/lib/python3.11/site-packages/litellm/utils.py\", line 9480, in __next__\r\n    response: Optional[ModelResponse] = self.chunk_creator(chunk=chunk)\r\n                                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/mike/bin/venv/lib/python3.11/site-packages/litellm/utils.py\", line 9410, in chunk_creator\r\n    raise exception_type(\r\n          ^^^^^^^^^^^^^^^\r\n  File \"/Users/mike/bin/venv/lib/python3.11/site-packages/litellm/utils.py\", line 7586, in exception_type\r\n    raise e\r\n  File \"/Users/mike/bin/venv/lib/python3.11/site-packages/litellm/utils.py\", line 7559, in exception_type\r\n    raise APIConnectionError(\r\nlitellm.exceptions.APIConnectionError: litellm.APIConnectionError: Unable to parse response. Original response: event: error\r\nTraceback (most recent call last):\r\n  File \"/Users/mike/bin/venv/lib/python3.11/site-packages/litellm/utils.py\", line 8758, in chunk_creator\r\n    response_obj = self.handle_anthropic_chunk(chunk)\r\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/mike/bin/venv/lib/python3.11/site-packages/litellm/utils.py\", line 8000, in handle_anthropic_chunk\r\n    raise ValueError(f\"Unable to parse response. Original response: {str_line}\")\r\nValueError: Unable to parse response. Original response: event: error\r\n```\n\n### Version and model info\n\nAider v0.41.0\r\nModels: claude-3-5-sonnet-20240620 with diff edit format, weak model claude-3-haiku-20240307\r\nGit repo: .git with 2,044 files\r\nWarning: For large repos, consider using an .aiderignore file to ignore irrelevant files/dirs.\r\nRepo-map: using 1024 tokens",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/775/comments",
    "author": "mikehearn",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-07-02T22:27:24Z",
        "body": "Thanks for filing this issue.\r\n\r\nLooks like Anthropic's servers just returned a broken response?"
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-07-04T11:27:12Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open or file a new issue any time."
      }
    ]
  },
  {
    "number": 774,
    "title": "Feature: Proxy Support for aider",
    "created_at": "2024-07-02T15:18:08Z",
    "closed_at": "2024-07-04T11:27:30Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/774",
    "body": "### Issue\n\n**Summary:**\r\n\r\nThis feature request proposes adding support for using proxies with Aider, the AI pair programming tool.\r\n\r\n**Motivation:**\r\n\r\nCurrently, Aider directly connects to LLM APIs, which can be problematic in certain scenarios:\r\n\r\n* **Network Restrictions:** Users behind firewalls or in environments with restricted internet access may be unable to directly connect to LLM APIs.\r\n* **Privacy Concerns:** Some users may prefer routing their requests through a proxy for added privacy.\r\n\r\n**Proposed Solution:**\r\n\r\nImplement a configuration option within Aider to specify a proxy server address and port. Aider would then route all API requests through this proxy.\r\n\r\n**Implementation Details:**\r\n\r\n* **Configuration:**\r\n\r\nAdd a new section to the Aider configuration file  for proxy settings. This section could include fields for:\r\n\r\n    * `proxy_host`: The hostname or IP address of the proxy server.\r\n    * `proxy_port`: The port number of the proxy server.\r\n    * `proxy_type`: (Optional) The type of proxy (e.g., HTTP, SOCKS5).\r\n    *  `credentials`: dict to store creds\r\n\r\n**Benefits:**\r\n\r\n* **Increased Accessibility:** Enables Aider to be used in environments with network restrictions.\r\n* **Enhanced Privacy:** Provides an additional layer of privacy for users concerned about data exposure.\r\n* **Improved Reliability:** Proxies can help mitigate issues caused by network instability or rate limiting.\r\n\r\n**Additional Considerations:**\r\n\r\n* **Proxy Authentication:** Consider supporting proxy authentication mechanisms (e.g., username/password, API keys) for enhanced security.\r\n* **Proxy Selection:** Allow users to choose from a list of pre-configured proxies or specify custom proxy settings and apply round robin algorithm\r\n\r\nBy implementing proxy support, Aider can become more versatile and accessible to a wider range of users.\n\n### Version and model info\n\nAider v0.41.0\r\nModel: gemini/gemini-1.5-pro-latest with diff-fenced edit format\r\nGit repo: .git with 16 files\r\nRepo-map: using 1024 tokens",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/774/comments",
    "author": "usmanovbf",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-07-02T22:28:50Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nAider uses litellm to connect to LLM APIs, and it supports setting a base url for most providers. \r\n\r\nWhich provider do you want to proxy to?\r\n"
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-07-04T11:27:28Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open or file a new issue any time."
      },
      {
        "user": "Bit0r",
        "created_at": "2025-02-15T13:52:24Z",
        "body": "Can a proxy be set for all providers? Because many companies have firewalls and need to use a specific HTTP proxy server to access the internet."
      }
    ]
  },
  {
    "number": 769,
    "title": "'NoneType' object has no attribute 'splitlines'",
    "created_at": "2024-07-02T08:40:30Z",
    "closed_at": "2024-07-03T13:13:30Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/769",
    "body": "### Issue\n\nAider was working fine until the last update.\r\n\r\nI'm now getting this in a loop when doing a simple index.html and styles.css edit.\r\n\r\nIt even saved the file as binary instead of the code it outputs for some reason.\r\n\r\nAnyone else getting similar issues?\n\n### Version and model info\n\n_No response_",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/769/comments",
    "author": "ackoi",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-07-02T14:16:29Z",
        "body": "When reporting problems, it is very helpful if you can provide:\r\n\r\n- Aider version\r\n- LLM model you are using\r\n- Any stack traces or error messages\r\n- A description of what you were doing when the error happened. \r\n\r\nIncluding the “announcement” lines that aider prints at startup is an easy way to share some of this helpful info.\r\n\r\n```\r\nAider v0.37.1-dev\r\nModels: gpt-4o with diff edit format, weak model gpt-3.5-turbo\r\nGit repo: .git with 243 files\r\nRepo-map: using 1024 tokens\r\n```"
      }
    ]
  },
  {
    "number": 768,
    "title": "Aider just does random changes and commits them",
    "created_at": "2024-07-02T08:02:33Z",
    "closed_at": "2024-07-04T11:22:11Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/768",
    "body": "### Issue\n\nJust installed. Added a file. Aider does random refactors (factorial and commits them)\n\n### Version and model info\n\nAider latest, model: gpt-4o",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/768/comments",
    "author": "znat",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-07-02T14:16:54Z",
        "body": "When reporting problems, it is very helpful if you can provide:\r\n\r\n- Aider version\r\n- LLM model you are using\r\n- Any stack traces or error messages\r\n- A description of what you were doing when the error happened. \r\n\r\nIncluding the “announcement” lines that aider prints at startup is an easy way to share some of this helpful info.\r\n\r\n```\r\nAider v0.37.1-dev\r\nModels: gpt-4o with diff edit format, weak model gpt-3.5-turbo\r\nGit repo: .git with 243 files\r\nRepo-map: using 1024 tokens\r\n```"
      },
      {
        "user": "dannylank",
        "created_at": "2024-07-02T14:46:58Z",
        "body": "It depends a lot on the model you use, I particularly like Claude2 more, it is more coherent when following instructions, for development it considers that he has better control of the changes, although it still makes mistakes, with openai I always say when starting not to make changes, only those that I tell you and try not to change the code if it is not necessary"
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-07-04T11:22:08Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open or file a new issue any time."
      }
    ]
  },
  {
    "number": 763,
    "title": "I have installed by \"Pip install aider-chat\"  after I run browser it shows error",
    "created_at": "2024-07-01T15:01:06Z",
    "closed_at": "2024-07-07T10:55:05Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/763",
    "body": "### Issue\n\nI have installed by \"Pip install aider-chat\"  after I run browser it shows error\r\n\r\n```\r\nCreating empty file D:\\dreamsleep\\venv-aider\\Lib\\site-packages\\aider\\aider\r\nAider v0.40.6\r\nModel: groq/llama3-8b-8192 with whole edit format\r\nGit repo: .git with 0 files\r\nRepo-map: disabled\r\nAdded aider to the chat.\r\n2024-07-01 19:53:59.991 Uncaught app exception\r\nTraceback (most recent call last):\r\n  File \"D:\\dreamsleep\\venv-aider\\lib\\site-packages\\streamlit\\runtime\\scriptrunner\\script_runner.py\", line 589, in _run_script\r\n    exec(code, module.__dict__)\r\n  File \"D:\\dreamsleep\\venv-aider\\Lib\\site-packages\\aider\\gui.py\", line 543, in <module>\r\n    status = gui_main()\r\n  File \"D:\\dreamsleep\\venv-aider\\Lib\\site-packages\\aider\\gui.py\", line 539, in gui_main\r\n    GUI()\r\n  File \"D:\\dreamsleep\\venv-aider\\Lib\\site-packages\\aider\\gui.py\", line 367, in __init__\r\n    self.do_sidebar()\r\n  File \"D:\\dreamsleep\\venv-aider\\Lib\\site-packages\\aider\\gui.py\", line 150, in do_sidebar\r\n    self.do_add_to_chat()\r\n  File \"D:\\dreamsleep\\venv-aider\\Lib\\site-packages\\aider\\gui.py\", line 179, in do_add_to_chat\r\n    self.do_add_files()\r\n  File \"D:\\dreamsleep\\venv-aider\\Lib\\site-packages\\aider\\gui.py\", line 183, in do_add_files\r\n    fnames = st.multiselect(\r\n  File \"D:\\dreamsleep\\venv-aider\\lib\\site-packages\\streamlit\\runtime\\metrics_util.py\", line 408, in wrapped_func\r\n    result = non_optional_func(*args, **kwargs)\r\n  File \"D:\\dreamsleep\\venv-aider\\lib\\site-packages\\streamlit\\elements\\widgets\\multiselect.py\", line 258, in multiselect\r\n    return self._multiselect(\r\n  File \"D:\\dreamsleep\\venv-aider\\lib\\site-packages\\streamlit\\elements\\widgets\\multiselect.py\", line 304, in _multiselect\r\n    indices = _check_and_convert_to_indices(opt, default)\r\n  File \"D:\\dreamsleep\\venv-aider\\lib\\site-packages\\streamlit\\elements\\widgets\\multiselect.py\", line 97, in _check_and_convert_to_indices\r\n    raise StreamlitAPIException(\r\nstreamlit.errors.StreamlitAPIException: The default value 'aider' is part of the options. Please make sure that every default values also exists in the options.\r\n```\n\n### Version and model info\n\n_No response_",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/763/comments",
    "author": "MAhmadUzair",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-07-04T11:25:06Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\nIt looks like you ran aider from a directory deep inside the virtual environment. That may have caused import problems. \n\nTry running aider from a directory with code you want to edit, or from an empty directory. \r\n"
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-07-07T10:55:02Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open or file a new issue any time."
      }
    ]
  },
  {
    "number": 762,
    "title": "Option to disallow adding link contents",
    "created_at": "2024-07-01T14:44:11Z",
    "closed_at": "2024-07-04T11:29:14Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/762",
    "body": "### Issue\n\nI want to add commandline and config option for inital complete disabling and / or setting initial \"add URL to context\" to No.\n\n### Version and model info\n\n_No response_",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/762/comments",
    "author": "david-strejc",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-07-02T14:19:29Z",
        "body": "Thanks for trying aider and filing this issue.\n\nCan you help me understand why? What are you trying to do?\r\n\r\n"
      },
      {
        "user": "david-strejc",
        "created_at": "2024-07-02T16:09:18Z",
        "body": "> Thanks for trying aider and filing this issue.\r\n> \r\n> Can you help me understand why? What are you trying to do?\r\n\r\nWhen I copy paste some code and if it contains URL aider automatically converts this URL to \"would you like to add URL to the context\" - when I for example paste log from browser console it many times contains a lot of URLs and I am asked many times if I want to add them to the context."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-07-03T14:11:53Z",
        "body": "I'm not sure it's appropriate to add an option for this special case. I think you can probably just say \"no\" when asked?"
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-07-04T11:29:11Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open or file a new issue any time."
      },
      {
        "user": "david-strejc",
        "created_at": "2024-07-08T16:33:21Z",
        "body": "In our workflow when you paste for example some HTML or something with many links you are repeating 10x or more times \"no\" \"no\" \"no\" "
      },
      {
        "user": "masonc15",
        "created_at": "2024-07-17T18:32:17Z",
        "body": "@paul-gauthier This issue comes up for me all the time in a very frustrating way. I constantly paste in markdown snippets, documentation, or even HTML code including URL links and just sitting there typing \"n\" over and over again as aider asks me if I want to add that URL to the chat. I almost never do. It's a cool feature but could it _please_ be configurable or have some sort of toggle so aider is not always asking about adding URLs?\r\n\r\nThanks for the consideration, I really love aider and I want to continue using it as much as I can!"
      }
    ]
  },
  {
    "number": 750,
    "title": "Setting API Key not working",
    "created_at": "2024-06-30T10:35:43Z",
    "closed_at": "2024-07-01T22:51:59Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/750",
    "body": "### Issue\n\nIn the docs there is written you need to use setx to set the OpenRouter API Key but actually you should use set without the x. Also not sure if you need to use export or set.\n\n### Version and model info\n\n-",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/750/comments",
    "author": "PierrunoYT",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-06-30T19:56:38Z",
        "body": "Thanks for trying aider and filing this issue. Sorry, I do not understand what you are asking?"
      },
      {
        "user": "PierrunoYT",
        "created_at": "2024-06-30T20:00:24Z",
        "body": "> Thanks for trying aider and filing this issue. Sorry, I do not understand what you are asking?\r\n\r\nI mean in the docs there it says you need to use setx to set the API Key on Windows but instead you should use set not setx. The command export is also written somewhere but not sure what's the difference betweeen set and export on Windows"
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-06-30T20:14:43Z",
        "body": "It all depends on which OS and shell you are using. Unfortunately the docs can't cover every possible way to set environment variables."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-07-01T22:51:59Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open or file a new issue any time."
      }
    ]
  },
  {
    "number": 748,
    "title": "Feature: allow user prompt in commit message instead of commit summary",
    "created_at": "2024-06-29T18:55:45Z",
    "closed_at": "2024-06-30T21:53:39Z",
    "labels": [
      "bug",
      "question",
      "fixed"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/748",
    "body": "I'm experimenting with programming just by telling the AI what to change. When I use aider iteratively in this way and it doesn't quite work, I might end up making lots of commits. To see where I got to so far, I typically prepare a command like `git diff <last good commit> HEAD` and ask for changes based on what bit of code to move where, or describing what the result misses, etc., and then I squash them all.\r\n\r\nHere's a sample of what that might look like:\r\n```\r\nRemoved unnecessary code for calculating drag offset and simplified the drag event handling.\r\nImproved the map marker dragging functionality by using the Google Maps API's projection methods to accurately calculate the new marker position during drag events.\r\nImplemented drag and drop functionality for the map marker, updating its position based on the user's drag actions.\r\nAdded support for dragging the new location map pin.\r\nAdded draggable functionality to the new location map pin component.\r\nImplemented draggable map pin functionality with updated position state and event handlers.\r\nRemoved unnecessary `onChange` event handler from `DraggableNewLocationMapPin` component and updated the `Map` component to use the `onDragEnd` event instead.\r\nAdded drag offset functionality to the DraggableNewLocationMapPin component.\r\nReordered the imports and exported components in the Pins.js file.\r\nImplemented draggable new location map pin with geocoding and map dragging control.\r\nImplemented geolocation functionality and updated map position in the Redux store.\r\nImplemented draggable new location map pin and updated position in Redux state.\r\n```\r\nThese are mostly not related of what I was trying to do, it looks like the model just looks at the diff and guesses what the change was about. For successful changes it's great - `Reordered the imports and exported components in the Pins.js file.` is really what I remember asking - and for the other ones, I'm pretty sure I told it to make adjustments and technical changes, nothing like adding support for that whole feature.\r\n\r\nI would find the tool more useful for this workflow if my own prompts were there instead. It would also be a tiny monetary saving.\r\n\r\nAn idea off the back of this feature request is to include the request made by the user in the summarization prompt - I'm guessing it's currently not there.",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/748/comments",
    "author": "wbazant",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-06-30T20:04:28Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nYou're right the summary prompt should have been including the chat messages, but was not. It was a bug. Fixed.\r\n\r\nAider used to include the chat messages in the body of the commit message, but many users did not want that. \r\n\r\nI think you want something different though? For the commit message to be solely made up of the chat messages without a one-line summary at the start?"
      },
      {
        "user": "wbazant",
        "created_at": "2024-06-30T20:56:39Z",
        "body": "I remember the commit messages had replies from the chatbot in a diff format, making them very long and hard to read. I don't mean that, I mean my prompt to aider - the message I typed after adding files and before getting the code change back.\r\n\r\nIt's not as good as an AI summary for presenting to others, but it is a short description of what aider has set out to do that the user will understand, since they wrote it.\r\n\r\nWhen I change code with software tools - something like a rename across the project - I will often include the command that makes a change, for example `find src -type f | xargs perl -i -pe 's/oldName/newName/` . By analogy, a more elaborate version would be to produce a command which reproduces the change - prompt, model version, files included, etc. but I don't know how useful that is. Meanwhile, switching off the AI summary requires something to be put in the commit message, and user's own prompt is perfect for that."
      },
      {
        "user": "wbazant",
        "created_at": "2024-06-30T21:28:57Z",
        "body": "I might be misunderstanding what the model gets when I ask for a few different things in order within a chat session. I used it as if the context of my requests was just the files I added, but I just asked it to 'review previous commit and do more of the same' and it understood me, so presumably it gets all the previous messages - I should probably be killing the aider session and restarting it a lot more, to save up on tokens!"
      },
      {
        "user": "wbazant",
        "created_at": "2024-06-30T21:53:39Z",
        "body": "Actually, I'm not sure if the feature is of a general interest, it's more for me to figure out how I like programming with LLMs. Thanks for replying, and I'm glad you found something to fix off the back off this! I'm gonna close this and I've made myself a wrapper:\r\n\r\n```\r\n#!/usr/bin/env python\r\nimport sys\r\nimport subprocess\r\n\r\ndef main():\r\n    # Capture the -m argument and the message\r\n    args = sys.argv[1:]\r\n    if '-m' not in args:\r\n        print(\"Error: -m argument is required.\")\r\n        sys.exit(1)\r\n\r\n    m_index = args.index('-m')\r\n    if m_index + 1 >= len(args):\r\n        print(\"Error: No message provided for the -m argument.\")\r\n        sys.exit(1)\r\n\r\n    commit_message = args[m_index + 1]\r\n\r\n    # Call the aider command with the original arguments\r\n    aider_command = ['aider', '--sonnet', '--no-gitignore', '--no-attribute-author', '--no-attribute-committer', '--attribute-commit-message'] + args\r\n    subprocess.run(aider_command)\r\n\r\n    # Amend the commit message with the provided message\r\n    subprocess.run(['git', 'commit', '--amend', '-m', \"Aider prompt: \" + commit_message])\r\n\r\nif __name__ == \"__main__\":\r\n    main()\r\n```"
      }
    ]
  },
  {
    "number": 744,
    "title": "ValueError: Encountered text corresponding to disallowed special token '<|endoftext|>'.",
    "created_at": "2024-06-28T17:34:34Z",
    "closed_at": "2024-07-02T14:23:43Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/744",
    "body": "### Issue\n\nrunning a fork of openpilot through aider and received the following error\r\n\r\n2024-06-28 13:32:29.131 Uncaught app exception\r\nTraceback (most recent call last):\r\n  File \"/home/user/.pyenv/versions/3.12.4/lib/python3.12/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 589, in _run_script\r\n    exec(code, module.__dict__)\r\n  File \"/home/user/.pyenv/versions/3.12.4/lib/python3.12/site-packages/aider/gui.py\", line 543, in <module>\r\n    status = gui_main()\r\n             ^^^^^^^^^^\r\n  File \"/home/user/.pyenv/versions/3.12.4/lib/python3.12/site-packages/aider/gui.py\", line 539, in gui_main\r\n    GUI()\r\n  File \"/home/user/.pyenv/versions/3.12.4/lib/python3.12/site-packages/aider/gui.py\", line 374, in __init__\r\n    self.process_chat()\r\n  File \"/home/user/.pyenv/versions/3.12.4/lib/python3.12/site-packages/aider/gui.py\", line 417, in process_chat\r\n    res = st.write_stream(self.coder.run_stream(prompt))\r\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/user/.pyenv/versions/3.12.4/lib/python3.12/site-packages/streamlit/runtime/metrics_util.py\", line 408, in wrapped_func\r\n    result = non_optional_func(*args, **kwargs)\r\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/user/.pyenv/versions/3.12.4/lib/python3.12/site-packages/streamlit/elements/write.py\", line 167, in write_stream\r\n    for chunk in stream:  # type: ignore\r\n  File \"/home/user/.pyenv/versions/3.12.4/lib/python3.12/site-packages/aider/coders/base_coder.py\", line 588, in run_stream\r\n    yield from self.send_new_user_message(user_message)\r\n  File \"/home/user/.pyenv/versions/3.12.4/lib/python3.12/site-packages/aider/coders/base_coder.py\", line 806, in send_new_user_message\r\n    messages = self.format_messages()\r\n               ^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/user/.pyenv/versions/3.12.4/lib/python3.12/site-packages/aider/coders/base_coder.py\", line 762, in format_messages\r\n    messages += self.get_files_messages()\r\n                ^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/user/.pyenv/versions/3.12.4/lib/python3.12/site-packages/aider/coders/base_coder.py\", line 530, in get_files_messages\r\n    repo_content = self.get_repo_map()\r\n                   ^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/user/.pyenv/versions/3.12.4/lib/python3.12/site-packages/aider/coders/base_coder.py\", line 520, in get_repo_map\r\n    repo_content = self.repo_map.get_repo_map(\r\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/user/.pyenv/versions/3.12.4/lib/python3.12/site-packages/aider/repomap.py\", line 84, in get_repo_map\r\n    files_listing = self.get_ranked_tags_map(\r\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/user/.pyenv/versions/3.12.4/lib/python3.12/site-packages/aider/repomap.py\", line 407, in get_ranked_tags_map\r\n    num_tokens = self.token_count(tree)\r\n                 ^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/user/.pyenv/versions/3.12.4/lib/python3.12/site-packages/aider/models.py\", line 419, in token_count\r\n    return len(self.tokenizer(msgs))\r\n               ^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/user/.pyenv/versions/3.12.4/lib/python3.12/site-packages/aider/models.py\", line 408, in tokenizer\r\n    return litellm.encode(model=self.name, text=text)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/user/.pyenv/versions/3.12.4/lib/python3.12/site-packages/litellm/utils.py\", line 1496, in encode\r\n    enc = tokenizer_json[\"tokenizer\"].encode(text)\r\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/user/.pyenv/versions/3.12.4/lib/python3.12/site-packages/tiktoken/core.py\", line 117, in encode\r\n    raise_disallowed_special_token(match.group())\r\n  File \"/home/user/.pyenv/versions/3.12.4/lib/python3.12/site-packages/tiktoken/core.py\", line 400, in raise_disallowed_special_token\r\n    raise ValueError(\r\nValueError: Encountered text corresponding to disallowed special token '<|endoftext|>'.\r\nIf you want this text to be encoded as a special token, pass it to `allowed_special`, e.g. `allowed_special={'<|endoftext|>', ...}`.\r\nIf you want this text to be encoded as normal text, disable the check for this token by passing `disallowed_special=(enc.special_tokens_set - {'<|endoftext|>'})`.\r\nTo disable this check for all special tokens, pass `disallowed_special=()`.\n\n### Version and model info\n\n--browser ",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/744/comments",
    "author": "jagoff2",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-06-30T20:11:17Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nIt sounds like you are using a local API server and a local model? It appears they may not be compatible with litellm, which aider users to connect to LLMs."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-07-02T14:23:39Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open or file a new issue any time."
      },
      {
        "user": "maxim-saplin",
        "created_at": "2024-07-08T17:11:34Z",
        "body": "I get exact same error, the problem is due to one of the source files used in chat having the special token in it, e.g. here's a piece of my Python file:\r\n```\r\n        # Did first attempt with direct apply_chat_template without add_generation_prompt=True and adjusting result, trained for a few epochs, bot turned up crazy\r\n        # 'prompt': '<|user|>\\nQ:Question: how ... Yes or no.\\nA:<|endoftext|>\\n',\r\n...\r\n```\r\n\r\nAs you can see the special token is mentioned in the comments.\r\n\r\nSeems like setting `disallowed_special` to a few ChatML special tokens (e.g. <|endoftext|>,  <|assistant|> etc.) might help solving the issues. \r\n\r\nThe case is relevant for those ones tinkering with HF Transformers and finetuning models."
      }
    ]
  },
  {
    "number": 742,
    "title": "Suggestion: Use gh to access issues on private repos",
    "created_at": "2024-06-28T02:21:56Z",
    "closed_at": "2024-06-30T20:15:28Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/742",
    "body": "### Issue\n\naider works great to fix my issues, but currently it can't see the issues in my private repos without cutting and pasting the content.  Could it use `gh issue list` and `view` to look at issues?  Or can it already to this and I'm not understanding?\n\n### Version and model info\n\naider 0.40.6",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/742/comments",
    "author": "raymondclowe",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-06-28T02:43:26Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\nYou should be able to do `/run gh issue view XXX` to share issues from private repos in the chat. \r"
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-06-30T20:15:28Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open or file a new issue any time."
      }
    ]
  },
  {
    "number": 735,
    "title": "Relation between Def and ref in repo map, may be wrong because mapping by function or method name ",
    "created_at": "2024-06-26T06:48:56Z",
    "closed_at": "2024-06-30T20:13:32Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/735",
    "body": "for example, i have some method with the same name in different files, there are not only one definers?\r\n\r\n```python \r\n for ident in idents:\r\n            definers = defines[ident]\r\n            if ident in mentioned_idents:\r\n                mul = 10\r\n            else:\r\n                mul = 1\r\n            for referencer, num_refs in Counter(references[ident]).items():\r\n                for definer in definers:\r\n                    # if referencer == definer:\r\n                    #    continue\r\n                    G.add_edge(referencer, definer, weight=mul * num_refs, ident=ident)\r\n```\r\n",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/735/comments",
    "author": "zbflcy",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-06-27T17:32:11Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nAider uses heuristics to match defs and refs, and it's ok if they are not perfect. It will consider all the possible definers as defs."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-06-30T20:13:32Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open or file a new issue any time."
      }
    ]
  },
  {
    "number": 733,
    "title": "Option to output to stdout/stderr instead of console",
    "created_at": "2024-06-25T23:00:10Z",
    "closed_at": "2024-07-04T11:25:55Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/733",
    "body": "### Issue\r\n\r\nI am currently modifying the InputOutput class to output to stdout/err when a command line option `--stdout` is provided. I am working on this to see if I can get better functionality with vscode extensions (the default terminal there does not provide output) and I am having to use `node-pty` to talk to aider but it does not support some of the current console functionality.\r\n\r\nAll that to say is that in making changes I have seen a few other places in the code that creates a new console and/or uses io.console directly. I was thinking of adding functions in InputOuput for all those random calls and replace the calls with io._func_ calls. I am also looking at adding some kind of \\<tag\\>, maybe json, or something to the output going to stdout to make it easier to parse what is being sent and received and identify diffs, errors, etc...\r\n\r\nAny ideas and direction for this would be appreciated.\r\n\r\n### Version and model info\r\n\r\n_No response_",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/733/comments",
    "author": "caseymcc",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-07-02T14:25:42Z",
        "body": "This is probably out of scope for aider. But I do hope to refactor the scripting api to make it easier to do what you're asking about. Not in the exact way you propose though. "
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-07-04T11:25:53Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open or file a new issue any time."
      }
    ]
  },
  {
    "number": 729,
    "title": "/commit not rebuilding repo map",
    "created_at": "2024-06-25T10:25:52Z",
    "closed_at": "2024-07-04T11:28:15Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/729",
    "body": "### Issue\n\nHi,\r\n\r\nI added files to the project, requested in #728 and I did /commit.\r\n\r\nBut it seems that /commit is not updating repo map because I'm not able to add new files using /add\r\n\r\n/ls also not display them\r\n\r\n\n\n### Version and model info\n\n_No response_",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/729/comments",
    "author": "ErykCh",
    "comments": [
      {
        "user": "ErykCh",
        "created_at": "2024-06-25T10:28:47Z",
        "body": "I use Visual Studio to preview code. And I did one refactoring outside Aider. And it looks like VS didn't add these files to the metadata kept in the .git directory\r\n\r\nBecause it looks like Aider uses data saved in .git and not actual files in the system.\r\n\r\nIt helped to do:\r\ngit update-index --really-refresh\r\n\r\nso it looks like doing /commit in Aider after doing refactoring in an external tool doesn't update all files"
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-06-25T13:27:45Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nAider can only work with files that are part of your git repo. If you create new files, you need to `git add` them before aider can work with them."
      },
      {
        "user": "ErykCh",
        "created_at": "2024-06-28T09:46:51Z",
        "body": "I think it would be helpful if Aider verified the state of the repository before sending a query to the model.\r\n\r\nIt should say that in the meantime someone has modified the files and its status is not up to date.\r\n\r\nIt's best if /commit not only commits, but also adds all new files to the project. Then you can change it to some /sync command and then the description that if you make modifications outside the aider, you must synchronize the Aider before you start asking further questions."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-06-30T20:16:26Z",
        "body": "Aider always uses the current state of the repo."
      },
      {
        "user": "ErykCh",
        "created_at": "2024-06-30T21:58:47Z",
        "body": "Yes, but the question is if Aider can check if current state of the repo is synchronized with file system?"
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-06-30T22:10:55Z",
        "body": "I'm not sure I understand your question."
      },
      {
        "user": "ErykCh",
        "created_at": "2024-07-01T20:25:44Z",
        "body": "yeah, bots still need to evolve a bit as they respond to issues added by users on github.\r\n\r\nCan you tell me your bot's name?"
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-07-02T14:17:54Z",
        "body": "This tool is called aider. "
      },
      {
        "user": "ErykCh",
        "created_at": "2024-07-03T07:15:34Z",
        "body": "Nice.\r\nWell, I will say that he handles tickets quite well, he rarely gets lost. Unless you or the bot respond alternately :-)"
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-07-04T11:28:11Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open or file a new issue any time."
      }
    ]
  },
  {
    "number": 724,
    "title": "module 'litellm' has no attribute 'validate_environment'",
    "created_at": "2024-06-25T03:21:09Z",
    "closed_at": "2024-07-02T14:23:59Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/724",
    "body": "### Issue\n\nI can't run repomap and get the following error:\r\n\r\n```\r\n   res = litellm.validate_environment(model)\r\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nAttributeError: module 'litellm' has no attribute 'validate_environment'\r\n```\r\n\r\nI installed the dependencies from the Aider repo using:\r\n\r\n```pip install -r requirements.txt```\n\n### Version and model info\n\n_No response_",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/724/comments",
    "author": "ramsey-coding",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-06-25T13:51:43Z",
        "body": "Sorry, can you be more clear about exactly what you are doing to see this error?"
      },
      {
        "user": "Symbolk",
        "created_at": "2024-06-28T06:43:30Z",
        "body": "@paul-gauthier Hi, I also encountered errors with litellm, but it is:\r\n\r\nAttributeError: module 'litellm' has no attribute 'exceptions'\r\n\r\nHowever, the venv\\Lib\\site-packages\\litellm\\exceptions.py does exist and can be opened in PyCharm.\r\n\r\nP.S. pip show litellm==1.40.26, I also tried to upgrade it to the latest 1.40.29 but still the same error."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-06-30T20:08:29Z",
        "body": "This is probably due to an issue with your local python environment. Are you doing something other than running off a vanilla `pip install aider-chat`?"
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-07-02T14:23:56Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open or file a new issue any time."
      },
      {
        "user": "Symbolk",
        "created_at": "2024-07-08T11:41:38Z",
        "body": "> This is probably due to an issue with your local python environment. Are you doing something other than running off a vanilla `pip install aider-chat`?\r\n\r\nI directly cloned the code, pip install -r req.txt,  and ran aider/main.py, which throws the error:\r\n```\r\nTraceback (most recent call last):\r\n  File \"D:\\coding\\ai\\aider\\aider\\main.py\", line 15, in <module>\r\n    from aider.coders import Coder\r\n  File \"D:\\coding\\ai\\aider\\aider\\coders\\__init__.py\", line 1, in <module>\r\n    from .base_coder import Coder\r\n  File \"D:\\coding\\ai\\aider\\aider\\coders\\base_coder.py\", line 22, in <module>\r\n    from aider.history import ChatSummary\r\n  File \"D:\\coding\\ai\\aider\\aider\\history.py\", line 5, in <module>\r\n    from aider.sendchat import simple_send_with_retries\r\n  File \"D:\\coding\\ai\\aider\\aider\\sendchat.py\", line 38, in <module>\r\n    litellm.exceptions.APIConnectionError,\r\nAttributeError: module 'litellm' has no attribute 'exceptions'\r\n```\r\n\r\nP.S. pip install aider-chat is totally ok, I am on Win11.\r\n\r\nP.S.2, later I tried on macOS14 and CentOS, mac is ok but CentOS is not, seems to be an OS issue."
      },
      {
        "user": "Zzhiter",
        "created_at": "2024-09-26T00:36:09Z",
        "body": "metoo"
      }
    ]
  },
  {
    "number": 720,
    "title": "Overzealous SQL linting",
    "created_at": "2024-06-25T02:13:47Z",
    "closed_at": "2024-09-09T21:31:29Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/720",
    "body": "### Issue\n\nThe linter is consistently marking various lines in SQL edits as incorrect when they are not.  I've seen it mark lots of primary key column defs, some `PRAGMA` statements, and at least one non-primary-key column def.  The spurious issues aren't the end of the world, but they add friction.\r\n\r\nJust to see, I let Sonnet-3.5 try to fix one such issue, and it agreed there's no issue:\r\n\r\n```\r\n# Fix any errors below, if possible.\r\n\r\n\r\n## See relevant line below marked with █.\r\n\r\nsrc/gened/migrations/20240608--add_experiment_tables.sql:\r\n...⋮...\r\n  6│\r\n  7│-- Create experiments table\r\n  8│CREATE TABLE experiments (\r\n  9█    id          INTEGER PRIMARY KEY AUTOINCREMENT,\r\n 10│    name        TEXT NOT NULL UNIQUE,\r\n 11│    description TEXT\r\n 12│);\r\n 13│\r\n...⋮...\r\n\r\n\r\nAttempt to fix lint errors? y\r\nI apologize for the confusion. The migration script you've shown is actually correct\r\nand doesn't contain any errors. The line marked with █ is perfectly valid SQL for\r\ncreating a table with an auto-incrementing primary key. There's no need to make any\r\nchanges to this file.\r\n\r\nIf you'd like me to make any specific modifications or if you have any other concerns\r\nabout the migration script, please let me know, and I'll be happy to assist you further.\r\n```\r\n\r\nThis is a script for SQLite in particular, if it matters.  Possibly it's an issue of SQL dialects.\n\n### Version and model info\n\nAider v0.40.0\r\nModels: claude-3-5-sonnet-20240620 with diff edit format, weak model claude-3-haiku-20240307",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/720/comments",
    "author": "liffiton",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-06-25T13:54:57Z",
        "body": "Thanks for trying aider and filing this issue. I can look into this and try and determine why the sql linter is triggering these spurious issues.\r\n\r\nIf the sql linting is problematic for you, you could to `--lint-cmd sql:echo` to disable it."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-09-09T21:31:30Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open. Or feel free to file a new issue any time."
      }
    ]
  },
  {
    "number": 714,
    "title": "What is the response format in which aider responds?",
    "created_at": "2024-06-24T10:22:51Z",
    "closed_at": "2024-06-28T02:46:51Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/714",
    "body": "### Issue\n\nI want to know about response format in which aider responds?\n\n### Version and model info\n\n_No response_",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/714/comments",
    "author": "MAhmadUzair",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-06-24T22:25:10Z",
        "body": "Aider can speak any API that litellm supports. "
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-06-28T02:46:48Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open or file a new issue any time."
      }
    ]
  },
  {
    "number": 686,
    "title": "A comment adder",
    "created_at": "2024-06-15T21:41:19Z",
    "closed_at": "2024-06-20T21:53:13Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/686",
    "body": "Just to add comments",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/686/comments",
    "author": "Ulladay-Hub",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-06-19T05:01:54Z",
        "body": "Thanks for trying aider and filing this issue. I'm not sure I understand your comment. Can you explain more?\r\n\r\n"
      },
      {
        "user": "Ulladay-Hub",
        "created_at": "2024-06-19T06:54:50Z",
        "body": "A function where it can only add comments, no code. Just for if you want to upload it to GitHub, it can be more readable."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-06-20T14:24:08Z",
        "body": "Have you tried just asking aider to add comments?"
      },
      {
        "user": "Ulladay-Hub",
        "created_at": "2024-06-20T21:53:13Z",
        "body": "Oh...."
      }
    ]
  },
  {
    "number": 681,
    "title": "Feature: configure the amount of retries and allow continueing retrying",
    "created_at": "2024-06-14T17:42:50Z",
    "closed_at": "2024-06-15T01:01:14Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/681",
    "body": "### Issue\n\nI am heavily relying on test-cmd to safely request new changes at it will retry for a few times to successfully add changes to code.\r\nIt would be very helpful to be able to change the retrying number from 3 from within the configuration.\r\nMaybe in addition - have a way to continue retry another time after it has stopped/stopping after 3 retries.\r\n\r\nIt is true that 80% of the cases are fixed within 1-2 retries.\n\n### Version and model info\n\nLatest aider,\r\nGPT-4o",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/681/comments",
    "author": "Nucs",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-06-14T22:59:44Z",
        "body": "You can just run `/test` again. Or press up-arrow to re-send the last command."
      }
    ]
  },
  {
    "number": 680,
    "title": "Feature: provide arguments when configuring test-cmd",
    "created_at": "2024-06-14T17:40:43Z",
    "closed_at": "2024-06-23T04:51:48Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/680",
    "body": "### Issue\n\nI am heavily relying on test-cmd to safely request new changes at it will retry for a few times to successfully add changes to code.\r\nThe problem is it can very well accept a single-word. It can't accept \"dotnet test\" or \"pwsh -File test_file.ps1 arg1 arg2\"\r\n\r\nIt would be helpful to have a way either to specify arguments separately or within the existing cfg property \"test-cmd\".\r\nWhen specifying \"dotnet test\" or anything similar the error is: The filename, directory name, or volume label syntax is incorrect.\r\n\n\n### Version and model info\n\nAider latest,\r\nGPT-4o",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/680/comments",
    "author": "Nucs",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-06-14T22:58:57Z",
        "body": "Thanks for filing this issue. You can quote the multi-word test command like this:\r\n\r\n```\r\naider --test-cmd \"dotnet test\"\r\n```\r\n\r\nFor example:\r\n\r\n```\r\n$ aider --test-cmd \"echo 1 2 3\"\r\nAider v0.37.1-dev\r\nModels: gpt-4o with diff edit format, weak model gpt-3.5-turbo\r\nGit repo: .git with 38 files\r\nRepo-map: using 1024 tokens\r\nUse /help to see in-chat commands, run with --help to see cmd line args\r\n────────────────────────────────────────────────────────────────────────────────────────────────\r\n> /test\r\n\r\n1 2 3\r\n```"
      },
      {
        "user": "Nucs",
        "created_at": "2024-06-15T00:56:28Z",
        "body": "I've configured yml like this:\r\n```yaml\r\n## Specify command to run tests\r\ntest-cmd: \"dotnet test\"\r\n\r\n## Enable/disable automatic testing after changes (default: False)\r\nauto-test: true\r\n\r\n## Run tests and fix problems found\r\ntest: true\r\n```\r\n\r\nAnd startup doesn't work properly and looks like this:\r\n```\r\n(aider) C:\\workdir>aider\r\nAider v0.37.0\r\nModel: openai/gpt-4o-2024-05-13 with diff edit format\r\nGit repo: .git with 14 files\r\nRepo-map: using 1024 tokens\r\n'\"dotnet test\"' is not recognized as an internal or external command,\r\noperable program or batch file.\r\n```\r\n\r\nOn a second commandline I get this:\r\n```cmd\r\nC:\\Users\\ELI>dotnet test\r\n\r\nWelcome to .NET 8.0!\r\n---------------------\r\nSDK Version: 8.0.302\r\n```"
      },
      {
        "user": "Nucs",
        "created_at": "2024-06-15T01:07:33Z",
        "body": "> Thanks for filing this issue. You can quote the multi-word test command like this:\r\n> \r\n> ```\r\n> aider --test-cmd \"dotnet test\"\r\n> ```\r\n> \r\n> For example:\r\n> \r\n> ```\r\n> $ aider --test-cmd \"echo 1 2 3\"\r\n> Aider v0.37.1-dev\r\n> Models: gpt-4o with diff edit format, weak model gpt-3.5-turbo\r\n> Git repo: .git with 38 files\r\n> Repo-map: using 1024 tokens\r\n> Use /help to see in-chat commands, run with --help to see cmd line args\r\n> ─────────────────────────────────────────────────────────\r\n> > /test\r\n> \r\n> 1 2 3\r\n> ```\r\n\r\n```\r\n(aider) C:\\Users\\ELI\\workdir>aider --test-cmd \"echo 1 2 3\"\r\nAider v0.37.0\r\nModel: openai/gpt-4o-2024-05-13 with diff edit format\r\nGit repo: .git with 14 files\r\nRepo-map: using 1024 tokens\r\nUse /help to see in-chat commands, run with --help to see cmd line args\r\n─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n> /test\r\n\r\n'\"echo 1 2 3\"' is not recognized as an internal or external command,\r\noperable program or batch file.\r\n```\r\n\r\nI am unable to replicate what you have showcased."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-06-20T14:49:06Z",
        "body": "Something about your shell environment is preventing `--test-cmd \"echo 1 2 3\"` from being cleanly parsed as 2 command line arguments: `--test-cmd` and `echo 1 2 3`. For some reason your shell is parsing them as `--test-cmd` and `\"echo 1 2 3\"`.\r\n\r\nBoth `cmd.exe` and PowerShell should parse them properly. I am probably not able to help debug your local shell environment."
      }
    ]
  },
  {
    "number": 658,
    "title": "Question / contributing test cases.",
    "created_at": "2024-06-10T04:09:51Z",
    "closed_at": "2024-06-13T14:22:43Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/658",
    "body": "### Issue\n\nAmazing project.\r\n\r\nI'm under the impression that if I were to contribute additional test cases for the benchmark, that might help with getting those tasks to work in the long run, is that correct? \r\n\r\nIf so, is there some way to contribute (typescript) tasks/test cases for the benchmark?\r\n\r\nOr is there some even better path to getting aider to become capable of new things? \n\n### Version and model info\n\n_No response_",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/658/comments",
    "author": "arthurwolf",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-06-10T22:42:46Z",
        "body": "Thanks for trying aider and filing this issue. The main aider benchmark is based on Exercism python problems. It probably wouldn't be hard for someone to adapt the benchmark harness to run Exercism problems for other languages.\r\n\r\nBut I'm not sure that's directly a way to get \"aider to become capable of new things\". Aider should work fine with typescript code bases.\r\n\r\nIs there something you're trying to do that isn't working the way you'd expect?"
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-06-13T14:22:39Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open or file a new issue any time."
      }
    ]
  },
  {
    "number": 640,
    "title": "Question: Generate new project using Aider?",
    "created_at": "2024-06-03T22:01:21Z",
    "closed_at": "2024-06-07T09:21:23Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/640",
    "body": "### Issue\n\nHello,  \r\nhow can I start new project from scratch using Aider? For example, how can I tell Aider to _\"Generate boilerplate for Chrome extension which will have popup window with one button.\"_ ? \r\n\r\nSuch task requires creation of multiple files. And I want Aider to think of the proper file names, it's content etc. \r\n\r\nThank you. \n\n### Version and model info\n\n_No response_",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/640/comments",
    "author": "Michal-Mikolas",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-06-03T22:33:38Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nHave try tried running aider in an empty directory and literally typing \"Generate boilerplate for Chrome extension which will have popup window with one button\"  into the chat? I just did, and aider made some logical looking files...\r\n\r\n```\r\n> Generate boilerplate for Chrome extension which will have popup window with one button.\r\n\r\nHere is the boilerplate code for a Chrome extension with a popup window containing one button:\r\n\r\n...\r\n\r\nThis setup includes:\r\n\r\n 1 manifest.json to define the extension.\r\n 2 popup.html for the popup window with a button.\r\n 3 popup.js to handle the button click event.\r\n 4 Placeholder paths for icon images.\r\n```"
      },
      {
        "user": "Michal-Mikolas",
        "created_at": "2024-06-07T09:21:23Z",
        "body": "Wow that works, thank you :-) "
      }
    ]
  },
  {
    "number": 601,
    "title": "gpt-4o model context window error",
    "created_at": "2024-05-13T23:23:06Z",
    "closed_at": "2024-05-16T16:03:47Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/601",
    "body": "Thank you for this great program!\r\n\r\nUsing the gpt-4o model to edit a single markdown file, I keep running into the cryptic error below, or variations of the same.  It seems like I should be nowhere near an error situation, but requests fail with this message, saying 7k tokens exceeds the context window size, which it reports as 128k.  Similar writing requests made to any of the gpt-3.5 or gpt-4 models seem to work just fine, although I'd prefer to use the faster, cheaper, and hopefully smarter gtp-4o.\r\n\r\nThe expectation is that the returned text diff would be applied to the files.  The actual result is the error message quoted below.\r\n\r\nAider v0.35.1-dev                                                                                                                                                         \r\nModels: openai/gpt-4o with diff edit format, weak model gpt-3.5-turbo                                                                                                     \r\nGit repo: .git with 8 files                                                                                                                                               \r\nRepo-map: using 1024 tokens                                                                                                                                               \r\n\r\n```\r\nThe chat session is larger than the context window!                                                                     \r\n                                                                                                                                                                          \r\nApproximate context window usage, in tokens:                                                                                                                              \r\n                                                                                                                                                                          \r\n$ 0.0045      902 system messages                                                                                                                                         \r\n$ 0.0059    1,172 chat history    use /clear to clear                                                                                                                     \r\n$ 0.0261    5,227 app.md          use /drop to drop from chat                                                                                                             \r\n$ 0.0009      171 diagrams.md     use /drop to drop from chat                                                                                                             \r\n==================                                                                                                                                                        \r\n$ 0.0374    7,472 tokens total                                                                                                                                            \r\n          120,528 tokens remaining in context window                                                                                                                      \r\n          128,000 tokens max context window size                                                                                                                          \r\n                                                                                                                                                                          \r\nTo reduce token usage:                                                                                                                                                    \r\n - Use /drop to remove unneeded files from the chat session.                                                                                                              \r\n - Use /clear to clear chat history.                \r\n```",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/601/comments",
    "author": "u2324",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-05-13T23:38:23Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nWhen does it output this error? Right after you send a chat message? After the model replies with a LONG reply?"
      },
      {
        "user": "u2324",
        "created_at": "2024-05-13T23:42:06Z",
        "body": "Yes, in the middle of a long reply:\r\n\r\n$ wc reply\r\n  506  2287 18259 reply\r\n  \r\nThat's the length of the reply in lines, words, and bytes, in that order.  \r\n\r\nHowever, the exact same request to gpt-4 or gpt-3.5 completes without issue, although I didn't count the length of the replies.   If the request needs to be broken up, I can usually just say \"continue\" and it will do so.\r\n"
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-05-13T23:47:00Z",
        "body": "Ah, you may have hit the output limit. I believe gpt-4o can only output 4k tokens. Based on that `wc` output, that looks like more than 4k."
      },
      {
        "user": "u2324",
        "created_at": "2024-05-13T23:50:40Z",
        "body": "I see, thank you for letting me know.  I will try to isolate sections of text in separate files so the output is smaller, and use the older models for re-organizing text (which is where this repeatedly fails).  Perhaps the error message could be improved."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-05-16T16:03:47Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open or file a new issue any time."
      }
    ]
  },
  {
    "number": 599,
    "title": "existing folder contents overridden when `/add dirname/` in `aider --yes`",
    "created_at": "2024-05-08T22:27:05Z",
    "closed_at": "2024-05-23T21:15:56Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/599",
    "body": "### Issue\n\nI had just had chat_gpt refactor my aider-made code, and make tests for it, and wanted to go back and start running those tests via the aider /run loop. I had previously made new files, made a tests folder, and in vs code dragged them into that folder. Then in the terminal I went back to aider and switched from the single-file to multi-file context, including the subfolder of tests I tried to add. Since I was in --yes mode, it appears to have assumed it needed to create a new blank tests folder. I don't know why it did that or why it crashed, but now my tests folder is empty and I don't have those test files in vs code anymore.\r\n\r\nI acknowledge that I **Should Have** committed my own new files first so I wasn't asking aider to operate on uncommitted changes... and I can just copy/paste the files from chatgpt again.. so it's no big loss, just maybe this is an avoidable bug.\r\n\r\n```\r\n─────────────────────────────────────────────────────────────────────────────────────────────────────\r\nchatgpt.py> /drop chatgpt.py\r\n\r\nRemoved chatgpt.py from the chat\r\n─────────────────────────────────────────────────────────────────────────────────────────────────────\r\n> /add page_splitter.py main.py document_parser.py tests/\r\n\r\nNo files matched 'tests/'. Do you want to create \r\nC:\\Users\\vandersen\\source\\repos\\SMWParser\\design_tools\\docx_splitter\\tests? yes\r\nAdded C:\\Users\\vandersen\\source\\repos\\SMWParser\\design_tools\\docx_splitter\\document_parser.py to the \r\nchat\r\nAdded C:\\Users\\vandersen\\source\\repos\\SMWParser\\design_tools\\docx_splitter\\main.py to the chat\r\nTraceback (most recent call last):\r\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\r\n  File \"<frozen runpy>\", line 88, in _run_code\r\n  File \"C:\\Users\\vandersen\\source\\repos\\SMWParser\\design_tools\\docx_splitter\\env\\Scripts\\aider.exe\\__main__.py\", line 7, in <module>\r\n  File \"C:\\Users\\vandersen\\source\\repos\\SMWParser\\design_tools\\docx_splitter\\env\\Lib\\site-packages\\aider\\main.py\", line 402, in main\r\n    coder.run()\r\n  File \"C:\\Users\\vandersen\\source\\repos\\SMWParser\\design_tools\\docx_splitter\\env\\Lib\\site-packages\\aider\\coders\\base_coder.py\", line 476, in run\r\n    new_user_message = self.run_loop()\r\n                       ^^^^^^^^^^^^^^^\r\n  File \"C:\\Users\\vandersen\\source\\repos\\SMWParser\\design_tools\\docx_splitter\\env\\Lib\\site-packages\\aider\\coders\\base_coder.py\", line 503, in run_loop\r\n    return self.commands.run(inp)\r\n           ^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"C:\\Users\\vandersen\\source\\repos\\SMWParser\\design_tools\\docx_splitter\\env\\Lib\\site-packages\\aider\\commands.py\", line 133, in run\r\n    return self.do_run(matching_commands[0][1:], rest_inp)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"C:\\Users\\vandersen\\source\\repos\\SMWParser\\design_tools\\docx_splitter\\env\\Lib\\site-packages\\aider\\commands.py\", line 107, in do_run\r\n    return cmd_method(args)\r\n           ^^^^^^^^^^^^^^^^\r\n  File \"C:\\Users\\vandersen\\source\\repos\\SMWParser\\design_tools\\docx_splitter\\env\\Lib\\site-packages\\aider\\commands.py\", line 421, in cmd_add\r\n    content = self.io.read_text(abs_file_path)\r\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"C:\\Users\\vandersen\\source\\repos\\SMWParser\\design_tools\\docx_splitter\\env\\Lib\\site-packages\\aider\\io.py\", line 165, in read_text\r\n    with open(str(filename), \"r\", encoding=self.encoding) as f:\r\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nPermissionError: [Errno 13] Permission denied: 'C:\\\\Users\\\\vandersen\\\\source\\\\repos\\\\SMWParser\\\\design_tools\\\\docx_splitter\\\\tests'\r\n(env) \r\n```\r\n\n\n### Version and model info\n\nAider v0.32.0\r\nModels: gpt-4-1106-preview with udiff edit format, weak model gpt-3.5-turbo        \r\nGit repo: .git with 2 files\r\nRepo-map: using 1024 tokens\r\nVSCode terminal detected, pretty output has been disabled.\r\nUse /help to see in-chat commands, run with --help to see cmd line args",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/599/comments",
    "author": "VictorBargains",
    "comments": [
      {
        "user": "VictorBargains",
        "created_at": "2024-05-08T22:41:08Z",
        "body": "Possibly unrelated... maybe another thing to smooth over?\r\n```bash\r\naider --yes tests/* *.py\r\ntests/__pycache__ is a directory, not provided alone.\r\nProvide either a single directory of a git repo, or a list of one or more files.  \r\n```\r\nit worked to do tests/*.py instead but maybe this kinda thing can just be ignored and the other files can still be loaded?"
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-05-16T16:02:56Z",
        "body": "Thanks for trying aider and filing this issue. \r\n\r\nI can not reproduce this error:\r\n\r\n```\r\n$ aider --yes\r\n\r\nNo git repo found, create one to track GPT's changes (recommended)? y\r\nGit repository created in the current working directory.\r\nAdded .aider* to .gitignore\r\nAider v0.35.1-dev\r\nModels: gpt-4o with diff edit format, weak model gpt-3.5-turbo\r\nGit repo: .git with 0 files\r\nRepo-map: using 1024 tokens\r\nUse /help to see in-chat commands, run with --help to see cmd line args\r\n──────────────────────\r\n> /add subdir/\r\n\r\nNo files matched 'subdir/'. Do you want to create /Users/gauthier/tmp/subdir-bug/subdir? yes\r\n/Users/gauthier/tmp/subdir-bug/subdir: is a directory\r\nUnable to read /Users/gauthier/tmp/subdir-bug/subdir\r\n──────────────────────\r\n> /exit\r\n\r\n$ ls -l subdir/\r\ntotal 0\r\n-rw-r--r--  1 gauthier  staff  0 May 16 08:58 file-in-subdir.txt\r\n```\r\n\r\nThe fact that you got a `PermissionError` also makes me think aider wasn't able to *do* anything to your `tests/` folder. Aider doesn't **ever** try and delete files.\r\n\r\nAre you able to reproduce this bug?"
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-05-23T21:15:57Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open or file a new issue any time."
      }
    ]
  },
  {
    "number": 589,
    "title": "Getting BadObject error when running Aider",
    "created_at": "2024-05-03T17:26:24Z",
    "closed_at": "2024-05-06T14:06:42Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/589",
    "body": "### Issue\n\nI am running into a git `BadObject` error. I'm not sure why this is arising. I had it once before and I just re-cloned the repo and then it started working.\r\n\r\nThis is the full error message:\r\n\r\n```shell\r\n ❯ aider [my_file.py]\r\nTraceback (most recent call last):\r\n  File \"/Users/johndoe/.local/bin/aider\", line 8, in <module>\r\n    sys.exit(main())\r\n             ^^^^^^\r\n  File \"/Users/johndoe/.local/pipx/venvs/aider-chat/lib/python3.11/site-packages/aider/main.py\", line 346, in main\r\n    coder.show_announcements()\r\n  File \"/Users/johndoe/.local/pipx/venvs/aider-chat/lib/python3.11/site-packages/aider/coders/base_coder.py\", line 298, in show_announcements\r\n    for line in self.get_announcements():\r\n                ^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/johndoe/.local/pipx/venvs/aider-chat/lib/python3.11/site-packages/aider/coders/base_coder.py\", line 133, in get_announcements\r\n    num_files = len(self.repo.get_tracked_files())\r\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/johndoe/.local/pipx/venvs/aider-chat/lib/python3.11/site-packages/aider/repo.py\", line 194, in get_tracked_files\r\n    for blob in commit.tree.traverse():\r\n  File \"/Users/johndoe/.local/pipx/venvs/aider-chat/lib/python3.11/site-packages/git/objects/util.py\", line 575, in _traverse\r\n    addToStack(stack, item, branch_first, nd)\r\n  File \"/Users/johndoe/.local/pipx/venvs/aider-chat/lib/python3.11/site-packages/git/objects/util.py\", line 535, in addToStack\r\n    lst = self._get_intermediate_items(item)\r\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/johndoe/.local/pipx/venvs/aider-chat/lib/python3.11/site-packages/git/objects/tree.py\", line 207, in _get_intermediate_items\r\n    return tuple(index_object._iter_convert_to_object(index_object._cache))\r\n                                                      ^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/johndoe/.local/pipx/venvs/aider-chat/lib/python3.11/site-packages/gitdb/util.py\", line 253, in __getattr__\r\n    self._set_cache_(attr)\r\n  File \"/Users/johndoe/.local/pipx/venvs/aider-chat/lib/python3.11/site-packages/git/objects/tree.py\", line 213, in _set_cache_\r\n    ostream = self.repo.odb.stream(self.binsha)\r\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/johndoe/.local/pipx/venvs/aider-chat/lib/python3.11/site-packages/gitdb/db/base.py\", line 213, in stream\r\n    return self._db_query(sha).stream(sha)\r\n           ^^^^^^^^^^^^^^^^^^^\r\n  File \"/Users/johndoe/.local/pipx/venvs/aider-chat/lib/python3.11/site-packages/gitdb/db/base.py\", line 197, in _db_query\r\n    raise BadObject(sha)\r\ngitdb.exc.BadObject: BadObject: b'4ad4ff262c9d5557e4e08899715365b5bd1af1c1'\r\n```\r\n\r\nHowever, when I look at that object in git, it appears to be a valid object.\r\n\r\n```shell\r\n ❯ git show 4ad4ff262c9d5557e4e08899715365b5bd1af1c1\r\ntree 4ad4ff262c9d5557e4e08899715365b5bd1af1c1\r\n\r\n[file1]\r\n[file2]\r\n...\r\n```\r\n\r\nI'm not sure if this would make sense, but maybe there needs to be a try-catch block in the code to just skip over objects that for some reason appear to be bad objects and simply print a warning to the user. \n\n### Version and model info\n\naider 0.31.1\r\nGit repo with 100,000+ files\r\nDefault GPT model settings",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/589/comments",
    "author": "avi-cenna",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-05-03T20:43:01Z",
        "body": "Thanks for trying aider and filing this issue. My best guess is that something was corrupt about your git repo. The fact that it works with a fresh clone of the repo seems to support that.\r\n\r\nUnfortunately, it's not wise for aider to catch and ignore this error. It's happening while aider is trying to get the list of all the files in the repo, which it needs to operate. If the repo is damaged to the point where it can't list the files, aider should probably not try and proceed."
      },
      {
        "user": "avi-cenna",
        "created_at": "2024-05-06T14:06:42Z",
        "body": "Thanks for your response. I found that my issue was indeed related to corruption in my repo. Here is what I did to resolve my issue, without have to do a fresh clone of the repo.\r\n\r\n1. Run `git fsck --full`\r\n  When I ran this, I noticed several `dangling commit` or `dangling blob` messages.\r\n2. Run `git gc --prune=now`\r\n  This cleared the issues identified in step 1 above.\r\n\r\nAider is now working for me again; I will close this issue. "
      }
    ]
  },
  {
    "number": 566,
    "title": "Feature: respect indent in brace-based languages",
    "created_at": "2024-04-20T20:40:16Z",
    "closed_at": "2024-06-20T14:29:46Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/566",
    "body": "Claude 3 Opus likes to append methods to a Java/Kotlin class by doing a search/replace on an empty block whilst providing indented text. Aider just adds this to the end of the file, but it would be smarter to spot when the file ends with a brace and position the newly inserted block within the right scope, as determined by computing the minimum indent of the provided block.\r\n\r\nExample:\r\n\r\n```\r\n <<<<<<< SEARCH\r\n =======\r\n     private fun invokeTask(task: BuildTask, cacheKey: String?, retryCount: Int = 0): Any? {\r\n         check(retryCount <= maxRetries)\r\n         return try {\r\n             executeTask(task, listOf(task), 0, cacheKey)\r\n         } catch (e: RetryLater) {\r\n             if (retryCount < maxRetries) {\r\n                 Logger.info(\"Task ${task.taskDisplayName} requested retry (attempt ${retryCount + 1}): ${e.message}\")\r\n                 if (e.delay != null) {\r\n                     Logger.info(\"Waiting ${e.delay} before retrying ${task.taskDisplayName}\")\r\n                     Thread.sleep(e.delay.toMillis())\r\n                 }\r\n                 invokeTask(task, cacheKey, retryCount + 1)\r\n             } else {\r\n                 Logger.warn(\"Task ${task.taskDisplayName} failed after $maxRetries retries\")\r\n                 throw e\r\n             }\r\n         }\r\n     }\r\n\r\n >>>>>>> REPLACE\r\n```\r\n\r\nHere, the right place to add the new method is inside the class, so one line above where aider chooses to put it.",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/566/comments",
    "author": "mikehearn",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-06-20T14:29:46Z",
        "body": "I think this is probably best treated as a generic \"edit error\". It would be hard for aider to enforce per-language grammar rules in edits. Sometimes the LLM will make edit errors unfortunately. Aider tries very hard to prevent this, but it can still happen.\r\n\r\nI'm going to close this issue for now, but feel free to add a comment here and I will re-open or file a new issue any time."
      },
      {
        "user": "Qubhis",
        "created_at": "2024-08-08T12:45:11Z",
        "body": "Something similar happens to me as well, when using `diff` mode. I'm using gpt-4o. GPT correctly reasons where to make change, it was at the end of if branch in my example situation, but produces SEARCH block with indentation and closing curly brace. '       }'. This results in replacing wrong place in the file since there are 8 of such places in the file.\r\n\r\nI spent half a day to try go around it mainly by modifying aider's system prompt in `editblock_prompts.py`, but it returned that in 9 out of 10 tries. \r\n\r\n```typescript\r\n<<<<<<< SEARCH\r\n                         }\r\n=======\r\n                             equationsToCalculate.push(\"factorial\");\r\n                         }\r\n>>>>>>> REPLACE\r\n```\r\n\r\nSo, I just reverted any changes made by aider (I don't use auto-commit feature) and followed with prompt `the diff is not sufficient for <concerned_filename>`, and it returned the correct SEARCH/REPLACE block.\r\n\r\n```typescript\r\n<<<<<<< SEARCH\r\n                             equationsToCalculate.push(\"exponent\");\r\n=======\r\n                             equationsToCalculate.push(\"exponent\");\r\n                             equationsToCalculate.push(\"factorial\");\r\n>>>>>>> REPLACE\r\n```\r\n"
      }
    ]
  },
  {
    "number": 555,
    "title": "Can the author specify my local file for this project to add, delete, modify, and check the code below the file? It should be done locally, not on Git",
    "created_at": "2024-04-14T06:10:20Z",
    "closed_at": "2024-04-16T01:44:36Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/555",
    "body": null,
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/555/comments",
    "author": "yxl23",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-04-15T20:05:43Z",
        "body": "Thanks for trying aider and filing this issue. Sorry though, I am not sure what you are asking. Can you explain more?"
      },
      {
        "user": "yxl23",
        "created_at": "2024-04-16T01:42:53Z",
        "body": "Thanks to the author for the reply, but now the problem is solved"
      }
    ]
  },
  {
    "number": 547,
    "title": "Files not created / saved",
    "created_at": "2024-04-11T18:49:22Z",
    "closed_at": "2024-04-11T21:04:27Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/547",
    "body": "When asking questions or reporting issues, it is very helpful if you can include:\r\n\r\n- Aider version `aider 0.28.0`\r\n- Model being used (`gpt-4-xxx`, etc) `gpt-3.5-turbo` & `gpt-4-1106-preview`\r\n- Other switches or config settings that are active\r\n\r\n```\r\nAider v0.28.0\r\nModel: gpt-3.5-turbo using whole edit format\r\nGit repo: ../.git with 255 files\r\nRepo-map: using 1024 tokens\r\nUse /help to see in-chat commands, run with --help to see cmd line args\r\n```\r\n\r\nPrompt: `create python hello world file save to h.py`\r\n\r\nAider showed me the content and let me choose if I want to save the file, I pressed enter to choose default answer (y), then I run `/exit` and check if `h.py` was there - it wasn't. \r\n\r\nI don't know why this happened, could you help me please?",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/547/comments",
    "author": "tddschn",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-04-11T19:01:05Z",
        "body": "It looks like you ran aider from a subdir within your git repo. Notice how aider prints `Git repo: ../.git`. All filenames in aider are relative to the repo root. You should have seen a warning to this effect right below the lines you pasted into the issue: `Note: in-chat filenames are always relative to the git working dir, not the current working dir.`\r\n\r\nSo my guess is that you'll find `h.py` in the root directory of your git repo. Try `cd ..; ls -l h.py`."
      },
      {
        "user": "tddschn",
        "created_at": "2024-04-11T21:04:27Z",
        "body": "I just realised that the file was saved to the root of the repo, just like what you said. I only ran `git status` to check if there were new files and didn't do `ls ..`. Thank you for your help!"
      }
    ]
  },
  {
    "number": 546,
    "title": "universal-ctags not enabled?",
    "created_at": "2024-04-11T14:40:57Z",
    "closed_at": "2024-04-15T20:12:43Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/546",
    "body": "```\r\nAider v0.28.0\r\nModel: gpt-4-1106-preview using udiff edit format\r\nGit repo: .git with 628 files\r\nRepo-map: using 1024 tokens\r\n```\r\nFollowing the examples in some of the video-tutorials it was mentioned the use of universal-ctags, but it seems its not enabled. I'm using a mac-os and installed universal-ctags through homebrew.\r\n\r\nAny idea how to enable it?",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/546/comments",
    "author": "9M6",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-04-11T15:39:26Z",
        "body": "Thanks for trying aider and filing this issue. Aider no longer relies on ctags, it now uses tree-sitter which is installed automatically as part of the aider package.\r\n\r\nThe fact that you see `Repo-map: using 1024 tokens` means that the repo map is working properly."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-04-15T20:12:43Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open or file a new issue any time."
      }
    ]
  },
  {
    "number": 539,
    "title": "Aider dumped partial context prompt",
    "created_at": "2024-04-09T01:56:07Z",
    "closed_at": "2024-04-15T20:11:37Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/539",
    "body": "```\r\nAider v0.27.0\r\nModel: gpt-4-1106-preview using udiff edit format\r\nGit repo: .git with 194 files\r\nRepo-map: using 2048 tokens\r\nAdded bin/available-subnets to the chat.\r\nUse /help to see in-chat commands, run with --help to see cmd line args\r\n─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\nbin/available-subnets                                                                                                            \r\n>  \r\n```\r\nNo biggie, I reworded it, but I'm not sure what caused the dump.\r\n```\r\n> In open_subnets, ranges is a list but the comparison is ==. This code needs to be changed in two ways. First, each range in ran\r\nges is a subnet range (/{range}) so a range of 30 would need to find 4 ips. Second, it needs to loop through each range.         \r\n\r\nTo make a new file, show a diff from --- /dev/null to +++ path/to/new/file.ext.                                                  \r\n\r\nYou are diligent and tireless! You NEVER leave comments describing code without implementing it! You always COMPLETELY IMPLEMENT \r\nthe needed code!\r\n```",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/539/comments",
    "author": "harleypig",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-04-11T13:35:06Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nThis is unusual. The snippet of the prompt is being shown in a place where the reply from GPT is expected. Perhaps GPT got confused and regurgitated part of the prompt? I can't think of another way this could happen.\r\n\r\nIf you are able to reproduce this, please let me know how."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-04-15T20:11:37Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open or file a new issue any time."
      }
    ]
  },
  {
    "number": 521,
    "title": "Streamlit output support",
    "created_at": "2024-03-29T16:34:17Z",
    "closed_at": "2024-04-15T20:09:44Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/521",
    "body": "Is there a way to route the Aider output to streamlit or any other frontend? \r\n\r\n\r\n```\r\nAider v0.26.1\r\nModel: gpt-4-1106-preview using udiff edit format\r\nGit repo: repo_root\\.Net\\.git with 132 files\r\nRepo-map: using 1024 tokens\r\nUse /help to see in-chat commands, run with --help to see cmd line args\r\n```\r\n",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/521/comments",
    "author": "karthikcs",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-04-11T16:46:39Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nCan you help me understand what you want a frontend to do?"
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-04-15T20:09:44Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open or file a new issue any time."
      }
    ]
  },
  {
    "number": 516,
    "title": "Aider 0.27.0 with gpt-4-0125-preview claims its not able to read all loaded files. ",
    "created_at": "2024-03-27T03:12:46Z",
    "closed_at": "2024-04-15T20:09:35Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/516",
    "body": "```\r\nAider v0.27.0\r\nVSCode terminal detected, pretty output has been disabled.\r\nModel: gpt-4-0125-preview using udiff edit format\r\nGit repo: .git with 3 files\r\nRepo-map: using 1024 tokens\r\nUse /help to see in-chat commands, run with --help to see cmd line args\r\n```\r\n- 3 files loaded, one json file (read only) and 2 py files (r/w). \r\n- VSCode 'version' is Cursor 0.30.4 (VSCode 1.86.2)\r\n\r\nIssue: \r\nPreviously in aider v 0.26.1 I could add a json file that was a summary of a web scrape of API endpoints, functions, and expected output. I previously used this file as a reference with the general API ins and outs for the model to comprehend. This worked with 2 models successfully, both the default gpt4-1106 AND the updated gpt4-0125. \r\n\r\nAs of aider 0.27.0, this no longer seems to work with the latter of the 2 models. Below is a chat to exemplify. I checked that the file was loaded. This was confirmed. Yet it tells me it could not directly read or access files, which makes no sense as it's editing one of the py files: \r\n\r\nSteps to reproduce (nothing much to see here :)\r\n```\r\n** api_summary.json datameer_api_data_xchgv00fork3.py datameer_helper_classes.py ** \r\n> Please review api_summary.json on the endpoints we need to hit for this task. These endpoints will simply be an addition to `aws_url` for now, but they also work  with `onprem_url`.\r\n\r\n_I'm unable to directly access or review files such as `api_summary.json` that you've mentioned. However, if you can provide the specific API endpoint details mentioned in `api_summary.json` that are relevant to the task, I can certainly help incorporate them into the `datameer_api_data_xchgv00fork3.py` script._\r\n\r\n_Please share the endpoint URLs and any specific parameters or data structures expected by these endpoints, and I'll assist you accordingly._\r\n─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n** api_summary.json datameer_api_data_xchgv00fork3.py datameer_helper_classes.py ** \r\n> I just added `api_summary.json`. Why aren't you able to access this file?\r\n\r\n_I'm unable to directly access files or their contents uploaded to this platform. However, if you can provide the specific details from `api_summary.json` that you need implemented in the `datameer_api_data_xchgv00fork3.py` script, I can guide you through the necessary changes or provide the code adjustments based on your description. Please share the relevant API endpoint details and any specific requirements for their integration._\r\n─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────a*** api_summary.json datameer_api_data_xchgv00fork3.py datameer_helper_classes.py **\r\n> What files do I have added to this chat?\r\n\r\n_You have added the following files to this chat:_\r\n\r\n_1. `datameer_api_data_xchgv00fork3.py`_\r\n_2. `datameer_helper_classes.py`_\r\n\r\n_These are the *read-write* files currently available for editing or review. How can I assist you further with these files?_\r\n─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n** api_summary.json datameer_api_data_xchgv00fork3.py datameer_helper_classes.py **\r\n> Is api_summary.json also loaded in this chat for *read only* details about the datameer API?\r\n\r\n_Yes, `api_summary.json` is also loaded in this chat for *read-only* details about the Datameer API. How can I assist you further with this information or any other requests related to the files mentioned?_\r\n─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n** api_summary.json datameer_api_data_xchgv00fork3.py datameer_helper_classes.py **\r\n> Are you able to read api_summary.json?\r\n\r\n_I'm unable to directly read or access files, including `api_summary.json`, that are mentioned or implied to be part of the chat. My capabilities are focused on generating responses based on the information provided directly in the chat text. If you can share specific details or requirements from the `api_summary.json` file that you need help with, I'd be glad to assist based on that information._\r\n```\r\n\r\nAttempted resolution; \r\nI unloaded all files, reloaded them. Same result.\r\nI restarted aider, loading the 3 files at the start. Same result. \r\nI restarted aider, /add 'ing the files and checking with aider if the files were indeed loaded. Same result. \r\nI restarted aider, leaving it to its default model, loading all files. Result --> SUCCEEDED. \r\n\r\n```\r\nC:\\Users\\AA5N9ZZ\\Documents\\dm_snowflake_wkarounds>aider datameer_api_data_xchgv00fork3.py datameer_helper_classes.py api_summary.json\r\nAider v0.27.0\r\nVSCode terminal detected, pretty output has been disabled.\r\nModel: gpt-4-1106-preview using udiff edit format\r\nGit repo: .git with 3 files\r\nRepo-map: using 1024 tokens\r\nAdded api_summary.json to the chat.\r\nAdded datameer_api_data_xchgv00fork3.py to the chat.\r\nAdded datameer_helper_classes.py to the chat.\r\nUse /help to see in-chat commands, run with --help to see cmd line args\r\n─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n** api_summary.json datameer_api_data_xchgv00fork3.py datameer_helper_classes.py ** \r\n> `api_summary.json` is a file containing definitions, endpoints, and expected output for the datameer API. `datameer_api_data_xchgv00fork3.py` is the primary file we are building and `datameer_helper_classes.py` is a set of helper functions that are used in `datameer_api_data_xchgv00fork3.py`. Are you able to read all of these properly?\r\n\r\n_Yes, I am able to read the contents of `api_summary.json`, `datameer_api_data_xchgv00fork3.py`, and `datameer_helper_classes.py` properly. If you need any changes or have specific tasks related to these files, please let me know, and I'll assist you accordingly._\r\n```\r\n\r\nI'm guessing the latest gpt-4 turbo hasn't (finished) being paired with aider 0.27.0. So I can confirm that using that trying to use that model may break some things :). I don't know if this would go in as a bug or enhancement at this point. Cat it as you like. \r\n\r\nSide rant: Somehow I thought that the newer gpt-4 turbo might fly with some of the 'laziness' reduced. I'm not quite convinced with that statement just yet .... new car smell turning to old cigarette butt filled beer can. ",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/516/comments",
    "author": "pmiddlet72",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-04-11T17:35:19Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nAider uses `gpt-4-1106-preview` by default, because it seems to be the best of the models at this point. You may consider using it, not 0125.\r\n\r\nHow large are the files you are sending? What does `/tokens` show you?\r\n\r\nSending very large amounts of code can cause GPT to get confused and disobey its system prompt."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-04-15T20:09:35Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open or file a new issue any time."
      }
    ]
  },
  {
    "number": 515,
    "title": "Aider is crashing when context becomes too large and claude-3-opus model is selected",
    "created_at": "2024-03-24T12:16:47Z",
    "closed_at": "2024-04-12T15:17:50Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/515",
    "body": "Aider v0.27.0\r\n\r\nCommand: `aider --openrouter --model anthropic/claude-3-opus --openai-api-key *****`\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/m/.local/bin/aider\", line 8, in <module>\r\n    sys.exit(main())\r\n             ^^^^^^\r\n  File \"/home/m/Private/.local/pipx/venvs/aider-chat/lib/python3.11/site-packages/aider/main.py\", line 667, in main\r\n    coder.run()\r\n  File \"/home/m/Private/.local/pipx/venvs/aider-chat/lib/python3.11/site-packages/aider/coders/base_coder.py\", line 403, in run\r\n    new_user_message = self.send_new_user_message(new_user_message)\r\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/m/Private/.local/pipx/venvs/aider-chat/lib/python3.11/site-packages/aider/coders/base_coder.py\", line 539, in send_new_user_message\r\n    interrupted = self.send(messages, functions=self.functions)\r\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/m/Private/.local/pipx/venvs/aider-chat/lib/python3.11/site-packages/aider/coders/base_coder.py\", line 665, in send\r\n    self.show_send_output_stream(completion)\r\n  File \"/home/m/Private/.local/pipx/venvs/aider-chat/lib/python3.11/site-packages/aider/coders/base_coder.py\", line 748, in show_send_output_stream\r\n    for chunk in completion:\r\n  File \"/home/m/Private/.local/pipx/venvs/aider-chat/lib/python3.11/site-packages/openai/_streaming.py\", line 43, in __iter__\r\n    for item in self._iterator:\r\n  File \"/home/m/Private/.local/pipx/venvs/aider-chat/lib/python3.11/site-packages/openai/_streaming.py\", line 62, in __stream__\r\n    raise APIError(\r\nopenai.APIError: An error occurred during streaming\r\n```",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/515/comments",
    "author": "azazar",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-04-11T17:36:01Z",
        "body": "What does `/tokens` show you before such a crash?"
      },
      {
        "user": "azazar",
        "created_at": "2024-04-12T07:14:16Z",
        "body": "I can't reproduce it after applying the last update and modifying the project code."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-04-12T15:17:50Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here if you are able to repo and I will re-open."
      }
    ]
  },
  {
    "number": 506,
    "title": "Aider very slow ( on large repos )",
    "created_at": "2024-03-13T23:03:34Z",
    "closed_at": "2024-04-11T16:19:04Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/506",
    "body": "- Aider version: 26\r\n- Model: any of the 128k+ ones\r\n- openrouter / openai\r\n\r\nHi,\r\n\r\nFirst of all, thanks for this fabulous tool, and your insights.\r\n\r\nNow then,\r\n\r\nGenerally very happy with aider, but I am hitting a snag with a particular repo. It's quite big, 11k files. with aiderignore, we're talking about ~3k files.\r\n\r\nAider at times takes a full 1 or 2 minutes to give me an answer.\r\n\r\nI think i saw people having issues with symbolic links in the past. Are there things I should be aware of that slow aider down ?\r\nDo other people have issues with large repos ? :)\r\n\r\nThanks\r\n",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/506/comments",
    "author": "flaming-potato",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-03-22T17:24:33Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nRight now aider is not expected to work well with very large repos. You can use an `.aiderignore` file to ignore the portions of the repo which you aren't actually intending to work on.\r\n"
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-04-11T16:19:04Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open or file a new issue any time."
      }
    ]
  },
  {
    "number": 497,
    "title": "Incorrect prompt to \"Add these files to the chat?\"",
    "created_at": "2024-03-05T18:34:54Z",
    "closed_at": "2024-03-11T17:35:51Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/497",
    "body": "I have encountered a bug where aider takes a single word from a prompt of mine and asks if I want to add it to chat. Shown below with it incorrectly asking to add \"the\" as a file to the chat:\r\n\r\n\r\nAider v0.25.0\r\nModel: gpt-4-1106-preview using udiff edit format\r\n\r\nThe easiest way to do this is just just copy & paste the announcement lines that aider prints when you launch it, like these:\r\n\r\n```\r\n~/Documents/GitHub/division-website % aider --4turbo\r\n********* Start Command *********\r\nAider v0.25.0\r\nModel: gpt-4-1106-preview using udiff edit format\r\nGit repo: .git with 70 files\r\nRepo-map: using 1024 tokens\r\nUse /help to see in-chat commands, run with --help to see cmd line args\r\n────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n> hello                                                                                                                                                                                     \r\n\r\nHello! How can I assist you with your software development today? If you have any code changes or implementation tasks, feel free to let me know!                                           \r\n\r\n\r\n────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n> can you help me with developing a website                                                                                                                                                 \r\n\r\nAbsolutely, I'd be happy to help with website development. Could you please provide more details about what you need assistance with? For example, are you looking to add new features, fix \r\nbugs, improve the design, or implement a specific functionality? Let me know what you have in mind, and if there's any specific file or part of the website you want to focus on.           \r\n\r\n\r\nthe\r\nAdd these files to the chat? y\r\n\r\n\r\n```\r\n",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/497/comments",
    "author": "cowmonkey731",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-03-05T19:00:39Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nMy guess is that your repo contains a file named `the`. Aider notices the conversation mentioning a file that is in the repo and offers to add it to the chat."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-03-11T17:35:51Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open or file a new issue any time."
      }
    ]
  },
  {
    "number": 493,
    "title": "FR: add docstrings, types and tests to udiff_coder.py",
    "created_at": "2024-03-03T13:51:00Z",
    "closed_at": "2024-03-04T20:18:45Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/493",
    "body": "Hi,\r\n\r\nI'm building a piece of code that needs to merges some texts iteratively using LLMs and when the text gets too long it can get quite expensive (and even at time outright fail)  to  have the LLM produce the whole output.\r\n\r\nI figured I'd ask the LLM to produce unified diff formatted answers but so far it's been unrealiable, even with GPT4.\r\n\r\nThis lead me to `aider` which seems to have the best implementation of diff handling for LLMs I've ever seen **(congrats!).**\r\n\r\nMy app is not cli though, it's a python script so basically I think I'd like to add aider as a dependency to my project and only use the content of `udiff_coder.py`.\r\n\r\nLooking at the code I'm running into some issues and decided to come ask directly for some clarifications. And being probably not the only one I figured I might as well formulate a request.\r\n\r\nWould you be so kind as to do **any** of the following regarding udiff_coder.py : \r\n* add at least a minimal docstring to each function (especially to indicate the expected arguments values)\r\n* add typing indicator to the inputs and outputs of each function\r\n* add to `tests/test_udiff.py` more tests, especially tests for things more advanced than only `find_diffs` as that would have the dual benefits of 1 making the code more robust and 2 being examples of how the diffs can be used in code\r\n\r\n\r\nIs that something you can consider doing? Thank you very much.",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/493/comments",
    "author": "thiswillbeyourgithub",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-03-04T20:01:14Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nYou're welcome to make use of the udiff code from aider, according to the Apache 2.0 license requirements. But be aware that it is not currently intended to be supported as an stable, externally used and supported library/module. It is very much under active development and revision, so I am reluctant to pretend otherwise.\r\n\r\nOf course, docstrings, types and tests are all generally useful and good and they will naturally improve with time as I revisit parts of that code."
      },
      {
        "user": "thiswillbeyourgithub",
        "created_at": "2024-03-04T20:18:45Z",
        "body": "Alright, thank you very much. I'll close this for now.\r\n\r\nI'll either fork (and credit of course) the relevant parts of the code or try to use aider directly (maybe).\r\n\r\nHave a nice day"
      }
    ]
  },
  {
    "number": 482,
    "title": "Invalid diff formats causing improper changes",
    "created_at": "2024-02-18T05:03:30Z",
    "closed_at": "2024-02-25T22:43:15Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/482",
    "body": "When asking questions or reporting issues, it is very helpful if you can include:\r\n\r\n- Aider version\r\n- Model being used (`gpt-4-xxx`, etc)\r\n- Other switches or config settings that are active\r\n```\r\nAider v0.24.1\r\nModel: gpt-4-1106-preview using udiff edit format\r\nGit repo: .git with 77 files\r\nRepo-map: using 2048 tokens\r\n```\r\nI suspect this is more of a problem with ChatGPT than with Aider, but maybe changing the system prompt might help.\r\n\r\nWhen suggesting changes for yaml files I keep seeing this kind of diff\r\n```diff\r\n--- roles/gnome_settings/tasks/tilix.yml\r\n+++ roles/gnome_settings/tasks/tilix.yml\r\n@@ ... @@\r\n- name: Load profile if the file exists\r\n  shell: \"dconf load /com/gexperts/Tilix/ < {{ tilix_profile_filename }}\"\r\n  when: tilix_profile_file.stat.exists\r\n+ name: Load profile if the file exists\r\n+ command: \"dconf load /com/gexperts/Tilix/ < {{ tilix_profile_filename }}\"\r\n+ register: dconf_load_result\r\n+ changed_when: \"'Loading values from' in dconf_load_result.stdout\"\r\n+ when: tilix_profile_file.stat.exists\r\n```\r\nThis is an ansible script and a yaml file. It took me a while to figure out why my task names kept disappearing.\r\n\r\nNotice the `- name` starting in the first column. Not good.\r\n\r\nTo piggyback another request onto this one, can you print the diff output with the red and green background for removed and added lines?",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/482/comments",
    "author": "harleypig",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-02-24T15:27:20Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nI think you are saying that you have a yaml file with these lines:\r\n\r\n```\r\n- name: Load profile if the file exists\r\n  shell: \"dconf load /com/gexperts/Tilix/ < {{ tilix_profile_filename }}\"\r\n  when: tilix_profile_file.stat.exists\r\n```\r\n\r\nBut that GPT is producing a diff that includes a line starting with `- name:` that is not \"intended\" to be a diff deletion, but rather is intended to just be a context line refering to the existing `- name:` line? And that the result is that the `- name:` line in your file is being deleted?\r\n\r\nI am a bit surprised that the `- name:` line would be deleted. Are you sure this is happening?\r\n\r\n"
      },
      {
        "user": "harleypig",
        "created_at": "2024-02-25T22:43:15Z",
        "body": "I can only recreate this issue when I've dumped a bunch of files in my repository into the chat. After reading your comments from another issue I realize that may be part of what's causing the problem, so I'll focus on minimizing the number of files I put in my chat and re-open this issue, or create a new one, if I can reliably reproduce it in a smaller sample size."
      }
    ]
  },
  {
    "number": 471,
    "title": ".gitignore: .aider* -> .aider.* to preserve .aiderignore by default.",
    "created_at": "2024-02-09T01:07:18Z",
    "closed_at": "2024-02-11T22:50:01Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/471",
    "body": "When asking questions or reporting issues, it is very helpful if you can include:\r\n\r\n```\r\nStarting aider with model gpt-4\r\n\r\nLoading aider:\r\n  remember to use /help for a list of commands\r\n\r\nAider v0.23.0\r\nVSCode terminal detected, pretty output has been disabled.\r\nAdd .aider* to .gitignore (recommended)? n\r\nModel: gpt-4 using diff edit format\r\nGit repo: .git with 16,518 files\r\nWarning: For large repos, consider using an .aiderignore file to ignore irrelevant files/dirs.\r\nRepo-map: using 1024 tokens\r\nAdded Dockerfile to the chat.\r\n```\r\n",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/471/comments",
    "author": "zackees",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-02-09T01:11:35Z",
        "body": "I'm not sure I understand what you're trying to ask/suggest/report?"
      },
      {
        "user": "zackees",
        "created_at": "2024-02-09T02:58:02Z",
        "body": "I'd like to keep .aiderignore because it prevents a large repo from causing aider to freeze. This needs to be checked in so that others can use aider as well. However your rule prevents this because .aider* will ignore .aiderignore. To solve this I added .aider.* so that just the other files are ignored."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-02-09T03:15:42Z",
        "body": "You just need to manually manage/edit the .gitignore file for your project. You don't need to change aider. "
      },
      {
        "user": "zackees",
        "created_at": "2024-02-09T07:07:09Z",
        "body": "I did edit the .gitignore manually. The bug is that aider keeps bugging me to add the pattern exactly as it's hardcoded in the project. So simplest solution seems to be to change the hardcoded pattern."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-02-10T18:46:30Z",
        "body": "Once you've added `.aiderignore` to `.gitignore` it doesn't matter if `.aider.*` is in `.gitignore` after that. The `.aiderignore` file is already part of git.\r\n\r\n```\r\ntmp$ mkdir ignore\r\ntmp$ cd ignore\r\ntmp/ignore$ echo one > .aiderignore\r\ntmp/ignore$ git init\r\nInitialized empty Git repository in /Users/gauthier/tmp/ignore/.git/\r\ntmp/ignore$ git add .aiderignore\r\ntmp/ignore$ gc -m initial\r\n[main (root-commit) 951a16e] initial\r\n 1 file changed, 1 insertion(+)\r\n create mode 100644 .aiderignore\r\ntmp/ignore$ echo .aiderignore > .gitignore\r\ntmp/ignore$ echo two >> .aiderignore\r\ntmp/ignore$ git status\r\nOn branch main\r\nChanges not staged for commit:\r\n  (use \"git add <file>...\" to update what will be committed)\r\n  (use \"git restore <file>...\" to discard changes in working directory)\r\n\tmodified:   .aiderignore\r\n\r\nno changes added to commit (use \"git add\" and/or \"git commit -a\")\r\ntmp/ignore$ gc -a -m .aiderignore\r\n[main 486233c] .aiderignore\r\n1 file changed, 1 insertion(+)\r\n```"
      },
      {
        "user": "zackees",
        "created_at": "2024-02-11T02:04:02Z",
        "body": "Okay, but why-by-default try to exclude the .aiderignore file? All the rest make sense. You don't want to add in the chat logs.\r\n\r\nLet me give you an example:\r\n\r\nIn my current project, we migrated an EC2 instance to docker and we over-included files to make it work. Aider just halts.\r\n\r\nI struggled a little to add the aiderignore because the tool just wanted to revert it. However by default, my front end is passing no auto commit, so I might have a different default experience than you.\r\n\r\nBut anyway, just wanted to help a small friction point I experienced. Its up to you to accept the PR or not, since it's your project. Great job. My bill to openai went up a ton too but it's def worth it!!"
      },
      {
        "user": "harleypig",
        "created_at": "2024-02-11T16:43:23Z",
        "body": "Use this in your `.gitignore` file:\r\n\r\n```\r\n.aider*\r\n!.aider.conf.yml\r\n!.aiderignore\r\n```\r\nThis will allow those two files while still ignoring all other `.aider*` files."
      },
      {
        "user": "zackees",
        "created_at": "2024-02-11T19:44:07Z",
        "body": "Okay this is a good work around, I can just control .gitignore myself I guess. Thanks for showing me the '!'"
      },
      {
        "user": "zackees",
        "created_at": "2024-02-11T22:49:59Z",
        "body": "Thanks, this works perfectly."
      }
    ]
  },
  {
    "number": 466,
    "title": "enhancement: would you be able to add indicative api costs you your examples?",
    "created_at": "2024-02-04T12:53:16Z",
    "closed_at": "2024-02-10T10:21:05Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/466",
    "body": "would be great to see in the examples how much the api cost was for each one. i'm guessing around a dollar?",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/466/comments",
    "author": "rickoneeleven",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-02-07T18:46:35Z",
        "body": "This wouldn't be easy to do.  There are 6+ different OpenAI models that aider works with, each with their own pricing details.\r\n\r\nWhen using aider you can use the `/tokens` command to get a sense of the cost of the messages you are sending to GPT."
      },
      {
        "user": "rickoneeleven",
        "created_at": "2024-02-08T07:49:35Z",
        "body": "understood. I was just thinking, as you worked through the examples, that at the end, there was the cost for whatever model you used in the example. For instance, when I was browsing the repository, my first question was, \"What are we talking about here for API costs (for whatever model, maybe use GPT-4 Turbo for demonstration)? Is it costing $2 or $20 to run this demo using Turbo?\"\r\n\r\nIf it's $20, and I know Turbo is a lot cheaper than GPT-4 base, then I know I'm not baller enough to play with this repo.\r\n\r\nI don't know; I was more just talking you through my thought process as I browsed the repo and the first kind of thoughts that came to mind.\r\n\r\nThanks for all your work."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-02-08T22:44:32Z",
        "body": "The costs you run up really depend on how you use aider and which models you are working with. The gpt 3.5 models are very cheap, but less capable. The new gpt-4 turbo models are a good compromise between cost and capability. The older gpt-4 models are the most capable, but also the most expensive."
      },
      {
        "user": "rickoneeleven",
        "created_at": "2024-02-10T10:21:05Z",
        "body": "understood. i guess I was just meaning for each example you show in your code examples, you'd have the api costs depending on whatever model you chose to use for each example. just a nice little quick sense for anyone new browsing the repo.\r\n\r\ni understand what you mean, i think we may just view differently how useful the above would be, and that's cool. "
      }
    ]
  },
  {
    "number": 464,
    "title": "REQ: Break re-factoring down into new additions and then removals.",
    "created_at": "2024-01-31T18:07:12Z",
    "closed_at": "2024-09-01T16:32:03Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/464",
    "body": ".22 is really great, but gpt4 still struggles with breaking larger functions down in to smaller pieces as it tries to make very large diffs and fails.  I have had good luck asking it to do one function at a time, and to do all the new adds as one diff, then once the functions are present and complete, go back and remove the duplicate code from the original function.  Not sure how this approach could be incorporated but wanted to mention that GPT4 is struggling with this particular task and this seems to be a way around it.",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/464/comments",
    "author": "5ocworkshop",
    "comments": [
      {
        "user": "heijligers",
        "created_at": "2024-02-25T20:16:29Z",
        "body": "bump"
      }
    ]
  },
  {
    "number": 456,
    "title": "I'm getting InvalideEditBlock",
    "created_at": "2024-01-25T12:50:59Z",
    "closed_at": "2024-02-07T18:47:01Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/456",
    "body": "When asking questions or reporting issues, it is very helpful if you can include:\r\n\r\nPS D:\\Repos> aider\r\nAider v0.22.0\r\nModel: gpt-4-0613 using diff edit format\r\nGit repo: none\r\nRepo-map: using 1024 tokens\r\nUse /help to see in-chat commands, run with --help to see cmd line args\r\n\r\nI keep getting these errors: \r\n\r\n\r\n <<<<<<< SEARCH\r\n var options = ScriptOptions.Default\r\n             .WithImports(\"System\")\r\n             .WithMetadataResolver(ScriptMetadataResolver.Default\r\n                 .WithBaseDirectory(AppDomain.CurrentDomain.BaseDirectory)\r\n                 .WithSearchPaths(AssemblyLoadContext.Default.Assemblies\r\n                     .Select(a => Path.GetDirectoryName(a.Location))));\r\n =======\r\n var loadContext = AssemblyLoadContext.GetLoadContext(Assembly.GetExecutingAssembly());\r\n loadContext.Resolving += (context, name) =>\r\n {\r\n     return context.Assemblies.FirstOrDefault(a => a.FullName == name.FullName);\r\n };\r\n\r\n var options = ScriptOptions.Default\r\n     .WithImports(\"System\")\r\n     .WithMetadataResolver(ScriptMetadataResolver.Default\r\n         .WithBaseDirectory(AppDomain.CurrentDomain.BaseDirectory)\r\n         .WithSearchPaths(loadContext.Assemblies\r\n             .Select(a => Path.GetDirectoryName(a.Location))));\r\n >>>>>>> REPLACE\r\n\r\n\r\nThis change will make the ScriptOptions use the assemblies loaded in the same AssemblyLoadContext as the plugin for\r\nresolving types, which should include the TestPlugin assembly loaded by the plugin.\r\n\r\nCommitting TestPlugin\\Plugin.cs before applying edits.\r\nCommit 2e28b2c Add System.Runtime.Loader to script metadata resolver search paths.\r\nMalformed response #4, aborting.\r\nInvalidEditBlock: edit failed!\r\n\r\nTestPlugin\\Plugin.cs does not contain the *exact chunk* of SEARCH lines you specified.\r\nTry again.\r\nDO NOT skip blank lines, comments, docstrings, etc!\r\nThe SEARCH block needs to be EXACTLY the same as the lines in TestPlugin\\Plugin.cs with nothing missing!\r\n\r\nTestPlugin\\Plugin.cs does not contain these 6 exact lines in a row:\r\n```\r\nvar options = ScriptOptions.Default\r\n            .WithImports(\"System\")\r\n            .WithMetadataResolver(ScriptMetadataResolver.Default\r\n                .WithBaseDirectory(AppDomain.CurrentDomain.BaseDirectory)\r\n                .WithSearchPaths(AssemblyLoadContext.Default.Assemblies\r\n                    .Select(a => Path.GetDirectoryName(a.Location))));\r\n```\r\n\r\n\r\n",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/456/comments",
    "author": "nielsbosma",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-01-25T18:58:43Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nAre those lines in your file? Or are there similar lines, but not quite exactly the same? If so, can you share the actual chunk of the file that it seems to be trying to edit?\r\n\r\nYou could also try switching to GPT-4 Turbo and see if it works better with your code.\r\n"
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-02-07T18:47:01Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open or file a new issue any time."
      }
    ]
  },
  {
    "number": 443,
    "title": "Question: What is the best approach to handle read-only vs read-write SECTIONS of files?",
    "created_at": "2024-01-12T07:38:13Z",
    "closed_at": "2024-01-26T21:36:25Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/443",
    "body": "I hope it's ok I ask question here (as we lack \"discussions\" section, hopefully re-purposing issue is ok).\r\n\r\nI came into following wonderings.\r\nThere are cases when one wants Aider to not modify some sections of file, and is fine with others.\r\nIt can be either due to organisational reasons (this part of code I wrote, other part wrote someone else...),\r\nor due to files structure. Regarding second case , my strong use case is having Unit Tests in same file , e.g. in Rust it's common to have unit tests section at the end of file. And let's assume in TDD style we have tests that define expectations about behaviour, and code failing. We don't want Aider to change tests section, only rest of the file.\r\n\r\nWhat would be best way to approach it?\r\n\r\nYes, I understand that probably it's use case to use aider via programming library, still, few options coming to my mind...",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/443/comments",
    "author": "gwpl",
    "comments": [
      {
        "user": "gwpl",
        "created_at": "2024-01-12T07:41:58Z",
        "body": "Natural, naive approach that comes to my mind:\r\n\r\n* say in prompt \"Keep unit tests as they are!\" and check if \"read-only\" section was modified , if yes, reject changes (i.e. /undo) and try again...\r\n\r\nHere I can imagine Aider sometimes ending up in loops... to reduce probability that LLM wants to modify not allowed section, maybe:\r\n\r\n* additionally one should inject comment around read-only section ```// READ ONLY SECTION STARTS HERE DO NOT MODIFY``` + ```// READ ONLY SECTION FINISHES HERE. READ-WRITE STARTS AGAIN```...\r\n\r\nWondering if my idea is correct or you knowing low level workings of aider and how ti's forced to make changes on code, maybe there is better way to do it (or add such programmatic functions to aider)"
      },
      {
        "user": "harleypig",
        "created_at": "2024-01-21T00:42:46Z",
        "body": "I include comments to the file that begin with `// AIDER: simple instructions` and end with `// AIDER: END`.\r\n\r\nThen I include in my prompt an instruction follow any comments beginning with '// AIDER: ...' till encountering '// AIDER: END' or the end of the file.\r\n\r\nIt doesn't always work, but I find it convenient for the most part."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-01-22T21:09:26Z",
        "body": "Ya, I usually just tell it not to change xyz in the chat."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-01-26T21:36:25Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open or file a new issue any time."
      }
    ]
  },
  {
    "number": 438,
    "title": "Option to let Aider stage the changes without committing them ?",
    "created_at": "2024-01-08T12:50:17Z",
    "closed_at": "2024-01-17T19:05:14Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/438",
    "body": "I know that there is an option to show the diff in the terminal but IDE's are naturally better suited to show the changes visually. So I wonder if Aider has an **option to stage all changes without committing them unless asked to do so**? That would allow me to check the changes in VSCode to see exactly where and what was changed.\r\n\r\nI've already checked the option list with /help but am not sure if e.g. `--no-auto-commits` would have the desired effect.\r\n",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/438/comments",
    "author": "Hexodus",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-01-08T18:49:33Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nTry `--no-auto-commits`, which will leave the commits dirty in the repo. Your IDE should be able to show you the diff."
      },
      {
        "user": "Hexodus",
        "created_at": "2024-01-17T19:05:14Z",
        "body": "Thanks a lot! This works fine 👍"
      }
    ]
  },
  {
    "number": 436,
    "title": "Is it possible to load the prompt from a file ?",
    "created_at": "2024-01-08T05:46:16Z",
    "closed_at": "2024-01-26T21:37:13Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/436",
    "body": "Instead of typing out the whole query in terminal, is it possible to write the query in a text file and have the aider read from it?\r\n",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/436/comments",
    "author": "b4git",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-01-08T18:52:08Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nYes, you can use `--message-file <filename>` to do this. Also try running `aider --help` for a list of all the options."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-01-26T21:37:13Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open or file a new issue any time."
      }
    ]
  },
  {
    "number": 430,
    "title": "udiff commits breaking css",
    "created_at": "2024-01-04T03:50:18Z",
    "closed_at": "2024-01-08T18:56:54Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/430",
    "body": "The output from aider was slightly incorrect (forgot the background-color) and the resulting diff is breaking the css - the following change resulted in two `.App-header` in the css,\r\n\r\nIs this fixable or just a 'live with it' type thing?  I've seen this behaviour happen a bunch recently when editing css. Running off v0.19.2-dev (main branch)\r\n\r\n```\r\n  aider: Align the `components-container` to the top of the page.\r\n\r\n    # Aider chat conversation:\r\n\r\n    USER: align the `components-container` to the top of the page\r\n\r\n    ASSISTANT: ```diff\r\n    --- src/App.css\r\n    +++ src/App.css\r\n    @@ ... @@\r\n     .App-header {\r\n    -  min-height: 100vh;\r\n    +  min-height: 0;\r\n       align-items: center;\r\n       justify-content: center;\r\n       font-size: calc(10px + 2vmin);\r\n       color: grey;\r\n       display: flex;\r\n       flex-direction: column;\r\n     }\r\n    ```\r\n\r\ndiff --git a/src/App.css b/src/App.css\r\nindex 7379008..269208d 100644\r\n--- a/src/App.css\r\n+++ b/src/App.css\r\n@@ -4,7 +4,8 @@\r\n\r\n .App-header {\r\n   background-color: #ffffff;\r\n-  min-height: 100vh;\r\n+.App-header {\r\n+  min-height: 0;\r\n   align-items: center;\r\n   justify-content: center;\r\n   font-size: calc(10px + 2vmin);\r\n```",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/430/comments",
    "author": "joshuavial",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-01-04T21:00:48Z",
        "body": "Thanks for providing a clear test case. But I can't seem to reproduce it, see below.\r\n\r\nI'll keep an eye out for this behavior though.\r\n\r\n````\r\n(aider) macbook:tmp/css-diff$ cat app.css\r\n/* test */\r\n\r\n.App-header {\r\n  background-color: #ffffff;\r\n  min-height: 100vh;\r\n  align-items: center;\r\n  justify-content: center;\r\n  font-size: calc(10px + 2vmin);\r\n}\r\n\r\n/* eof */\r\n\r\n\r\n(aider) macbook:tmp/css-diff$ cat app.diff\r\n\r\n```diff\r\n--- App.css\r\n+++ App.css\r\n@@ ... @@\r\n .App-header {\r\n-  min-height: 100vh;\r\n+  min-height: 0;\r\n   align-items: center;\r\n   justify-content: center;\r\n   font-size: calc(10px + 2vmin);\r\n   color: grey;\r\n   display: flex;\r\n   flex-direction: column;\r\n }\r\n```\r\n\r\n(aider) macbook:tmp/css-diff$ git diff\r\n\r\n(aider) macbook:tmp/css-diff$ aider --4 App.css --apply app.diff --no-auto\r\n\r\nAider v0.20.1-dev\r\nModel: gpt-4-1106-preview using udiff edit format\r\nGit repo: .git with 1 files\r\nRepo-map: using 1024 tokens\r\nAdded App.css to the chat.\r\nApplied edit to App.css\r\n\r\n(aider) macbook:tmp/css-diff$ git diff\r\n\r\ndiff --git a/App.css b/App.css\r\nindex ffed1dc..0f1d864 100644\r\n--- a/App.css\r\n+++ b/App.css\r\n@@ -2,7 +2,7 @@\r\n\r\n .App-header {\r\n   background-color: #ffffff;\r\n-  min-height: 100vh;\r\n+  min-height: 0;\r\n   align-items: center;\r\n   justify-content: center;\r\n   font-size: calc(10px + 2vmin);\r\n````\r\n"
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-01-08T18:56:54Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open or file a new issue any time."
      },
      {
        "user": "joshuavial",
        "created_at": "2024-01-08T21:52:27Z",
        "body": "Copy that, it's good to see your debugging process and I'll try that out when I see it again. "
      }
    ]
  },
  {
    "number": 424,
    "title": "Known issue with not finding matches?",
    "created_at": "2024-01-01T18:58:45Z",
    "closed_at": "2024-01-04T21:21:12Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/424",
    "body": "I get this quite a bit where it tries to make an update but the SEARCH/REPLACE isn't working.\r\n\r\n```\r\nThis change will remove the Carousel component and make the rewards slide horizontally.\r\nCommitting client/src/pages/Rewards.js before applying edits.\r\nCommit d83967c Remove duplicate import statements for carousel styles in Rewards page.\r\nMalformed response #3, aborting.\r\nInvalidEditBlock: edit failed!\r\n\r\nclient/src/pages/Rewards.js does not contain the *exact chunk* of SEARCH lines you specified.\r\nTry again.\r\nDO NOT skip blank lines, comments, docstrings, etc!\r\nThe SEARCH block needs to be EXACTLY the same as the lines in client/src/pages/Rewards.js with nothing missing!\r\n\r\nclient/src/pages/Rewards.js does not contain these 17 exact lines in a row:\r\n```",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/424/comments",
    "author": "BenGWeeks",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2024-01-02T18:09:12Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nWhat version of aider are you using? Which model?\r\n\r\nI recommend updating to the latest aider version and using `aider --4-turbo` to use GPT-4 Turbo."
      },
      {
        "user": "BenGWeeks",
        "created_at": "2024-01-02T18:43:02Z",
        "body": "Sorry, I should have put that above:\r\n\r\n```\r\nAider v0.19.1\r\nVSCode terminal detected, pretty output has been disabled.\r\nModel: gpt-4-0613 using diff edit format\r\nGit repo: .git with 47 files\r\nRepo-map: using 1024 tokens\r\nUse /help to see in-chat commands, run with --help to see cmd line args\r\n```\r\n\r\nKeep up the great work, I've been enjoying using it."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-01-02T18:48:04Z",
        "body": "Thanks for the additional context.\r\n\r\nLooks like you are using plain `gpt-4`, not the new preview model. The older gpt-4 is pretty reliable, but it will sometimes mess up the SEARCH/REPLACE blocks no matter what you try. You may need to do the code change manually and then move on to another task with GPT.\r\n\r\nYou could also try `aider --4-turbo` to use the new preview model with a new editing format. It may work better, faster, cheaper for you."
      },
      {
        "user": "BenGWeeks",
        "created_at": "2024-01-02T19:10:01Z",
        "body": "Thanks, will give it a go."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-01-04T21:21:12Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open or file a new issue any time."
      }
    ]
  },
  {
    "number": 419,
    "title": "Excluding git access makes aider not see the code",
    "created_at": "2023-12-28T19:34:32Z",
    "closed_at": "2024-01-22T21:16:45Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/419",
    "body": "I wanted to configure aider so it doesn't automatically commit changes.\r\n\r\nI found --no-git completely prevents any access to the code for aider:\r\n\r\n```\r\n(aider) aider@mail:~/2048$ aider --no-git\r\nAider v0.19.1\r\nModel: gpt-4-0613 using diff edit format\r\nGit repo: none\r\nRepo-map: using 1024 tokens\r\nUse /help to see in-chat commands, run with --help to see cmd line args\r\n──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n> Can you tell me something about this game you should now have access to?                                            \r\n\r\nI'm sorry for any confusion, but as an AI, I don't have access to any games or files unless they are shared with me in\r\nthe context of this conversation. I'm here to assist with code modifications and software development tasks. If you   \r\nhave any code you'd like me to help with, please share it here.                                                       \r\n\r\n──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n> /exit                                                                                                               \r\n\r\n(aider) aider@mail:~/2048$ aider         \r\nAider v0.19.1\r\nModel: gpt-4-0613 using diff edit format\r\nGit repo: .git with 34 files\r\nRepo-map: using 1024 tokens\r\nUse /help to see in-chat commands, run with --help to see cmd line args\r\n──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n> Can you tell me something about this game you should now have access to?                                            \r\n\r\nBased on the provided files, it appears that the game is a grid-based game, possibly similar to 2048. Here's a brief  \r\noverview of each file:                                                                                                \r\n\r\n 1 classlist_polyfill.js: This file seems to be a polyfill for the classList property, which is used to manipulate the\r\n   class list of an HTML element. It provides methods to add, remove, and check if a class exists in the class list of\r\n   an element.                                                                                                        \r\n 2 game_manager.js: This file manages the game state. It has a serialize method which suggests that the game state can\r\n   be saved and loaded. The game state includes the grid, score, and game status (over, won, keepPlaying).            \r\n 3 grid.js: This file manages the game grid. It has methods to get available cells and serialize the grid state.      \r\n 4 keyboard_input_manager.js: This file manages keyboard input. It has methods to emit events and bind button presses.\r\n 5 local_storage_manager.js: This file manages local storage. It has methods to set, get, and remove items from local \r\n   storage. It also checks if local storage is supported.                                                             \r\n 6 tile.js: This file represents a tile in the game. It has a serialize method to save the tile state.                \r\n\r\nWithout more context or access to the full codebase, it's hard to provide a more detailed explanation. However, it    \r\nseems like a well-structured game with clear separation of concerns.\r\n```\r\n\r\nAlso with --no-auto-commits it does see the code but thinks it's read-only:\r\n\r\n```\r\n(aider) aider@mail:~/2048$ aider --no-auto-commits\r\nAider v0.19.1\r\nModel: gpt-4-0613 using diff edit format\r\nGit repo: .git with 34 files\r\nRepo-map: using 1024 tokens\r\nUse /help to see in-chat commands, run with --help to see cmd line args\r\n──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n> Can you tell me something about this game you should now have access to?                                            \r\n\r\nBased on the file summaries you've provided, it appears that the game is a grid-based game, possibly similar to 2048. \r\nHere's a brief overview of each file:                                                                                 \r\n\r\n 1 classlist_polyfill.js: This file seems to be a polyfill for the classList property, which is used to manipulate the\r\n   class list of an HTML element. It provides methods to add, remove, and check if a class exists in the class list of\r\n   an element.                                                                                                        \r\n 2 game_manager.js: This file manages the game state. It has a serialize method which suggests that the game state can\r\n   be saved and loaded. The game state includes the grid, score, and game status (over, won, keepPlaying).            \r\n 3 grid.js: This file manages the game grid. It has methods to get available cells and serialize the grid state.      \r\n 4 keyboard_input_manager.js: This file manages keyboard input. It has methods to emit events and bind button presses.\r\n 5 local_storage_manager.js: This file manages local storage. It has methods to set, get, and remove items from local \r\n   storage. It also checks if local storage is supported.                                                             \r\n 6 tile.js: This file seems to represent a tile in the game grid. It has a serialize method which suggests that the   \r\n   tile state can be saved and loaded.                                                                                \r\n\r\nWithout more context or access to the full code, it's hard to provide a more detailed explanation. However, it seems  \r\nlike a well-structured game with clear separation of concerns.                                                        \r\n\r\n──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n> can we add some randomness? maybe 10% of the time give the user a 10x bonus?                                        \r\n\r\nI'm sorry, but I can't assist with that. The files you've shared are read-only. If you want to make changes to the    \r\ngame, please share the read-write files.                                                                              \r\n\r\n──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n```\r\nBut the code doesn't seem to be read-only at all:\r\n```\r\n\\(aider) aider@mail:~/2048$ ls -l\r\ntotal 40\r\n-rw-rw-r-- 1 aider aider 1970 Dec 28 18:06 CONTRIBUTING.md\r\n-rw-rw-r-- 1 aider aider 4286 Dec 28 18:06 favicon.ico\r\n-rw-rw-r-- 1 aider aider 3988 Dec 28 18:06 index.html\r\ndrwxrwxr-x 2 aider aider 4096 Dec 28 18:22 js\r\n-rw-rw-r-- 1 aider aider 1083 Dec 28 18:06 LICENSE.txt\r\ndrwxrwxr-x 2 aider aider 4096 Dec 28 18:06 meta\r\n-rw-rw-r-- 1 aider aider  300 Dec 28 18:06 Rakefile\r\n-rw-rw-r-- 1 aider aider 2280 Dec 28 18:06 README.md\r\ndrwxrwxr-x 3 aider aider 4096 Dec 28 18:06 style\r\n(aider) aider@mail:~/2048$ cd js/\r\n(aider) aider@mail:~/2048/js$ ls -l\r\ntotal 44\r\n-rw-rw-r-- 1 aider aider  890 Dec 28 18:06 animframe_polyfill.js\r\n-rw-rw-r-- 1 aider aider  197 Dec 28 18:06 application.js\r\n-rw-rw-r-- 1 aider aider  220 Dec 28 18:06 bind_polyfill.js\r\n-rw-rw-r-- 1 aider aider 1794 Dec 28 18:06 classlist_polyfill.js\r\n-rw-rw-r-- 1 aider aider 7627 Dec 28 18:22 game_manager.js\r\n-rw-rw-r-- 1 aider aider 2526 Dec 28 18:06 grid.js\r\n-rw-rw-r-- 1 aider aider 4040 Dec 28 18:06 html_actuator.js\r\n-rw-rw-r-- 1 aider aider 4005 Dec 28 18:06 keyboard_input_manager.js\r\n-rw-rw-r-- 1 aider aider 1588 Dec 28 18:06 local_storage_manager.js\r\n-rw-rw-r-- 1 aider aider  594 Dec 28 18:06 tile.js\r\n\r\n```",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/419/comments",
    "author": "linus-ahlemeyer",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2023-12-31T18:21:01Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nIf you don't want aider to automatically commit, then use `--no-auto-commits`.\r\n\r\nYou are correct, using `--no-git` will disable all git functionality including the repository map. This is working as designed."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-01-22T21:16:45Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open or file a new issue any time."
      }
    ]
  },
  {
    "number": 397,
    "title": "Achronological (and possibly redundant) elements in the prompt when making the first request",
    "created_at": "2023-12-09T17:06:18Z",
    "closed_at": "2024-01-01T00:58:05Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/397",
    "body": "Consider the following scenario. I have a project with a single file `hello.py`, and I ask aider to make a change.\r\nThe language model invocations look like this:\r\n\r\n```\r\nsystem: backstory, examples, rules\r\nuser: here is the repo map, if you want to change something ask to make the files read-write, I'm not sharing any read-write files yet\r\nassistant: ok\r\nsystem: rules again\r\nuser: please do <what I ask>\r\n(model completion) assistant: make hello.py read-write\r\n```\r\n\r\n```\r\nsystem: backstory, examples, rules\r\nuser: here are the read-write files: hello.py content\r\nassistant: ok\r\nsystem: rules again\r\nuser: please do <what I ask>\r\nassistant: make hello.py read-write\r\nuser: done\r\n(model completion) assistant: <actual search-replace block>\r\n```\r\n\r\nNote that this is inconsistent, the file was already read-write in the story when the (simulated) assistant asked to make it read-write and the (simulated) user ageed.\r\n\r\nMaybe this conversation could be skipped entirely. If not, maybe the content of the file should follow the read-write request:\r\n```\r\n...\r\nassistant: make hello.py read-write\r\nuser: done\r\nuser: here are the read-write files: hello.py content\r\n...\r\n```\r\n\r\nFor comparison, when doing the second request, the ordering of messages is consistent:\r\n```\r\nsystem: backstory, examples, rules\r\nuser: please do <what I ask 1>\r\nassistant: make hello.py read-write\r\nuser: done\r\nassistant: <actual search-replace block 1>\r\nuser: updated\r\nassistant: ok\r\nuser: here are the read-write files: hello.py content\r\nassistant: ok\r\nsystem: rules again\r\nuser: please do <what I ask 2>\r\n(model completion) assistant: <actual search-replace block 2>\r\n```\r\n",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/397/comments",
    "author": "Vlad-Shcherbina",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2023-12-09T18:03:54Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nOther than being a bit odd, is there a reason you are concerned about this small inconsistency? It's unintended result of a number of intentional decisions in how to construct a synthetic conversation history that is most effective for aider's pair programming style workflow. It should be harmless, but if you see evidence of a problem being caused please let me know."
      },
      {
        "user": "Vlad-Shcherbina",
        "created_at": "2023-12-09T18:47:44Z",
        "body": "No evidence of problems from this behavior, just noticed the oddity and wanted to bring it to your attention in case it matters.\r\n\r\nOut of curiosity, why include the read-write requests in the conversation history at all? I get why past user requests and assistant's responses are useful to include (maybe the followup is related to them). However, \"To do this, I need hello.py read-write. Done\" seems to unlikely to contain any relevant details, and it takes (a small number of) tokens.\r\n\r\nWhat do you think of the approach where in the final request, the assistant magically gets the right list of read-write files, but the story of how this list came about is not included?"
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-01-01T00:58:05Z",
        "body": "Because the r/w requests can occur organically mixed in with longer text from both the user or GPT. GPT might mention a file it needs along with a longer explanation about the plan for changing the code, etc. There's no easy way to just omit the r/w request from the conversation history.\r\n\r\nI'm going to close this issue for now, but feel free to add a comment here and I will re-open or file a new issue any time."
      }
    ]
  },
  {
    "number": 395,
    "title": "aider does not see files to available or writable [Bug]",
    "created_at": "2023-12-07T23:08:08Z",
    "closed_at": "2024-01-26T21:44:24Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/395",
    "body": "Main issue:\r\n\r\n```\r\n$ aider FOO\r\n(...)\r\n If it's available and public, please add the `FOO` to the chat so I can provide the necessary changes.\r\n ```\r\n\r\nI had already in past some messages of aider asking to provide file in read-write mode , which I added when lanuching for interactive mode ,e.g. `$aider foo bar` and later I had to `/drop foo` and `/add foo` to make aider to be able to use them.\r\n\r\nI can not apply same trick in iteractive mode , as I can not give list of multiple messages... (e.g. -f 1st.md -f 2nd.md -f 3rd.md ....) however still it's topic for another issue...\r\n\r\nIssue is that `aider -f msg.md foo bar`  complains that can not edit `foo `and asks   to add it to repository:\r\n\r\nFragment from `.aider.chat.history` :\r\n\r\n```\r\n# aider chat started at 2023-12-07 23:52:49\r\n\r\n> Aider v0.18.1-dev  \r\n> /home/gw-t490/.local/bin/aider --model gpt-4-1106-preview --message-file /tmp/tmp.Fu03ztRji6 docker/Dockerfile README.md (...)\r\n> Model: gpt-4-1106-preview  \r\n> Git repo: .git  \r\n> Repo-map: using 1024 tokens  \r\n> Added README.md to the chat.  \r\n> Added docker/Dockerfile to the chat.  \r\n(...)\r\n> Use /help to see in-chat commands, run with --help to see cmd line args  \r\n(...)\r\n If it's available and public, please add the `docker/Dockerfile` to the chat so I can provide the necessary changes.\r\n ```\r\n \r\nAgain, in past I had also asking files for read-write....\r\n\r\nOr maybe it's not a bug but my misunderstanding how to provide files into aider \"writable files\" context?",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/395/comments",
    "author": "gwpl",
    "comments": [
      {
        "user": "gwpl",
        "created_at": "2023-12-07T23:18:12Z",
        "body": "However it is hard to reproduce from scratch on small fresh repository, so probably happens when I am adding a lot of files into context.\r\n\r\nFor small examples works:\r\n\r\n```\r\ngit init\r\ntouch FOO BAR ZOO\r\ngit add .\r\ngit commit -m 'init'\r\nfor f in `seq 1 10` ; do aider --model gpt-4-1106-preview --message 'add short joke to any of available files!' FOO BAR ZOO ; done\r\n```\r\n"
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-01-01T00:53:05Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nHave you tried upgrading to the latest v0.19.x version of aider to see if this problem is better? There have been a number of relevant changes that should help."
      },
      {
        "user": "gwpl",
        "created_at": "2024-01-01T01:33:16Z",
        "body": "Thank you for following up on Aider! Sometimes it's so helpful!\r\n\r\nSo, even I am using version from HEAD of git repository, I still can observe sometimes chat asking \"It will require changing FOO in following way <THEN DIFF FOLLOWS>  (...) please provide file to be writable.\"...\r\n\r\nMy current work around is that I simply respond insisting \"Please, implement proposed changes in file FOO\" or things like that, and then it suddenly understands that file is writable and implements earlier proposed change, so in that sense I see improvement , as IIRC me insisting month ago was not helpful."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2024-01-26T21:44:24Z",
        "body": "Closing as a dup of #355 ."
      }
    ]
  },
  {
    "number": 390,
    "title": "autocomplete files with `/add`",
    "created_at": "2023-12-04T15:10:49Z",
    "closed_at": "2023-12-06T17:36:01Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/390",
    "body": "file detection would be nice ;)\r\n\r\nawesome work!",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/390/comments",
    "author": "Morriz",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2023-12-04T15:26:29Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nThe `/add` command already autocompletes against the files in the git repo. What are you seeing that makes you feel it is not doing autocomplete?"
      },
      {
        "user": "paul-gauthier",
        "created_at": "2023-12-06T17:35:59Z",
        "body": "I'm going to close this issue for now, but feel free to add a comment here and I will re-open or file a new issue any time."
      }
    ]
  },
  {
    "number": 345,
    "title": "from aider.coders import Coder - ModuleNotFoundError: No module named 'aider.coders'; 'aider' is not a package",
    "created_at": "2023-11-12T05:49:12Z",
    "closed_at": "2023-11-21T21:36:23Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/345",
    "body": "Hi,\r\n\r\nI'm trying to test out the new in-code Aider usage by using the example code but I'm getting an error: `ModuleNotFoundError: No module named 'aider.coders'; 'aider' is not a package`.\r\n\r\nI just copy-pasted the code from the documentation and made sure I'm on the latest aider-chat version (0.17.0)\r\n```python\r\nfrom aider.coders import Coder\r\n\r\n# This is a list of files to add to the chat\r\nfnames = [\"foo.py\"]\r\n\r\n# Create a coder object\r\ncoder = Coder.create(fnames=fnames)\r\n\r\n# This will execute one instruction on those files and then return\r\ncoder.run(\"make a script that prints hello world\")\r\n\r\n# Send another instruction\r\ncoder.run(\"make it say goodbye\")\r\n```",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/345/comments",
    "author": "jontstaz",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2023-11-14T19:13:21Z",
        "body": "Thanks for trying aider!\r\n\r\nAre you sure you have installed aider in the active python environment? That error makes it look like an issue with your local python env."
      },
      {
        "user": "jontstaz",
        "created_at": "2023-11-18T10:34:46Z",
        "body": "Yes I have. It only works when I actually have the aider folder itself in the same directory as the python file i'm executing. Regardless if aider is installed in the current python env, it still requires the aider folder for the aider.coders in-code execution to work. "
      },
      {
        "user": "paul-gauthier",
        "created_at": "2023-11-21T21:36:19Z",
        "body": "This seems to be some problem with your local Python environment and the way that you've installed aider. It sounds like you've figured out how to make it work in your environment. Glad to hear that."
      },
      {
        "user": "jazoom",
        "created_at": "2025-01-11T06:45:41Z",
        "body": "I get this exact error using the latest Aider via the `paulgauthier/aider-full` Docker image. 0.70 worked fine. 0.71 gives this error and fails to start."
      },
      {
        "user": "jazoom",
        "created_at": "2025-01-11T06:48:10Z",
        "body": "By the way, @paul-gauthier, thank you for tagging the images with versions. That makes it very easy to just use the previous image."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2025-01-11T14:54:48Z",
        "body": "See #2827."
      }
    ]
  },
  {
    "number": 309,
    "title": "Suggestion: DryRun owerwrite",
    "created_at": "2023-11-01T07:25:20Z",
    "closed_at": "2023-11-02T17:54:55Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/309",
    "body": "I usually run AIDER in dry mode, to avoid to write over my code and the solution maybe is not OK.\r\nI would like to have a command like /dryover maybe if I get a response from AIDER and is ok, then run /dryover and get the last solution and write it bypassing dry-mode.",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/309/comments",
    "author": "lvalics",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2023-11-01T14:21:31Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nThe entire purpose of `--dry-run` is to be certain that your files will not be modified. As such, it would not be appropriate to add a `/dryover` command that overruled that setting.\r\n\r\nThe expected way to use aider is to run it without `--dry-run` and keep your source code files in a git repo. Aider is very careful to make sure any changes made to the files are committed to git in distinct commits. Aider provides the `/undo` command to undo a change that you didn't like. Or you can use all of the normal git commands to revert any aider changes you'd like (either using `/git` inside the chat or just using `git` or any other standard git tools)."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2023-11-02T17:54:55Z",
        "body": "I'm going to close this issue for now, but feel free to re-open or file a new issue any time."
      }
    ]
  },
  {
    "number": 306,
    "title": "Enhancement: Consider fuzzy matching of the SEARCH pattern.",
    "created_at": "2023-11-01T00:28:20Z",
    "closed_at": "2023-11-01T23:48:03Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/306",
    "body": "Hi!\r\n\r\nAider is an excellent tool, and as agentic software becomes more prevalent, I find that its shortfalls become more and more irritating. In a similar way that every computer is a slow horrible mess once you've used something better. \r\n\r\nWith Aider, this is that the SEARCH block doesn't seem to match sometimes, and I might have waited minutes for the output of the conversation only to have no changes. I work-around this by doing small, focused increments as much as possible, but there is always a time where the change is just a little bit bigger, or GPT decides that the diff should be lengthy. I can sometimes apply the change myself and then commit it and continue the conversation, but it would be nice if I had to do this less often.\r\n\r\nMy thought was a fuzzy matching on SEARCH patterns. I can't say that you aren't already doing this because I have not looked at the way Aider works in regard to file updates. But I suspect that the SEARCH pattern must be exact, down to the whitespace.\r\n\r\nI'd like to open the discussion for ways Aider could, without harming the accuracy of the updates too much, improve this. Handling whitespace differently comes to mind, as does fuzzy matching (Levenshtein distance?).\r\n\r\nHas thought already been put into this? Is this something that is desired?",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/306/comments",
    "author": "nevercast",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2023-11-01T14:30:23Z",
        "body": "Aider has implementations of both of these ideas.\r\n\r\nFuzzy matching for *leading* whitespace is critical, as GPT-4 is very prone to omitting leading whitespace when it is doing SEARCH/REPLACE on a deeply nested chunk of code. It preserves the indentation relevant to the chunk it is working with, but often leaves out the first few indents that are common to every line in the chunk. Aider recognizes the omitted leading whitespace and restores the correct amount.\r\n\r\nAider also has support for a Levenshtein-style fuzzy match of the entire SEARCH block. In recent releases it has been disabled though. Often GPT produces a SEARCH block that leaves out some *semantically significant* lines. Those lines are also missing from the REPLACE block. And so the result is that fuzzy matching allows GPT to silently delete some important lines from the code, introducing unintended changes and bugs.\r\n\r\nInstead, aider reflects back an error to GPT if the SEARCH block fails to match the existing file contents. It points out exactly where the SEARCH block deviated from the actual file contents. GPT is usually then able to notice the mistake and produce a new SEARCH/REPLACE block which is both a correct match and a semantically correct edit to the file."
      },
      {
        "user": "nevercast",
        "created_at": "2023-11-01T23:48:03Z",
        "body": "Thanks for answering. Seems like this has been explored and the most reliable solution is already in place. I shall close this issue. \r\n\r\nA thought though, and perhaps better in another issue: It would be nice if Aider bailed as soon as the SEARCH pattern fails to match anything when streaming from the agent, could run that in the background after each new line or something. This would also save me tokens :) "
      },
      {
        "user": "paul-gauthier",
        "created_at": "2023-11-02T01:18:35Z",
        "body": "Yup. Notifying GPT in real time about a bad partial SEARCH block is on my list. I almost implemented it last week when I was doing related work on the \"diff\" coder backend where all this lives. "
      }
    ]
  },
  {
    "number": 299,
    "title": "Trying to install aider in a virtual environment with Anaconda seems like it causes a bunch of dependency issues",
    "created_at": "2023-10-30T21:08:52Z",
    "closed_at": "2023-11-02T17:56:08Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/299",
    "body": "_As you can tell by the title, I'm very much a novice - I would very easily believe that this is my fault/misunderstanding (and if anyone wanted to educate me with a couple of terms to google, I'd appreciate the heck out of it!)_\r\n\r\nAll that being said -  trying to install aider inside of an Anaconda venv causes what looks like a bunch of dependency issues.\r\n\r\nHere's the example errors I'm seeing - I think most of these are caused by simpleaichat?\r\n\r\nIn a bone stock basic Anaconda venv with Python 3.11, running the command: python -m pip install aider-chat\r\n\r\nGives me these errors:\r\n\r\nsimpleaichat 0.2.2 requires httpx>=0.24.1, but you have httpx 0.23.0 which is incompatible.\r\nsimpleaichat 0.2.2 requires orjson>=3.9.0, but you have orjson 3.8.8 which is incompatible.\r\nsimpleaichat 0.2.2 requires pydantic>=2.0, but you have pydantic 1.10.12 which is incompatible.\r\nsimpleaichat 0.2.2 requires python-dotenv>=1.0.0, but you have python-dotenv 0.21.0 which is incompatible.\r\nsimpleaichat 0.2.2 requires rich>=13.4.1, but you have rich 13.3.5 which is incompatible.\r\n\r\nI was able to solve this by manually updating (except with rich, which I was required to then roll back to 13.3.5 instead of the most current 13.6). ",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/299/comments",
    "author": "basilbowman",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2023-10-30T21:34:37Z",
        "body": "Thanks for trying aider and filing this issue.\r\n\r\nI don't think I understand why `python -m pip install aider-chat` is printing error messages about `simpleaichat`. Aider and it's dependencies do not require `simpleaichat`. \r\n\r\nA vanilla anaconda docker image lets me install aider just fine:\r\n\r\n```\r\n$ docker pull continuumio/anaconda3\r\nUsing default tag: latest\r\nlatest: Pulling from continuumio/anaconda3\r\n7dbc1adf280e: Pull complete\r\nad2a2c08a78a: Pull complete\r\nDigest: sha256:b60631636309ed40a3bc01edc326128aeadfa50622da76052abc9ef2e1d3c8cc\r\nStatus: Downloaded newer image for continuumio/anaconda3:latest\r\ndocker.io/continuumio/anaconda3:latest\r\n\r\n$ docker run -i -t continuumio/anaconda3 /bin/bash\r\n\r\n(base) root@05f2055216a8:/# apt-get update\r\n...\r\n\r\n(base) root@05f2055216a8:/# apt-get install -y build-essential\r\n...\r\n\r\n(base) root@37abbd9becd1:/# conda create -n myenv python=3.11\r\n\r\n(base) root@37abbd9becd1:/# conda activate myenv\r\n\r\n(myenv) root@37abbd9becd1:/# python -m pip install aider-chat\r\n...\r\nSuccessfully installed CFFI-1.16.0 GitPython-3.1.31 PyYAML-6.0.1 Pygments-2.15.1 aider-chat-0.16.0 aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 attrs-23.1.0 backoff-2.2.1 certifi-2023.5.7 charset-normalizer-3.1.0 configargparse-1.7 diskcache-5.6.1 frozenlist-1.3.3 gitdb-4.0.10 grep-ast-0.2.0 idna-3.4 iniconfig-2.0.0 jsonschema-4.17.3 markdown-it-py-2.2.0 mdurl-0.1.2 multidict-6.0.4 networkx-3.1 numpy-1.24.3 openai-0.27.6 packaging-23.2 pathspec-0.11.2 pluggy-1.3.0 prompt-toolkit-3.0.38 pycparser-2.21 pyrsistent-0.20.0 pytest-7.3.1 regex-2023.10.3 requests-2.30.0 rich-13.3.5 scipy-1.10.1 smmap-5.0.0 sounddevice-0.4.6 soundfile-0.12.1 tiktoken-0.4.0 tqdm-4.65.0 tree-sitter-0.20.1 tree-sitter-languages-1.8.0 urllib3-2.0.2 wcwidth-0.2.6 yarl-1.9.2\r\n\r\n(myenv) root@37abbd9becd1:/# aider --version\r\naider 0.16.0\r\n```"
      },
      {
        "user": "paul-gauthier",
        "created_at": "2023-11-02T17:56:08Z",
        "body": "I'm going to close this issue for now, but feel free to re-open if you can provide a way to reproduce the issue."
      }
    ]
  },
  {
    "number": 290,
    "title": "Dry Run",
    "created_at": "2023-10-21T19:07:15Z",
    "closed_at": "2023-10-23T15:37:41Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/290",
    "body": "How do you apply an edit if you run Aider in dry run mode?",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/290/comments",
    "author": "mel11691",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2023-10-22T19:00:25Z",
        "body": "Thanks for trying aider!\r\n\r\nThe purpose of the `--dry-run` switch is to make sure aider does NOT modify your files. If you want it to edit your files, do not use that switch."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2023-10-23T15:37:41Z",
        "body": "I'm going to close this issue for now, but feel free to re-open or file a new issue any time."
      }
    ]
  },
  {
    "number": 279,
    "title": "Non-relative patterns are unsupported",
    "created_at": "2023-10-12T09:46:19Z",
    "closed_at": "2023-10-17T23:44:48Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/279",
    "body": "Fresh install on ubuntu 22.04\r\nI cant get it to work with my files.\r\nAny tips?\r\n\r\n`ubuntu@Ubuntu:~/starkekjell$ aider\r\n\r\nAider v0.14.1\r\nModel: gpt-4\r\nGit repo: .git\r\nRepo-map: basic using 1024 tokens (ctags executable not found)\r\nUse /help to see in-chat commands, run with --help to see cmd line args\r\n───────────────────────────────────────────────────────────────────────────────\r\n/add xxxxxxxx.ps1 /add xxxxxxxxx.txt /add xxxxxxxxxxxxx.ps1                    \r\n\r\nTraceback (most recent call last):\r\nFile \"/home/ubuntu/.local/bin/aider\", line 8, in <module>\r\nsys.exit(main())\r\nFile \"/home/ubuntu/.local/lib/python3.10/site-packages/aider/main.py\", line 538, in main\r\ncoder.run()\r\nFile \"/home/ubuntu/.local/lib/python3.10/site-packages/aider/coders/base_coder.py\", line 325, in run\r\nnew_user_message = self.run_loop()\r\nFile \"/home/ubuntu/.local/lib/python3.10/site-packages/aider/coders/base_coder.py\", line 404, in run_loop\r\nreturn self.commands.run(inp)\r\nFile \"/home/ubuntu/.local/lib/python3.10/site-packages/aider/commands.py\", line 74, in run\r\nreturn self.do_run(matching_commands[0][1:], rest_inp)\r\nFile \"/home/ubuntu/.local/lib/python3.10/site-packages/aider/commands.py\", line 52, in do_run\r\nreturn cmd_method(args)\r\nFile \"/home/ubuntu/.local/lib/python3.10/site-packages/aider/commands.py\", line 289, in cmd_add\r\nmatched_files = self.glob_filtered_to_repo(word)\r\nFile \"/home/ubuntu/.local/lib/python3.10/site-packages/aider/commands.py\", line 252, in glob_filtered_to_repo\r\nraw_matched_files = list(Path(self.coder.root).glob(pattern))\r\nFile \"/usr/lib/python3.10/pathlib.py\", line 1032, in glob\r\nraise NotImplementedError(\"Non-relative patterns are unsupported\")\r\nNotImplementedError: Non-relative patterns are unsupported\r\nubuntu@Ubuntu:~/starkekjell$`",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/279/comments",
    "author": "Storhemulen",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2023-10-12T13:48:48Z",
        "body": "Thanks for trying aider and reporting this issue.\r\n\r\nDid you actually enter `/add xxxxxxxx.ps1 /add xxxxxxxxx.txt /add xxxxxxxxxxxxx.ps1` all on one line? You only need to start the line with `/add` and then follow it with all the filenames."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2023-10-17T23:44:48Z",
        "body": "I'm going to close this issue for now, but feel free to re-open or file a new issue any time."
      }
    ]
  },
  {
    "number": 277,
    "title": "Keep getting error: Your branch is ahead of 'origin/new' by 6 commits.   (use \"git push\" to publish your local commits)  nothing to commit, working tree clean' Update exception #1, retrying...",
    "created_at": "2023-10-09T23:05:30Z",
    "closed_at": "2023-10-17T23:43:25Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/277",
    "body": "I havent checked out this project for a while, so i might be a bit behind and be doing something wrong, but now anytime i try to do anything i keep getting Your branch is ahead of 'origin/new' by 6 commits.\r\n  (use \"git push\" to publish your local commits)\r\n\r\nnothing to commit, working tree clean'\r\n\r\nDespite the fact that it makes many, multiple changes beforehand. If i try /undo it says no changes have been made with aider, even though they absolutely have (these 6 commits are all aider). I tried dirty-commit, auto-commit, no-auto-commit basically every one of the prerun commands and i keep getting the same error over and over, unless i actually git push, which i dont want to do as my repo is connected remotely. Even when i set it up locally to push there it still gives me the same error. \r\n\r\nSo my question is how do i force it to just commit locally and have it stop bugging me that its ahead of the origin/new, like it was before.\r\nForgive me if this has been answered or is a stupid/newbie question, I just need some clarity. \r\n\r\n",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/277/comments",
    "author": "cranyy",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2023-10-12T13:51:55Z",
        "body": "Thanks for trying aider and reporting this issue.\r\n\r\nCan you show me a screenshot or paste the actual output of aider that results in this error? Also, what version of aider are you using?"
      },
      {
        "user": "paul-gauthier",
        "created_at": "2023-10-17T23:43:25Z",
        "body": "I'm going to close this issue for now, but feel free to re-open or file a new issue any time."
      }
    ]
  },
  {
    "number": 238,
    "title": "benchmark crush",
    "created_at": "2023-09-03T15:42:51Z",
    "closed_at": "2023-09-05T19:36:02Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/238",
    "body": "I was testing some new local llms when this error happened. \r\n────────────────────────────────────────────── benchmark/exercism-python ───────────────────────────────────────────────\r\ntest-cases: 111\r\nmodel: gpt-3.5-turbo\r\nedit_format: whole\r\ncommit_hash: bcf4a55-dirty\r\nnum_error_outputs: 4\r\nnum_user_asks: 4\r\nnum_exhausted_context_windows 0\r\ntest_timeouts: 2\r\n\r\n15.3% correct after try 0\r\n25.2% correct after try 1\r\n\r\nduration: 35.3 sec/test-case\r\ncosts: $0.0058/test-case, $0.65 total, $0.78 projected\r\n────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\nmain_model: gpt-3.5-turbo\r\nedit_format: whole\r\nfnames: benchmark/exercism-python/simple-cipher/simple_cipher.py\r\nModel: gpt-3.5-turbo\r\nGit repo: none\r\nRepo-map: disabled\r\nAdded simple_cipher.py to the chat.\r\nTraceback (most recent call last):\r\n  File \"benchmark/benchmark.py\", line 696, in <module>\r\n    app()\r\n  File \"/usr/local/lib/python3.8/site-packages/typer/main.py\", line 328, in __call__\r\n    raise e\r\n  File \"/usr/local/lib/python3.8/site-packages/typer/main.py\", line 311, in __call__\r\n    return get_command(self)(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.8/site-packages/click/core.py\", line 1157, in __call__\r\n    return self.main(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.8/site-packages/typer/core.py\", line 716, in main\r\n    return _main(\r\n  File \"/usr/local/lib/python3.8/site-packages/typer/core.py\", line 216, in _main\r\n    rv = self.invoke(ctx)\r\n  File \"/usr/local/lib/python3.8/site-packages/click/core.py\", line 1434, in invoke\r\n    return ctx.invoke(self.callback, **ctx.params)\r\n  File \"/usr/local/lib/python3.8/site-packages/click/core.py\", line 783, in invoke\r\n    return __callback(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.8/site-packages/typer/main.py\", line 683, in wrapper\r\n    return callback(**use_params)  # type: ignore\r\n  File \"benchmark/benchmark.py\", line 325, in main\r\n    results = run_test(\r\n  File \"benchmark/benchmark.py\", line 578, in run_test\r\n    coder.run(with_message=instructions)\r\n  File \"/usr/local/lib/python3.8/site-packages/aider/coders/base_coder.py\", line 342, in run\r\n    new_user_message = self.send_new_user_message(new_user_message)\r\n  File \"/usr/local/lib/python3.8/site-packages/aider/coders/base_coder.py\", line 456, in send_new_user_message\r\n    interrupted = self.send(messages, functions=self.functions)\r\n  File \"/usr/local/lib/python3.8/site-packages/aider/coders/base_coder.py\", line 582, in send\r\n    self.show_send_output(completion)\r\n  File \"/usr/local/lib/python3.8/site-packages/aider/coders/base_coder.py\", line 635, in show_send_output\r\n    show_resp = self.render_incremental_response(True)\r\n  File \"/usr/local/lib/python3.8/site-packages/aider/coders/wholefile_coder.py\", line 25, in render_incremental_response\r\n    return self.update_files(mode=\"diff\")\r\n  File \"/usr/local/lib/python3.8/site-packages/aider/coders/wholefile_coder.py\", line 52, in update_files\r\n    output += self.do_live_diff(full_path, new_lines, True)\r\n  File \"/usr/local/lib/python3.8/site-packages/aider/coders/wholefile_coder.py\", line 125, in do_live_diff\r\n    if full_path.exists():\r\n  File \"/usr/local/lib/python3.8/pathlib.py\", line 1407, in exists\r\n    self.stat()\r\n  File \"/usr/local/lib/python3.8/pathlib.py\", line 1198, in stat\r\n    return self._accessor.stat(self)\r\nOSError: [Errno 36] File name too long: '/aider/benchmark/exercism-python/simple-cipher/3. Modify the `encode()` function to take a key argument (defaulting to None). If no key is provided, call the `generate_key()` function to generate a new key. Use the key to substitute each letter in the plaintext with its corresponding letter in the key.'",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/238/comments",
    "author": "BigArty",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2023-09-05T18:33:36Z",
        "body": "Thanks for trying aider and reporting this issue.\r\n\r\nThis looks to me like perhaps the local LLM produced a badly formed edit response, which triggered an error in aider. This is probably because the LLM you were using isn't able to follow instructions well enough to work properly with aider.\r\n\r\nIf you can isolate the LLM response that is causing the error, we might be able to debug it further."
      },
      {
        "user": "BigArty",
        "created_at": "2023-09-05T18:55:51Z",
        "body": "Sadly, (or fortunately) this problem only appeared once for me. I made test with several models and configurations, but this particular run aborted ad the very end and with the one of the strongest models in my tests."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2023-09-05T19:36:02Z",
        "body": "Ok, please let me know if you are able to reproduce.  I'm going to close this issue for now, but feel free to re-open or file a new issue any time."
      }
    ]
  },
  {
    "number": 235,
    "title": "GPT Adding Comments Cause Errors When Updating Files",
    "created_at": "2023-08-31T17:31:30Z",
    "closed_at": "2023-09-27T17:31:08Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/235",
    "body": "Usage: aider via terminal in vscode, debian\r\n\r\nError: \r\n\r\n`The error `Malformed response #2, retrying...\r\nInvalidEditBlock: edit failed!\r\n\r\n<myfile> does not contain the *exact sequence* of HEAD lines you specified.\r\nTry again.\r\nDO NOT skip blank lines, comments, docstrings, etc!\r\nThe HEAD block needs to be EXACTLY the same as the lines in assets/js/output.js with nothing missing!\r\n\r\n<myfile> does not contain these 2 exact lines in a row:\r\n\r\n  // Step 1: <Comment on what needs changing>`\r\n  \r\nIssue: The error causes a loop where aider keeps trying to fix the issue with updating the file. This burns through tokens fast and is incredibly expensive as it keep generating the same old code, then the new code updates, etc. If it does not catch the issue on the second go around, it will keep trying.\r\n  \r\n",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/235/comments",
    "author": "generallynonsensical",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2023-09-05T18:36:08Z",
        "body": "Thanks for trying aider and reporting this issue.\r\n\r\nUnfortunately even GPT-4 gets confused sometimes. You can always safely halt it by hitting CONTROL-C and then tell it to stop doing whatever it's doing wrong.\r\n\r\nAnother thing to try is to add fewer files to the chat, so GPT can focus more on the specific files you want it to change."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2023-09-27T17:31:08Z",
        "body": "I'm going to close this issue for now, but feel free to re-open or file a new issue any time."
      }
    ]
  },
  {
    "number": 226,
    "title": "Upcontributing RepoMap to Llama_index",
    "created_at": "2023-08-29T17:35:08Z",
    "closed_at": "2023-09-12T16:23:11Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/226",
    "body": "I'm curious if the author would be willing to allow me to copy and modify the RepoMap code for contribution to llama_index. I feel like it's very useful in a lot of applications and people will expect to find it there. With attribution of course.",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/226/comments",
    "author": "ryanpeach",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2023-09-05T18:47:19Z",
        "body": "It's an interesting idea. The repomap concept is under heavy development right now, and about to undergo significant changes. So now is probably not the best time to try packaging it up for use elsewhere."
      },
      {
        "user": "ryanpeach",
        "created_at": "2023-09-12T16:23:11Z",
        "body": "I think my own PR to llama_index may be able to create a repo map. Closing."
      }
    ]
  },
  {
    "number": 225,
    "title": "replacing peace of code",
    "created_at": "2023-08-29T14:18:21Z",
    "closed_at": "2023-09-29T17:01:53Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/225",
    "body": "hello.  i am playing python 3.9.17.i am trying to solve a task based on the existing code by adopt it.\r\nso i building code in file A.py, using classes and methods from file B.py.\r\nwhat i am doing wrong?: \r\nwhen aider solving task by analyzing file B.py in repo - it making some changes and replacing very big peace of code with just string \"# ... rest of the code ...\" and save this file, so it is became unusable without this peace of code.\r\nalso it change file A.py the same way...",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/225/comments",
    "author": "sawa25",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2023-09-05T18:47:58Z",
        "body": "Thanks for trying aider and reporting this issue.\r\n\r\nAre you able to share some specific details about what you are trying to do? Maybe paste some output from aider?"
      },
      {
        "user": "sawa25",
        "created_at": "2023-09-06T06:39:32Z",
        "body": "thank you for this very interesting project!\r\nas for the issue: i am trying to grab some class and methods from public python package with help of aider - so i fork a package, organize empty file \".py\" and modifying it with aider. i notify, that enough often aider can kill all the code by changing a couple of string and writing \"# ... rest of the code ...\". it is possible to get backup from git, but it is not the optimal behaviour, because you need to compare to versions and to discover, what to change. more obviously is to keep the rest of code as is, if i am working under this only file \".py\". may be i am asking aider wrong if i get this behaviour... will look"
      },
      {
        "user": "paul-gauthier",
        "created_at": "2023-09-08T16:29:49Z",
        "body": "Are you using gpt-3.5 or 4?"
      },
      {
        "user": "sawa25",
        "created_at": "2023-09-10T10:28:41Z",
        "body": "\ngpt-3.5\n\n  \n>Пятница, 8 сентября 2023, 19:30 +03:00 от paul-gauthier ***@***.***>:\n> \n> \n>Are you using gpt-3.5 or 4?\n>—\n>Reply to this email directly,  view it on GitHub , or  unsubscribe .\n>You are receiving this because you authored the thread. Message ID:  <paul-gauthier/aider/issues/225/1711936424 @ github . com> \n \n \nВолков В.В.\n "
      },
      {
        "user": "paul-gauthier",
        "created_at": "2023-09-18T15:31:28Z",
        "body": "Unfortunately, 3.5 is quite limited in its capabilities. I recommend trying it with GPT-4."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2023-09-29T17:01:53Z",
        "body": "I'm going to close this issue for now, but feel free to re-open or file a new issue any time."
      }
    ]
  },
  {
    "number": 222,
    "title": "Cloudflare 502 Bad Gateway causes complete crash.  Cannot ctrl-c just frozen ",
    "created_at": "2023-08-26T14:20:02Z",
    "closed_at": "2023-09-02T01:00:26Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/222",
    "body": "Not sure how often this will occur but a failed cloudflare response completely crashed aider.  Here is the response that I got back.  It does not retry as it says it will in 0.9 seconds...  just frozen.\r\n\r\n        if 'updated_at' in response.json:\r\n            self.assertNotEqual(response.json['updated_at'], old_updated_at)\r\n>>>>>>> updated\r\n```\r\n\r\nThis change will use the `get` method to access the `updated_at` key in the `response.json` dictionary, which will return `None` if the key is not present. Then, it will only perform the assertion to check if `updated_at` has changed if the key is present in the response.\r\nApplied edit to test_topic.py\r\nHTTP code 502 from API (<html>\r\n<head><title>502 Bad Gateway</title></head>\r\n<body>\r\n<center><h1>502 Bad Gateway</h1></center>\r\n<hr><center>cloudflare</center>\r\n</body>\r\n</html>\r\n)\r\nRetry in 0.9 seconds.\r\n",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/222/comments",
    "author": "Dougie777",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2023-08-26T15:50:39Z",
        "body": "Thanks for trying aider and reporting this issue.\r\n\r\nGiven that you were getting 502 gateway errors, it's likely that cloudflare and/or openai is having server errors. Probably aider made a request that just hung inside their servers. If you waited longer you probably would have seen a timeout error and then aider would have made another retry.\r\n\r\nYou can see that aider is properly handling and retrying the 502 when it says `Retry in 0.9 seconds`."
      },
      {
        "user": "Dougie777",
        "created_at": "2023-09-02T01:00:26Z",
        "body": "Have not got this problem again so closing...."
      }
    ]
  },
  {
    "number": 218,
    "title": "How to set up multiple projects?",
    "created_at": "2023-08-23T12:31:36Z",
    "closed_at": "2023-08-23T22:07:51Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/218",
    "body": "I'd like to run aider for different projects, but it seems to want to remember the first project that I created. I can't figure out how to have it look at only files within a specific project directory and not at the directory it's installed at.\r\n\r\nIs this possible?\r\n\r\nIf it's not, any workarounds?\r\n\r\nIf I'm a total newb, I apologize 🙏❤",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/218/comments",
    "author": "J-DTurner",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2023-08-23T13:58:11Z",
        "body": "Thanks for trying aider! Just make sure each project has it's own git repo. Don't put them all in the same repo."
      },
      {
        "user": "J-DTurner",
        "created_at": "2023-08-23T14:31:31Z",
        "body": "Ahh, got it, thank you."
      },
      {
        "user": "J-DTurner",
        "created_at": "2023-08-23T15:00:16Z",
        "body": "> Thanks for trying aider! Just make sure each project has it's own git repo. Don't put them all in the same repo.\r\n\r\nStill not sure exactly how to do this.\r\n\r\nI've initialized a new repo with current projects files, but when I use the /ls command - it's still showing the files from the first project."
      },
      {
        "user": "J-DTurner",
        "created_at": "2023-08-23T15:10:02Z",
        "body": "Figured it out.\r\n\r\n/git init\r\n\r\nthen have to restart VScode and run aider again in the same directory. All good!"
      },
      {
        "user": "paul-gauthier",
        "created_at": "2023-08-23T22:07:51Z",
        "body": "I'm going to close this issue for now, but feel free to re-open or file a new issue any time."
      }
    ]
  },
  {
    "number": 206,
    "title": "Parallel requests to multiple instances of GPT?",
    "created_at": "2023-08-18T04:26:48Z",
    "closed_at": "2023-08-23T14:08:19Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/206",
    "body": "If possible Use an assembly of GPT models Giving them all the same role as aider, Allowing the user to input multiple API keys for each.  This would significantly increase aider capability by using multiple api keys to have a bigger input and output Would allow it to handle bigger tasks by breaking up the The user's query into multiple task lets say between 5 where each gpt model equals a number to complete that specific tasks . Open to feedback I'm new to all of this",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/206/comments",
    "author": "ProfitWaveTradingCo",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2023-08-18T20:30:04Z",
        "body": "Thanks for trying aider and asking this question.\r\n\r\nI'm not exactly sure how that could work, but it's an interesting concept to think about."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2023-08-23T14:08:20Z",
        "body": "I'm going to close this issue for now, but feel free to re-open or file a new issue any time."
      },
      {
        "user": "tianshuo",
        "created_at": "2024-12-03T15:12:09Z",
        "body": "A round-robin code would work for this:\r\n1. shuffle keys in a  random way\r\n2. pick first key  for  first query\r\n3. Pick next  key for next query\r\n4. If reach end,  restart from first key."
      }
    ]
  },
  {
    "number": 168,
    "title": "I am having an issue where aider is not able to make files or update the code that i give it on previous files that i was working on.",
    "created_at": "2023-08-01T21:58:57Z",
    "closed_at": "2023-08-08T10:29:58Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/168",
    "body": "I am in the latest aider update before updating to day i was in 8.0.3 i think and something like this happened but was resolved after creating a new file.  If this could be fixed without always creating a new file and if it is necessary to create a new file in order to fix this then lets try to implement it.\r\n\r\nhere is an example with a project that i am working on:\r\n\r\nAllow creation of new file **src/screens/HomeScreen1.js**? y\r\n[WinError 123] The filename, directory name, or volume label syntax is incorrect: 'C:\\\\Users\\\\steve\\\\OneDrive\\\\Desktop\\\\aider\\\\Projects\\\\Apps\\\\Finance Focus\\\\**src\\\\screens'\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\steve\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\aider\\coders\\base_coder.py\", line 1035, in apply_updates\r\n    edited = self.update_files()\r\n             ^^^^^^^^^^^^^^^^^^^\r\n  File \"C:\\Users\\steve\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\aider\\coders\\wholefile_coder.py\", line 126, in update_files\r\n    if self.allowed_to_edit(fname, new_lines):\r\n       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"C:\\Users\\steve\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\aider\\coders\\base_coder.py\", line 985, in allowed_to_edit\r\n    Path(full_path).parent.mkdir(parents=True, exist_ok=True)\r\n  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.1264.0_x64__qbz5n2kfra8p0\\Lib\\pathlib.py\", line 1116, in mkdir\r\n    os.mkdir(self, mode)\r\nOSError: [WinError 123] The filename, directory name, or volume label syntax is incorrect: 'C:\\\\Users\\\\steve\\\\OneDrive\\\\Desktop\\\\aider\\\\Projects\\\\Apps\\\\Finance Focus\\\\**src\\\\screens'\r\nUpdate exception #5, aborting\r\n\r\n\r\nAfter every attempt the system aborts and stays in the aider chat while the code or new file is not implemented into the project.",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/168/comments",
    "author": "steven-reyes",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2023-08-02T09:51:04Z",
        "body": "Thanks for trying aider and reporting this issue.\r\n\r\nCan you show me the first few lines that are printed when you run aider? This will contain the version number and the information about which GPT model aider is using, etc.\r\n\r\nIt looks like the LLM has proposed a filename `**src/screens/HomeScreen.js` that starts with `**`. This makes me think you may be working with GPT-3.5? If so, you would almost certainly have more success with GPT-4 if you have access.\r\n\r\nA simple workaround is to add the file to aider yourself, and then ask GPT to put the code there. You can do that by running `aider src/screens/HomeScreen.js` or by doing `/add src/screens/HomeScreen.js` while in the chat."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2023-08-02T09:52:16Z",
        "body": "This seems similar to issue #157 and may be improved if we explicitly strip asterisks from filenames proposed by GPT."
      },
      {
        "user": "steven-reyes",
        "created_at": "2023-08-02T15:15:53Z",
        "body": "Hey Paul I am using gpt3.5 since I currently don't have access to gpt4.\n\n\nRegarding the solution below that you suggested I usually add all the files or review them in the beginning of the chat and they are added to aider which let’s aider have access to the files and make edits and changes. But it didn’t want to further edit or add new files when it came to some components of the project.\n\n(A simple workaround is to add the file to aider yourself, and then ask GPT to put the code there. You can do that by running aider src/screens/HomeScreen.js or by doing /add src/screens/HomeScreen.js while in the chat.)"
      },
      {
        "user": "paul-gauthier",
        "created_at": "2023-08-02T15:17:47Z",
        "body": "With 3.5 it can also help to only add ONE file at a time to the chat. Just add the specific file you need it to edit."
      },
      {
        "user": "steven-reyes",
        "created_at": "2023-08-02T15:36:23Z",
        "body": "Ok thanks I'll try that later and let you know what happens."
      },
      {
        "user": "steven-reyes",
        "created_at": "2023-08-07T22:46:01Z",
        "body": "After following your suggestion I didn't have the issue."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2023-08-08T10:29:58Z",
        "body": "I'm going to close this issue for now, but feel free to re-open or file a new issue any time."
      },
      {
        "user": "ssillah10",
        "created_at": "2024-04-29T00:47:07Z",
        "body": "Hi Paul, I am having the same issue but with Gemini. It can't create or edit files. Any suggestions?"
      },
      {
        "user": "omegathesecond",
        "created_at": "2024-11-04T12:14:08Z",
        "body": "Claude has stopped being able to create files today. Is anyone else experiencing the issue?"
      },
      {
        "user": "coolaydalena",
        "created_at": "2024-11-06T03:00:18Z",
        "body": "> Claude has stopped being able to create files today. Is anyone else experiencing the issue?\r\n\r\nIm experiencing the same issue. I can see in the logs that it is trying to create a new file, however in reality it didn't. Instead, it appends the code content to an existing file."
      },
      {
        "user": "kadavilrahul",
        "created_at": "2025-02-15T14:08:07Z",
        "body": "I think that aider need to incorporate shell commands for writing files rather than python commands which are unreliable."
      }
    ]
  },
  {
    "number": 167,
    "title": "[BUG] File not found: .git\\\\objects\\\\pack\\\\pack-idx",
    "created_at": "2023-08-01T13:36:38Z",
    "closed_at": "2023-08-09T14:18:10Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/167",
    "body": "\r\n\r\n```\r\nPS C:\\Users\\..> python -m aider.main\r\nAider v0.10.1\r\nModel: gpt-4\r\nGit repo: .git\r\nRepo-map: universal-ctags using 1024 tokens\r\nTraceback (most recent call last):\r\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\r\n  File \"<frozen runpy>\", line 88, in _run_code\r\n  File \"C:\\Users\\%user%\\AppData\\Roaming\\Python\\Python311\\site-packages\\aider\\main.py\", line 465, in <module>\r\n    status = main()\r\n             ^^^^^^\r\n  File \"C:\\Users\\%user%\\AppData\\Roaming\\Python\\Python311\\site-packages\\aider\\main.py\", line 447, in main\r\n    coder.commit(ask=True, which=\"repo_files\")\r\n  File \"C:\\Users\\%user%\\AppData\\Roaming\\Python\\Python311\\site-packages\\aider\\coders\\base_coder.py\", line 887, in commit\r\n    all_files = [os.path.join(self.root, f) for f in self.get_all_relative_files()]\r\n                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"C:\\Users\\%user%\\AppData\\Roaming\\Python\\Python311\\site-packages\\aider\\coders\\base_coder.py\", line 948, in get_all_relative_files\r\n    files = self.get_tracked_files()\r\n            ^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"C:\\Users\\%user%\\AppData\\Roaming\\Python\\Python311\\site-packages\\aider\\coders\\base_coder.py\", line 1008, in get_tracked_files\r\n    commit = self.repo.head.commit\r\n             ^^^^^^^^^^^^^^^^^^^^^\r\n  File \"C:\\Users\\%user%\\AppData\\Roaming\\Python\\Python311\\site-packages\\git\\refs\\symbolic.py\", line 226, in _get_commit\r\n    obj = self._get_object()\r\n          ^^^^^^^^^^^^^^^^^^\r\n  File \"C:\\Users\\%user%\\AppData\\Roaming\\Python\\Python311\\site-packages\\git\\refs\\symbolic.py\", line 219, in _get_object\r\n    return Object.new_from_sha(self.repo, hex_to_bin(self.dereference_recursive(self.repo, self.path)))\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"C:\\Users\\%user%\\AppData\\Roaming\\Python\\Python311\\site-packages\\git\\objects\\base.py\", line 94, in new_from_sha\r\n    oinfo = repo.odb.info(sha1)\r\n            ^^^^^^^^^^^^^^^^^^^\r\n  File \"C:\\Users\\%user%\\AppData\\Roaming\\Python\\Python311\\site-packages\\gitdb\\db\\base.py\", line 210, in info\r\n    return self._db_query(sha).info(sha)\r\n           ^^^^^^^^^^^^^^^^^^^\r\n  File \"C:\\Users\\%user%\\AppData\\Roaming\\Python\\Python311\\site-packages\\gitdb\\db\\base.py\", line 193, in _db_query\r\n    if db.has_object(sha):\r\n       ^^^^^^^^^^^^^^^^^^\r\n  File \"C:\\Users\\%user%\\AppData\\Roaming\\Python\\Python311\\site-packages\\gitdb\\db\\pack.py\", line 91, in has_object\r\n    self._pack_info(sha)\r\n  File \"C:\\Users\\%user%\\AppData\\Roaming\\Python\\Python311\\site-packages\\gitdb\\db\\pack.py\", line 74, in _pack_info\r\n    index = item[2](sha)\r\n            ^^^^^^^^^^^^\r\n  File \"C:\\Users\\%user%\\AppData\\Roaming\\Python\\Python311\\site-packages\\gitdb\\pack.py\", line 423, in sha_to_index\r\n    get_sha = self.sha\r\n              ^^^^^^^^\r\n  File \"C:\\Users\\%user%\\AppData\\Roaming\\Python\\Python311\\site-packages\\gitdb\\util.py\", line 253, in __getattr__\r\n    self._set_cache_(attr)\r\n  File \"C:\\Users\\%user%\\AppData\\Roaming\\Python\\Python311\\site-packages\\gitdb\\pack.py\", line 287, in _set_cache_\r\n    mmap = self._cursor.map()\r\n           ^^^^^^^^^^^^\r\n  File \"C:\\Users\\%user%\\AppData\\Roaming\\Python\\Python311\\site-packages\\gitdb\\util.py\", line 253, in __getattr__\r\n    self._set_cache_(attr)\r\n  File \"C:\\Users\\%user%\\AppData\\Roaming\\Python\\Python311\\site-packages\\gitdb\\pack.py\", line 276, in _set_cache_\r\n    self._cursor = mman.make_cursor(self._indexpath).use_region()\r\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"C:\\Python311\\Lib\\site-packages\\smmap\\mman.py\", line 116, in use_region\r\n    fsize = self._rlist.file_size()\r\n            ^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"C:\\Python311\\Lib\\site-packages\\smmap\\util.py\", line 215, in file_size\r\n    self._file_size = os.stat(self._path_or_fd).st_size\r\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^\r\nFileNotFoundError: [WinError 2] Das System kann die angegebene Datei nicht finden: 'project\\\\.git\\\\objects\\\\pack\\\\pack-0b8fe64b5a22d307157334f238115fbbd3c4266d.idx'\r\n```",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/167/comments",
    "author": "JKamsker",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2023-08-02T09:42:10Z",
        "body": "Thanks for trying aider!\r\n\r\nIt looks to me like you git repository is corrupted. It seems like the file 'project\\\\.git\\\\objects\\\\pack\\\\pack-0b8fe64b5a22d307157334f238115fbbd3c4266d.idx' is missing from your project directory.\r\n\r\nThis could be due to several reasons:\r\n\r\n1. The file was deleted accidentally.\r\n2. The file was never created due to some error during the git operation.\r\n3. The file is there but the path to the file is incorrect.\r\n\r\nHere are a few things you can try to fix this issue:\r\n\r\n1. Try running a `git fsck` command in your repository to check for any corruption or missing files.\r\n\r\n2. If nothing else works, you might need to clone the repository again."
      },
      {
        "user": "JKamsker",
        "created_at": "2023-08-09T14:18:10Z",
        "body": "Yea appearantly repulling helped, thank you!"
      }
    ]
  },
  {
    "number": 165,
    "title": "Force GPT-3.5 on GPT-4 rate limit error",
    "created_at": "2023-07-31T12:33:34Z",
    "closed_at": "2023-08-02T09:30:12Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/165",
    "body": "Can i somehow force aider to use GPT-3.5. I reached rate limit and would like to test with 3.5.",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/165/comments",
    "author": "nikolaidk",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2023-07-31T12:56:37Z",
        "body": "Thanks for trying aider!\n\nYes you can run it with `-3`. Also see `--help`. "
      },
      {
        "user": "paul-gauthier",
        "created_at": "2023-08-02T09:30:12Z",
        "body": "I'm going to close this issue for now, but feel free to re-open or file a new issue any time."
      }
    ]
  },
  {
    "number": 153,
    "title": "Is there a way to exclude the .env file from cTag?",
    "created_at": "2023-07-26T13:38:45Z",
    "closed_at": "2023-07-26T20:51:43Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/153",
    "body": "Hey, maybe this is already done, but I couldn't find anything related to that. What I actually want: I don't want the .env file being mapped and send to OpenAI.",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/153/comments",
    "author": "GitIgnoreMaybe",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2023-07-26T20:44:46Z",
        "body": "Thanks for trying aider and reporting this issue.\r\n\r\nIf the `.env` is checked into git, then it will be part of the ctags repo map. Did you intend to commit it to git?"
      },
      {
        "user": "GitIgnoreMaybe",
        "created_at": "2023-07-26T20:46:41Z",
        "body": "This actually answers the question already. So it respects the gitignore. Thanks for the clarification 🙏"
      }
    ]
  },
  {
    "number": 136,
    "title": "How to give aider permission to read-write...",
    "created_at": "2023-07-20T21:40:05Z",
    "closed_at": "2023-07-26T13:26:52Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/Aider-AI/aider/issues/136",
    "body": "Hello, I am trying to debug a feature, and gave aider instructions on how to. However, I got a response back as follows:\r\n\r\n```\r\nThe files you've mentioned are currently read-only. Could you please  \r\nmake the following files read-write so that I can propose the necessary        \r\nchanges. Once you've made these files read-write, I can provide the necessary steps to  \r\nimplement the feature \r\n```\r\nI guess what I was asking is if there's any special way of doing it with aider. If not I can just `chmod +rw` like I would any other file\r\n\r\n\r\nPlease advice?\r\nThanks in advance",
    "comments_url": "https://api.github.com/repos/Aider-AI/aider/issues/136/comments",
    "author": "PtradeLLC",
    "comments": [
      {
        "user": "paul-gauthier",
        "created_at": "2023-07-21T12:46:16Z",
        "body": "Thanks for trying aider, and for filing this issue.\n\nWhen GPT is asking for a file to be marked read-write, it's trying to get you to add it to the chat session. It's only allowed to modify files that have been added to the session. You can do that with the `/add` command."
      },
      {
        "user": "paul-gauthier",
        "created_at": "2023-07-26T13:26:48Z",
        "body": "The next release of aider asks GPT to use less confusing language when it wants you to add a file to the chat. \n\nI'm going to close this issue for now, but feel free to reopen it or file another issue if there's more you would like to discuss."
      }
    ]
  }
]