[
  {
    "number": 7464,
    "title": "Texture load in @ti.func",
    "created_at": "2023-03-01T00:42:23Z",
    "closed_at": "2023-03-09T18:13:59Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/taichi-dev/taichi/issues/7464",
    "body": "Hi,\r\nI have a question related with texture load in Taichi.\r\nIn example `python/taichi/examples/rendering/simple_texture.py`, the texture object is declared out of taichi scope, and passed as `ti.types.texture` type to @ti.kernel function. It seemed that the texture will be converted to `taichi.lang._texture.TextureSampler` object type. \r\nMy question is that how can use texture method like `sample_lod` or `fetch` in @ti.func?\r\n",
    "comments_url": "https://api.github.com/repos/taichi-dev/taichi/issues/7464/comments",
    "author": "afiretony",
    "comments": [
      {
        "user": "bobcao3",
        "created_at": "2023-03-01T01:12:30Z",
        "body": "You need to pass the texture in `@ti.template` (pass-by-reference)"
      },
      {
        "user": "afiretony",
        "created_at": "2023-03-01T01:26:05Z",
        "body": "Hi @bobcao3 , thanks for answering!\r\nCould you elaborate what do you meant to pass in `ti.template`?\r\nThis is what I tried to do but not works:\r\n\r\n```\r\ntexture = ti.Texture(ti.Format.r32f, (n, n, n))\r\n\r\n@ti.kernel\r\ndef paint(t: ti.f32, n: ti.i32):\r\n    for i, j in pixels:\r\n        uv = ti.Vector([i / res[0], j / res[1], t])\r\n        c = ti.math.vec4(0.0)\r\n        c = sample_tex(texture, uv)\r\n        pixels[i, j] = [c.r, c.r, c.r]\r\n\r\n@ti.func\r\ndef sample_tex(tex:ti.template(), uv):\r\n    tex.sample_lod(uv, 0.0)\r\n```\r\n\r\nAttributeError: 'Texture' object has no attribute 'sample_lod'"
      },
      {
        "user": "bobcao3",
        "created_at": "2023-03-01T01:52:59Z",
        "body": "You would also need to pass the texture into the kernel. Taichi textures can not be captured through global varaibles"
      },
      {
        "user": "afiretony",
        "created_at": "2023-03-01T02:26:10Z",
        "body": "Hey @bobcao3 thanks, do you mean\r\n```\r\n@ti.kernel\r\ndef paint(t: ti.f32, tex: ti.types.texture(num_dimensions=3), n: ti.i32):\r\n    for i, j in pixels:\r\n        uv = ti.Vector([i / res[0], j / res[1], t])\r\n        c = ti.math.vec4(0.0)\r\n        c = sample_tex(tex, uv)\r\n        pixels[i, j] = [c.r, c.r, c.r]\r\n\r\n@ti.func\r\ndef sample_tex(tex:ti.template(), uv):\r\n    tex.sample_lod(uv, 0.0)\r\n```\r\nBut still gets error:\r\n\r\nTraceback (most recent call last):\r\n  File \"playground.py\", line 93, in <module>\r\n    main()\r\n  File \"playground.py\", line 86, in main\r\n    paint(t,texture, n)\r\n  File \"C:\\Users\\\\Anaconda3\\envs\\taichi\\lib\\site-packages\\taichi\\lang\\kernel_impl.py\", line 974, in wrapped\r\n    return primal(*args, **kwargs)\r\n  File \"C:\\Users\\\\Anaconda3\\envs\\taichi\\lib\\site-packages\\taichi\\lang\\kernel_impl.py\", line 901, in __call__\r\n    return self.runtime.compiled_functions[key](*args)\r\n  File \"C:\\Users\\\\Anaconda3\\envs\\taichi\\lib\\site-packages\\taichi\\lang\\kernel_impl.py\", line 826, in func__\r\n    raise e from None\r\n  File \"C:\\Users\\\\Anaconda3\\envs\\taichi\\lib\\site-packages\\taichi\\lang\\kernel_impl.py\", line 823, in func__\r\n    t_kernel(launch_ctx)\r\nRuntimeError: [type_factory.cpp:taichi::lang::promoted_type@222] Assertion failure: a->is<TensorType>() && b->is<TensorType>()\r\n"
      },
      {
        "user": "ailzhang",
        "created_at": "2023-03-09T08:23:47Z",
        "body": "@afiretony sorry for the late reply, this is not a bug since your `ti.func` is missing a return but we didn't do well in error reporting lol. \r\n\r\nThis works for me: \r\n```\r\n@ti.func\r\ndef sample_tex(tex: ti.template(), uv):\r\n    return tex.sample_lod(uv, 0.0)\r\n\r\n@ti.kernel\r\ndef paint(t: ti.f32, pixels: ti.types.ndarray(ndim=2),\r\n          tex: ti.types.texture(num_dimensions=2)):\r\n    for i, j in pixels:\r\n        uv = ti.Vector([i / res[0], j / res[1]])\r\n        warp_uv = uv + ti.Vector(\r\n            [ti.cos(t + uv.x * 5.0),\r\n             ti.sin(t + uv.y * 5.0)]) * 0.1\r\n        c = ti.math.vec4(0.0)\r\n        if uv.x > 0.5:\r\n            # c = tex.sample_lod(warp_uv, 0.0)\r\n            c = sample_tex(tex, warp_uv)\r\n        else:\r\n            c = tex.fetch(ti.cast(warp_uv * 128, ti.i32), 0)\r\n        pixels[i, j] = [c.r, c.r, c.r, 1.0]\r\n```\r\nLet us know if you have followup questions! We'll try to improve the error message here. \r\n"
      }
    ]
  },
  {
    "number": 7255,
    "title": "dataclass in the for loop not showing the right value",
    "created_at": "2023-01-30T04:54:49Z",
    "closed_at": "2023-02-03T02:26:21Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/taichi-dev/taichi/issues/7255",
    "body": "Hi all,\r\n\r\nThis might be a silly question but I think I don't understand the multiple for-loops here.\r\n\r\nThe data class called inside the third for loop is not showing the right value as I expect. I learned from the tutorial that the outermost loop will be parallelized, and others are the same with python. But that did not happen either.\r\n\r\nI am wondering why the inside value is not changing but keeps its initial value.\r\nThank you! The code is as follows:\r\n\r\n\r\n```python\r\nimport taichi as ti\r\n\r\nti.init()\r\nNp = 3\r\nNw = 2\r\nNt = 5\r\n\r\n@ti.dataclass\r\nclass Particle:\r\n    r: ti.types.vector(3, ti.f64)\r\n    t: ti.f64\r\n    @ti.func\r\n    def initParticles(self,x,y,z):\r\n        self.r = ti.Vector([x,y,z])\r\n        self.t = 0\r\n\r\n\r\n\r\nparticles = Particle.field(shape = (Np,))\r\n\r\ndr = 0.1\r\ndw = 0.3\r\n\r\n@ti.kernel\r\ndef init():\r\n    for n in range(Np):\r\n        particles[n].initParticles(0,0,dr * n)\r\n        \r\n@ti.kernel\r\ndef simulate():\r\n    for n in range(Np):\r\n        for t in range(Nt):\r\n            #rr = particles[n].r\r\n            print('time***',t )\r\n            print('r outside',particles[n].r)\r\n            for m in range(Nw):\r\n                print('r inside',particles[n].r) # why particles [n].r here showing particles' init value\r\n\r\n            particles[n].r +=ti.Vector([0,0,1])\r\n                \r\ninit()\r\nsimulate()\r\n```\r\n\r\n\r\nThe result is \r\n\r\n> [Taichi] Starting on arch=arm64\r\ntime*** 0\r\nr outside [0.000000000000, 0.000000000000, 0.000000000000]\r\nr inside [0.000000000000, 0.000000000000, 0.000000000000]\r\nr inside [0.000000000000, 0.000000000000, 0.000000000000]\r\ntime*** 1\r\nr outside [0.000000000000, 0.000000000000, 1.000000000000]\r\nr inside [0.000000000000, 0.000000000000, 0.000000000000]\r\nr inside [0.000000000000, 0.000000000000, 0.000000000000]\r\ntime*** 2\r\nr outside [0.000000000000, 0.000000000000, 2.000000000000]\r\nr inside [0.000000000000, 0.000000000000, 0.000000000000]\r\nr inside [0.000000000000, 0.000000000000, 0.000000000000]\r\ntime*** 3\r\nr outside [0.000000000000, 0.000000000000, 3.000000000000]\r\nr inside [0.000000000000, 0.000000000000, 0.000000000000]\r\nr inside [0.000000000000, 0.000000000000, 0.000000000000]\r\ntime*** 4\r\nr outside [0.000000000000, 0.000000000000, 4.000000000000]\r\nr inside [0.000000000000, 0.000000000000, 0.000000000000]\r\nr inside [0.000000000000, 0.000000000000, 0.000000000000]\r\ntime*** 0\r\nr outside [0.000000000000, 0.000000000000, 0.100000001490]\r\nr inside [0.000000000000, 0.000000000000, 0.100000001490]\r\nr inside [0.000000000000, 0.000000000000, 0.100000001490]\r\ntime*** 1\r\nr outside [0.000000000000, 0.000000000000, 1.100000001490]\r\nr inside [0.000000000000, 0.000000000000, 0.100000001490]\r\nr inside [0.000000000000, 0.000000000000, 0.100000001490]\r\ntime*** 2\r\nr outside [0.000000000000, 0.000000000000, 2.100000001490]\r\nr inside [0.000000000000, 0.000000000000, 0.100000001490]\r\nr inside [0.000000000000, 0.000000000000, 0.100000001490]\r\ntime*** 3\r\nr outside [0.000000000000, 0.000000000000, 3.100000001490]\r\nr inside [0.000000000000, 0.000000000000, 0.100000001490]\r\nr inside [0.000000000000, 0.000000000000, 0.100000001490]\r\ntime*** 4\r\nr outside [0.000000000000, 0.000000000000, 4.100000001490]\r\nr inside [0.000000000000, 0.000000000000, 0.100000001490]\r\nr inside [0.000000000000, 0.000000000000, 0.100000001490]\r\ntime*** 0\r\nr outside [0.000000000000, 0.000000000000, 0.200000002980]\r\nr inside [0.000000000000, 0.000000000000, 0.200000002980]\r\nr inside [0.000000000000, 0.000000000000, 0.200000002980]\r\ntime*** 1\r\nr outside [0.000000000000, 0.000000000000, 1.200000002980]\r\nr inside [0.000000000000, 0.000000000000, 0.200000002980]\r\nr inside [0.000000000000, 0.000000000000, 0.200000002980]\r\ntime*** 2\r\nr outside [0.000000000000, 0.000000000000, 2.200000002980]\r\nr inside [0.000000000000, 0.000000000000, 0.200000002980]\r\nr inside [0.000000000000, 0.000000000000, 0.200000002980]\r\ntime*** 3\r\nr outside [0.000000000000, 0.000000000000, 3.200000002980]\r\nr inside [0.000000000000, 0.000000000000, 0.200000002980]\r\nr inside [0.000000000000, 0.000000000000, 0.200000002980]\r\ntime*** 4\r\nr outside [0.000000000000, 0.000000000000, 4.200000002980]\r\nr inside [0.000000000000, 0.000000000000, 0.200000002980]\r\nr inside [0.000000000000, 0.000000000000, 0.200000002980]",
    "comments_url": "https://api.github.com/repos/taichi-dev/taichi/issues/7255/comments",
    "author": "donglai96",
    "comments": [
      {
        "user": "AmesingFlank",
        "created_at": "2023-01-30T17:40:20Z",
        "body": "This looks like a bug in TLS optimization. I wrote more about it here: #7263. For now, you can work around this issue by doing `advanced_optimization = False` in `ti.init()`"
      }
    ]
  },
  {
    "number": 7185,
    "title": "Performance implications of dynamic indexing",
    "created_at": "2023-01-17T02:19:33Z",
    "closed_at": "2023-01-17T03:05:03Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/taichi-dev/taichi/issues/7185",
    "body": "I have a rather large taichi program, which I wrote before `dynamic_indexing` is enabled by default, it contained a lot of loops unrolled using `for i in ti.static(range(..))`.  Now that  `dynamic_indexing` is the default, I decided to try rewriting my program to always use dynamic indices. I noticed that after dynamic indices are used, the performance of the program dropped by around 15%. I mostly use the CUDA backend.\r\n\r\nSo my questions are:\r\n* Is the performance drop expected?\r\n* Are there any general guidelines of when should loop-unrolling should be preferred over dynamic indexing in terms of performance? What are the rules of thumb?\r\n\r\n@strongoier \r\nThanks!",
    "comments_url": "https://api.github.com/repos/taichi-dev/taichi/issues/7185/comments",
    "author": "AmesingFlank",
    "comments": [
      {
        "user": "strongoier",
        "created_at": "2023-01-17T02:48:59Z",
        "body": "Thanks for your feedback on trying the feature!\r\n\r\n> Is the performance drop expected?\r\n\r\nYes. The reason is that for a local matrix, the internal representation goes from multiple scalars to an array.\r\n\r\n> Are there any general guidelines of when should loop-unrolling should be preferred over dynamic indexing in terms of performance? What are the rules of thumb?\r\n\r\nWe don't expect users to rewrite all their previous programs at this moment. For those matrices with only constant indices required, using loop-unrolling can optimize the array representation to scalars so as to achieve best performance. Of course, automatic loop-unrolling in certain cases can be an optimization opportunity in Taichi in the future.\r\n\r\nFor now, just as the release note says,\r\n\r\n> Before v1.4.0, when you wanted to access a vector/matrix with a runtime variable instead of a compile-time constant, you had to set ti.init(dynamic_index=True). However, that option only works for LLVM-based backends (CPU & CUDA) and may slow down runtime performance because all matrices are affected. Starting from v1.4.0, that option is no longer needed. You can use variable indices whenever necessary on all backends without affecting the performance of those matrices with only constant indices.\r\n\r\nFor previous users, the removal of the option is most beneficial for cases where the dynamic index feature is really needed (i.e., loop-unrolling cannot solve their problem). But for new users, this feature makes it easier to learn Taichi. Loop-unrolling is now only treated as an optimization strategy rather than a required concept to write normal programs."
      }
    ]
  },
  {
    "number": 5970,
    "title": "print has no output inside taichi kernel",
    "created_at": "2022-09-04T02:53:43Z",
    "closed_at": "2022-09-04T14:07:51Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/taichi-dev/taichi/issues/5970",
    "body": "The code:\r\n```python\r\nimport taichi as ti\r\n\r\nti.init(arch=ti.cpu, debug=True)\r\n\r\nx = ti.field(ti.f32)\r\nblock = ti.root.pointer(ti.ij, (4,4))\r\npixel = block.bitmasked(ti.ij, (2,2))\r\npixel.place(x)\r\n\r\n@ti.kernel\r\ndef activate():\r\n    x[2,3] = 1.0\r\n    x[2,4] = 2.0\r\n\r\n@ti.kernel\r\ndef print_active():\r\n    for i, j in block:\r\n        print(\"Active block\", i, j)\r\n    for i, j in x:\r\n        print('field x[{}, {}] = {}'.format(i, j, x[i, j]))\r\n\r\nif __name__ == '__main__':\r\n    print_active()\r\n```\r\n\r\noutput:\r\n```\r\n[Taichi] version 1.1.2, llvm 10.0.0, commit f25cf4a2, linux, python 3.7.4\r\n[Taichi] Starting on arch=x64\r\n```\r\n\r\nThe `print` in taichi kernel has no output.\r\n",
    "comments_url": "https://api.github.com/repos/taichi-dev/taichi/issues/5970/comments",
    "author": "hiyyg",
    "comments": [
      {
        "user": "yuanming-hu",
        "created_at": "2022-09-04T12:32:33Z",
        "body": "I believe you forgot to call `activate()` before `print_active()`. The following code would work as expected:\r\n\r\n```python\r\nimport taichi as ti\r\n\r\nti.init(arch=ti.cpu, debug=True)\r\n\r\nx = ti.field(ti.f32)\r\nblock = ti.root.pointer(ti.ij, (4,4))\r\npixel = block.bitmasked(ti.ij, (2,2))\r\npixel.place(x)\r\n\r\n@ti.kernel\r\ndef activate():\r\n    x[2,3] = 1.0\r\n    x[2,4] = 2.0\r\n\r\n@ti.kernel\r\ndef print_active():\r\n    for i, j in block:\r\n        print(\"Active block\", i, j)\r\n    for i, j in x:\r\n        print('field x[{}, {}] = {}'.format(i, j, x[i, j]))\r\n\r\nif __name__ == '__main__':\r\n    activate()\r\n    print_active()\r\n```"
      }
    ]
  },
  {
    "number": 4934,
    "title": "unexpected behavior with Hilles-Steele scan ",
    "created_at": "2022-05-09T03:13:59Z",
    "closed_at": "2022-05-15T16:15:14Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/taichi-dev/taichi/issues/4934",
    "body": "I'm not sure if this is a bug of some kind, or just user error/misunderstanding of how Taichi is supposed to work, but I was surprised by the behavior in the code example below.\r\n\r\nThis snippet implements a simple Hilles-Steele scan and uses it to attempt get the cumulative sum of a 100000 element field filled with 1s.\r\n\r\nThe output is fine up until the 30720th entry in the array, after which the entries are incorrect, and non-derministic. For example, the last element of the output array should of course be 100000, but I've been seeing values from 210000 to 290000 ish.\r\n\r\nThe number 30720 looked suspicious to me, and indeed it's 16*1920, the latter of which is the number of CUDA cores available in my Nvidia RTX 2060.\r\n\r\nI don't really know what is going wrong -- my best guess is that it seems to be some kind of race situation, in particular because of the appearance of that magic number 30720... maybe the hardware is saturated, and <something something> data race? But I'm not really sure why there would be a race condition -- I've certainly run parallel `for` loops over fields with many more elements than this without any issues.\r\n\r\nThis scan implementation is inspired by the `parallel_sort` function in `python/taichi/_kernels.py`, and I have noticed that that function includes a `sync()` call. I've tried putting `sync()` in a many different places with no change in the values I'm seeing, but I wonder if I need to use `sync()` somehow, or some other low-level runtime method like that?\r\n\r\nFinally, in case it might be helpful for writing docs that guide other users away from whatever I am misunderstanding, I'll add a bit of background about why I found this behavior surprising (and, I guess relatedly, why I was surprised that a `sync()` function even exists, and was surprised it would be needed in `parallel_sort`): In my mental model of Taichi, and based on the examples I've looked at, I have been assuming that from the perspective of the python code calling the kernels, kernel invocations are inherently serial and synchronous. That is: if you have python code like...\r\n```python\r\nti_kernel_1()\r\nti_kernel_2()\r\nti_kernel_3()\r\n```\r\n...then all of the GPU work associated with `ti_kernel_1` will finish before any of `ti_kernel_2`'s work starts, and all of `ti_kernel_2`'s work will finish before ti_kernel_3` starts, and it should not be possible to have data races between these kernels. The existence of the `sync()` function seem like a hint to me my mental model is not correct, because it seems like it would not be needed if all kernel invocations were serial and synchronous.\r\n\r\nSo I guess perhaps this is an area of the docs that might benefit from some clarification:\r\n- when are kernels launched async/parallel vs sync/serial? and how is this controlled?\r\n- when can kernel invocations result in race conditions between subsequent invocations? how can these race conditions be prevented?\r\n- what does the `sync()` function do, and when is it needed?\r\n\r\nThanks as always for the great work on Taichi! I'm always learning something fun when I work with it :-) (And I'm sure I will learn a lot from whatever I'm misunderstanding in this example!)\r\n\r\n### My non-working scan code\r\n\r\n```python\r\nimport taichi as ti\r\nimport numpy as np\r\n\r\nti.init(arch=ti.gpu)\r\n\r\n@ti.kernel\r\ndef fill_int(field: ti.template(), x: int):\r\n    for i in field:\r\n        field[i] = x\r\n\r\n\r\ndef prepare_HS_scan(in_field, out_field, ti_func):\r\n    @ti.kernel\r\n    def scan_stage(last: ti.template(), step: int):\r\n        for i in last:\r\n            out_field[i] = last[i] if i < step else ti_func(last[i - step], last[i])\r\n\r\n    def scan():\r\n        step = 1\r\n        while step < N:\r\n            last = in_field if step == 1 else out_field\r\n            scan_stage(last, step)\r\n            step = step * 2\r\n\r\n    return scan\r\n\r\n\r\n@ti.func\r\ndef ti_sum(a, b):\r\n    return a + b\r\n\r\n\r\nN = int(100000)\r\nfield_in = ti.field(ti.int32, shape=N)\r\nfill_int(field_in, 1)\r\n\r\nfield_out = ti.field(ti.int32, shape=N)\r\n\r\nscan1 = prepare_HS_scan(in_field=field_in, out_field=field_out, ti_func=ti_sum)\r\n\r\nscan1()\r\n\r\nfield_out_np = field_out.to_numpy()\r\n\r\n# last value in the array\r\n# should be 100000, non-deterministic output from 220000 to 280000 ish\r\nprint(field_out[N - 1])\r\n\r\n# first element of the arrays that doesn't match\r\n# always 30720 on my machine, which is 1920*16 -- RTX2060 has 1920 cuda cores\r\nprint(np.argmin(np.equal(field_out_np, np.arange(1, N + 1))))\r\n```\r\n\r\nExample output from the above (including version and system info)\r\n```\r\n[Taichi] version 1.0.1, llvm 10.0.0, commit 1c3619d9, linux, python 3.9.7\r\n[Taichi] Starting on arch=cuda\r\n290112\r\n30720\r\n```",
    "comments_url": "https://api.github.com/repos/taichi-dev/taichi/issues/4934/comments",
    "author": "bcolloran",
    "comments": [
      {
        "user": "bobcao3",
        "created_at": "2022-05-09T03:34:08Z",
        "body": "That sync is for dealing with a previous bug in Vulkan. Speaking of Vulkan, can you try this on Vulkan as well so that we can narrow down the problem a bit. (If Vulkan also shows a wrong number we might have a CHI-IR level problem, if not then we have a CUDA runtime / codegen problem) Thanks!"
      },
      {
        "user": "bcolloran",
        "created_at": "2022-05-09T04:20:41Z",
        "body": "Thanks for the fast reply @bobcao3!\r\n\r\nIndeed, I get similar behavior with `ti.init(arch=ti.vulkan)`. Example output:\r\n```\r\n[Taichi] version 1.0.1, llvm 10.0.0, commit 1c3619d9, linux, python 3.9.7\r\n[Taichi] Starting on arch=vulkan\r\n[I 05/08/22 21:11:43.047 140724] [vulkan_device_creator.cpp:pick_physical_device@363] Found Vulkan Device 0 (NVIDIA GeForce RTX 2060)\r\n[I 05/08/22 21:11:43.047 140724] [vulkan_device_creator.cpp:pick_physical_device@363] Found Vulkan Device 1 (llvmpipe (LLVM 12.0.0, 256 bits))\r\n[I 05/08/22 21:11:43.048 140724] [vulkan_device_creator.cpp:create_logical_device@431] Vulkan Device \"NVIDIA GeForce RTX 2060\" supports Vulkan 0 version 1.2.175\r\n305088\r\n30720\r\n```\r\n\r\nJust to see what would happen, I also decided to try it out with `ti.cpu`... in this case I got very different (incorrect) results. In case it will be helpful, here are some example outputs:\r\n```\r\n$ python scan_error.py \r\n[Taichi] version 1.0.1, llvm 10.0.0, commit 1c3619d9, linux, python 3.9.7\r\n[Taichi] Starting on arch=x64\r\n41257076\r\n4\r\n\r\n\r\n$ python scan_error.py \r\n[Taichi] version 1.0.1, llvm 10.0.0, commit 1c3619d9, linux, python 3.9.7\r\n[Taichi] Starting on arch=x64\r\n-1087188976\r\n4\r\n\r\n\r\n$ python scan_error.py \r\n[Taichi] version 1.0.1, llvm 10.0.0, commit 1c3619d9, linux, python 3.9.7\r\n[Taichi] Starting on arch=x64\r\n919975044\r\n4\r\n\r\n\r\n$ python scan_error.py \r\n[Taichi] version 1.0.1, llvm 10.0.0, commit 1c3619d9, linux, python 3.9.7\r\n[Taichi] Starting on arch=x64\r\n-1183775544\r\n4\r\n\r\n\r\n$ python scan_error.py \r\n[Taichi] version 1.0.1, llvm 10.0.0, commit 1c3619d9, linux, python 3.9.7\r\n[Taichi] Starting on arch=x64\r\n-14705324\r\n4\r\n```\r\n(that is with AMD Ryzen 5 2600 Six-Core Processor)\r\n\r\nPlease let me know if I can supply any more information! :-)\r\n"
      },
      {
        "user": "bobcao3",
        "created_at": "2022-05-14T16:27:23Z",
        "body": "Just checked your code, it seems out_field might be used as both input and output in some cases? That might be why this produces non deterministic outputs "
      }
    ]
  },
  {
    "number": 4854,
    "title": "IndexError: Field with dim 2 accessed with indices of dim 1",
    "created_at": "2022-04-24T13:23:57Z",
    "closed_at": "2022-04-25T05:18:33Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/taichi-dev/taichi/issues/4854",
    "body": "I started learning Taichi and wrote the following code:\r\n```\r\nimport taichi as ti\r\nimport numpy\r\nti.init(arch=ti.opengl)\r\n\r\n\r\ndic = numpy.array([[10,9,8,7], [10,9,8,2]])\r\n@ti.kernel\r\ndef func(dic:ti.types.ndarray()):\r\n\tdic[0][0]=11\r\n\t\r\nfunc(dic)\r\nprint(dic)\r\n```\r\n\r\nAnd get error:\r\n`IndexError: Field with dim 2 accessed with indices of dim 1`\r\n\r\nWhy it not works? ",
    "comments_url": "https://api.github.com/repos/taichi-dev/taichi/issues/4854/comments",
    "author": "compik710",
    "comments": [
      {
        "user": "bobcao3",
        "created_at": "2022-04-24T23:27:21Z",
        "body": "use ```dic[0, 0]```"
      }
    ]
  },
  {
    "number": 4385,
    "title": "How to import pictures",
    "created_at": "2022-02-25T03:26:25Z",
    "closed_at": "2022-02-25T09:27:54Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/taichi-dev/taichi/issues/4385",
    "body": "A = ti.field.from_numpy(ti.imread('296363.jpg'))\r\n\r\nreport\uff1a\r\nAttributeError: 'function' object has no attribute 'from_numpy'",
    "comments_url": "https://api.github.com/repos/taichi-dev/taichi/issues/4385/comments",
    "author": "chuiliuyiyi",
    "comments": [
      {
        "user": "bobcao3",
        "created_at": "2022-02-25T05:57:28Z",
        "body": "The `from_numpy` function only works on fields. You should declare a field first and then load the image:\r\n\r\n```python\r\nA = ti.Vector.field(n=3, dtype=ti.f32, shape=(width, height))\r\nA.from_numpy(ti.imread('296363.jpg'))\r\n```\r\n\r\nThe other option is to use `ti.ext_arr` and directly use the numpy array as input field to kernel. (This will be slower if you need to use the image multiple times)"
      }
    ]
  }
]