[
  {
    "number": 5071,
    "title": "[Question]: \u6570\u636e\u96c6\u5728embedding \u89e3\u6790\u7684\u8fc7\u7a0b\u4e2d\uff0c\u4e3a\u4ec0\u4e48\u53ea\u8c03\u7528\u4e86CPU\uff0c\u6ca1\u6709\u8c03\u7528GPU\u8d44\u6e90",
    "created_at": "2025-02-18T06:16:44Z",
    "closed_at": "2025-02-18T15:33:11Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/infiniflow/ragflow/issues/5071",
    "body": "### Describe your problem\n\n\u6570\u636e\u96c6\u5728embedding \u89e3\u6790\u7684\u8fc7\u7a0b\u4e2d\uff0c\u4e3a\u4ec0\u4e48\u53ea\u8c03\u7528\u4e86CPU\uff0c\u6ca1\u6709\u8c03\u7528GPU\u8d44\u6e90\n",
    "comments_url": "https://api.github.com/repos/infiniflow/ragflow/issues/5071/comments",
    "author": "brookejiang",
    "comments": [
      {
        "user": "tristanwqy",
        "created_at": "2025-02-18T06:52:42Z",
        "body": "docker compose \u7528\u5e26 gpu \u540e\u7f00\u7684 yaml \u542f\u52a8"
      },
      {
        "user": "JinHai-CN",
        "created_at": "2025-02-18T15:33:08Z",
        "body": "Yes, you may check docker/docker-compose-gpu.yml.\n\nPS: We intend to create an international community, so we encourage using English for communication.\n"
      }
    ]
  },
  {
    "number": 3317,
    "title": "[Question]: How to use GPU to run OCR model",
    "created_at": "2024-11-10T03:52:22Z",
    "closed_at": "2024-11-11T04:39:50Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/infiniflow/ragflow/issues/3317",
    "body": "### Describe your problem\n\n\u5982\u9898\uff0c\u8bf7\u6559",
    "comments_url": "https://api.github.com/repos/infiniflow/ragflow/issues/3317/comments",
    "author": "fg2501",
    "comments": [
      {
        "user": "KevinHuSh",
        "created_at": "2024-11-11T02:10:49Z",
        "body": "OCR dose not support GPU. It uses onnx for inference."
      },
      {
        "user": "fg2501",
        "created_at": "2024-11-11T02:40:33Z",
        "body": "> OCR dose not support GPU. It uses onnx for inference.\r\n\r\n\u6211\u542c\u8bf4\u6709\u4eba\u5148\u5378\u8f7d\u4e86onnx\uff0c\u7136\u540e\u518d\u5b89\u88c5\u4e86onnx\u7684GPU\u7248\u672c\uff0c\u901a\u8fc7\u8fd9\u6837\uff0c\u5b9e\u73b0gpu\u8fd0\u884c\uff0c\u4f46\u662f\u6211\u4e0d\u77e5\u9053\u5177\u4f53\u662f\u600e\u4e48\u505a\u5230\u7684\uff0c\u6240\u4ee5\u6211\u6765\u8fd9\u91cc\u8be2\u95ee\u3002"
      },
      {
        "user": "KevinHuSh",
        "created_at": "2024-11-11T04:00:23Z",
        "body": "GPU onnx is not stable and dose not accelerate it by my experiments."
      }
    ]
  },
  {
    "number": 3148,
    "title": "[Question]: How to obtain detailed backend logs\uff1f",
    "created_at": "2024-11-01T07:52:23Z",
    "closed_at": "2024-11-04T02:27:23Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/infiniflow/ragflow/issues/3148",
    "body": "### Describe your problem\n\n# I have started ragflow from the source code\r\n- `docker logs -f ragflow-server` cannot meet the logging requirements. I need to obtain logs of front-end operations on the webpage, including logs from conversations and more details on file parsing. I hope to distinguish between the details of the conversation and the file. I use `Olama` as an API service provider\r\n- I used xinference as rerank provider. I saw the effect of rerank in the `test retrieval` of the knowledge base. Does this part also have background logs?\r\n- I hope that in the question, there is a more detailed check method for the situation that the documents cannot be retrieved, such as viewing the slice of the hits\r\n- Is there a more detailed document for viewing logs?",
    "comments_url": "https://api.github.com/repos/infiniflow/ragflow/issues/3148/comments",
    "author": "SiDaiJie",
    "comments": [
      {
        "user": "yuzhichang",
        "created_at": "2024-11-02T03:43:55Z",
        "body": "There are multiple log files under `docker/ragflow-logs`, each for a dedicated internal package.\r\nWe'll merge all into one log file in future, maybe v0.15.\r\n"
      },
      {
        "user": "KevinHuSh",
        "created_at": "2024-11-04T01:32:04Z",
        "body": "All the logs are in ragflow/logs."
      }
    ]
  },
  {
    "number": 3095,
    "title": "[Question]: Chat assistant not retrieving any chunks",
    "created_at": "2024-10-29T14:38:01Z",
    "closed_at": "2024-10-30T13:10:58Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/infiniflow/ragflow/issues/3095",
    "body": "### Describe your problem\r\n\r\nI have added a document to a new KB and chucked it using the 'General' method. When I do retrieval testing on the KB, it retrieves the correct chucks. I have also created a chat assistant on my knowledge base, when I ask the same question as I did during retrieval testing it returns no results. I have tried all different types of configuration on the assistant but it doesn't seem to work. Is there any way I can see what the query the assistant is sending?",
    "comments_url": "https://api.github.com/repos/infiniflow/ragflow/issues/3095/comments",
    "author": "rplescia",
    "comments": [
      {
        "user": "KevinHuSh",
        "created_at": "2024-10-30T01:58:42Z",
        "body": "I think it's the thing about LLM lack of capability to under stand the relevance between your question and the retrievals.\r\nThere's a lamp up on the assistant output. You could click it to see the prompt send to LLM."
      }
    ]
  },
  {
    "number": 2612,
    "title": "[Question]:  When I chat with Agent, error: LookupError('Model(deepseek-chat) not authorized')",
    "created_at": "2024-09-26T12:29:40Z",
    "closed_at": "2024-09-26T13:32:30Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/infiniflow/ragflow/issues/2612",
    "body": "### Describe your problem\n\nfactory: 'Tongyi-Qianwen' \u8bbe\u7f6e\u901a\u4e49\u5343\u95ee\uff0c\u4f46\u662fagent\u95ee\u7b54\u7684\u65f6\u5019\u62a5\u9519\u8bf4LookupError('Model(deepseek-chat) not authorized')",
    "comments_url": "https://api.github.com/repos/infiniflow/ragflow/issues/2612/comments",
    "author": "LillyChen",
    "comments": [
      {
        "user": "JinHai-CN",
        "created_at": "2024-09-26T13:06:24Z",
        "body": "From the error message, it seems 'deepseek-chat' is used in your agent. You may change the LLM of your agent to 'Qianwen'.\r\n"
      }
    ]
  },
  {
    "number": 1563,
    "title": "[Question]: Why is the token count fixed at 128 when using the Ollama embedding model, instead of being based on the text content?",
    "created_at": "2024-07-17T05:53:35Z",
    "closed_at": "2024-07-18T03:54:09Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/infiniflow/ragflow/issues/1563",
    "body": "### Describe your problem\n\nWhy is the token count fixed at 128 when using the Ollama embedding model, instead of being based on the text content?",
    "comments_url": "https://api.github.com/repos/infiniflow/ragflow/issues/1563/comments",
    "author": "hwzhuhao",
    "comments": [
      {
        "user": "KevinHuSh",
        "created_at": "2024-07-18T03:46:11Z",
        "body": "It's just a mockup data since ollama doesn't return the count."
      }
    ]
  },
  {
    "number": 1189,
    "title": "dependency conflict[Question]: ",
    "created_at": "2024-06-17T09:37:59Z",
    "closed_at": "2024-09-28T10:01:54Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/infiniflow/ragflow/issues/1189",
    "body": "### Describe your problem\n\nWhen I run the `pip install -r requirements.txt` command I get an error\uff1a\r\n```bash\r\nERROR: Cannot install -r requirements.txt (line 139), -r requirements.txt (line 77) and pytz==2024.1 because these package versions have conflicting dependencies.\r\n\r\nThe conflict is caused by:\r\n    The user requested pytz==2024.1\r\n    pandas 2.2.1 depends on pytz>=2020.1\r\n    volcengine 1.0.141 depends on pytz==2020.5\r\n\r\nTo fix this you could try to:\r\n1. loosen the range of package versions you've specified\r\n2. remove package versions to allow pip attempt to solve the dependency conflict\r\n``` ",
    "comments_url": "https://api.github.com/repos/infiniflow/ragflow/issues/1189/comments",
    "author": "Old-Lane",
    "comments": [
      {
        "user": "aopstudio",
        "created_at": "2024-06-17T10:05:17Z",
        "body": "You can delete `pytz==2024.1` in requirements.txt. It will be automatically installed by other dependencies."
      },
      {
        "user": "TeslaZY",
        "created_at": "2024-06-24T04:21:31Z",
        "body": "\u6700\u65b0\u7684main\u5206\u652f\uff0c\u5b89\u88c5\u4f9d\u8d56\u62a5\u9519\u3002\r\nINFO: pip is looking at multiple versions of volcengine to determine which version is compatible with other requirements. This could take a while.\r\nERROR: Cannot install -r requirements.txt (line 138), -r requirements.txt (line 52) and pycryptodome==3.20.0 because these package versions have conflicting dependencies.\r\n\r\nThe conflict is caused by:\r\n    The user requested pycryptodome==3.20.0\r\n    minio 7.2.4 depends on pycryptodome\r\n    volcengine 1.0.141 depends on pycryptodome==3.9.9\r\n\u9700\u8981\u4fee\u6539volcengine\u7684\u4f9d\u8d56\u7248\u672c\u8fd8\u662f\u4fee\u6539pycryptodome\u7684\u7248\u672c\u3002\r\n\r\n\r\n\r\n\r\n> We have refined the requirements.txt. What about the latest one?\r\n\r\n"
      },
      {
        "user": "yuzhichang",
        "created_at": "2024-09-28T10:01:54Z",
        "body": "We've replaced pip with poetry."
      }
    ]
  },
  {
    "number": 1012,
    "title": "[Question]: How to improve the parallelism of file parsing?",
    "created_at": "2024-05-31T08:12:12Z",
    "closed_at": "2024-06-03T02:13:39Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/infiniflow/ragflow/issues/1012",
    "body": "### Describe your problem\n\nI found that when I am processing multiple files at the same time, the parsing block is serial. \r\nAfter checking the server.py file, I found that the number of workers is only 1, and the parameters are not exposed in the configuration file.\r\n Is there any other way to improve the efficiency of parsing documents besides improving workers",
    "comments_url": "https://api.github.com/repos/infiniflow/ragflow/issues/1012/comments",
    "author": "liweiyang2023",
    "comments": [
      {
        "user": "CamusGao",
        "created_at": "2024-06-02T09:08:36Z",
        "body": "just see entrypoint.sh in docker folder and there is a variable WS. You could pass this variable to docker by using -e or writing into docker-compose.yml if you're using docker."
      }
    ]
  },
  {
    "number": 448,
    "title": "[Question]: How to start RagFlow manually ?",
    "created_at": "2024-04-19T05:25:13Z",
    "closed_at": "2024-04-19T08:10:50Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/infiniflow/ragflow/issues/448",
    "body": "### Describe your problem\n\nHow to prevent RagFlow from auto startng, and instead start it manually when needed? My system is Ubuntu.",
    "comments_url": "https://api.github.com/repos/infiniflow/ragflow/issues/448/comments",
    "author": "Kryto614",
    "comments": [
      {
        "user": "Alphayellowcat",
        "created_at": "2024-04-19T07:09:58Z",
        "body": "@Kryto614 \r\nTo set up your Docker project so that containers only start when manually triggered rather than automatically on Docker start, you need to adjust the service settings in your `docker-compose.yml` file. Typically, containers start automatically if they are configured to do so, especially when the `restart` policy is set to `always`.\r\n\r\nHere's what you can do:\r\n\r\n1. **Modify the Restart Policy**: Locate the `restart` policy in your `docker-compose.yml` for the service you want to control. Change it from `always` to `no`:\r\n\r\n```\r\n    services:\r\n      ragflow:\r\n        restart: no\r\n\r\n```\r\n    This change ensures that the service won't automatically start when Docker starts.\r\n\r\n2. **Starting Containers Manually**: After making the above change, you will need to manually start your containers whenever you need them by using the Docker Compose command:\r\n\r\n    ```bash\r\n    docker compose up\r\n    ```"
      }
    ]
  }
]