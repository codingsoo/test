[
  {
    "number": 1919,
    "title": "Add time frames",
    "created_at": "2024-03-04T13:30:38Z",
    "closed_at": "2024-03-10T14:01:53Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/ggerganov/whisper.cpp/issues/1919",
    "body": "Tell me, in the example it is indicated\r\n./main -m models/ggml-large-v1.bin -l ru --no-timestamps -f ~/output.wav -of output -otxt\r\nThis is to remove the time frames, but how can we make sure they still exist? If I delete --no-timestamps, then they are still not there? How can I make them exist?",
    "comments_url": "https://api.github.com/repos/ggerganov/whisper.cpp/issues/1919/comments",
    "author": "DittmerOk",
    "comments": [
      {
        "user": "bobqianic",
        "created_at": "2024-03-05T16:04:24Z",
        "body": "In the function located in main.cpp, you'll notice that when we direct the output to a text file, we only include the textual content, excluding any special tokens. If you wish to include special tokens in the text file output, please make use of the additional option `--print-special`"
      }
    ]
  },
  {
    "number": 1531,
    "title": "Why does whisper.cpp not support Chinese recognition",
    "created_at": "2023-11-21T00:44:06Z",
    "closed_at": "2023-11-26T03:43:59Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/ggerganov/whisper.cpp/issues/1531",
    "body": "Whisper supports Chinese recognition. Whisper is an advanced speech recognition system developed by OpenAI, capable of recognizing and transcribing multiple languages, including Chinese. This means Whisper can recognize Chinese speech and convert it into Chinese text. Thanks to its advanced deep learning model, Whisper excels in handling a variety of languages and dialects. Why does whisper.cpp not support Chinese recognition?",
    "comments_url": "https://api.github.com/repos/ggerganov/whisper.cpp/issues/1531/comments",
    "author": "litongjava",
    "comments": [
      {
        "user": "flameddd",
        "created_at": "2023-11-21T05:58:46Z",
        "body": "what's your issue ? you can indicate language with `-l` flag\r\n\r\n```\r\n -l zh\r\n```"
      },
      {
        "user": "litongjava",
        "created_at": "2023-11-21T06:04:04Z",
        "body": "I tested it, it supports Chinese recognition, but the result is very bad.But Whipser recognizes it better than that.Why?"
      },
      {
        "user": "bobqianic",
        "created_at": "2023-11-21T10:05:34Z",
        "body": "> I tested it, it supports Chinese recognition, but the result is very bad.But Whipser recognizes it better than that.Why?\r\n\r\nCan you check if beam search is enabled? Please make sure that the `-bs` parameter is set to `5`."
      },
      {
        "user": "yexiangyu",
        "created_at": "2023-11-26T01:51:31Z",
        "body": "> I tested it, it supports Chinese recognition, but the result is very bad.But Whipser recognizes it better than that.Why?\r\n\r\n- please consider to use prompt like, `--prompt \"\u8bf7\u7528\u7b80\u4f53\u4e2d\u6587\u8f93\u51fa\"`\r\n- use `-l zh`\r\n- use larger model if tiny is used."
      },
      {
        "user": "sheng-di",
        "created_at": "2023-12-16T03:53:14Z",
        "body": "How to enable multiple language output?"
      }
    ]
  },
  {
    "number": 1465,
    "title": "talk-llama: say command not found",
    "created_at": "2023-11-09T11:21:18Z",
    "closed_at": "2023-11-12T20:47:22Z",
    "labels": [
      "question",
      "solution"
    ],
    "url": "https://github.com/ggerganov/whisper.cpp/issues/1465",
    "body": "Thanks for this work, highly appreciated. I'm getting quite good results on an orangepi5, using wizardLM-7B.ggmlv3.q4_0.bin that I've converted to gguf.\r\n\r\nWhen I test talk-llama, I get this in the exchanges:\r\n```\r\nGeorgi:./examples/talk-llama/speak: line 13: say: command not found\r\nmain: failed to speak\r\n```\r\nThis isn't a big deal, but a little annoying.",
    "comments_url": "https://api.github.com/repos/ggerganov/whisper.cpp/issues/1465/comments",
    "author": "hbarnard",
    "comments": [
      {
        "user": "ggerganov",
        "created_at": "2023-11-09T11:28:42Z",
        "body": "You can edit the script `./examples/talk-llama/speak` to use any TTS you'd like. You can make it empty to disable speaking completely"
      }
    ]
  },
  {
    "number": 578,
    "title": "What is the audio length in the stream?",
    "created_at": "2023-03-07T00:34:03Z",
    "closed_at": "2023-03-07T21:53:32Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/ggerganov/whisper.cpp/issues/578",
    "body": "```\r\n./stream -m ./models/ggml-base.en.bin -t 8 --step 500 --length 5000\r\n```\r\nin the --help it says\r\n>            --length N      [10000  ] audio length in milliseconds\r\n\r\nI thought is the max length of a segment?  but it is not that\r\nthe length to run the stream? (I know it isn't that)\r\nis it the time allowed to process it?\r\n",
    "comments_url": "https://api.github.com/repos/ggerganov/whisper.cpp/issues/578/comments",
    "author": "G2G2G2G",
    "comments": [
      {
        "user": "ggerganov",
        "created_at": "2023-03-07T19:35:02Z",
        "body": "It's the length of each segment.\r\nEach transcribed line by the `stream` example is a segment and it corresponds to `--length` ms of audio."
      }
    ]
  }
]