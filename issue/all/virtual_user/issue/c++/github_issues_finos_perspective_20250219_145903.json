[
  {
    "number": 1145,
    "title": "How can one control the number of TBB threads being used? ( perspective-python )",
    "created_at": "2020-07-31T15:34:49Z",
    "closed_at": "2020-08-10T04:19:52Z",
    "labels": [
      "question",
      "Python"
    ],
    "url": "https://github.com/finos/perspective/issues/1145",
    "body": "While trying out perspective-python we noticed our CPU usage skyrocketed to use almost all 36 cores on our box.\r\nProfiling one of those threads shows TBB as the top hitter\r\n  47.97%  python   libtbb.so            [.] tbb::internal::rml::private_worker::run\r\n  20.77%  python   libtbb.so            [.] tbb::internal::rml::private_server::wake_some\r\n  17.21%  python   libtbb.so            [.] tbb::internal::custom_scheduler<tbb::internal::IntelSchedulerTraits>::receive_or_steal_task\r\n...\r\n\r\nwe dont use tbb in our code and i see TBB is used in perspective.  Is there a way to control how many cores are dedicated here?",
    "comments_url": "https://api.github.com/repos/finos/perspective/issues/1145/comments",
    "author": "robambalu",
    "comments": [
      {
        "user": "timkpaine",
        "created_at": "2020-07-31T15:42:07Z",
        "body": "This is more of a question for intel, does `TBB_NUM_THREADS` env var work?"
      },
      {
        "user": "timkpaine",
        "created_at": "2020-07-31T15:48:08Z",
        "body": "alternatively we can make it a parameter and implement this:\r\n`tbb::global_control c(tbb::global_control::max_allowed_parallelism, nthreads)`\r\n\r\n"
      },
      {
        "user": "robambalu",
        "created_at": "2020-07-31T15:50:54Z",
        "body": "configuration option would be preferable to env var if thats doable"
      },
      {
        "user": "texodus",
        "created_at": "2020-08-10T04:22:22Z",
        "body": "Thanks @robambalu and @timkpaine  - I've added `set_threadpool_size()`method which allows specifying the TBB threadpool size, it will be released in `v0.5.3`."
      }
    ]
  },
  {
    "number": 1113,
    "title": "Lazy loading with perspective-python backend",
    "created_at": "2020-07-08T13:47:22Z",
    "closed_at": "2020-07-09T15:00:46Z",
    "labels": [
      "question"
    ],
    "url": "https://github.com/finos/perspective/issues/1113",
    "body": "Does exist a way to provide lazy loading of data from perspective-python backend?\r\nWhen I use remote Perspective via perspective-python and Tornado server as in example:\r\n\r\n```python\r\nfrom perspective import Table, PerspectiveManager, PerspectiveTornadoHandler\r\nimport tornado.ioloop\r\nimport tornado.web\r\n\r\n# Create an instance of PerspectiveManager, and host a Table\r\nMANAGER = PerspectiveManager()\r\n\r\nTABLE = Table(large_dataset)\r\nVIEW_2015 = TABLE.view(filter=[[\"Year\", \"==\", \"2015\"]])\r\n\r\nMANAGER.host_view(\"view_2015\", VIEW_2015)\r\n\r\napp = tornado.web.Application([\r\n    # create a websocket endpoint that the client Javascript can access\r\n    (r\"/websocket\", PerspectiveTornadoHandler, {\"manager\": MANAGER, \"check_origin\": True})\r\n])\r\n\r\n# Start the Tornado server\r\napp.listen(8888)\r\nloop = tornado.ioloop.IOLoop.current()\r\nloop.start()\r\n```\r\nand on my frontend load this VIEW:\r\n\r\n```javascript\r\nperspectiveViewer.load(websocket.open_view(\"view_2015\"))\r\n```\r\nIs there a way to make immediate render of visible rows (or some first chunk of data) and load rest data in background (or by user scroll events)?\r\n\r\nMy dataset that pushing to browser through websocket is ~135Mb, and I need to wait all this data before see any rows.",
    "comments_url": "https://api.github.com/repos/finos/perspective/issues/1113/comments",
    "author": "Yuri2b",
    "comments": [
      {
        "user": "sc1f",
        "created_at": "2020-07-08T14:27:16Z",
        "body": "For larger datasets, use `host_table` and `websocket.open_table`. The user will get whatever data they are currently seeing, i.e. whatever is rendered in the grid.\r\n\r\nWe're working on a smoother/faster API for hosted views and large datasets."
      },
      {
        "user": "Harry040",
        "created_at": "2022-03-21T11:18:52Z",
        "body": "If my server only has 1G, large_dataset is 4G, Could I  use `TABLE = Table(large_dataset)`?\r\n\r\n"
      },
      {
        "user": "Harry040",
        "created_at": "2022-03-21T11:21:50Z",
        "body": "I have large data using feather format\uff0cIt's out of memory, how to transform `Table`? @sc1f "
      }
    ]
  }
]